{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "207ad027-6513-4f7b-a8a9-64da5fe9bbce",
   "metadata": {},
   "source": [
    "# [A5] Neural Networks\n",
    "\n",
    "In this exercise, you will use PyTorch to build a couple of supervised learning models:\n",
    "* Logistic regression\n",
    "* Shallow neural network\n",
    "* Deep neural network (\"Multilayer Perceptron\")\n",
    "* Convolutional neural network\n",
    "\n",
    "Although PyTorch is a full-fledged deep learning framework with lots of components pre-built (many of them, such as different neural network layers, loss functions, and optimization algorithms in PyTorch's `.nn` submodule), you will build as much as possible from scratch in this exercise.\n",
    "\n",
    "## 1: PyTorch Basics\n",
    "\n",
    "Some of PyTorchs features are very similar to numpy. As you can see in the following code cell, you can define \"arrays\" very similar, but this time they are called [\"Tensor\"](https://en.wikipedia.org/wiki/Tensor_(machine_learning)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37bf0275-6ac5-4ad2-bbcf-3e554a9d9920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch 2.7.0+cu126\n",
      "x: tensor([[[-5.4391e-11,  3.0910e-41, -5.4394e-11,  3.0910e-41],\n",
      "         [ 8.4078e-45,  0.0000e+00, -5.4398e-11,  3.0910e-41],\n",
      "         [-5.4382e-11,  3.0910e-41, -5.4385e-11,  3.0910e-41]],\n",
      "\n",
      "        [[-5.4387e-11,  3.0910e-41, -5.4389e-11,  3.0910e-41],\n",
      "         [-5.4391e-11,  3.0910e-41, -5.4394e-11,  3.0910e-41],\n",
      "         [ 9.8091e-45,  0.0000e+00, -5.4399e-11,  3.0910e-41]]])\n",
      "x.shape: torch.Size([2, 3, 4])\n",
      "y: tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Latex\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "x = torch.Tensor(2, 3, 4)\n",
    "y = torch.zeros(3, 3)\n",
    "\n",
    "print(f\"Using torch {torch.__version__}\")\n",
    "print(f\"x: {x}\\nx.shape: {x.shape}\\ny: {y}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f91c3b42",
   "metadata": {},
   "source": [
    "### 1.1: Basic Operations\n",
    "\n",
    "It is also possible to perform operations on these tensors, often named the same as the numpy methods:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08833efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "+ tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "= tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.,  8.],\n",
      "        [ 9., 10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.ones(3, 4)\n",
    "x2 = torch.arange(3 * 4).reshape(3, 4)\n",
    "sum = x1 + x2\n",
    "\n",
    "print(f\"  {x1}\\n+ {x2}\\n= {sum}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7d09756",
   "metadata": {},
   "source": [
    "You can also do more performant in-place operations that change the original tensor by adding a ` ` _ ` ` after a method name. \n",
    "\n",
    "Note how we need to explictly convert the data type of one of the two tensors, as this conversion is not done automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f85713b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n"
     ]
    }
   ],
   "source": [
    "x2 = torch.arange(3 * 4).reshape(3, 4)\n",
    "x2.add_(x1.long())\n",
    "print(x2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82eeb994",
   "metadata": {},
   "source": [
    "For matrix multiplication, we can use the [@ operator](https://pytorch.org/docs/stable/generated/torch.bmm.html?highlight=bmm#torch.bmm) or the [matmul](https://pytorch.org/docs/stable/generated/torch.matmul.html) function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faa76f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  tensor([[1, 1, 1, 1],\n",
      "        [2, 2, 2, 2],\n",
      "        [3, 3, 3, 3]])\n",
      "@ tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n",
      "= tensor([[18, 22, 26],\n",
      "        [36, 44, 52],\n",
      "        [54, 66, 78]])\n",
      "= tensor([[18, 22, 26],\n",
      "        [36, 44, 52],\n",
      "        [54, 66, 78]])\n"
     ]
    }
   ],
   "source": [
    "x3 = torch.tile(torch.arange(1, 4), (4, 1)).T\n",
    "x4 = torch.arange(3 * 4).reshape(4, 3)\n",
    "mult = x3 @ x4\n",
    "print(f\"  {x3}\\n@ {x4}\\n= {mult}\\n= {torch.matmul(x3, x4)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f474422b",
   "metadata": {},
   "source": [
    "### 1.2: Gradients\n",
    "\n",
    "Another very important feature of PyTorch is the possibilty to calculate gradients (multiple values) and the derivative (single value) of functions we define. \n",
    "\n",
    "This is very useful when performing gradient descent for the backpropagation algorithm (for weight update in neural networks).\n",
    "\n",
    "All tensors need to be of dtype float and need to have \"requires_grad\" enabled.\n",
    "\n",
    "Let's do a simple example to understand the math behind this. You remember from school that the derivation of $a\\cdot x^n $ is $ n\\cdot a\\cdot x^{n-1}$, so let's use\n",
    "\n",
    "$$ f(x) = 4x^2 $$\n",
    "$$ f'(x)=2 \\cdot  4 \\cdot  x^1 = 8x$$ \n",
    "\n",
    "Given e.g. $x=5$ we can now easily calculate by hand: \n",
    "$$f(5)=4\\cdot 5^2=100$$\n",
    "$$f'(5)=8\\cdot 5=40$$\n",
    "\n",
    "With PyTorch, we can calculate $f'(5)$  without even specifying the $f'(x)$ function first:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31958624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ f(5.0)=100.0 \\\\ f'(5.0)=40.0 $$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x5 = torch.tensor(5.0, requires_grad=True)\n",
    "fx5 = 4 * x5**2\n",
    "fx5.backward()\n",
    "\n",
    "display(Latex(f\"$$ f({x5})={ fx5 } \\\\\\\\ f'({x5})={ x5.grad } $$\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c60d20c8",
   "metadata": {},
   "source": [
    "Partial derivatives can be calculated very similar:\n",
    "$$ f(u, v) = 2u^4 + 3v^3 + 2uv $$\n",
    "\n",
    "$$f'_u({u}, {v})=\\frac{\\partial f(u, v)}{\\partial u} = 8u^3 + 2v$$\n",
    "$$f'_v({u}, {v})=\\frac{\\partial f(u, v)}{\\partial v} = 9v^2 + 2u$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6b2cf00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ f(3.0,4.0)=378.0       \\\\   f'_u(3.0,4.0)=224.0 \\\\   f'_v(3.0,4.0)=150.0 $$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u = torch.tensor(3.0, requires_grad=True)\n",
    "v = torch.tensor(4.0, requires_grad=True)\n",
    "fuv = 2 * u**4 + 3 * v**3 + 2 * u * v\n",
    "fuv.backward()\n",
    "\n",
    "display(\n",
    "    Latex(\n",
    "        f\"$$ f({u},{v})={ fuv }       \\\\\\\\\"\n",
    "        f\"   f'_u({u},{v})={ u.grad } \\\\\\\\\"\n",
    "        f\"   f'_v({u},{v})={ v.grad } $$\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "612a6acb",
   "metadata": {},
   "source": [
    "We can apply our function to multiple values at once using non-scalar tensors.\n",
    "\n",
    "Just like our good old graphical calculator did it back in the day, we can now calculate the derivation function values for multiple values of x.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe0893a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_derivation(x, y, x_label=\"X\"):\n",
    "    plt.plot(x.detach().numpy(), y.detach().numpy(), label=f\"$f({x_label})$\")\n",
    "    plt.plot(x.detach().numpy(), x.grad.detach().numpy(), label=f\"$f'({x_label})$\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(x_label)\n",
    "    plt.gca().spines[\"left\"].set_position(\"zero\")\n",
    "    plt.gca().spines[\"bottom\"].set_position(\"zero\")\n",
    "    plt.gca().spines[\"right\"].set_color(\"none\")\n",
    "    plt.gca().spines[\"top\"].set_color(\"none\")\n",
    "    plt.grid()\n",
    "\n",
    "    return plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24da230d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGLCAYAAABa0JF/AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAb69JREFUeJzt3Xd4VFX6wPHvTDLpvSeQAoReQuihWagCCsjaFhCxK6Kgoj9dbNiwu6usbRFcUbAsimKkqHRCSSD0FkgI6YQ00icz9/fHJBNCKAGS3JnJ+3keHs3MuXfekzuZ8865p2gURVEQQgghRIulVTsAIYQQQqhLkgEhhBCihZNkQAghhGjhJBkQQgghWjhJBoQQQogWTpIBIYQQooWTZEAIIYRo4SQZEEIIIVo4SQaEaOEURaGoqAhZf0yIlkv1ZECv17NixQr0er3aoTQJqZ/1s/U65uXl4enpSV5entqhNAlbv35g+3WU+jU91ZMBIYQQQqhLkgEhhBCihZNkQAghhGjhJBkQQgghWjhJBoQQQogWTpIBIYQQooWTZEAIIYRo4SQZEEIIIVo4SQaEEEKIFk6SASGEEKKFk2RACCGEaOEkGRDCQsyfPx+NRsOsWbPMj5WXlzNjxgx8fX1xc3Nj0qRJZGdn1zkuNTWVsWPH4uLiQkBAAHPmzKGqqqqZoxdCWDNJBoSwADt37uSzzz6jR48edR6fPXs2v/76Kz/88AMbNmwgIyODW2+91fy8wWBg7NixVFZWsnXrVr766isWL17Miy++2NxVEEJYMUkGhFBZcXExkydP5osvvsDb29v8eGFhIQsXLuT999/nxhtvpHfv3ixatIitW7eybds2ANasWcPBgwdZsmQJPXv25KabbuLVV19lwYIFVFZWqlUlIYSVUTUZOJBRyP/9tJ+kIjWjEEJdM2bMYOzYsQwfPrzO4wkJCej1+jqPd+rUibCwMOLi4gCIi4uje/fuBAYGmsuMGjWKoqIiDhw40DwVEEJck+3JeXybpOVgpnqNoX1DCzbFPstL4lL4364MevhoecSG96k+97+2xtbrB01bx++++46EhATi4uLQ6/UoioLRaESv15OWloaDgwOurq51XjsgIID09HT0ej0ZGRkEBATUed7HxweAtLQ0unXrVu81KyoqqKioMP+cl5dnrp8tXkd5j1o/W6/f4q0pbD+tZemOVLoEezT6+XU63WXLNDgZiI2NvaZgLiS80hTCvjwN361ci49jo7+ExVi7dq3aITQpW68fNH4dT58+zdNPP80rr7zCX3/9BcCZM2dITk4mNjaWxMREjEZjvb+9wsJCTpw4QWxsLKmpqZw+fbpOmZqGfufOnRiNxnqvu3TpUr777rt6j69btw4XF5fGrKJFkfeo9bPF+uVVwJ+H7QANbfSpxMamNvprjB8//rJlNIqiKA05WVNlZFMW7mB7SgEPDArjmdGdmuQ11KTX61m7di0jRoxoUHZmbWy9ftB0dVyxYgW33XYbdnZ25scMBgMajQatVstvv/3G6NGjycnJwcvLy1wmMjKSmTNn8sQTT/Dyyy+zcuVK4uPjzc8nJyfTsWNHtm/fTnR0dL3XvVDPQIcOHcjMzMTX17fR6mcp5D1q/Wy5fu+uOcZnm5Jp72FkxaxhTVK/Ru0ZaKoLcHdMONtTCvhxdyZPje6Ck87u8gdZIZ1OZ3Nv4nPZev2g8es4atQo9u3bV+ex6dOn06lTJ5599llCQ0PR6XRs3LiRSZMmAXDkyBFSU1MZPHgwOp2OwYMHM3/+fPLz8wkICABg/fr1eHh4EBUVdcF4dTodbm5uTV4/S2Pr9QPbr6Ot1a9cb+D7hDQAhgYrqtavwclAU7mxoz9eDgr5pXpW7s3kb71bqx2SEM3C3d293j19V1dXfH19zY/fd999PPnkk/j4+ODh4cHMmTOJiYlhwIABAIwcOZIuXbowdepU3n77bbKyspg7dy4zZszA0dGG77sJYQN+3ZNBfqmeEE8nunoXqxqL6lML7e20DA4y3df8amsKDbxrIUSL8MEHHzBu3DgmTZrE0KFDCQoKYvny5ebn7ezsWLlyJXZ2dsTExDBlyhTuvvtu5s2bp2LUQojLURSFr+JSAPh7v1DsNOrGo3rPAEBMgMKaDC370gvZfaqAXmHelz9ICBu0fv36Oj87OTmxYMECFixYcNFjwsPDm2SArxCi6exKLWB/ehEO9lpu692KbRsOqRqP6j0DAG46GNc9CDD1DgghhBC2rKatGx8Vgo+rg7rBYCHJAMDU/mEAxO7LJOdsucrRCCGEEE0jp6ic2H2ZAEwbGKFuMNUsJhno1sqD6DAv9AaFpdtPqR2OEEII0SS+3ZFKlVGhV5gX3Vp5qh0OYEHJAMA91RnSN9tPojfUXyxFCCGEsGaVVUa+2W5aWMhSegXAwpKBm7oF4+fmSM7ZClbtz1I7HCGEEKJRrTqQxemzFfi7O3JTt2C1wzGzqGTAwV7L36vHDvy3esqFEEIIYSv+Wz1w8O/9wnCwt5wm2HIiqTa5fxj2Wg07U/I5kFGodjhCCCFEo9ifXkj8yXzstRrzF19LYXHJQKCHE6O7maYZ/nfrSZWjEUIIIRpHTY/3Td2DCfRwUjeY81hcMgC1gyp+Tkwnv6RS3WCEEEKIa5RfUsmKxAwApsWEqxxNfRaZDPQJ96ZLsAcVVUa+j5dphkIIIazbd/GnqKgy0jXEg97hlrfKrkUmAxqNhmkDTZnT19tOYjDKfgVCCCGsk8Go8HWc6bb3tJgINBqVNyK4AItMBgDG92yFl4uOtPwy/jqco3Y4QgghxFX581A26QVleLnouKVniNrhXJDFJgNOOjvu6BMKyDRDIYQQ1uu/1b0Cd/QNxUlnp3I0F2axyQDAlAHhaDSw6VguSTnq7vUshBBCXKmknLNsTspFq4Ep/S1v4GANi04GQn1cGNYpEICvpXdACCGElanpFRjWOZBQHxeVo7k4i04GoHa/gh8T0jhbrlc3GCGEEKKBzpbr+V9CGlDbllkqi08GBkX60s7flZJKA8t3pasdjhBCCNEg/0tIo6TSQGSAGwPb+aodziVZfDJgmmYYAcBXcSkYZZqhEEIIC2c0KuZbBNNiwi1yOuG5LD4ZALi1V2vcHO05cbqELcdz1Q5HCCGEuKTNSbmcyC3BzdGeib1aqx3OZVlFMuDmaM/fept+mV9V7/gkhBBCWKqatupvvU1fZi2dVSQDAFOr13L+83AOp/JKVY5GCCGEuLDUM6X8dcS0WN7dFrgPwYVYTTLQzt+NIe39UBTTEsVCCCGEJfp6WwqKAkM7+NPW303tcBrEapIBMK3pDPDdzlOUVRrUDUYIIYQ4T1mlge92mjbYs8TdCS/GqpKBGzoFEOrjTGGZnhWJMs1QCCGEZfk5MZ2i8irCfFy4vmOA2uE0mFUlA3ZaDVMHmDKtr+JOoigyzVAIIYRlUBTFPHBw6oBw7LSWPZ3wXFaVDADc3icUJ52WQ5lF7EzJVzscIYQQAoAdyXkczjqLk07L7dUb7VkLq0sGvFwcmNCzFWBahEgIIYSwBDWLDE2MboWni07laK6M1SUDAHdXDyRctT+LrMJydYMRQgjR4mUWlrHqQBZQ20ZZE6tMBrqEeNAvwgeDUeHb7TLNUAghhLq+3Z6KwajQr40PnYM91A7nilllMgCY9yv4dkcqFVUyzVAIIYQ6KqoMLN2RClj+7oQXY7XJwMiugQR5OJFbXMnv+7LUDkcIIUQLFbsvk9ziSoI8nBjRJVDtcK6K1SYDOjstk/uHAbBY9isQQgihksVbTberpwwIQ2dnnc2qdUZd7c5+YTjYaUk8VcCeUwVqhyOEEKKFqWl/HOy03NkvTO1wrppVJwP+7o6M7REMyDRDIYQQze+/1T3T43oE4+fmqG4w18CqkwGo3RFq5Z5MzhRXqByNEEKIliK3uIKVezMBuNtKBw7WsPpkIDrMm6jWnlQajCyr3hxCCCGEaGrLdqRSaTASFepFz1AvtcO5JlafDEDtAg9Ltp2kymBUNxghhBA2r8pgZMk203RCa9qd8GJsIhkY2yMYX1cHMgvLWXswW+1whBBC2Lg1B7PJKirH19XBPHbNmtlEMuCks+POfqZNIWQgoRBCiKZWszvhXf3CcLS3UzeYRmATyQDA5P6m7SK3ncjjcFaR2uEIIYSwUYcyi9ienIedVsPkAdY7nfBcNpMMhHg5M7J65aeanaOEEEKIxlbTxozqGkiwp7PK0TQOm0kGoHa/gp92pVNYqlc3GCGEEDansFTPz7vTAZhmhbsTXoxNJQP92/jQMdCdMr2BHxJkmqEQQojG9UPCKcr0BjoFudOvjY/a4TQam0oGNBqNuXfg620nMRoVdQMSQghhMwxGxXyLYNrACDQajcoRNR6bSgYAJkSH4OFkz8kzpWw4elrtcIQQQtiIDUdzSM0rxcPJnvE9Q9QOp1HZXDLg4mDP7X1M0wxlN0MhhBCNpWZ3wjv6huLiYK9yNI3L5pIBgKkx4Wg0sOHoaZJyzqodjhBCCCuXlHOWjUdPo9HA1AERaofT6GwyGQj3dWVEZ9M0w0/Wn1A5GiGEENbu3+uPAzCySyBhvi4qR9P4bDIZAHj0hkgAViSmk15QpnI0QgghrFVafim/JGYA8Oj1kSpH0zRsNhnoGerFwHa+VBkVvtgovQNCCCGuzhcbT1BlVBgU6UuUle9OeDE2mwxAbQa3bGcqucUVKkcjhBDC2uQWV7Bsp2ndGlvtFQAbTwYGRfoS1dqTcr2RRVuS1Q5HCCGElflyczIVVUaiqnubbZVNJwMajYZHqjO5/8ad5Gy5LFEshBCiYYrK9XxdvcjQo9e3s6lFhs5n08kAmEZ+Rga4cba8iiXbUtUORwghhJVYsu0kZyuqaB/gZp6hZqtsPhnQajU8fF07ABZuTqZcb1A5IiGEEJauXG/gy82m28sPX9cOrdZ2ewWgBSQDAON7htDKy5nc4gp+iJcNjIQQQlza9/GnyC2upJWXM7fY2NLDF9IikgGdnZYHh7YF4LONJ6gyGFWOSAghhKXSG4x8tsE0Jf2h69qis7P9ptL2a1jt9j6h+Lo6kJZfxq97M9QORwghhIX6dU8G6QVl+Lk5mPe6sXUtJhlwdrDj3sFtAPhk/XHZ3lgIIUQ9RqPCJ9VLD08f1AYnnZ3KETWPFpMMAEwZEI67oz1Hs4v583CO2uGIFu6TTz6hR48eeHh44OHhQUxMDL///rv5+fLycmbMmIGvry9ubm5MmjSJ7OzsOudITU1l7NixuLi4EBAQwJw5c6iqqmruqghhM/44lM2xnGLcHe2ZGhOudjjNpkUlA57OOqZUX9wF65JQFOkdEOpp3bo18+fPJyEhgfj4eG688UbGjx/PgQMHAJg9eza//vorP/zwAxs2bCAjI4Nbb73VfLzBYGDs2LFUVlaydetWvvrqKxYvXsyLL76oVpWEsGqKorCguldgakw4Hk46lSNqPi0qGQC4d1AbHO21JJ4qIO7EGbXDES3YzTffzJgxY2jfvj0dOnTg9ddfx83NjW3btlFYWMjChQt5//33ufHGG+nduzeLFi1i69atbNu2DYA1a9Zw8OBBlixZQs+ePbnpppt49dVXWbBgAZWVlSrXTgjrE3f8DHtOFeBorzXfVm4pWlwy4O/uaB4QUnNfSAi1GQwGli1bRklJCTExMSQkJKDX6xk+fLi5TKdOnQgLCyMuLg6AuLg4unfvTmBg7WIoo0aNoqioyNy7IIRouJptiu/oG4qfm6PK0TQv+4YW1OubZinfmvM21fkv5N6BYXy7I5VNx3LZlZJL91aeTfZaatSvOdl6/aBp67hv3z6GDh1KeXk5bm5u/PDDD7Rv3574+HgcHBxwdXWt87oBAQGkp6ej1+vJyMggICCgzvM+Pj4ApKWl0a1btwu+ZkVFBRUVtRt35eXlmetni9dR3qPWrznqtzetkM1JudhrNdw7MKxZf5dNXT+d7vK3OzRKA2+cr1ix4poDsiRLjmnZmaulh4+R+zrKugNCHXq9ntzcXEpKSoiLi2Pt2rW8/vrrnDhxgo8++ogff/yxTvk5c+bQrVs3pk2bxoIFCzh9+jQvv/yy+fmKigruuOMOXnjhBXr37n3B11y6dCnfffddvce//fZbXFxcGrV+QliLhUe07M3T0tffyJRI22oTxo8ff9kyDU4GmrJnYO3atYwYMaJB2UtjOZZdzJiPt6LRwO8zB9HO37VJXket+jUXW68fNG8dR48eTdu2bbntttsYNWoUOTk5eHl5mZ+PjIxk5syZPPHEE7z88susXLmS+Ph48/PJycl07NiR7du3Ex0dfcHXuFDPQIcOHcjMzMTX1/Z2ZZP3qPVr6vol5RRz00dbAYidOZD2AW6N/hqX0tT1a8g5G3yboKnfYDqdrlnfxF1aezOiSyBrD2bzny0nefe2qCZ9veauX3Oz9fpB89RRURT0ej39+/dHp9OxceNGJk2aBMCRI0dITU1l8ODB6HQ6Bg8ezPz588nPzycgIACA9evX4+HhQVRU1EVj1el0uLnV/7Cz9Wto6/UD269jU9XvP1tMm9iN7BJIl1bejX7+hlLz+jU4GbBFj17fjrUHs/l5dzqzR3SglZez2iGJFuS5557jpptuIiwsjLNnz/Ltt9+yfv16Vq9ejaenJ/fddx9PPvkkPj4+eHh4MHPmTGJiYhgwYAAAI0eOpEuXLkydOpW3336brKws5s6dy4wZM3B0bFmDn4S4Wmn5paxITAfg0RsiVY5GPS1uNsG5osO8GdjOlyqjwhcbT6gdjmhhcnJyuPvuu+nYsSPDhg1j586drF69mhEjRgDwwQcfMG7cOCZNmsTQoUMJCgpi+fLl5uPt7OxYuXIldnZ2xMTEMGXKFO6++27mzZunVpWEsDpfbDxBlVFhUKQvPUO91A5HNS26ZwDg0esj2Xr8DMt2pjLzxkh8W9h0EqGehQsXXvJ5JycnFixYwIIFCy5aJjw8nNjY2MYOTYgWIbe4gmU7TTvZPnp9y+0VgBbeMwAwKNKXHq09KdcbWbQlRe1whBBCNJNFW5KpqDIS1dqTge1sb/DslWjxyYBGozFnhF/FpXC23Dbn6QohhKhVVK7nv3EnAdNYAY1Go3JE6mrxyQCYRpBGBrhxtryKJdtS1Q5HCCFEE1uy7SRny6toH+DGiM6Blz/AxkkyAGi1Gh6+rh0ACzcnU643qByREEKIplKuN/Dl5mQAHr6uHVpty+4VAEkGzMb3DKGVlzO5xRX8kJCmdjhCCCGayA/xp8gtrqSVlzO39AxROxyLIMlANZ2dlgeHtgXgsw3HqTLY1nKUQgghQG8w8ln1VPKHrmuLzk6aQZBkoI7b+4Ti6+pAWn4Zv+7NUDscIYQQjezXPRmk5Zfh5+Zg3sFWSDJQh7ODnXkP60/WH8dobNC2DUIIIayA0aiYt66fPqgNTjo7lSOyHJIMnGfKgHDcHO05ml3Mn4dz1A5HCCFEI/njUDbHcopxd7Rnaky42uFYFEkGzuPprDO/SRasS6KBmzoKIYSwYIqisKC6V2BqTDgeTra7odPVkGTgAu4d1AZHey2JpwqIO3FG7XCEEEJco7jjZ9hzqgBHe635drCoJcnABfi7O5oHltTcXxJCCGG9/l39WX5H31D8ZA+aeiQZuIgHh7bFTqth07Fc9qUVqh2OEEKIq7Q3rYDNSbnYaTU8MKSt2uFYJEkGLiLUx4XxUabFKP69PknlaIQQQlytf68z9QqM7xlCqI+LytFYJkkGLuHh601LFK86kEVSTrHK0QghhLhSSTlnWX0wC4BHqpedF/VJMnAJHQLdGdElEEWBTzfI2AEhhLA2n6w/gaKYNqRrH+iudjgWS5KBy3i0unfg593ppBeUqRyNEEKIhkovKGNFYjpg2qZYXJwkA5cRHebNwHa+VBkVvqhez1oIIYTl+2LjCaqMCoMifekZ6qV2OBZNkoEGePR6U0a5bGcqZ4orVI5GCCHE5eQWV7BsZypQ+xkuLk6SgQYYFOlLj9aelOuNLNqSonY4QgghLmPRlmTK9UaiWnsysJ2v2uFYPEkGGkCj0ZjHDnwVl8LZcr3KEQkhhLiYs+V6/ht3EoBHro9Eo9GoHJHlk2SggUZ2CaKdvytny6v4Znuq2uEIIYS4iCXbUjlbXkVkgBsjuwSqHY5VkGSggbRaDY9U33f6z6ZkyvUGlSMSQghxvnK9gYWbkwHTugJarfQKNIQkA1dgfM8QWnk5k1tcwQ8JaWqHI4QQ4jw/xJ8it7iCVl7O3NIzRO1wrIYkA1dAZ6flwaGmda0X/JUkvQNCCGFByioNfLzOtHz8g0PborOTJq6h5Dd1he7sF0orL2eyispZvDVF7XCEEEJUW7w1hewiU6/Anf1C1Q7HqkgycIUc7e14ckQHAP69LonCUplZIIQQaisoreST6k3lnhrZAUd7O5Ujsi6SDFyFCdGt6BjoTlF5Ff/eIDsaCiGE2j5Zf5yi8io6BbkzvmcrtcOxOpIMXAU7rYZnb+oIwOItKWQWyp4FQgihloyCMhZV37Z9dnQn7GQGwRWTZOAq3dAxgH4RPlRUGflw7TG1wxFCiBbrwz+OUlllpF8bH67v6K92OFZJkoGrpNFoePamTgD8kHCKpJyzKkckhBAtz7Hss/xYPdX7/27qJKsNXiVJBq5B73BvRnYJxKjA26uOqB2OEEK0OG+vPoJRgVFdA+kV5q12OFZLkoFr9Mzojmg1sOZgNgkn89UORwghWoyEk3msPZiNVgNzRnVUOxyrJsnANYoMcOe23qb5rG/9fhhFUVSOSAghbJ+iKMz//TAAt/cJJTLAXeWIrJskA41g1oj2ONpr2ZGSx7ojOWqHI4QQNu+vwznsTMnH0V7LrOEd1A7H6kky0AiCPZ25Z1AEYBo7YDBK74AQQjQVg1Exj9OaPqgNQZ5OKkdk/SQZaCSPXheJh5M9h7PO8vPudLXDEUIIm/XT7nSOZJ/Fw8meR65rp3Y4NkGSgUbi6aIzb3H8/tqjsomREEI0gXK9gQ/WHgXg0Rsi8XTRqRyRbZBkoBFNHxRBkIcT6QVlLNl2Uu1whBDC5izZdpL0gjKCPJy4Z2CE2uHYDEkGGpGTzo5Zw9sDsGBdEkXlsomREEI0lrPlevMWxbNHtMdJJ5sRNRZJBhrZ33q3pp2/K/mlej7fcELtcIQQwmZ8sSmFglI9kQFuTOrVWu1wbIokA43M3k7LnFGmZYoXbk4m52yFyhEJIYT1K6yERXGm269zRnXE3k6ar8Ykv80mMKprINFhXpTpDXy87rja4QghhNVblaalXG+kV5gXI7sEqh2OzZFkoAloNBqeHW3qHfg+IZ0c2eFYCCGuWnJuCduyTRsQPTtaNiNqCpIMNJEBbX25oaM/BqNC7Cn5NQshxNX64I8kjGi4voMf/dv6qh2OTZJWqgk9M7oTGg3sPqNlX3qh2uEIIYTV2XOqgN8PZKNB4ekR7dUOx2ZJMtCEOgd7ML5HMADvrDkmmxgJIcQVOHczoj7+Ch2DZDOipiLJQBN7YlgkdhqFuBN5bDqWq3Y4QghhNTYeyyXuxBl0dhrGhBrVDsemSTLQxFp7OzM4yNQj8NaqwxhlEyMhhLgso1HhrepegSn9w/BxVDkgGyfJQDMY2cqIq6MdBzKK+HVvhtrhCCGExft1bwYHM4twd7Tn4aFt1A7H5kky0AzcdPDAYNOb+b01R6msku4uIYS4mMoqI++tMW1G9NB1bfFxdVA5ItsnyUAzmT4wDD83R1LzSlm2M1XtcIQQwmIt3ZFKal4p/u6O3DtYegWagyQDzcTFwZ4nqjcx+tefxyipqFI5IiGEsDzFFVX8689jADwxrD0uDvYqR9QySDLQjO7sG0qErwu5xZX8Z1Oy2uEIIYTF+c+mE5wpqaSNnyt39A1VO5wWQ5KBZqSz0/LUyI4AfL7xOLnFsomREELUyC2u4IuNpt1enxrZAZ1sRtRs5DfdzMZ2D6Z7K09KKg18/FeS2uEIIYTF+PivJEoqDfRo7cmYbsFqh9OiSDLQzLTa2k2Mvtl+ktQzpSpHJIQQ6ks9U8o3201bFD87uhNarWxG1JwkGVDB4PZ+DGnvh96g8P7aI2qHI4QQqntv7RH0BoUh7f0YFOmndjgtjiQDKqnpHfg5MYMDGbKJkRCi5dqfXsiKRNOCbDWfjaJ5STKgkm6tPBlXvYnR26ukd6AlevPNN+nbty/u7u4EBAQwYcIEjhyp+14oLy9nxowZ+Pr64ubmxqRJk8jOzq5TJjU1lbFjx+Li4kJAQABz5syhqkqmrgrr8fZq0/v+5qgQurXyVDmalkmSARU9PbIj9loNG46eZutx2cSopdmwYQMzZsxg27ZtrF27Fr1ez8iRIykpKTGXmT17Nr/++is//PADGzZsICMjg1tvvdX8vMFgYOzYsVRWVrJ161a++uorFi9ezIsvvqhGlYS4YluTctl49DT2Wg1Pj+ygdjgtliQDKorwc+WufmEAvLXqiGxx3MKsWrWKe+65h65duxIVFcXixYtJTU0lISEBgMLCQhYuXMj777/PjTfeSO/evVm0aBFbt25l27ZtAKxZs4aDBw+yZMkSevbsyU033cSrr77KggULqKysVLN6QlyWoii8tcq0GdHf+4cR7uuqckQtlyQDKps5LBIXBzv2nCpg1f4stcMRKiosNI0d8fHxASAhIQG9Xs/w4cPNZTp16kRYWBhxcXEAxMXF0b17dwIDA81lRo0aRVFREQcOHGjG6IW4cr/vz2JPWiEuDnbMvLG92uG0aA1e51Gv1zdJADXnbarzq+1y9fN2smP6wHAWrD/B26sOc317H+ytaKENW79+0Dx1NBqNPPHEEwwcOJCOHTui1+tJS0vDwcEBV1fXOq8dEBBAeno6er2ejIwMAgIC6jxfk0ykpaXRrVu3eq9VUVFBRUXtgld5eXmAqX62eB3lPWqZ9AYjb1f3Ctw7MBwvJ+1F47fG+l2Jpq6fTqe7bJkGJwOxsbHXFMzlrF27tknPr7ZL1S+sClzt7Ug+U8rL/13NwEDru11g69cPmraOn376KQkJCbz55pvmv7XExESMRmO9v73CwkJOnDhBbGwsqampnD59uk6ZmoZ+586dGI31d8hcunQp3333Xb3H161bh4uLS2NWy6LIe9SybMnWkHLGDld7hdCSo8TGHr3sMdZUv6vRVPUbP378ZctolAbeqG7KnoG1a9cyYsSIBmUv1qah9Vscd5LXY48Q4O7I2lmDrGZzDlu/ftD0dXziiSf49ddf+fPPP2nTpnaHtnXr1jFq1ChycnLw8vIyPx4ZGcnMmTN54oknePnll1m5ciXx8fHm55OTk+nYsSPbt28nOjq63utdqGegQ4cOZGZm4uvr2+j1U5u8Ry1PaWUVwz/YzOniSuaO6ci0mPBLlre2+l2ppq5fo/YMNPUF0Ol0NnmRa1yufncPbMNXcamk5ZfxycaT/N9N1jXX1tavHzR+HRVFYebMmaxYsYL169fTvn3de6b9+/dHp9OxceNGJk2aBMCRI0dITU1l8ODB6HQ6Bg8ezPz588nPzycgIACA9evX4+HhQVRU1AXj1el0uLm5NXn9LI2t1w+sp47//iOJ08WVtPZ2ZurANujs7Rp0nLXU72qpWT/ruTlt4xzt7Xjp5q6AadeuI1lnVY5INLUZM2awZMkSvv32W9zd3cnKyiIrK4uysjIAPD09ue+++3jyySdZt24dCQkJTJ8+nZiYGAYMGADAyJEj6dKlC1OnTmXPnj2sXr2auXPnMmPGDBwdHdWsnhAXdDiriIXVu7a+fHNXHBuYCIimJcmABRnRJZCRXQKpMir846d9GI3WN3ZANNwnn3xCYWEh119/PcHBweZ/597P/+CDDxg3bhyTJk1i6NChBAUFsXz5cvPzdnZ2rFy5Ejs7O2JiYpgyZQp333038+bNU6NKQlyS0ajwj5/2U2VUGNU1kOFdAi9/kGgW1nFjugV5+ZaubE7KJf5kPt/Hn+LO6nUIhO1pyHAdJycnFixYwIIFCy5aJjw8vMkH+ArRGL6LP0XCyXxcHWp7QoVlkJ4BCxPi5cyTI0yrcL35+2HOFFdc5gghhLB8ucUVzP/dNJVw9ogOhHg5qxyROJckAxbonoERdA72oLBMz+uxh9QORwghrtkbvx2isExPl2AP7hkYoXY44jySDFggezstb0zshkYDy3ely74FQgirtjUpl+W709Fo4PWJ3axqYbWWQq6IhYoO8+bv1eMF5v68n4oqg8oRCSHElauoMjD35/0ATO4fRnSYt8oRiQuRZMCCPTO6E35ujpw4XcJnG06oHY4QQlyxT9ef4ERuCf7ujswZZV3rp7QkkgxYME9nHS+M6wzAx+uSSMktucwRQghhOZJzS1iwPgmAF8Z1wdPZdhcMsnaSDFi4W6JCGBzpR2WVkRdW7JdtjoUQVkFRFF74eT+VVUaGtPfj5h7BaockLkGSAQun0Wh4dUI3HOy1bDqWy697M9UOSQghLuuXPRlsTsrFwV7Lq+O7odFo1A5JXIIkA1agjZ8rM66PBGDerwcpLLPNbTyFELahsEzPqytN06IfuyGSCD9XlSMSlyPJgJV4+Pq2tPV3Jbe4gndXH1E7HCGEuKh3Vh8mt7iCtv6uPHRdW7XDEQ0gyYCVcLS347UJ3QBYsv0kiacK1A1ICCEuYHdqPt9sTwXg9QndZSMiKyHJgBUZ2M6PW6NboSjw/PJ9VBmMaockhBBmVQYjz/+0H0WBW3u1Iqadr9ohiQaSZMDKPD+2M57OOg5mFrF4a4ra4QghhNnirSkcyizC01nHP8Z0VjsccQUkGbAyfm6O/N9NpoU73l97lIyCMpUjEkIIyCgo4/21RwF47qZO+Lo5qhyRuBKSDFihO/qE0jvcm9JKA6/8ekDtcIQQgpd/OUBppYE+4d7c3idU7XDEFZJkwApptRrTZh9aDasPZPPHwWy1QxJCtGBrD2az5mA29loNr0/sjlYrawpYG0kGrFSnIA/uG9IGgJd+OUBpZZXKEQkhWqLSyipe/sXUQ3n/kLZ0DHJXOSJxNSQZsGJPDGtPKy9n0gvK+Oefx9QORwjRAv3zj2OkF5TR2tuZJ4a1VzsccZUkGbBiLg72zBvfFYCFm5I5nFWkckRCiJbkUGYR/9mcDMC88V1xdpA1BayVJANWbljnQEZ3DaLKqPD88n0YjbKRkRCi6RmNCs//tA+DUeGmbkHc2ClQ7ZDENZBkwAa8dEsXXB3s2JVawHfxp9QORwjRAizbeYrdqQW4Otjx4s1d1A5HXCNJBmxAsKczT47sCMD8301rggshRFM5fbaC+b+bNiJ6amRHgj2dVY5IXCtJBmzEtJhwuoZ4UFim543fDqkdjhDChr0Re4ii8iq6tfLg7phwtcMRjUCSARthb6fl9Ynd0Whg+e50tiblqh2SEMIGbUnK5afd6Wg0po2I7O2kGbEFchVtSM9QL6YOMGXpc3/eT0WVQeWIhBC2pFxvYO7P+wG4e0A4UaFe6gYkGo0kAzbm6VEd8Xd35ERuCZ+uP6F2OEIIG/LphuMk55YQ4O7IU6M6qh2OaESSDNgYDycdL44zjexdsD6J5NwSlSMSQtiC5NwS/r3uOAAv3twFDyedyhGJxiTJgA0a1yOYIe39qKwy8sLP+1EUWXtACHH1FEVh7s/7qDQYGdrBn7Hdg9UOSTQySQZskEaj4bUJ3XC017I5KZdf9mSoHZIQwor9sieDLUlncLTX8tr4bmg0shGRrZFkwEaF+7oy88ZIAF5deYjCMr3KEQkhrFFhqZ5XVx4E4PFh7QnzdVE5ItEUJBmwYQ8MbUs7f1dyiyt4Z/VhtcMRQliht1cfJre4ksgANx4Y0lbtcEQTkWTAhjna2/H6xO4AfLM9ld2p+SpHJISwJrtS8/l2RyoAr0/ohoO9NBm2Sq6sjRvQ1pdJvVqjKDDnx72UVcraA0KIyyutrOKZH/eiKPC33q3p39ZX7ZBEE5JkoAX4x9jOBLg7kpRTzLyVB9QORwhhBeb9epCknGIC3B15fkxntcMRTUySgRbAx9WBD+/oiUYDS3ecYuVemV0ghLi4X/dksGznKTQa+PDOnvi4Oqgdkmhikgy0EAMj/ZhxvWl2wXP/28epvFKVIxJCWKJTeaU8v3wfAI/dEMnAdn4qRySagyQDLcis4e3pHe7N2YoqZi7djd5gVDskIYQF0RuMPLZ0N2crqugT7s0Tw9qrHZJoJpIMtCD2dlr+eWdPPJzsSTxVwHtrjqodkhDCgry75gh7ThXg4WTPP++Klh0JWxC50i1Ma28X3v5bD8C06cimY6dVjkgIYQk2Hj3NZxtMm5u9/bcoWnk5qxyRaE6SDLRAo7sFM7l/GACzv9vD6bMVKkckhFBTztlynvw+EYApA8IY3S1I3YBEs5NkoIV6YVwXOga6k1tcwZPfJ2I0ymZGQrRERqPCU9/vIbe4kk5B7swd20XtkIQKJBlooZx0dnz892icdFo2Hcvli00n1A5JCKGCzzedYNOxXJx02urPBDu1QxIqkGSgBWsf6M7LN3cF4J3VR0g8VaBuQEKIZrU7NZ93Vx8B4JVbuhIZ4K5yREItkgy0cHf0DWVsj2CqjAozl+6iqFx2NxSiJSgq1zNz6W6qjArjegRze59QtUMSKpJkoIXTaDS8eWt3Wns7cyqvjOeX70NRZPyAELZMURSeW76PtPwyQn2ceePW7mg0GrXDEiqSZEDg4aTjX3dFY6/VsHJvJt/Hn1I7JCFEE/pu5yl+25uJvVbDv+6MxsNJp3ZIQmWSDAgAeoV589TIjgC89MsBknLOqhyREKIpHMs+y8u/mjYse3pUR6LDvFWOSFgCSQaE2UND2zKkvR/leiOPfbubcr1sdyyELSnXG5i5dDfleiND2vvx4JC2aockLIQkA8JMq9Xw3u1R+Lk5cDjrLK//dkjtkIQQjei13w5yOOssfm6OvH97T7RaGScgTCQZEHUEuDvx/u09Afh620lW7c9SNyAhRKNYtT+TJdtSAXj/9ij83R1VjkhYEkkGRD1DO/jz0HWm7sNnftxDekGZyhEJIa5FWn4pz/y4F4CHr2vH0A7+KkckLI0kA+KCnh7ZkahQL4rKq3hi6W6qZLtjIaxSlcHIrGWJFJVX0TPUi6dGdlA7JGGBJBkQF6Sz0/LRndG4O9oTfzKff/15TO2QhBBX4Z9/HiP+ZD7ujvZ8dFc0OtmWWFyAvCvERYX5uvDGrd0B+GhdEluP56ockRDiSmxNyuXjdUkAvHFrd0J9XFSOSFgqSQbEJd0cFcIdfUJRFJj9XSJnimW7YyGswZniCmZ9l4iiwJ19Q7k5KkTtkIQFk2RAXNZLt3QhMsCN7KIK5vy4V5YrFsLCGY0KT/+wh5yzFUQGuPFS9YZkQlyMJAPislwc7Pn479E42Gv563AOX25JUTskIcQlfLklmXVHTuNob9qW2NlBtiUWlybJgGiQTkEevDC2MwDzfz/EvrRClSMSQlzIvrRC3lp1GIC547rQKchD5YiENZBkQDTYlAHhjOoaiN5g2u64uKJK7ZCEEOcorqhi5tJd6A0Ko7sGMaV/mNohCSshyYBoMI1Gw1uTehDi6UTKmVJe/Hm/2iFZtY0bN3LzzTcTEhKCRqPh559/rvO8oii8+OKLBAcH4+zszPDhwzl2rO4Uz7y8PCZPnoyHhwdeXl7cd999FBcXN2MthKVQFHjpl0OknCmllZczb03qIdsSiwaTZEBcES8XB/55VzRaDSzfnc5PuzPUDslqlZSUEBUVxYIFCy74/Ntvv82//vUvPv30U7Zv346rqyujRo2ivLzcXGby5MkcOHCAtWvXsnLlSjZu3MiDDz7YXFUQFmTnaQ2/7M3ETqvhn3f2xNNFtiUWDSfJgLhifSN8mD3ctIrZyysPkSOrFV+Vm266iddee42JEyfWe05RFD788EPmzp3L+PHj6dGjB//973/JyMgw9yAcOnSIVatW8Z///If+/fszePBgPvroI5YtW0ZGhiRpLUlybgk/JJs+zmcPb0+fCB+VIxLWRpIBcVUevSGSAW19KK008NUxOypku+NGlZycTFZWFsOHDzc/5unpSf/+/YmLiwMgLi4OLy8v+vTpYy4zfPhwtFot27dvb/aYhTrK9QZmfb+XSqOGAW28eeT6SLVDElbIvqEF9Xp9kwRQc96mOr/abLl+707qxs0L4kgr0fP0j/v45x1RNrklanNdw6qqKvNrpKWlAeDj41Pndf39/cnIyECv15Oeno6/v3+9uHx8fEhPT79ovBUVFVRU1C4elZeXB5jqZ4vvU1v+GzQaFWZ/v5eDmWdxtVeYP6EzRkMVRhvLzW35GkLT10+nu/wtowYnA7GxsdcUzOWsXbu2Sc+vNlut398jNHx6SMuqgzk8+MlqJkYYsdUxS019DRMSEsx/tIcPm6aG/fnnn/j41Hb5ZmZmotFoiI2N5ciRI5SUlNT726ysrGT//v0X/ZtdunQp3333Xb3H161bh4uL7S5Xa2t/g4oCy1O0bMzSYqdRmN7ByJ5tG9mjdmBNyNau4fmaqn7jx4+/bBmN0sDl5JqyZ2Dt2rWMGDGiQdmLtWkJ9Xtr6R98dcy0qMkzo9rzwOA2KkfVuJrjGjo4OPDDDz+Y/2hPnDhBp06d2LFjBz179jSXGzZsGFFRUbz//vssXryYZ555hpycHPPzVVVVuLu7s3TpUiZMmHDB17pQz0CHDh3IzMzE19e3SeqnJlv9G/x8UzLvrDHNLnn31i7oMvfaXB1r2Oo1rNHU9WvUnoGmvgA6nc4mL3INW65fLz+FkHYdeHPVUd5efYxgLxcmRrdWO6xG19TX0N7e3nz+Dh06EBQUxMaNG+nbty8ARUVF7Nixg0cffRSdTsfgwYMpKChg79699O7dGzB9uzcajQwaNOiisep0Otzc3C74uK2+R8G26rd8V5o5EZg7tjPjo1sTm7nXpup4IVK/ptPgZECIS7l3UASni/X8Z3Myc37Yi5+bI0Pa+6sdlkUrLi4mKSnJ/HNycjKJiYn4+PgQFhbGrFmzeO2112jfvj1t2rThhRdeICQkxPyNv3PnzowePZoHHniATz/9FL1ez2OPPcadd95JSIhsSmOrNh49zTM/7gXggSFtuH9IW5u9ly6aj8wmEI3m+TGduSUqhCqjwsNfJ7A/XZYsvpT4+Hiio6OJjo4G4MknnyQ6OpoXX3wRgGeeeYaZM2fy4IMP0rdvX4qLi1m1ahVOTk7mc3zzzTd06tSJYcOGMWbMGAYPHsznn3+uSn1E09uXVsgjSxKoMiqM7xnCczd1VjskYSOkZ0A0Gq1Wwzu39SC3uIKtx89wz6IdLH9kEGG+tjso7Vpcf/31l9wBUqPRMG/ePObNm3fRMj4+Pnz77bdNEZ6wMCfPlDB98Q5KKg0MivTlnb/Z5uwdoQ7pGRCNytHejs+m9qZzsAe5xZXc/eV2zhRXXP5AIcRF5RZXMO3LHeQWV9Il2INPp/TGwV4+vkXjkXeTaHTuTjq+mt6XVl7OpJwp5d7FOymtlE2NhLgaJRVV3Ld4JylnSmnt7czi6X1xd7LdQXRCHZIMiCYR4OHEf+/rh5eLjj1phcz4Zhd6g1HtsISwKnqDkRnf7mJPWiHeLjq+urcfAR5Olz9QiCskyYBoMu383Vg4rS9OOi3rjpzmHz/tu+Q9ciFELUVReG75PtYfOY2TTsvCe/rSzr/+lFAhGoMkA6JJ9Q735qO7eqHVwPfxaby/9qjaIQlhFd5bc5QfE9LQauDju3rRK8xb7ZCEDZNkQDS5EV0CeX1idwA++iuJJdtOqhyREJbt620n+XidaQ2KNyZ2Z3iXQJUjErZOkgHRLO7qF8YTw9oD8OKK/aw+kKVyREJYplX7s3hxxX4AZg1vz539wlSOSDSps9loDv5Ej1OL0ZxSb7dRWWdANJtZw9uTc7acpTtO8fjS3Xxzf3/Zd12Ic+xMyePxZbtRlLoJtLAhRZlwcgukbDb9O3MMe6ANYEjqDm0HqxKWJAOi2Wg0Gl4d343TZyv541A2930Vz48Px9A+0F3t0IRQ3bHss9y3eCeVVUaGdw7k1fFd0djqFqAtSVEGpGyBlE2mJOBM0nkFNCiB3ThhDCa83TBVQgRJBkQzs7fT8tFd0Uz+zzZ2pRYw7csdLH90EEGeMl1KtFyZhWVM+3IHReVV9Arz4qO7orG3k7u4VqkwzdT4n6z+5p934rwCGgjqDhFDIGIwhMdQZe/G/thYwsIGqhIySDIgVODsYMfCaX2Z9OlWTpwu4Z5FO/juoRg8nWUhFdHyFJbpuefLnWQUltPO35WF0/ri7GCndliioQpOmRr9msY/P6Xu8xotBPUwNfwRgyEsBpy96paxgI2mJBkQqvB2deCr6f249ZOtHM46y0Nfx/PVvf1wtJcPQdFylOsNPPjfeI5knyXA3ZGv7u2Ht6uD2mGJS8k/Wfeef8F5s6M0WgjuCRGDTN/+wwaAk6cqoV4JSQaEakJ9XFg8vS93fLaNbSfyePL7PXx0Z7RsviJaBKNR4anv97A9OQ93R3sWT+9Ha2/Z1MuiKIqpsa9p+FO2QGFq3TIaOwiJrm38Q/uDk4c68V4DSQaEqrqGePL51N5MW7SD3/ZmEuDuyIvjusjAKWHTFEVh3sqD/LYvE52dhs+m9qZLiPU1IDZHUSA/ubbhT9kMRWl1y2jtIaRXdeM/2NT4O1r/IGhJBoTqBkb68d7tPXl86W4WbUkhyMOJh65rp3ZYQjSZzzaeYPHWFADeu70nAyP91A2opVIU0wC/mm/+J7dAUXrdMlp7aNW7erDfoOrG3/aWhZZkQFiEW6JCyCkq57XfDvHm74cJ8HBkYnRrtcMSotEt35XG/N8PAzB3bGduiQpROaIWRFHgzHHTNL+axv9sZt0yWh207mNq+CMGQ2g/cHBVJ95mJMmAsBj3D2lLVmE5/9mczJwf9uLn5siQ9v5qhyVEo9l49DTP/LgXgAeGtOH+IW1VjsjGKQrkHqud45+yGYqz65axc4BWfWpH+7fuCw4tb+yGJAPCojw/pjM5Zyv4ZU8GD3+dwHcPxdCtleWPxBXicvanF/LIkgSqjArje4bw3E2d1Q7J9igKnD5SO80vZQuU5NQtY+doavAjBpvu+7fuCzpndeK1IJIMCIui1Wp457Ye5BZXsPX4Gf7+xTY+v7sPA9r6qh2aEFct7vgZHvo6npJKA4MifXnnb1Eya6YxKAqcPlzd8G8yNf6luXXL2Dmauvprvvm36gM6WeTsfJIMCIvjaG/HZ1N7M+3LHexKLWDqwu2887coJkS3Ujs0Ia7YT7vTeObHvegNCr3Dvfl0Sm8c7GV1wauiGCH7QN0Bf6Vn6paxd6pu/IeY7vu36i2NfwNIMiAskruTjm8fGMCT3ycSuy+LWd8lkpZfyowbImXaobAKiqLw8V9JvLf2KABjuwfz3u1ROOlkYa0GMxoh5wDaExvpe+J/2H8wC8ry6paxd4aw/hBe882/F9g7qhKuNZNkQFgsJ50dH9/Vi/neh/l84wneXXOUU3llvDaxGzpZt11YML3ByD9+2sf38aY56g8NbcuzozvJrYHLMRohe3/tt/6TW6AsHzvAPOdC52Ka3hcx2PTtPyQa7GXVxmslyYCwaFqthufHdCbU25mXfjnAd/GnyCgs49+Te+HuJHsZCMtztlzPo9/sYtOxXLQaeOWWrkyNiVA7LMtkNEDWvtqR/ie3QHlh3TI6V4yh/Tlc5kuHkfdiH9YX7ORvv7FJMiCswtSYCEK8nHns291sOpbLbZ/GsWh6X4I9ZRSwsBwZBWXcu3gnh7PO4uJgx8d/j+bGToFqh2U5jAbI2ls70v/kVqg4r/F3cDOt51/zzT84CoMRjsXG0r61JAJNRZIBYTWGdQ7k+4diuPcr04fthAVb+PKevnQNkamHQn0HMgq5d/FOsosq8Hd35MtpfeneuoW/Nw1VkLWntvFPjYOKorplHNwhPKZ6hb/BEBwFduc1TUb1d/WzdZIMCKvSvbUnPz06kOmLdnIsp5jbP41jweReXN8xQO3QRAu27kgOj32zi5JKAx0C3Vg0vR+tvFpgr5WhCjL31K7wl7oNKs/WLePoYdrGt2aef9AFGn/R7OQKCKvT2tuFHx8ZyCNLEth6/Az3fRXPaxO6cVe/MLVDEy3Qt9tTeWHFfgxGhYHtfPlkSm88nVtIV7ZBDxmJtSv8pW6DyuK6ZZw8IWzgOY1/D9DKjApLI8mAsEqezjoWT+/H/y3fy/Jd6Ty3fB+n8kp5emRHGbEtmoXRqPDOmiN8sv44AJN6tebNW7vb9hoCVZWQsbt2hb/U7aAvqVvGyat2Xf+IQRDYTRp/KyDJgLBaDvZa3rstijAfFz784xj/Xn+cU/llvHtbDxzt5cNHNJ1yvYE5P+7l1z0ZAMwe3oHHh9ngGhhVlZCxq3Z1v1PbQV9at4yzd3XjP8TU+Ad0Ba0NJ0Q2SpIBYdU0Gg2zhnegtbcL//c/04dzdmE5n03tjberzD0WjS+/pJIHv45nZ0o+9loNb03qwaTeNrLDZlUFpCeYGv6UTXBqB1SV1S3j4nvON//B4N9ZGn8bIMmAsAl/692aYE8nHv46gR0peUz6ZCuLp/cjzLfl7T4mms7JMyVMX7STE7kluDvZ89mU3gyM9FM7rKunL4f0+NrGP20nVJXXLePiZ/rGHzHE1Pj7dZTG3wZJMiBsxqBIP358ZCD3LjZ9WE/89xa+mNaHXmHeaocmbMCu1Hzu/yqevJJKWnk5s2h6XzoEuqsd1pXRl5ka/JTqRX7SdoKhom4Z14Dqxr96qp9/R7C12x+iHkkGhE3pGOTOT48O5N6vdrI/vYi7Pt/GP++MZnS3ILVDE1Zs1f5MnliWSEWVkW6tPPhyWl8CPKxg85vK0urGv3p1v7SdYKisW8YtsLrhr/7279deGv8WSJIBYXMCPJz47sEYZi7dzV+Hc3jkmwTmju3CfYPbqB2asDKKorBwczKvxx5CUeDGTgF8dFc0ro4W+tFZWQKpu89p/OPrL9jjFlR7vz9iCPi2k8ZfSDIgbJOroz2fT+3Ny78eYMm2VF5deZBTeaW8MK4LdjL1UDSAwajw6sqDLN6aAsDUAeG8dHMX7C1pk6yKYji1He2JTQw+uhL7PffVb/zdQ2qn+UUMAZ+20viLeiQZEDbL3k7Lq+O7Eebjwhuxh1m8NYW0/DL+dVdPXBzkrS8urrSyiseXJvLHoWwA/jGmM/cPaaP+1MGKYji1rXp5382mOf/GKuwA35oyHq1qp/lFDAbvNtL4i8uST0Rh0zQaDQ8ObUcrLxdmf2/6cL/r8238Z1pf/N1lz3NRX87Zcu7/Kp69aYU42Gv58I6ejOkerE4w5UWmuf018/wzdoNiqFvGMxRjWAx7Cj3oNu5hdP6R0viLKybJgGgRxvYIJsjTkfu/imdPWiET/72Ff97Zk97hPmqHJixIfEoeTyxLJL2gDB9XB764u3fzvkfKC01L+tZ888/cU7/x9wozffOvmevvHY5Bryc1NpZu3hGSCIirIsmAaDF6h/uw/NFBTF+0g5QzpUz6JI67+oXy7OhOeLnIAkUtWUFpJW+tOszSHacAiPB1YfH0fkT4uTbtC5cVVDf+1Wv7Z+4BxVi3jHdE7TS/iEGmZECIRibJgGhR2vi58vOMQbwZe5jv4k+xdMcp1hzIZu64zkzo2Ur9e8KiWSmKws+J6by28hBnSkxT7u7oE8pzY5ooQSzLh5NxpoY/ZRNk7avf+Pu0rbu8r6eNrG4oLJokA6LF8XJx4K2/mZaQff6nfSTlFDP7uz38mJDGq+O70dbfTe0QRTM4cbqYuT/vZ+vxMwC0D3Dj9Ynd6demEW8LlOZBalxtt3/WPkCpW8Y3sm7j7xHSeK8vRANJMiBarH5tfIh9fAhfbDrBv/48xpakM4z+cBOP3tCOR65vJ5sd2ahyvYFP1h/nk/XHqTQYcbTX8viw9jwwpO217zhYmlf9rX+zacBf9n7qN/7ta+f5hw8CD5UGJwpxDkkGRIvmYK9lxg2R3NwjhBdW7GfD0dN8+McxfknM4LUJ3ax73XlRz9akXOb+vJ8TuaZtd6/r4G+afnq1e1iU5FY3/tUJQM6B+mX8Op6zvO8gcJfVMIXlkWRACCDM14XF0/vy275MXvn1ICdyS/j7f7YzMboVz46MVDs8cY3O6uHpH/exYk8mAP7ujrx0cxfGdg++snEixafh5Obaxv/0ofpl/DvV/ebvFtBItRCi6UgyIEQ1jUbDuB4hDO3gz7urj/D1tpP8tDudvw5nc1OwhtFG5fInERbFaFT4Lj6NN3bbUWrIRKOBuweE89Sojng46S5/guKc2vv9KZsh90j9MgFdahv+8EHg5t/4FRGiiUkyIMR5PJx0zBvfjVt7teb55fs4mFnEshN2HFu4kzdu7UHHICvbqa6FOpJ1ln/8tI/4k/mAhi7B7rx5aw+iQr0uftDZrNqG/+QWyD1av0xgt9o5/uGDwNW3fhkhrIwkA0JcRM9QL355bBBfbj7Bu6sPk5BawNh/beL+IW15Ylh7nB1kgKElKqs08M8/j/GfTSeoMiq4ONgxKqSSN+7pj7PTeatOFmWYuvxPVicAZ5LOO5vG1Pibu/0HgossVCVsjyQDQlyCvZ2W6QPDccg+wJayENYeyuHTDcdZuTeDV8d344ZOcj/Ykqw7nMMLK/aTll8GwMgugcwd05HdW/4ybTBUmF47xz9lC+QdP+8MGgjqVj3NbzCExUjjL1oESQaEaABvR/j3xJ6sP5bHS9WNzfTFOxnTPYiXbu5KoDXsbW/DsgrLmbfyALH7sgBo5eXMy7d0ZUQrPVXHf0FJ/Q77f78E+cl1D9RoIaj7OY3/AHD2VqEGQqhLkgEhrsCILoEMbOfLh38c5cstKcTuy2Lj0VyeHtmBqTERsj1yMzMYFf4bl8J7a45SXFFFqDaXOZ1yucktCd2aWVBwEnsgvOYAjRaCo2qX9w0bAM5eqsUvhKWQZECIK+TqaM8/xnZhYrRpBcPEUwW8/OtBlu9O542J3enWylPtEFuEfWmFfPjjH3if3s7L2kMMcTlCoDEbTpxTSGOHMagHxw3BtLlhKvZtBoGTXB8hzifJgBBXqUuIB/97ZCDf7kjl7VWH2ZtWyC0fb+ZvvVtzR98weoV5yV4HjUlRUPJTOJmwhtwDfxKcn8BCTS7UzBA0Aho7CImuHfAX2h+DnTMHY2OJiBwBugZMJxSiBZJkQIhrYKfVMHVAOKO6BvLaykP8sieD7+PT+D4+jbZ+rkzq3ZqJ0a0I8XJWO1Troyime/wpmyk9ugFD8ibcK7KJACIANGDADmNwNLp2Q8yNP47nTf3U65s9dCGsjSQDQjSCAHcn/nVXNFNjwlm6PZXf92dxIreEd1Yf4d01RxjUzo9JvVsxqmsQLg7yZ3dBigJ5J8wj/Y0pm9CeNa0YWLNYsF6xYx/tOOPXj7BeI+jYZzh2jrKxlBDXSj6VhGhEfSN86Bvhw7wJVcTuy+R/CWlsT85jc1Ium5NycXXYz9gewUzq1Zp+bXxa9m0ERTHN6z93hb/iLPPTWqBSsSNRiWSbsTNFAf3o0m84I6Pb4eYoH11CNCb5ixKiCbg52nN7n1Bu7xPKqbxS/rcrjf/tSuNUXpn5NkKojzOTerVmUq/WhPpc5UY51kRRIPdY9Tf/6hX+irPrFKnEnt1GU+O/zdiFXM8ejOvdjlt7tWoZvyMhVCLJgBBNLNTHhVnDO/D4je3ZmZLH/3alEbsvi1N5ZXz4xzE+/OMY/dv4MKl3a8Z0D7adb72KAqePmBr/mp39SnLqFDFoHThk34k/SiPZZuzCbmMkOkcXxvQMYnbvUPpGeLfs3hMhmomNfOoIYfm0Wg392/rSv60vr9zSjdUHsvgxIY0tx3PZnpzH9uQ8XlpxgJu6BTGpd2ti2vqitaZ1C4xGOH247gp/pbl1iij2ThT69iTO0Jml2WFsL29DBQ5oNDA40o+3erVmVNcgWepZiGYmyYAQKnB2sGNCdCsmRLcio6CMn3an87+ENE7klrB8dzrLd6fTysuZidGtmNS7NW38XNUOuT6j0bSFb8rm6m//W6H0TN0y9s4Q2o/8gP6sKm7Hp8e8OHnSYH5aZlwIYRkkGRBCZSFezsy4IZJHr2/H7lMF/JiQxq97MkgvKOPjdUl8vC6J3uHeTIhuRZdgD0K9nfFzc6zTa7BgwQLeeecdsrKyiIqK4qOPPqJfv36NG6jRCDkH6u7qV5Zft4zOBSW0PyXB/Unz7ENCVRv+l5jNrg0F1QUMuDvZc0tUCJN6tyY6VNZiEMISSDIghIXQaDT0CvOmV5g3L47rwtqD2fxvVxobj54m4WQ+CSdrG14HOy2tvJ1p7e1MRV4mf6zYwrTZbzAwqhO/Ll3MqFGjOXLkMAEB17CRktEA2ftN3f01jX95QZ0iVXbOZHhEcdCxB9uNXdhc0pqTR6qoPGgEKoEjAGg1MLSDP3/r3ZrhnQNx0sltACEsiSQDQlggJ50dN0eFcHNUCNlF5fy8O52/DueQll9GZmEZlQYjybklJOeWADo8Bk/mp0z4KTMTvEfhcf+NDP9wM93bhtDay4XW3s609nGmtbcLrbycCfRwqr+PgtEAGbsxJm+m8vhG7NO2YV9ZVKdIKU7sNHYkztCZ7cbO7FPaUFVy7sdIJWBq/IM9TcnKsM4BTOjZigDZzEkIiyXJgBAWLtDDiYeua8dD17UDQG8wklVYTlp+GSdzz/LonLkMu+UOtO5+pBeUkVlYjgEdRUbYknQGOFPvnPZaDaGeDgx0y6BH+W4AKt/vAY5laIGaZvus4sxOY0e2GzuzzdiZ/UobDNhhp9UQ7OVEby9TgtG6upei5v+DPJ3Q2Wmb5xckhLhmDUoGFEUhLy+vSQLQ6/WUlpZy5swZdDa4brjUz/pZYh1dgA5e4F5WTP6mb7jv+Sn07dsBgCqDkefmvcXOg0k8OfdVMgsryCgsIzu/BJeCQ7Qt3Ucv4xF65R/DvaCcogoFAENFCWmKM7uMHUhQOpHs0o0yr04EersS4unMRE8nHvVyIsTLiQA3R+wv1tgrZRQVlDXPL6IBLPH6NTZbr6PU79rodDrc3d0vOT5HoyiKcrkTFRUV4ekpO30JIYQQ1qiwsBAPD4+LPt+gZKApewby8/Pp3r07+/btw9vbu0leQ01SP+tnyXWsrKykdevWLFq0iLGjR6LJ2ofm1DYOrVlEO8c8nO2Mdcorjh4YQvpQEdgLfau+GH06cCo9g6FDh7Jr1y7CwsJUqknTseTr11hsvY5Sv2vTkJ6BBt0m0Gg0+Pr6Nlpg5ysvL8fb27tJX0NNUj/rZ5F1rKqEjF18dHsEfQ+/ge+pZ0FfCsDAms8TZx8IH2Ta0S98EAR2Be15I/mrf7a4+jUii7x+jczW6yj1a1oygFAIa1FVAem7qqf5bYbU7VBVxqMdq5/XQ5WDJ3sL3Vm2PZ1n/70C305DQCsD+YQQlybJgBCWqqoC0uJrG/9TO6HqvIF5Lr4QMZgNJw28tmQDmw5nE9UzmH/9azW+XfqrE7cQwuqongw4Ojpyxx134OjoqHYoTULqZ/2arY76ckjbWb22/2bT/1eV1y3j6l/b7R8xBPw7gkbDdcB1c67uZR0cHOr819bIe9T6Sf2ankUkA3fddZdNX2Spn3Vrsjrqy+DUjnMa/3gwVNQt4xpQ3fBX//PrAI28fG9NvWz1Gsp71PpJ/Zqe6smAEC1GZSmk7ahe238LpMeDobJuGbeg6oZ/kOmbv29kozf+QghxPkkGhGgqlSVwavs5jX8CGPV1y7gHn/PNfwj4tJXGXwjR7CQZEKKxVBTDqW21G/tk7AJjVd0yHq1qp/lFDJbGXwhhESQZEOJqVZyF1G21W/pm7AbFULeMR2toM6S28feOkMZfCGFxmnwC8uuvv87AgQNxcXHBy8vrgmVOnz7N+PHjcXFxISAggDlz5lBVVXXBsjXy8vKYPHkyHh4eeHl5cd9991FcXNwENbgy69evR6PRmP85ODgwYcIEHBwc2Llz50WPu/766+scp9FoePjhh5sx8oaLiIioV7+33377kseUl5czY8YMfH19cXNzY9KkSWRnZzdTxA2XkpLCfffdR5s2bXB2dqZdu3a88sor6PV6U+N/dA2seQG+uBHmh8M3f4MtH5ru/ysGUgqMfJVYyT0/l/GP0zfD7P0w8VPoNRV82qiWCCxYsICIiAicnJzo378/O3bsuGT5H374gU6dOuHk5ET37t2JjY1tpkivzJtvvknfvn1xd3cnICCACRMmcOTIkUses3jx4np/a05Olruj4ssvv1wv3k6dOl3yGEu/fgaDgfLycsrLyxk0aBARERH1/j3//PPmMuXl5djb21NeXs7SpUvrle3QoUOdsmr/27RpE9OnT6dfv35ERESwcuXKOs+XlZXx9ttv07dvXzp27MjUqVPJy8u77HkXLlzIoEGD6NChA7fccgs7duzAYDBc/hfeAE3eM1BZWcltt91GTEwMCxcurPe8wWDg1VdfpX379mzdupXMzEzuvvtudDodb7zxxkXPO3nyZDIzM1m7di16vZ7p06fz4IMP8u233zZldS5r4MCBZGZmmn/W6/Xcd999JCUl0adPn0se+8ADDzBv3jzzzy4uLk0W57WaN28eDzzwAHq9nj///JMJEyZcsvzs2bP57bff+OGHH/D09OSxxx7j1ltvZcuWLc0TcAMdPnwYo9HIZ599RvuwQHJ2/kz8//5JVKUL9gdKQKm7vC9e4RAxhDeXbqTIpwdPvPQeo4BRVF8/C+gF+O6773jyySf59NNP6d+/Px9++CGjRo3iyJEjBAQE1Cu/detW7rrrLt58803GjRvHt99+y4QJE9i1axfdunVToQYXt2HDBmbMmEHfvn2pqqri+eefZ+TIkRw8eBBXV9eLHufh4VEnabjUMq2WoGvXrvzxxx/mn+3tL/7RbcnXT1EUsrKyKCgoMD/22Wef1Smj1+vJzs4mMDCQ5ORk83FBQUGcOnWKyMhIPvvsM1q1alXnuJqylsDV1ZUHH3wQBwcHTp8+jb+/f534CgsLiYqKYtiwYdjb21NQUEBFRQWpqaloL7JIWElJCa1ateLDDz/E0dGRoqIi8vPzOXToEL6+vgQFBV3b+1hpJosWLVI8PT3rPf7LL78oWq1WOXXqlPmxTz75RPHw8FAqKioueK6DBw8qgLJz507zY7///rui0WiU9PT0Ro/9WpSUlCienp7KSy+9dMly1113nfLEE080S0zXKjw8XPnggw8URVGUyspK5eeff1YqKysvWr6goEDR6XTKDz/8YH7s0KFDCqDExcU1dbgNV5qvKIdjFWXV84ry6VBFedlLUV7yqPvvwyhF+XmGoiQuVZT8VPOhlnz9+vXrp8yYMcP8s8FgUEJCQpQ333xTURRFyc3NVQAlNzdXURRFuf3225WxY8fWOUf//v2Vhx56qPmCvko5OTkKoGzYsMH82Pnv0Yt9Flmql156SYmKirpkmXPraMnXLyMjQzl48KCSm5urlJaWKmVlZfX+HT9+XNmzZ0+d50tKSpTs7GylpKREycjIUBISEi54rCX+27lzp5KVlWX+ubS0VNm9e7eSmppqfqyoqEiJj49XMjIyLnqe/fv3K8ePH693nqSkJOXgwYNKRkbGNV0b1dcp3bZtG2FhYQQGBpofGzVqFEVFRRw4cOCCx8TFxeHl5VXnm/bw4cPRarVs3769yWO+Er/++itnz55l2rRply37zTff4OfnR7du3XjuuecoLS1thgivzvz58/H19aVv37789NNPl7ytk5CQgF6vZ/jw4ebHOnXqRFhYGHFxcc0R7oWV5sHh32DV8/DpEHgrApbeCXEfQ2aiqRfApx07DJ15crM7+pl74YlEGP8xRN0JXqF1TmeJ16+yspKEhIQ6v3utVsvw4cMv+ruPi4urUx5Mf5OqXqsGKiwsBMDHx+eS5YqLiwkPDyc0NJTx48df9LPGUhw7doyQkBDatm3L5MmTSU1NvWhZS71+BoOBgoICAgIC8PX1xdnZGScnpzr/HBwcKCoqwt/fv97zDg4OODk5odPpMBqNHD16lKNHj5KWloaiKPXOZSn/AHPsTk5OaLVaqqqq8PX1NT/m6uqKk5MTer3+gudwcHCgrKwMb29v82POzs54enqiKAoBAQEUFBRc0y0D1QcQZmdn1xtLUJMYZGVlXfCYrKyset2b9vb2+Pj4XPQYtSxevJiePXvSunXrS5b7+9//Tnh4OCEhIezdu5dnn32WI0eOsHz58maKtOEef/xxevXqhY+PD5s2beLZZ5/Fy8uLDz/88ILls7KycHBwuOB1btbrVZoHJ7fWDvjL3g+ct2mnb/vaOf7hg0jKKWFE795MmTIFPEIuempLvX65ubkYDIY6yTaYfveHDx++4DFZWVkXLG9pf1vnMxqNzJo1i0GDBl2yO7xjx458+eWX9OjRg8LCQt59910GDhzIgQMHLvt3qob+/fuzePFiOnbsSGZmJq+88gpDhgxh//79uLu71ytvqddPrzdNq73U7c+CggJzQ3kxTk5ORERE4OLigsFgICsri8OHD9O1a1erWEWz5vdw/q0eOzs783Pnq/mypdPp6jyu0+koLy83/071ej12dnb1jm+Iq0oG/u///o+33nrrkmUOHTp02UEu1uRq6pyWlsaaNWt4+umnL3v+Bx980Pz/3bt3Jzg4mGHDhnH8+HHatWt39YE30JXU78knnzQ/1rlzZw4fPsyCBQt46623LGuFsJIz5tX9Mrf9SLD2TL0ih04b2HDSwPqUKl79eh3towebn0tPT2f06NFMmjSJkSNHXvKl1L5+AmbMmMH+/fvZvHnzJcvFxMQQExNj/nngwIF07tyZzz77jFdffbWpw7xiN910k/n/e/ToQf/+/QkPD+f777/nvvvuUzGyq3Op+9q5ubl4enpeslF3c3PDzc3N/LOrqysHDhzg9OnT9cYRtBSNMeblqpKBp556invuueeSZdq2bdugcwUGBtYZTAKYR5kHBQVd8JigoCBycnLqPFZVVUVeXt5Fj7lWV1PnRYsW4evrS79+/a749fr3N20yk5SU1CyNybVc0w4dOlBVVUVKSgodO3as93xQUBCVlZUUFBTU6R3Izs5u3OtVklu9qU/1PP+cg+angqtviFV4tKE0oJfpn380GmdfrgeuB8LPqV9GRgY33HADAwcO5JNPPmHVqlVXFEpzX7+L8fPzw87Ort7MjUv97oOCgq6ovCV47LHHWLlyJRs3brzib/c6nY7o6GiSkpKaKLrG5eXlRYcOHS4arzVeP4CKigqKioqIjIy8ouO0Wi0uLi5UVFRcvrAFqPl2X1VVVSfpMRgMF+01qelFOL/nQK/X1+stuFpXlQz4+/vj7+/fKAEMGDCA+fPnk5OTY87q1q5di4eHB126dLngMTExMRQUFJCQkEDv3r0B+OuvvzAajeYP4cZ2pXVWFIVFixYxZcqUS478vZjExEQAgoODr/jYq3Et1zQ5ORmtVnvBkekAvXv3RqfT8eeffzJp0iQAjhw5Qmpqap1vaFes+LRpN7+aFf5OH6pfxr9z7Qp/4YNwdPPHEfC+xGnT09O54YYb6N27N4sWLcJoNF6i9IU19/W7GAcHB3r37l1nxofRaOTPP//kscceu+AxMTEx/Pnnn8yaNcv82Nq1a6/tWjURRVGYOXMmP/30E+vXr6dNmzZXfA6DwcC+ffsYM2ZME0TY+IqLizl+/DhTp0694PPWdP3OdebMGXQ6HZ6enld0nKIolJWVXfFxanFwcECn01FUVGRu/I1GI+Xl5RdN2LRaLa6urpw9exZvb9Onl6IoFBUVXfRz94pd8/DQyzh58qSye/du5ZVXXlHc3NyU3bt3K7t371bOnj2rKIqilJWVKWFhYcqIESOUxMREZdWqVYq/v7/y3HPPmc+xfft2pWPHjkpaWpr5sdGjRyvR0dHK9u3blc2bNyvt27dX7rrrrqauToP98ccfCqDs3bu33mj7tLQ0pWPHjsr27dsVRVGUpKQkZd68eUp8fLySnJysrFixQmnbtq0ydOhQtcK/qK1btyoffPCBkpiYqBw/flxZvHix4unpqUyZMsVc5vz6KYqiPPzww0pYWJjy119/KfHx8UpMTIwSExNzZS9elKUo+35UlF9nK8pHfeuP9H/JQ1EWxCjKb08ryoGfFaX49BXXLy0tTYmMjFSGDRumpKWlKZmZmUpqaqqyaNEi8zW0tuu3bNkyxdHRUVm8eLFy8OBB5cEHH1S8vLyUrKwsRVFMswc4ZzbBli1bFHt7e+Xdd99VDh06pLz00kuKTqdT9u3bp2Y1LuiRRx5RPD09lfXr1yuZmZnmf6WlpeYykydPViZNmmS+fq+88oqyevVq5fjx40pCQoJy5513Kk5OTsqBAwfUqsYlPfXUU8r69euV5ORkZcuWLcrw4cMVPz8/JScnR1EURZk6daoyZ84c8+eMpV6/srIy5eDBg0pZWVm954xGo7Jnz546s8pqnDhxQjl16pSSn5+vGAwGJT09XSkoKFDKy8uV4uJi5fjx40p8fHyda662qqoqpaSkRCkpKTHPJigpKVHKy8sVRTHNqti1a5eSn5+vlJSUKEePHlUSExOVqqoq8zkOHz6sZGdnm38+c+aMEh8fr5w+fVopLS1VUlJSlF27dimVlZWX/N02VJMnA9OmTVMwjdKq82/dunWKopimxHz++efK6NGjFWdnZ8XPz0956qmnFL1ebz7HunXrFEBJTk42P3bmzBnlrrvuUtzc3BQPDw9l+vTp5gTDEtx1113KwIEDLzj1Ljk5uc7vIDU1VRk6dKji4+OjODo6KpGRkcqcOXOUwsJClaK/uISEBKV///6Kp6en4uTkpHTq1EmZMmVKnd/9+fVTFNMHwaOPPqp4e3srLi4uysSJE5XMzMxLv1hRpqLs/UFRfnlCUf7V+8KN/78HKkrsM4py8BdFKc695votWrTogu9XwHwNrfH6ffTRR0pYWJji4OCg9OvXT9m2bZv5uYEDB9ZJBhRFUb7//nulQ4cOioODg9K1a1flt99+UyPsy7rYtVq0aJG5zNChQ5UbbrjBfP1mzZpl/l0EBgYqY8aMUXbt2qVSDS7vjjvuUIKDgxUHBwelVatWyh133KEkJSWZn7/uuuuUqVOn1vmcscTrd6kGq6CgQNm5c+cFnzt8+LBy4sQJczKQmpqq7NmzR4mPj1cSExOVo0ePKiUlJc1RBUVRFOVf//qXEhYWptjZ2Sn33HOP4u/vX6dtUhRFKSoqUnbu3Fnv34kTJxRFMSU/aWlpSmJiohIfH29u+A0Gg3LHHXco7777rrJnz556U+Wzs7PNdT948GCdL9XXmgxoFEU5bzh189Lr9cTGxjJmzJhGu/dhSaR+V6Aow9TdX9P1f+b8e6IaCOpmHulP+EBwufQUssZg69fwzJkz+Pn5kZube8lR3NbK1q8fWEcdy8vLSU5Opk2bNle84qPRaKSoqAgPD4+LLsrTHPbs2UOfPn1YsWIF0dHRvPPOO5w9e5YvvviiTqxdunRh0qRJvP766+bHf/vtNyZOnMiyZcu49dZb65z33PodPHiQoUOHkpyc3OBbH9fyu62h+tRC0YIVplcP+Ktu/PNOnFdAA8E9ILx6S9/wgeB8qbv9QgjRdFauXEm/fv0YM2YMpaWlLFy4kNWrV9cpo9Vqee6553jiiSd45pln8PT0ZNeuXdxxxx289dZb9RKB83Xr1o127dqxZMkSZsyY0ZTVqUOSAdF8Ck5Vj/TfZOoByD9v+VCNFoJ61G7nGzYAnL1UCVUIIc4VGRnJ8ePHAdNUPmdnZ9zc3BgwYEC9spMnT+aVV17h448/ZurUqYwbN47p06cze/bsBr3WzTffzLJlyyQZEDYi/2TtNL+UzVBwsu7zGi0E96xd5CdsADhZx4hgIcS1UxSFMv3lV80zGo2UVRqwr6xqtNsEzjq7K5qfv3XrVmJiYnjkkUeYMmUK//jHP8jIyLhgWXt7e5599lnmzp3L0qVL6du3L//85z8b/Fr9+vXj9ddfp6KiotnWbpFkQDQORYH8lNppfimbofC8JVM1dhDSs/abf2h/cPJQI1ohhAUo0xvo8uLqyxdsAgfnjcLFoeFNoJubGykpKQwePJigoCDOnDlDSMjFVyWdPHkys2bNIigoiKVLl9ZJYiIiIszjH7y9vfnzzz/rHBsSEkJlZSVZWVmEh4dfeeWugiQD4uooCuQnozm+kV4p32P/8XNQlF63jNYeQqKr5/gPhrD+4Fh/+VQhhLB0e/fuBUwrjAKUlZVdcrBezToeubm5F+zN2Lp1q3klxfPXMnF2dgZo1v1NJBkQDaMopgF+NV3+J7dAUTr2gHm7Hq09tOptGukfMdj0zd/R7RInFUK0ZM46Ow7OG3XZckajkbNFZ3H3cG/U2wRXIjExkcjISPPW2H5+fuTn51+w7AsvvMBvv/3Gtm3bGD58OAsXLryi+/95eXkAjba4X0NIMiAuTFHgzHHTYL+a+/5nM+uW0eowhvQiSR9A2xunYd9mIDhcfA95IYQ4l0ajaVBXvdFopMrBDhcHe9WmFiYmJhIVFWX+OTo6miVLltQr98UXX/Dee+/x119/ERUVxaxZs3j77bd58MEHzdM+NRoN1113HVqtllmzZnHXXXfVOcf+/ftp3bo1fn5+TVupc0gyIEwUBXKPnbO872Yorru+OXYO0KpP9T3/QdC6HwaNjkOxsbRpez1Y6PxmIYS4VomJidxyyy3mn0eNGsVzzz1Hfn6+eYng2NhYHnvsMZYtW2aeZfDYY4/xzjvv8PXXX3PvvfcCsHnzZlq1akVmZibDhw+na9euREREmM+9adOmy26O1tjUW71BqEtR4PQR2Pkf+GE6vNsBFvSFlbNh//9MiYCdo+le/3XPwrRf4f9S4d7f4cZ/QNvrweHiW5EKdRkMBgYOHFhvTnNhYSGhoaH84x//uOw5NBpNvX/Lli1rqpCFsFhGo5F9+/bV6Rno3r07vXr14vvvvwcgISGB22+/nbfffpuJEyeay3l6evL4448zf/58DAbTzImafXiCg4MZM2YMu3btMpcvLy/n559/5oEHHmiOqplJz0BLoShw+nDde/4lp+uWsXOE0H61G/u06gO6q1vNSqjLzs6OxYsX07NnT7755hsmT54MwMyZM/Hx8eGll15q0HkWLVrE6NGjzT+fu+ukEC2FVqulpKSk3uMvvvgic+bM4YEHHqB3794UFxdf8Ph58+Yxb948AEpKSjAajbi7u1NcXMxff/3F3/72N3PZRYsW0a9fvwuuX9CUJBmwVUajaRe/lOpFfk5uhdLcumXsnSG0b+3yvq16S+NvQzp06MD8+fOZOXMmN954Izt27GDZsmXs3LnzkvvFn8vLy8vit74VQi1jx47l2LFjpKenExoaevkDMG0nXdNzYDAYeOCBB+jbty9FRUWAaYvjjz76qMlivhhJBmyF0Qg5B6u/+Vc3/mV5dcvoXGq/+YcPhla9wL55FrQQ6qjZ3nfq1Kns27ePF198sU5X5+XMmDGD+++/n7Zt2/Lwww8zffr0K1qoRQhbd+5W0Q3Rtm1b9uzZU+exc6cW3n///Y0R1hWTZMBaGY2Qvb+2y//kFig7b5qLzsW0ql/NVL+QXmDfsG+EwjZoNBo++eQTOnfuTPfu3fm///u/Bh87b948brzxRlxcXFizZg2PPvooxcXFPP74400YsRBCDZIMWAujAbL21U7zO7kFygvrltG5mhr/mhX+QnqCnYzwb+m+/PJLXFxcSE5OJi0trc6o5Ut54YUXzP8fHR1NSUkJ77zzjiQDQtggSQYslaEKsvae0/jHQcV5jb+DG4TF1A74C46Sxl/UsXXrVj744APWrFnDa6+9xn333ccff/xxVV39/fv359VXX23W9dKFEM1DkgFLYaiCrD21o/1Tt0FFUd0yjh7VjX91t39QFNjJJRQXVlpayj333MMjjzzCDTfcQJs2bejevTuffvopjzzyyBWfLzExEW9vb0kEhLBB0pKoxaCHzD212/mmboPKs3XLOHpA+MDqAX+DTNv7SuMvGui5555DURTmz58PmDZHeffdd3n66ae56aabLnm74NdffyU7O5sBAwbg5OTE2rVreeONN3j66aebKXohRHOSlqW5GPSQtbv2m/+p7VB53pxUJ08IG1jb7R/UHbRXtn62EAAbNmxgwYIFrF+/HheX2sWhHnroIZYvX37Z2wU6nY4FCxYwe/ZsFEUhMjKS999/v9kXQhFCNA9JBppKVSVk7EZ7YgMxSSuw3/8I6M9btMLJq3akf8QgCOwmjb9oFNdddx1VVVUXfG716stvGTt69Og6iw0JIWybJAONpaoS0hNq1/Y/tQP0pdgBATVlnL3PafwHQ0BXUGnTDSGEEKKGJANXq6rC1PinnNP4V5XVLePiizE0hv0lXnS+6UF0wd2l8RcW4eGHHzbvuKYoCgBhYWFoNBqmTJnCp59+qmZ4QohmJslAQ+nLIT2+dnnftJ1QVV63jItf9Uj/6uV9/TthMBhIjo2lc0AXSQSExZg3b555MGB+fj79+vVj/fr1eHt74+HhoXJ0QojmJsnAxejLTQ1+zTf/tJ1gqKhbxtW/dqR/xBDw7wjnD8iq3qVKCEsSEBBAQIDpBtaZM2cA0zKpvr6+aoYlhMX76KOPePfdd0lPT2fWrFmEh4czc+ZM8/Nnzpyhc+fO7Nixo8ELfF3KnXfeSd++fXnqqaeu+VyXIslADX2Zqau/ZnW/tJ1gqKxbxi2wuuGvbvz9OtRv/IUQQtikPXv28OSTT7JixQqio6MZOHAgK1asqFPm9ddfZ/z48eZEwGg00qVLFyZNmsTrr79uLvfbb78xceJEli1bxoQJEy76mnPnzmXo0KHcf//9eHp6NkW1gJacDFSWmqb31azwl55wgcY/qHakf8QQ8I2Uxl8IIVqolStX0q9fP8aMGUNGRgZhYWH06NHD/HxpaSkLFy6sM2NHq9Xy3HPP8cQTT/DMM8/g6enJrl27uOOOO3jrrbe49dZb62xUdL5u3brRrl07lixZwowZM5qsbi0nGagsMTX+KZtN9/3TE8Cor1vGPaRu4+/TVhp/IYQQREZGcvz4cQDz+hzff/99nTKxsbE4OjoyYMCAOo9PnjyZV155hY8//pipU6cybtw4pk+fzuzZsxv02jfffDPLli2TZOCqVBTDqW3VA/42Q8YuMJ4379qjVe00v4jB4N1GGn8hhBD1bN26lZiYGB555BGmTJnCu+++y8SJE+uU2bRpE7179653rL29Pc8++yxz585l6dKl9O3bl3/+858Nfu1+/frx+uuvN+m+ILaTDFSchdTt1cv7boaM3aCcN3jPM7S24Q8fBN4R0vgLIYRaFAX0pZcvZzSaylXaNd6sLJ3LFX3+u7m5kZKSwuDBgwkKCuLdd9+tV+bkyZOEhIRc8PjJkycza9YsgoKCWLp0Kdpz6tG2bVtcXV3R6XR4e3uzbt26OseGhIRQWVlJVlYW4eHhDY75SlhvMlBeZFrPP2WT6b5/RmL9xt8rrHaaX8Rg8G6aX6IQQoiroC+FNy7ceJ5LC3g19ms/nwEOrg0uvnfvXgC6d+9+0TJlZWU4OTld8LnHHnsMgNzc3DqJQI3Vq1cTEhJyweecnZ0B05iEpmI9yUBZQd3GP3MPKOcNuvCOqP7WX33f3ytMjUiFEELYmMTERCIjI3F1vXgC4efnR35+fr3HX3jhBX777Te2bdvG8OHDWbhw4RXd/8/LywPA39//ygNvIMtNBsry4WRc9VS/zZC5F1DqlvFpWzvHP2IQeLZWJVQhhBBXQedi+oZ+GUajkaKzZ/Fwd7/gN+erfu0rkJiYSFRU1CXLREdHm1f2rPHFF1/w3nvv8ddffxEVFcWsWbN4++23efDBB9HpdIBpQOK4cePQ6XTMmjWLyZMn1znH/v37ad26NX5+flcU85WwnGSgLB+SdlRP9dsEWfup3/i3q3vP37OVKqEKIYRoBBpNw7rqjUbQGUxlVVrJNTExkVtuueWSZUaNGsVzzz1Hfn4+3t7exMbG8thjj7Fs2TLzDIPHHnuMd955h6+//pp7770XgI0bN+Lu7k5JSQkjR46ke/fudaYsbtq0iZEjRzZd5VA7GUjZjPbACq4/9Dv2u9Oo1/j7tq/b+HsEqxKmEEKIlstoNLJv3z5eeOGFS5br3r07vXr14vvvv6dPnz7cfvvtvP3223VmHXh6evL4448zf/58pk2bhp2dHa1ataKoqIjg4GDGjBnDrl27zMlAeXk5P//8M6tWrWrSOqqbDBxbi93OzzGvqeTXsXqOf3Xj7x6kZnRCCCEEWq2WkpKSyxcEXnzxRebMmcP+/fspLi6+YJl58+Yxb948AEpKSszbjRcXF/PXX39x++23m8suWrSIfv361Vu7oLGpmwx0GI2hvIhdZ5zpOX4GOm/p9hdCCGG9xo4dy7Fjx0hPTyc0NPSy5bOzs5k4cSKG6n1sHnjgAfr27Wt+XqfT8dFHHzVZvDXUTQbCYzCG9CEjNpaebgGqhiKEEEI0hlmzZjW4bNu2bdm9ezdFRUV4eHjUGyB5//33N3J0FyZ76gohhBAtnCQDQgghRAsnyYAQQgjRwkkyIIQQQrRwkgwIIYQQLZwkA0IIIZqN0Wi8fCFxRRrjd2o5yxELIYSwWQ4ODmi1WjIyMvD398fBwQFNA7cQNhqNVFZWUl5e3nh7E1iQq62foihUVlZy+vRptFotDg4OVx2DJANCqOT111/nt99+IzExEQcHBwoKCuqVSU1N5ZFHHmHdunW4ubkxbdo03nzzTezta/90169fz5NPPsmBAwcIDQ1l7ty53HPPPc1XESEaQKvV0qZNGzIzM8nIuPzmROdSFIWysjKcnZ0bnEBYk2utn4uLC2FhYdeUKEkyIIRKKisrue2224iJiWHhwoX1njcYDIwdO5agoCC2bt1KZmYmd999NzqdjjfeeAOA5ORkxo4dy8MPP8w333zDn3/+yf33309wcDCjRo1q7ioJcUkODg6EhYVRVVVlXnGvIfR6PRs3bmTo0KHmnf5sybXUz87ODnt7+2tOkiQZEEIlr7zyCgCLFy++4PNr1qzh4MGD/PHHHwQGBtKzZ09effVVnn32WV5++WUcHBz49NNPadOmDe+99x4AnTt3ZvPmzXzwwQeSDAiLpNFo0Ol0V9To2dnZUVVVhZOTk00mA5ZQP9u7+SKEjYiLi6N79+4EBgaaHxs1ahRFRUUcOHDAXGb48OF1jhs1ahRxcXHNGqsQwro1uGdAr9c3SQA1522q86tN6mf9mrqONd2l558/IyODgICAOo/7+PgAkJaWRrdu3cjMzMTPz69OGV9fX4qKiigqKsLZ2bne61VUVFBRUWH+OS8vz/z6tngd5T1q/aR+16YhvQ0NTgZiY2OvKZjLWbt2bZOeX21SP+vXkDr+97//Zfny5Zcs8/HHH9O6dWvzz3v27EGv19f7G0tNTeX06dN1Hq9pxHfu3InRaKS0tJQjR47UKRMfHw/AqlWrcHR0rPf6S5cu5bvvvqv3+Lp163BxcblsHa2VvEetn9Tv6owfP/6yZRqcDIwZM+aagrkYvV7P2rVrGTFihE3eC5L6Wb8rqWPfvn15+eWXL1mmbdu2daYA5ebmotPp6v2N7dixg5UrV9Z5PDk5GYBx48YRHR1N27Zt8fb2rlPm9OnTeHh4MHHixAu+/rBhw1iwYIH557y8PDp06MANN9yAr6/vJWO3RvIetX5Sv6anURRFUeWVhRCAaQDhrFmz6k0t/P333xk3bhyZmZkEBJi2+P7888+ZM2cOOTk5ODo68uyzzxIbG8u+ffvMx/39738nLy+PVatWNej1i4qK8PT0pLCwEA8Pj0arlxDCesgAQiFUkpqaSmJiIqmpqRgMBhITE0lMTKS4uBiAkSNH0qVLF6ZOncqePXtYvXo1c+fOZcaMGebu/4cffpgTJ07wzDPPcPjwYf7973/z/fffM3v27AbH4e7uTmFhIe7u7k1STyGE5ZOeASFUcs899/DVV1/Ve3zdunVcf/31AJw8eZJHHnmE9evX4+rqyrRp05g/f369RYdmz57NwYMHad26NS+88IIsOiSEuCKSDAghhBAtnNwmEEIIIVo4SQaEEEKIFk6SASGEEKKFk2RACCGEaOEkGRBCCCFaOEkGhBBCiBZOkgEhhBCihZNkQAghhGjhJBkQQgghWjhJBoQQQogWTpIBIYQQooWTZEAIIYRo4f4fSgtmGQlFP88AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_range = 10\n",
    "X5 = torch.linspace(-sample_range, sample_range, 21, requires_grad=True)\n",
    "fX5 = 4 * X5**2\n",
    "fX5.sum().backward()\n",
    "\n",
    "plt_derivation(X5, fX5, x_label=\"X_5\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9ea104f",
   "metadata": {},
   "source": [
    "We can use the same approach to plot and calculate gradients of our more advanced function that takes two variables and has two derivations.\n",
    "\n",
    "Note how we create a grid of (repeated) U and V values (feel free to print their values) to properly vectorize the ` ` fUV ` ` function (apply it over all combinations of $u$ and $v$ values).\n",
    "\n",
    "To keep the gradient backtracking functionality, we are not allowed to use any non-PyTorch methods or for example regular ` `for` `-loops. This way, calculation will also be a lot faster.\n",
    "\n",
    "By default, gradients will only be calculated for the starting nodes (\"leafs\") of the \"computation graph\" that PyTorch creates (U and V in this case). If we want to take a look at gradients of intermediate variables, we need to explicitly tell PyTorch to retain the calculated gradient for this variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8e8f4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_derivation_3d(u, v, y, u_label=\"U\", v_label=\"V\"):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(projection=\"3d\")\n",
    "    # ax.set_proj_type('ortho') # ax.view_init(elev=0, azim=-90, roll=0)\n",
    "    for z_label, Z in {\"f\": y, \"f'_u\": u.grad, \"f'_v\": v.grad}.items():\n",
    "        s = ax.plot_surface(\n",
    "            X=u.detach().numpy(),\n",
    "            Y=v.detach().numpy(),\n",
    "            Z=Z.detach().numpy(),\n",
    "            label=f\"${z_label}({u_label},{v_label})$\",\n",
    "            alpha=0.4,\n",
    "        )\n",
    "        # quick fix for bug in some matplotlib versions:\n",
    "        s._facecolors2d, s._edgecolors2d = s._facecolor3d, s._edgecolor3d\n",
    "    ax.legend()\n",
    "    ax.update({\"xlabel\": u_label, \"ylabel\": v_label, \"zlabel\": \"f\"})\n",
    "    return plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63617193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_range = 5\n",
    "U = torch.linspace(-sample_range, sample_range, 21, requires_grad=True)\n",
    "#V = torch.linspace(-sample_range, sample_range, 21, requires_grad=True)\n",
    "\n",
    "U_grid, V_grid = torch.meshgrid((U, U), indexing=\"xy\")\n",
    "U_grid.retain_grad()\n",
    "V_grid.retain_grad()\n",
    "\n",
    "fUV = 2 * U_grid**4 + 3 * V_grid**3 + 2 * U_grid * V_grid\n",
    "fUV.sum().backward()\n",
    "\n",
    "plt_derivation_3d(U_grid, V_grid, fUV)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aac54773",
   "metadata": {},
   "source": [
    "We can use this \"autograd\" functionality for any kind of tensors and chain operations as we want.\n",
    "\n",
    "As you see, with every operation, a function ` ` grad_fn ` ` is passed to the resulting tensor, allowing us to perform the backwards step starting from the last element:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68dfb569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  tensor([0., 1., 2.], requires_grad=True)\n",
      "+ tensor([4., 5., 6.], requires_grad=True)\n",
      "= tensor([4., 6., 8.], grad_fn=<AddBackward0>)\n",
      "+ 2\n",
      "= tensor([ 6.,  8., 10.], grad_fn=<AddBackward0>)\n",
      "^ tensor([0., 1., 2.], requires_grad=True)\n",
      "= tensor([  1.,   8., 100.], grad_fn=<PowBackward1>)\n",
      "-----------------------------------------------------\n",
      "grad(x6) = tensor([  1.7918,  17.6355, 250.2585])\n",
      "grad(x7) = tensor([ 0.,  1., 20.])\n"
     ]
    }
   ],
   "source": [
    "x6 = torch.arange(3, dtype=torch.float32, requires_grad=True)\n",
    "x7 = torch.arange(4, 7, dtype=torch.float32).requires_grad_()\n",
    "\n",
    "a1 = x6 + x7\n",
    "a2 = a1 + 2\n",
    "a3 = a2**x6\n",
    "print(f\"  {x6}\\n+ {x7}\\n= {a1}\\n+ 2\\n= {a2}\\n^ {x6}\\n= {a3}\")\n",
    "\n",
    "a3.sum().backward()\n",
    "print(\"-\" * 53 + f\"\\ngrad(x6) = {x6.grad}\\ngrad(x7) = {x7.grad}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f841b220",
   "metadata": {},
   "source": [
    "### 1.3:  Gradient Exercises\n",
    "\n",
    "1. Calculate the derivative $f'(x)$ and $f'(4)$ of $ f(x) = 8x^4 + 4x^2 + x $ by hand using no code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a806ad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Answer\n",
    "# 32x^3 + 8x + 1\n",
    "\n",
    "# 4 = \n",
    "\n",
    "# 2081\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de8fbe8e",
   "metadata": {},
   "source": [
    "2. Implement $f(x)$ as a python method and calculate the derivative $f'(4)$ using PyTorch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94b11415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f'(4) = 2081.0\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement\n",
    "\n",
    "x = torch.tensor(4.0, requires_grad=True)\n",
    "f = 8 * (x**4) + 4 * (x**2) + x\n",
    "\n",
    "f.backward()\n",
    "\n",
    "\"\"\"def f(x):\n",
    "    return 8*x**4 + 4*x**2 + x\n",
    "    \n",
    "print(f(1))\"\"\"\n",
    "print(\"f'(4) =\", x.grad.item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fd51d4c",
   "metadata": {},
   "source": [
    "3. Plot $f(x)$ and $f'(x)$ for $x\\in[-15, 30]$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cd5884d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'fX_t = 8 * x**4 + 4 * x**2 + x\\nf_der = fX_t.backward()\\nprint()'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Implement\n",
    "\n",
    " \n",
    "x_values = torch.linspace(-15, 30, 20, requires_grad=True)\n",
    "\n",
    "f = 8 * (x_values**4) + 4 * (x_values**2) + x_values\n",
    "f.sum().backward()\n",
    "\n",
    "plt_derivation(x_values, f)\n",
    "\n",
    "\n",
    "\"\"\"fX_t = 8 * x**4 + 4 * x**2 + x\n",
    "f_der = fX_t.backward()\n",
    "print()\"\"\"\n",
    "\n",
    "#plt_derivation(X_t, fX_t)\n",
    "#ist richtig so sieht weird aus wegen dem Scaling der Y-Achse\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3122c007-f55b-4713-802c-6559d941e96c",
   "metadata": {},
   "source": [
    "## 2: Classifying the Iris Dataset\n",
    "\n",
    "Using the basics learned above, we can now load the Iris dataset into PyTorch tensors.\n",
    "\n",
    "### 2.1:  Load and Preprocess the Dataset\n",
    "\n",
    "1. Load the Iris dataset and modify it to only seperate if something is of class _setosa_ or not. Call this _binary iris_ dataset _biris_ and the variables ``biris_X``, and ``biris_y``. Create a list ``biris_data`` of tuples containing the X values and the corresponding true/false label for each row.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "72eb7477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n",
      "(array([5.1, 3.5, 1.4, 0.2]), np.True_)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement\n",
    "biris = pd.read_csv(\n",
    "    \"data/iris.data\",\n",
    "    header=None,\n",
    "    sep=\",\",\n",
    "    names=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"class\"]\n",
    ")\n",
    "biris_X = biris.iloc[:, 0:4].values\n",
    "biris_Y = (biris[\"class\"] == \"Iris-setosa\").map(bool)\n",
    "\n",
    "print(biris_X.shape)\n",
    "print(biris_Y.shape)\n",
    "biris_data = []\n",
    "for index, i in enumerate(biris_X):\n",
    "    biris_data.append((biris_X[index], biris_Y[index]))\n",
    "\n",
    "#display(biris_data)\n",
    "print(biris_data[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5dc2fff1",
   "metadata": {},
   "source": [
    "2. Convert ``biris_X`` and ``biris_y`` to PyTorch tensors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "903fa34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False])\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement\n",
    "tensor_X = torch.tensor(biris_X)\n",
    "tensor_Y = torch.tensor(biris_Y)\n",
    "\n",
    "#print(tensor_X)\n",
    "print(tensor_Y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60cbf1a1",
   "metadata": {},
   "source": [
    "### 2.2:  Logistic Regression\n",
    "\n",
    "We want to perform a binary classification using a logistic regression and the sigmoid function. In a logistic regression, for each feature weights are learned.\n",
    "\n",
    "1. Define a python method ``sigmoid(x)`` that implements the sigmoid function (using PyTorch methods). Compare it to the ``torch.sigmoid`` method for values $x\\in[-5,5]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cc7cfd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([0.0067, 0.0074, 0.0082, 0.0090, 0.0100, 0.0110, 0.0122, 0.0135, 0.0149,\n",
      "        0.0164, 0.0182, 0.0201, 0.0221, 0.0244, 0.0270, 0.0297, 0.0328, 0.0362,\n",
      "        0.0399, 0.0439, 0.0483, 0.0532, 0.0585, 0.0644, 0.0707, 0.0776, 0.0852,\n",
      "        0.0934, 0.1023, 0.1120, 0.1224, 0.1337, 0.1458, 0.1589, 0.1728, 0.1878,\n",
      "        0.2036, 0.2205, 0.2384, 0.2572, 0.2770, 0.2976, 0.3192, 0.3415, 0.3646,\n",
      "        0.3883, 0.4125, 0.4372, 0.4622, 0.4874, 0.5126, 0.5378, 0.5628, 0.5875,\n",
      "        0.6117, 0.6354, 0.6585, 0.6808, 0.7024, 0.7230, 0.7428, 0.7616, 0.7795,\n",
      "        0.7964, 0.8122, 0.8272, 0.8411, 0.8542, 0.8663, 0.8776, 0.8880, 0.8977,\n",
      "        0.9066, 0.9148, 0.9224, 0.9293, 0.9356, 0.9415, 0.9468, 0.9517, 0.9561,\n",
      "        0.9601, 0.9638, 0.9672, 0.9703, 0.9730, 0.9756, 0.9779, 0.9799, 0.9818,\n",
      "        0.9836, 0.9851, 0.9865, 0.9878, 0.9890, 0.9900, 0.9910, 0.9918, 0.9926,\n",
      "        0.9933])\n",
      "tensor([0.0067, 0.0074, 0.0082, 0.0090, 0.0100, 0.0110, 0.0122, 0.0135, 0.0149,\n",
      "        0.0164, 0.0182, 0.0201, 0.0221, 0.0244, 0.0270, 0.0297, 0.0328, 0.0362,\n",
      "        0.0399, 0.0439, 0.0483, 0.0532, 0.0585, 0.0644, 0.0707, 0.0776, 0.0852,\n",
      "        0.0934, 0.1023, 0.1120, 0.1224, 0.1337, 0.1458, 0.1589, 0.1728, 0.1878,\n",
      "        0.2036, 0.2205, 0.2384, 0.2572, 0.2770, 0.2976, 0.3192, 0.3415, 0.3646,\n",
      "        0.3883, 0.4125, 0.4372, 0.4622, 0.4874, 0.5126, 0.5378, 0.5628, 0.5875,\n",
      "        0.6117, 0.6354, 0.6585, 0.6808, 0.7024, 0.7230, 0.7428, 0.7616, 0.7795,\n",
      "        0.7964, 0.8122, 0.8272, 0.8411, 0.8542, 0.8663, 0.8776, 0.8880, 0.8977,\n",
      "        0.9066, 0.9148, 0.9224, 0.9293, 0.9356, 0.9415, 0.9468, 0.9517, 0.9561,\n",
      "        0.9601, 0.9638, 0.9672, 0.9703, 0.9730, 0.9756, 0.9779, 0.9799, 0.9818,\n",
      "        0.9836, 0.9851, 0.9865, 0.9878, 0.9890, 0.9900, 0.9910, 0.9918, 0.9926,\n",
      "        0.9933])\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement\n",
    "\n",
    "x = torch.linspace(-5, 5, steps=100)\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "\n",
    "torch_sigmoid = torch.sigmoid(x)\n",
    "own_sigmoid = sigmoid(x)\n",
    "print(torch.allclose(torch_sigmoid, own_sigmoid))\n",
    "print(torch_sigmoid)\n",
    "print(own_sigmoid)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8fa95f80",
   "metadata": {},
   "source": [
    "2. For the logistic regression, we will need to pass both weights and data to the logistic function. Define a method ``logistic(w, x)`` that passes the result of a matrix multiplication of data and weights (``x @ w``) to the sigmoid function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "99974da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement\n",
    "def logistic(w, x):\n",
    "    return sigmoid(x @ w)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35d2f606",
   "metadata": {},
   "source": [
    "3. Call the logistic function using ``biris_X`` and random weights. Save the predictions in the variable ``y_pred_random``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3450b2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.8540,  0.8143, -2.0645,  0.9981], dtype=torch.float64)\n",
      "torch.Size([150])\n",
      "tensor([9.1811e-05, 8.8531e-05, 1.8556e-04, 1.3625e-04, 1.1989e-04, 4.7923e-05,\n",
      "        2.3626e-04, 8.2869e-05, 2.0619e-04, 7.0707e-05, 5.0401e-05, 9.7669e-05,\n",
      "        9.6441e-05, 4.5255e-04, 5.6943e-05, 6.2394e-05, 1.0944e-04, 1.0145e-04,\n",
      "        2.2924e-05, 1.0536e-04, 2.6123e-05, 1.0731e-04, 5.7448e-04, 5.6656e-05,\n",
      "        5.2578e-05, 4.8672e-05, 8.2305e-05, 6.2049e-05, 7.0311e-05, 9.9894e-05,\n",
      "        7.6501e-05, 4.8198e-05, 9.1531e-05, 7.7339e-05, 7.0707e-05, 1.3080e-04,\n",
      "        5.3765e-05, 7.0707e-05, 2.7495e-04, 6.8846e-05, 1.5010e-04, 1.4275e-04,\n",
      "        3.2357e-04, 1.0901e-04, 5.0981e-05, 1.1775e-04, 7.7568e-05, 1.8169e-04,\n",
      "        6.0666e-05, 9.3903e-05, 7.7346e-09, 3.9283e-08, 6.2751e-09, 2.3023e-07,\n",
      "        1.9167e-08, 8.5048e-08, 3.7508e-08, 2.3889e-06, 1.4149e-08, 7.5541e-07,\n",
      "        9.4819e-07, 1.5669e-07, 6.2253e-08, 3.2136e-08, 7.1199e-07, 2.3099e-08,\n",
      "        1.4710e-07, 1.1025e-07, 2.5210e-08, 2.2664e-07, 7.2087e-08, 1.1373e-07,\n",
      "        1.1709e-08, 2.4262e-08, 3.8083e-08, 2.5630e-08, 6.5818e-09, 8.3238e-09,\n",
      "        6.4591e-08, 4.2216e-07, 3.0913e-07, 3.4392e-07, 2.0342e-07, 1.7572e-08,\n",
      "        2.1313e-07, 1.0724e-07, 1.3739e-08, 2.2876e-08, 2.7514e-07, 2.7095e-07,\n",
      "        1.1649e-07, 4.2856e-08, 1.5253e-07, 1.8294e-06, 1.7530e-07, 1.6828e-07,\n",
      "        1.7140e-07, 5.5177e-08, 3.6716e-06, 1.9422e-07, 6.2904e-09, 3.4349e-08,\n",
      "        9.2196e-10, 5.1572e-09, 3.8091e-09, 8.6003e-11, 4.3761e-07, 1.9039e-10,\n",
      "        1.1737e-09, 1.2316e-09, 1.5577e-08, 7.4729e-09, 3.6720e-09, 4.7720e-08,\n",
      "        6.1379e-08, 1.6738e-08, 4.7469e-09, 1.2320e-10, 3.3904e-11, 1.3011e-08,\n",
      "        2.9006e-09, 9.0152e-08, 4.4695e-11, 1.8591e-08, 3.7342e-09, 5.4353e-10,\n",
      "        2.9843e-08, 3.4390e-08, 5.3281e-09, 5.7163e-10, 2.4345e-10, 1.2938e-10,\n",
      "        5.8874e-09, 9.8924e-09, 3.9261e-09, 2.4490e-10, 1.4104e-08, 6.1986e-09,\n",
      "        5.0887e-08, 4.0683e-09, 5.2622e-09, 9.2275e-09, 3.4349e-08, 2.3104e-09,\n",
      "        5.5666e-09, 1.0025e-08, 1.4199e-08, 1.0767e-08, 2.3218e-08, 3.2972e-08],\n",
      "       dtype=torch.float64)\n",
      "tensor([[5.1000, 3.5000, 1.4000, 0.2000],\n",
      "        [4.9000, 3.0000, 1.4000, 0.2000],\n",
      "        [4.7000, 3.2000, 1.3000, 0.2000],\n",
      "        [4.6000, 3.1000, 1.5000, 0.2000],\n",
      "        [5.0000, 3.6000, 1.4000, 0.2000]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement\n",
    "\n",
    "w_random = torch.randn((4), dtype=torch.double)\n",
    "print(w_random)\n",
    "\n",
    "y_pred_random = logistic(w_random, tensor_X)\n",
    "print(y_pred_random.shape)\n",
    "print(y_pred_random[:])\n",
    "print(tensor_X[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba7e2fa6",
   "metadata": {},
   "source": [
    "4. Of course, in reality, the weights should be updated in an iterative process. For this, we will need a loss function. Implement the binary cross entropy loss $$ L_{BCE} = - \\frac{1}{n} \\sum^n_{i=1}\\left(Y_i\\cdot \\log\\hat{Y_i} + (1-Y_i) \\cdot \\log(1-\\hat{Y_i})\\right) $$ (with the predicted labels $\\hat{Y}$ and the groundtruth labels $Y$) in a python method ``bce(y, y_hat)`` using PyTorch methods. Make use of built-in aggregation methods and vectorized methods instead of using ``for``-loops. Note: As calculating the BCE loss is known to be numerically unstable, clamp the output of each $\\log$ to be $\\geq - 100$ (read more [here](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d9ae0b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement\n",
    "def bce(y, y_hat):\n",
    "   return - torch.mean(y * torch.log(y_hat) + (1- y) * torch.log(1- y_hat))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7200f258",
   "metadata": {},
   "source": [
    "5. Evaluate the prediction ``y_pred_random`` using the bce loss function. \n",
    "Compare your own loss value to the output of the method ``torch.nn.functional.binary_cross_entropy(Y_hat, Y)`` (which requires ``Y`` to be of type float).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6def519d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150])\n",
      "torch.Size([150])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.0922, dtype=torch.float64)\n",
      "tensor(3.0922, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement\n",
    "print(y_pred_random.shape)\n",
    "print(tensor_Y.shape)\n",
    "display(tensor_Y)\n",
    "\n",
    "tensor_Y = tensor_Y.type(torch.DoubleTensor)\n",
    "display(tensor_Y)\n",
    "bce_original = torch.nn.functional.binary_cross_entropy(y_pred_random,tensor_Y )\n",
    "bce_ours = bce(tensor_Y, y_pred_random)\n",
    "\n",
    "print(bce_original)\n",
    "print(bce_ours)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "405beb4e",
   "metadata": {},
   "source": [
    "6. Create a new random weight tensor ``w``, but this time enable ``requires_grad``. For the given ``biris_X``, ``biris_y`` and the random weigths ``w`` create a combined loss function $L(X, y, w)$, similar to $f(U,V)$ earlier. Call ``backward()`` on this method instance and print partial derivative $L'_w(X, Y, w) = $ ``w.grad``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8fd454c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor([2.0322, 0.5714, 2.4096, 0.9093], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement\n",
    "w_random_grad_enabled = torch.randn((4), dtype=torch.double, requires_grad=True)\n",
    "print(w_random_grad_enabled.grad)\n",
    "#wtest = w_random_grad_enabled.clone().detach()\n",
    "def loss(X, y, w):\n",
    "    y_pred_random2 = logistic(  w, X)\n",
    "   \n",
    "    loss = bce(y, y_pred_random2)\n",
    "    loss.backward()\n",
    "    print(w.grad)\n",
    "    return loss\n",
    "\n",
    "\n",
    "loss1 = loss(tensor_X, tensor_Y, w_random_grad_enabled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65fa39a1",
   "metadata": {},
   "source": [
    "7. Perform a single weight update step by subtracting the calculated gradient from the previous weight vector w. Predict ``y_pred_learned`` by running the logistic function with the updated weights. Evaluate the predictions using the bce loss function. If the loss increases, try multiplying the gradient with a learning rate, e.g. 0.001 before subtracting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d1aa94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  tensor([-1.1229, -0.1863,  2.2082, -0.6380], dtype=torch.float64,\n",
      "       requires_grad=True) \n",
      "w gradient:  tensor([2.0322, 0.5714, 2.4096, 0.9093], dtype=torch.float64)\n",
      "tensor([-1.3261, -0.2435,  1.9672, -0.7289], dtype=torch.float64)  substracted\n",
      "2.6445847387058046\n",
      "1.9355410257867864\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement\n",
    "#print(wtest)\n",
    "print(\"w: \", w_random_grad_enabled , \"\\nw gradient: \", w_random_grad_enabled.grad)\n",
    "\n",
    "gradient_with_learning_rate = w_random_grad_enabled.grad * 0.1\n",
    "with torch.no_grad():\n",
    "    new_w = w_random_grad_enabled.subtract(gradient_with_learning_rate)\n",
    "print(new_w, \" substracted\")\n",
    "y_pred_learned = logistic(new_w, tensor_X)\n",
    "\n",
    "lossf = torch.nn.functional.binary_cross_entropy(y_pred_learned, tensor_Y)\n",
    "#lossf.backward()\n",
    "print(loss1.item())\n",
    "print(lossf.item())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bbd4d698",
   "metadata": {},
   "source": [
    "8. To perform multiple weight update steps, the gradient descent algorithm is used. Run the given method with the fixed learning rate $\\alpha=0.01$ and randomly initialized weights to retrieve learned weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd9faa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd(modelfunc, lossfunc, X, y, w0, alpha, max_epochs=500):\n",
    "    \"\"\"Gradient Descent Algorithm\n",
    "\n",
    "    This basic method is given given here, you can implement and improve it by yourself in the optimization lab.\n",
    "\n",
    "    For each epoch:\n",
    "        - forward-step (predict labels and calculate loss)\n",
    "        - backward-step (perform backpropagation)\n",
    "        - update weights (create new weight tensor with resetted gradient tracking)\n",
    "        - log weight history\n",
    "\n",
    "    \"\"\"\n",
    "    w = w0.clone().detach().requires_grad_()\n",
    "    for k in range(max_epochs):\n",
    "        pred = modelfunc(w, X)\n",
    "        loss = lossfunc(y, pred)\n",
    "        loss.backward()\n",
    "        direction_of_descent = -w.grad\n",
    "        w = w + alpha * direction_of_descent\n",
    "        w.grad = None\n",
    "        w.retain_grad()\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36904c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement\n",
    "w_init = torch.randn((4,), dtype=torch.double) \n",
    "alpha = 0.01 \n",
    "\n",
    "learned_w = gd(logistic, bce, tensor_X, tensor_Y, w_init, alpha)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81eb0248",
   "metadata": {},
   "source": [
    "9. Use the gradient-descent learned weights to predict ``y_pred_gd_``. Evaluate using the bce loss function (the error should be even lower).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "229eaefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1190, dtype=torch.float64, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Gelerntes w: tensor([0.8400, 0.7765, 0.8172, 0.7625, 0.8487, 0.8395, 0.8214, 0.8097, 0.7517,\n",
      "        0.7681, 0.8493, 0.7864, 0.7735, 0.8219, 0.9147, 0.9106, 0.8944, 0.8407,\n",
      "        0.8331, 0.8553, 0.7782, 0.8461, 0.8964, 0.7608, 0.7195, 0.7343, 0.7922,\n",
      "        0.8249, 0.8310, 0.7569, 0.7446, 0.8186, 0.8820, 0.9047, 0.7681, 0.8394,\n",
      "        0.8614, 0.7681, 0.7868, 0.8115, 0.8547, 0.6854, 0.8118, 0.8064, 0.7858,\n",
      "        0.7753, 0.8390, 0.7966, 0.8478, 0.8162, 0.0945, 0.1105, 0.0701, 0.0910,\n",
      "        0.0755, 0.0764, 0.0948, 0.1872, 0.0812, 0.1300, 0.1183, 0.1257, 0.0882,\n",
      "        0.0690, 0.2073, 0.1179, 0.0881, 0.1099, 0.0528, 0.1167, 0.0764, 0.1369,\n",
      "        0.0421, 0.0636, 0.1102, 0.1089, 0.0620, 0.0575, 0.0857, 0.1888, 0.1199,\n",
      "        0.1325, 0.1371, 0.0377, 0.0861, 0.1221, 0.0856, 0.0637, 0.1340, 0.1047,\n",
      "        0.0720, 0.0829, 0.1153, 0.1774, 0.0980, 0.1213, 0.1138, 0.1079, 0.2689,\n",
      "        0.1182, 0.0224, 0.0374, 0.0216, 0.0256, 0.0228, 0.0100, 0.0573, 0.0126,\n",
      "        0.0156, 0.0278, 0.0589, 0.0317, 0.0334, 0.0359, 0.0413, 0.0471, 0.0317,\n",
      "        0.0167, 0.0052, 0.0289, 0.0314, 0.0498, 0.0076, 0.0496, 0.0327, 0.0223,\n",
      "        0.0592, 0.0604, 0.0243, 0.0240, 0.0150, 0.0241, 0.0245, 0.0418, 0.0195,\n",
      "        0.0185, 0.0384, 0.0338, 0.0669, 0.0408, 0.0321, 0.0582, 0.0374, 0.0245,\n",
      "        0.0334, 0.0471, 0.0383, 0.0454, 0.0476, 0.0470], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Finaler Loss: 0.11900796114605704\n",
      "Loss nach einem Step: 1.9355410257867864\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement\n",
    "y_pred_gd_ =  logistic(learned_w, tensor_X)\n",
    "final_loss = torch.nn.functional.binary_cross_entropy(y_pred_gd_, tensor_Y)\n",
    "print(final_loss)\n",
    "print(\"Gelerntes w:\", y_pred_gd_)\n",
    "print(\"Finaler Loss:\", final_loss.item())\n",
    "print(\"Loss nach einem Step:\", lossf.item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3920b90c",
   "metadata": {},
   "source": [
    "10. When you round the output of the logistic function to either 0 or 1, you get the predicted class. Calculate the prediction accuracy for each set of predictions we had so far (``y_pred_random``, ``y_pred_learned`` and ``y_pred_gd``)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "babd3a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0058, 0.0149, 0.0147, 0.0084, 0.0142, 0.0104, 0.0091, 0.0138, 0.0059,\n",
      "        0.0080, 0.1375, 0.1814, 0.2045, 0.2825, 0.2066, 0.4169, 0.2539, 0.2110,\n",
      "        0.2048, 0.2888, 0.2767, 0.2002, 0.2055, 0.3613, 0.1195, 0.1188, 0.4020,\n",
      "        0.2666, 0.2693, 0.2379, 0.3841, 0.1359, 0.3973, 0.4014, 0.1569, 0.1362,\n",
      "        0.2181, 0.2654, 0.2884, 0.1156], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement\n",
    "print(y_pred_learned[40:80])\n",
    "y_pred_learned_rounded = torch.round(y_pred_learned)\n",
    "print(y_pred_learned_rounded[40:80])\n",
    "\n",
    "#print(y_pred_random)\n",
    "y_pred_random_rounded = torch.round(y_pred_random)\n",
    "y_pred_gd_rounded = torch.round(y_pred_gd_)\n",
    "print(y_pred_random_rounded[:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ae88e02",
   "metadata": {},
   "source": [
    "11. Write a new gradient descent method ``gdi`` that saves the weights and the loss in each epoch (and returns lists of both in the end).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "731f4148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gdi(modelfunc, lossfunc, X, y, w0, alpha, max_epochs=500):\n",
    "    # TODO: Implement\n",
    "    w_history = []\n",
    "    l_history = []\n",
    "\n",
    "    w = w0.clone().detach().requires_grad_()\n",
    "    for k in range(max_epochs):\n",
    "        pred = modelfunc(w, X)\n",
    "        loss = lossfunc(y, pred)\n",
    "        loss.backward()\n",
    "        direction_of_descent = -w.grad\n",
    "        w = w + alpha * direction_of_descent\n",
    "        w.grad = None\n",
    "        w.retain_grad()\n",
    "        w_history.append(w)\n",
    "        l_history.append(loss)\n",
    "    return w_history, l_history\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81622be5",
   "metadata": {},
   "source": [
    "12. Write a method ``visualize_error(errors)`` to visualize the loss in each epoch. Train ``gdi`` for 1000 epochs on biris and plot the error for each epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad10bf39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqYAAAHWCAYAAAClsUvDAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAS0xJREFUeJzt3Xl8VNX9//H37NkTwpKwhH0TWUVB1tKyKFjFrValgv60fm3B5Uu1aq0VWi0uX61VW9T2q9Vvi1ZR3EUiKIgFZFdQkEUQISEEyE4mk8z5/ZHMkBiWzOQmMwOv5+Mxj8ycuXPvZ3KMvj33nnNtxhgjAAAAIMLskS4AAAAAkAimAAAAiBIEUwAAAEQFgikAAACiAsEUAAAAUYFgCgAAgKhAMAUAAEBUIJgCAAAgKhBMAQAAEBUIpgAAS+3atUs2m03/8z//E+lSAMQYgimAqPGPf/xDNptNa9asiXQpUS0Q/I73ePDBByNdIgCExRnpAgAA4bnqqqs0adKkeu2DBg2KQDUA0HgEUwBoRpWVlfL7/XK73Y3e11lnnaWf/exnFlQFANGBU/kAYs769es1ceJEpaSkKCkpSWPHjtXKlSvrbOPz+TR79mz16NFDcXFxatmypUaOHKns7OzgNrm5ubruuuvUoUMHeTwetW3bVpMnT9auXbtOePxrr71WSUlJ2rlzp8477zwlJiaqXbt2+v3vfy9jTHC72tdaPv744+rWrZs8Ho++/PJLSdKSJUs0atQoJSYmKi0tTZMnT9ZXX31l3S9KUufOnfXjH/9YixYt0sCBAxUXF6c+ffro9ddfr7ftzp079ZOf/ETp6elKSEjQueeeq3fffbfeduXl5Zo1a5Z69uypuLg4tW3bVpdeeql27NhRb9tnn302+L3POeccrV69ut42W7Zs0eWXX6709HTFxcXp7LPP1ltvvWXNLwBATGHEFEBM2bx5s0aNGqWUlBT9+te/lsvl0jPPPKMxY8Zo6dKlGjp0qCRp1qxZmjNnjm644QYNGTJERUVFWrNmjdatW6fx48dLki677DJt3rxZN998szp37qy8vDxlZ2fr22+/VefOnU9YR1VVlc4//3yde+65evjhh7Vw4ULdd999qqys1O9///s62z7//PMqLy/XjTfeKI/Ho/T0dH344YeaOHGiunbtqlmzZunIkSN68sknNWLECK1bt+6kx5eksrIy5efn12tPS0uT03n0X+/btm3TT3/6U910002aNm2ann/+ef3kJz/RwoULg7+L/fv3a/jw4SorK9Mtt9yili1b6oUXXtBFF12k+fPn65JLLgl+7x//+MdavHixrrzySt16660qLi5Wdna2Nm3apG7dugWPO2/ePBUXF+u//uu/ZLPZ9PDDD+vSSy/Vzp075XK5gv05YsQItW/fXnfddZcSExP1yiuv6OKLL9Zrr70WPC6A04QBgCjx/PPPG0lm9erVx93m4osvNm632+zYsSPYtm/fPpOcnGxGjx4dbBswYIC54IILjrufw4cPG0nmkUceCbnOadOmGUnm5ptvDrb5/X5zwQUXGLfbbQ4cOGCMMeabb74xkkxKSorJy8urs4+BAweaNm3amIMHDwbbNm7caOx2u5k6deoJjx/Y7/EeK1asCG7bqVMnI8m89tprwbbCwkLTtm1bM2jQoGDbbbfdZiSZTz75JNhWXFxsunTpYjp37myqqqqMMcY899xzRpJ57LHH6tXl9/vr1NeyZUtz6NCh4PtvvvmmkWTefvvtYNvYsWNNv379THl5eZ39DB8+3PTo0eOEvwcApx5O5QOIGVVVVVq0aJEuvvhide3aNdjetm1bXX311Vq+fLmKiookVY8abt68Wdu2bTvmvuLj4+V2u/Xxxx/r8OHDYdUzY8aM4HObzaYZM2aooqJCH374YZ3tLrvsMrVu3Tr4OicnRxs2bNC1116r9PT0YHv//v01fvx4vffeew06/o033qjs7Ox6jz59+tTZrl27dnVGHlNSUjR16lStX79eubm5kqT33ntPQ4YM0ciRI4PbJSUl6cYbb9SuXbuClx+89tpratWqlW6++eZ69dhstjqvf/rTn6pFixbB16NGjZJUfcmAJB06dEhLlizRFVdcoeLiYuXn5ys/P18HDx7Ueeedp23btmnv3r0N+l0AODUQTAHEjAMHDqisrEy9evWq994ZZ5whv9+vPXv2SJJ+//vfq6CgQD179lS/fv10xx136PPPPw9u7/F49NBDD+n9999XRkaGRo8erYcffjgY1E7GbrfXCceS1LNnT0mqd41qly5d6rzevXu3JB33e+Tn56u0tPSkNfTo0UPjxo2r90hJSamzXffu3euFxu/Xunv37uPWU7vmHTt2qFevXnUuFTiejh071nkdCKmB/xHYvn27jDG699571bp16zqP++67T5KUl5d30uMAOHUQTAGckkaPHq0dO3boueeeU9++ffX3v/9dZ511lv7+978Ht7ntttv09ddfa86cOYqLi9O9996rM844Q+vXr7e0lvj4eEv3FyscDscx203NBDG/3y9Juv3224858pudna3u3bs3W70AIo/JTwBiRuvWrZWQkKCtW7fWe2/Lli2y2+3KysoKtqWnp+u6667Tddddp5KSEo0ePVqzZs3SDTfcENymW7du+tWvfqVf/epX2rZtmwYOHKhHH31U//znP09Yi9/v186dO4Mjj5L09ddfS9JJJy516tRJko77PVq1aqXExMQT7iMUgZHJ2qOm36+1U6dOx62nds3dunXTqlWr5PP5ghOYwhUYcXa5XBo3blyj9gXg1MCIKYCY4XA4NGHCBL355pt1Tpfv379f8+bN08iRI4OnsQ8ePFjns0lJSerevbu8Xq+k6hnt5eXldbbp1q2bkpOTg9uczFNPPRV8bozRU089JZfLpbFjx57wc23bttXAgQP1wgsvqKCgINi+adMmLVq06JiL5jfGvn37tGDBguDroqIivfjiixo4cKAyMzMlSZMmTdJnn32mFStWBLcrLS3Vs88+q86dOwevW73sssuUn59f57sHmFpLZTVEmzZtNGbMGD3zzDPKycmp9/6BAwdC2h+A2MeIKYCo89xzz2nhwoX12m+99Vbdf//9ys7O1siRI/XLX/5STqdTzzzzjLxerx5++OHgtn369NGYMWM0ePBgpaena82aNZo/f35wwtLXX3+tsWPH6oorrlCfPn3kdDq1YMEC7d+/X1deeeVJa4yLi9PChQs1bdo0DR06VO+//77effdd/eY3v6kz0el4HnnkEU2cOFHDhg3T9ddfH1wuKjU1VbNmzWrQ72ndunXHHNnt1q2bhg0bFnzds2dPXX/99Vq9erUyMjL03HPPaf/+/Xr++eeD29x111166aWXNHHiRN1yyy1KT0/XCy+8oG+++Uavvfaa7PbqcYypU6fqxRdf1MyZM/XZZ59p1KhRKi0t1Ycffqhf/vKXmjx5coNqD/jLX/6ikSNHql+/fvr5z3+url27av/+/VqxYoW+++47bdy4MaT9AYhxEV0TAABqCSwXdbzHnj17jDHGrFu3zpx33nkmKSnJJCQkmB/+8IfmP//5T5193X///WbIkCEmLS3NxMfHm969e5sHHnjAVFRUGGOMyc/PN9OnTze9e/c2iYmJJjU11QwdOtS88sorJ61z2rRpJjEx0ezYscNMmDDBJCQkmIyMDHPfffcFl1Uy5uiyScdbkurDDz80I0aMMPHx8SYlJcVceOGF5ssvvzzp8U+2XNS0adOC23bq1MlccMEF5oMPPjD9+/c3Ho/H9O7d27z66qv19rtjxw5z+eWXm7S0NBMXF2eGDBli3nnnnXrblZWVmXvuucd06dLFuFwuk5mZaS6//PLgEl4n+t6SzH333VfvuFOnTjWZmZnG5XKZ9u3bmx//+Mdm/vz5J/1dADi12IwJ8dwLAJzmrr32Ws2fP18lJSWRLuWkOnfurL59++qdd96JdCkAcFJcYwoAAICoQDAFAABAVCCYAgAAICpwjSkAAACiAiOmAAAAiAoEUwAAAESFmF5g3+/3a9++fUpOTq5zqz0AAABEB2OMiouL1a5du+DNOo4npoPpvn376twXGwAAANFpz5496tChwwm3ielgmpycLKn6iwbuj92UfD6fFi1apAkTJsjlcjX58WA9+jD20Yexjz6MffRh7GvOPiwqKlJWVlYwt51ITAfTwOn7lJSUZgumCQkJSklJ4Q8xRtGHsY8+jH30YeyjD2NfJPqwIZddMvkJAAAAUYFgCgAAgKhAMAUAAEBUIJgCAAAgKhBMAQAAEBUIpgAAAIgKBFMAAABEBYIpAAAAogLBFAAAAFGBYAoAAICoQDAFAABAVCCYAgAAICoQTAEAABAVCKYhmPX2V3pwg0OLt+RFuhQAAIBTDsE0BHsLjijniE2Hy3yRLgUAAOCUQzANgctR/euqqPRHuBIAAIBTD8E0BG5nTTCtIpgCAABYLaLBdNasWbLZbHUevXv3jmRJJ+R22CRJPoIpAACA5ZyRLuDMM8/Uhx9+GHztdEa8pOMKjphWmghXAgAAcOqJeAp0Op3KzMyMdBkNErjGlBFTAAAA60U8mG7btk3t2rVTXFychg0bpjlz5qhjx47H3Nbr9crr9QZfFxUVSZJ8Pp98vqafKV9zJl/lFZXNcjxYL9Bv9F/sog9jH30Y++jD2NecfRjKMWzGmIidl37//fdVUlKiXr16KScnR7Nnz9bevXu1adMmJScn19t+1qxZmj17dr32efPmKSEhocnrfXu3XR/us+sHbf26tDOjpgAAACdTVlamq6++WoWFhUpJSTnhthENpt9XUFCgTp066bHHHtP1119f7/1jjZhmZWUpPz//pF/UCn/K/lp/XbZLV57dTn+Y3LfJjwfr+Xw+ZWdna/z48XK5XJEuB2GgD2MffRj76MPY15x9WFRUpFatWjUomEb8VH5taWlp6tmzp7Zv337M9z0ejzweT712l8vVLH8Yce7qX1eVsfGHGOOa658ZNB36MPbRh7GPPox9zdGHoew/qtYxLSkp0Y4dO9S2bdtIl3JMR2flcxofAADAahENprfffruWLl2qXbt26T//+Y8uueQSORwOXXXVVZEs67iYlQ8AANB0Inoq/7vvvtNVV12lgwcPqnXr1ho5cqRWrlyp1q1bR7Ks43JzS1IAAIAmE9Fg+vLLL0fy8CFzBe/8FDXzxQAAAE4ZUXWNabQLXmPKqXwAAADLEUxDwDWmAAAATYdgGgJm5QMAADQdgmkIAteYVnCNKQAAgOUIpiFgVj4AAEDTIZiGwM01pgAAAE2GYBoCZuUDAAA0HYJpCI6uY0owBQAAsBrBNARHZ+Uz+QkAAMBqBNMQsI4pAABA0yGYhiA4K7/KL2MYNQUAALASwTQEgRFTY6QqP8EUAADASgTTELidtuBzZuYDAABYi2AagsCIqST5mAAFAABgKYJpCJx2m2yqDqTeqqoIVwMAAHBqIZiGwGazqWYpU/mqGDEFAACwEsE0RDVLmaqikmtMAQAArEQwDdHREVOCKQAAgJUIpiFixBQAAKBpEExDFFgxiuWiAAAArEUwDREjpgAAAE2DYBoirjEFAABoGgTTEAVP5TNiCgAAYCmCaYgCN39ixBQAAMBaBNMQOW01d35ixBQAAMBSBNMQOYMjptz5CQAAwEoE0xBxjSkAAEDTIJiGiGtMAQAAmgbBNESMmAIAADQNgmmIHNz5CQAAoEkQTEPEnZ8AAACaBsE0RE7u/AQAANAkCKYhYsQUAACgaRBMQ+RgxBQAAKBJEExD5LRXL6zP5CcAAABrEUxDdHS5KO78BAAAYCWCaYgCC+wzYgoAAGAtgmmIgrPymfwEAABgKYJpiJyMmAIAADQJgmmIWMcUAACgaRBMQxS4xtTLqXwAAABLEUxDxIgpAABA0yCYhujoclEEUwAAACsRTEMUmPzEiCkAAIC1CKYhcthq7vzEiCkAAIClCKYhOjpiyp2fAAAArEQwDZGj5hpTZuUDAABYi2AaIq4xBQAAaBoE0xAxKx8AAKBpEExDxIgpAABA0yCYhihwjWml38jvZwIUAACAVQimIXLW+o1VMGoKAABgGYJpiALXmEoEUwAAACsRTEPkqBVMfUyAAgAAsAzBNEQ2m+SqSaeMmAIAAFiHYBoGt6P61+arZPITAACAVQimYXDVBNOKqqoIVwIAAHDqIJiGwV0zNb+CEVMAAADLEEzDwDWmAAAA1ouaYPrggw/KZrPptttui3QpJxW4xpTbkgIAAFgnKoLp6tWr9cwzz6h///6RLqVBAteYcltSAAAA60Q8mJaUlGjKlCn629/+phYtWkS6nAY5eo0pwRQAAMAqzkgXMH36dF1wwQUaN26c7r///hNu6/V65fV6g6+LiookST6fTz6fr0nrDBxHOnpb0iPe5jkurBPoL/otdtGHsY8+jH30Yexrzj4M5RgRDaYvv/yy1q1bp9WrVzdo+zlz5mj27Nn12hctWqSEhASryzuukqICSXatWrNWvl3MzI9F2dnZkS4BjUQfxj76MPbRh7GvOfqwrKyswdtGLJju2bNHt956q7KzsxUXF9egz9x9992aOXNm8HVRUZGysrI0YcIEpaSkNFWpQT6fT9nZ2cpo1VLbiw6rb/8BmjSwXZMfF9YJ9OH48ePlcrkiXQ7CQB/GPvow9tGHsa85+zBwhrshIhZM165dq7y8PJ111lnBtqqqKi1btkxPPfWUvF6vHA5Hnc94PB55PJ56+3K5XM36h+FxVf/aqoyNP8gY1dz/zMB69GHsow9jH30Y+5qjD0PZf8SC6dixY/XFF1/UabvuuuvUu3dv3XnnnfVCaTQJrGPKrHwAAADrRCyYJicnq2/fvnXaEhMT1bJly3rt0SYwK9/LrHwAAADLRHy5qFh0dB1TJj4BAABYJeLLRdX28ccfR7qEBmEdUwAAAOsxYhoG7vwEAABgPYJpGNw1k58qCKYAAACWIZiGwe3gVD4AAIDVCKZhcAWuMWXEFAAAwDIE0zAERkx9jJgCAABYhmAaBjcjpgAAAJYjmIaBOz8BAABYj2AaBiY/AQAAWI9gGobAOqYV3PkJAADAMgTTMBy981NVhCsBAAA4dRBMw3D0GlNGTAEAAKxCMA3D0RFTrjEFAACwCsE0DIFrTJmVDwAAYB2CaRiYlQ8AAGA9gmkYAteYssA+AACAdQimYeAaUwAAAOsRTMPANaYAAADWI5iGgRFTAAAA6xFMw+AOjpiyjikAAIBVCKZhcNea/GQM4RQAAMAKBNMwBK4xlRg1BQAAsArBNAyBa0wllowCAACwCsE0DHVGTJkABQAAYAmCaRgcdpscdhbZBwAAsBLBNEzBuz8xYgoAAGAJgmmYAktGMWIKAABgDYJpmAIToLj7EwAAgDUIpmEKjphyKh8AAMASBNMwuRgxBQAAsBTBNEyBEVMvI6YAAACWIJiGKbCWKXd+AgAAsAbBNEyByU9cYwoAAGANgmmY3A6uMQUAALASwTRMjJgCAABYi2AapuCdnxgxBQAAsATBNEyMmAIAAFiLYBomF9eYAgAAWIpgGiZGTAEAAKxFMA0Ts/IBAACsRTANEyOmAAAA1iKYhilwjWkFd34CAACwBME0TIyYAgAAWItgGiZm5QMAAFiLYBomDyOmAAAAliKYholZ+QAAANYimIYpcEtSL8EUAADAEgTTMLmdDkmSj1P5AAAAliCYhikwYlrBiCkAAIAlCKZhCiwXxTWmAAAA1gg5mB45ckRlZWXB17t379bjjz+uRYsWWVpYtAtMfmJWPgAAgDVCDqaTJ0/Wiy++KEkqKCjQ0KFD9eijj2ry5MmaO3eu5QVGKxbYBwAAsFbIwXTdunUaNWqUJGn+/PnKyMjQ7t279eKLL+qJJ56wvMBoFQimXoIpAACAJUIOpmVlZUpOTpYkLVq0SJdeeqnsdrvOPfdc7d692/ICoxWn8gEAAKwVcjDt3r273njjDe3Zs0cffPCBJkyYIEnKy8tTSkqK5QVGK0ZMAQAArBVyMP3d736n22+/XZ07d9bQoUM1bNgwSdWjp4MGDbK8wGjlqVnHlOWiAAAArOEM9QOXX365Ro4cqZycHA0YMCDYPnbsWF1yySWWFhfNmPwEAABgrZCDqSRlZmYqMzNTklRUVKQlS5aoV69e6t27t6XFRTMPwRQAAMBSIZ/Kv+KKK/TUU09Jql7T9Oyzz9YVV1yh/v3767XXXrO8wGgVHDHlVD4AAIAlQg6my5YtCy4XtWDBAhljVFBQoCeeeEL3339/SPuaO3eu+vfvr5SUFKWkpGjYsGF6//33Qy0pIgKz8qv8RpWEUwAAgEYLOZgWFhYqPT1dkrRw4UJddtllSkhI0AUXXKBt27aFtK8OHTrowQcf1Nq1a7VmzRr96Ec/0uTJk7V58+ZQy2p2gRFTiVFTAAAAK4QcTLOysrRixQqVlpZq4cKFweWiDh8+rLi4uJD2deGFF2rSpEnq0aOHevbsqQceeEBJSUlauXJlqGU1O0/tYMp1pgAAAI0W8uSn2267TVOmTFFSUpI6deqkMWPGSKo+xd+vX7+wC6mqqtKrr76q0tLS4BJU3+f1euX1eoOvi4qKJEk+n08+ny/sYzdU4Bg+n08ul2S3SX4jlZZXKNFla/Ljo/Fq9yFiE30Y++jD2Ecfxr7m7MNQjmEzxphQD7BmzRrt2bNH48ePV1JSkiTp3XffVVpamkaMGBHSvr744gsNGzZM5eXlSkpK0rx58zRp0qRjbjtr1izNnj27Xvu8efOUkJAQ6tdotNtXOeTz2/S7QZVqGdpgMQAAwGmhrKxMV199tQoLC096M6awgmlA4KM2W/ijhRUVFfr2229VWFio+fPn6+9//7uWLl2qPn361Nv2WCOmWVlZys/Pb5a7Tvl8PmVnZ2v8+PFyuVwa/MASFZVX6oNbRqhr68QmPz4a7/t9iNhDH8Y++jD20Yexrzn7sKioSK1atWpQMA1rHdMXX3xRjzzySHCyU8+ePXXHHXfommuuCXlfbrdb3bt3lyQNHjxYq1ev1p///Gc988wz9bb1eDzyeDz12l0uV7P+YQSO53Y6JFXKb7PzhxljmvufGViPPox99GHsow9jX3P0YSj7DzmYPvbYY7r33ns1Y8aM4Gn75cuX66abblJ+fr7++7//O9Rd1uH3++uMikazwAQoL5OfAAAAGi3kYPrkk09q7ty5mjp1arDtoosu0plnnqlZs2aFFEzvvvtuTZw4UR07dlRxcbHmzZunjz/+WB988EGoZUUEtyUFAACwTsjBNCcnR8OHD6/XPnz4cOXk5IS0r7y8PE2dOlU5OTlKTU1V//799cEHH2j8+PGhlhUR3JYUAADAOiEH0+7du+uVV17Rb37zmzrt//73v9WjR4+Q9vW///u/oR4+qhy9LWlVhCsBAACIfSEH09mzZ+unP/2pli1bFrzG9NNPP9XixYv1yiuvWF5gNAvclpQRUwAAgMYL+c5Pl112mVatWqVWrVrpjTfe0BtvvKFWrVrps88+0yWXXNIUNUYtN5OfAAAALBPWclGDBw/WP//5zzpteXl5+uMf/1jvFP+pjMlPAAAA1gl5xPR4cnJydO+991q1u5gQOJXPiCkAAEDjWRZMT0eMmAIAAFiHYNoIHqdDklRRRTAFAABoLIJpIzBiCgAAYJ0GT36aOXPmCd8/cOBAo4uJNSywDwAAYJ0GB9P169efdJvRo0c3qphYc3SBfYIpAABAYzU4mH700UdNWUdMYoF9AAAA63CNaSMcXWCfW5ICAAA0FsG0ETzc+QkAAMAyBNNGYFY+AACAdQimjUAwBQAAsA7BtBGCk5+YlQ8AANBoYQXTTz75RD/72c80bNgw7d27V5L0f//3f1q+fLmlxUU7RkwBAACsE3Iwfe2113TeeecpPj5e69evl9frlSQVFhbqj3/8o+UFRjMmPwEAAFgn5GB6//336+mnn9bf/vY3uVyuYPuIESO0bt06S4uLdoyYAgAAWCfkYLp169Zj3uEpNTVVBQUFVtQUMzxOhySCKQAAgBVCDqaZmZnavn17vfbly5era9eulhQVK7glKQAAgHVCDqY///nPdeutt2rVqlWy2Wzat2+f/vWvf+n222/XL37xi6aoMWpxS1IAAADrOEP9wF133SW/36+xY8eqrKxMo0ePlsfj0e23366bb765KWqMWm4mPwEAAFgm5GBqs9l0zz336I477tD27dtVUlKiPn36KCkpqSnqi2pHJz9VRbgSAACA2BdyMC0sLFRVVZXS09PVp0+fYPuhQ4fkdDqVkpJiaYHRLHAqnxFTAACAxgv5GtMrr7xSL7/8cr32V155RVdeeaUlRcUKT63JT8aYCFcDAAAQ20IOpqtWrdIPf/jDeu1jxozRqlWrLCkqVgSWizJGqvQTTAEAABoj5GDq9XpVWVlZr93n8+nIkSOWFBUrAteYSszMBwAAaKyQg+mQIUP07LPP1mt/+umnNXjwYEuKihUEUwAAAOuEPPnp/vvv17hx47Rx40aNHTtWkrR48WKtXr1aixYtsrzAaOaw2+Sw21TlNyyyDwAA0Eghj5iOGDFCK1asUIcOHfTKK6/o7bffVvfu3fX5559r1KhRTVFjVGORfQAAAGuEPGIqSQMHDtS8efOsriUmuZ12HfFVyctapgAAAI0SVjCtqqrSggUL9NVXX0mS+vTpo8mTJ8vpDGt3Mc3D3Z8AAAAsEXKS3Lx5sy666CLl5uaqV69ekqSHHnpIrVu31ttvv62+fftaXmQ0O3r3J4IpAABAY4R8jekNN9ygM888U999953WrVundevWac+ePerfv79uvPHGpqgxqhFMAQAArBHyiOmGDRu0Zs0atWjRItjWokULPfDAAzrnnHMsLS4WBCc/MSsfAACgUUIeMe3Zs6f2799frz0vL0/du3e3pKhY4mHEFAAAwBINCqZFRUXBx5w5c3TLLbdo/vz5+u677/Tdd99p/vz5uu222/TQQw81db1Rx83kJwAAAEs06FR+WlqabDZb8LUxRldccUWwzZjq+8RfeOGFqqo6vZZN4hpTAAAAazQomH700UdNXUfM8jgdkgimAAAAjdWgYPqDH/ygqeuIWYHJT14mPwEAADRKyJOfUBen8gEAAKxBMG2ko3d+Or2urQUAALAawbSRPK6aYOpjxBQAAKAxQgqmxhh9++23Ki8vb6p6Yk5g8hPLRQEAADROyMG0e/fu2rNnT1PVE3PiakZMy32cygcAAGiMkIKp3W5Xjx49dPDgwaaqJ+YwYgoAAGCNkK8xffDBB3XHHXdo06ZNTVFPzGHyEwAAgDUatI5pbVOnTlVZWZkGDBggt9ut+Pj4Ou8fOnTIsuJiQZyLEVMAAAArhBxMH3/88SYoI3YFR0y5xhQAAKBRQg6m06ZNa4o6YlZwuShGTAEAABolrHVMd+zYod/+9re66qqrlJeXJ0l6//33tXnzZkuLiwVxgclPrGMKAADQKCEH06VLl6pfv35atWqVXn/9dZWUlEiSNm7cqPvuu8/yAqNdYMS0nMlPAAAAjRJyML3rrrt0//33Kzs7W263O9j+ox/9SCtXrrS0uFjgYcQUAADAEiEH0y+++EKXXHJJvfY2bdooPz/fkqJiCctFAQAAWCPkYJqWlqacnJx67evXr1f79u0tKSqWBJaLKmfEFAAAoFFCDqZXXnml7rzzTuXm5spms8nv9+vTTz/V7bffrqlTpzZFjVGNEVMAAABrhBxM//jHP6p3797KyspSSUmJ+vTpo9GjR2v48OH67W9/2xQ1RjVuSQoAAGCNkNcxdbvd+tvf/qZ7771XmzZtUklJiQYNGqQePXo0RX1RLy4wK99XJWOMbDZbhCsCAACITSEH04COHTuqY8eOVtYSkwIjpn4jVfqNXA6CKQAAQDgaFExnzpzZ4B0+9thjDd52zpw5ev3117VlyxbFx8dr+PDheuihh9SrV68G7yPSAuuYStWn812OsO5ZAAAAcNprUDBdv359ndfr1q1TZWVlMEB+/fXXcjgcGjx4cEgHX7p0qaZPn65zzjlHlZWV+s1vfqMJEyboyy+/VGJiYkj7ipTA5CdJ8vqqlOQJexAaAADgtNagFPXRRx8Fnz/22GNKTk7WCy+8oBYtWkiSDh8+rOuuu06jRo0K6eALFy6s8/of//iH2rRpo7Vr12r06NEh7StSbDab3E67Kir9KmcCFAAAQNhCHt579NFHtWjRomAolaQWLVro/vvv14QJE/SrX/0q7GIKCwslSenp6cd83+v1yuv1Bl8XFRVJknw+n3w+X9jHbajAMb5/LE9NMC094pUvkRHTaHa8PkTsoA9jH30Y++jD2NecfRjKMWzGGBPKzpOTk/X2229rzJgxddo/+ugjXXTRRSouLg5ld0F+v18XXXSRCgoKtHz58mNuM2vWLM2ePbte+7x585SQkBDWca1w7xqHinw2/bp/pdrHxhUIAAAAzaKsrExXX321CgsLlZKScsJtQw6mU6dO1SeffKJHH31UQ4YMkSStWrVKd9xxh0aNGqUXXnghrKJ/8Ytf6P3339fy5cvVoUOHY25zrBHTrKws5efnn/SLWsHn8yk7O1vjx4+Xy+UKtv/w0WX6rqBcr944RAOz0pq8DoTveH2I2EEfxj76MPbRh7GvOfuwqKhIrVq1alAwDfm889NPP63bb79dV199dXBo1ul06vrrr9cjjzwSVsEzZszQO++8o2XLlh03lEqSx+ORx+Op1+5yuZr1D+P7x/PU3Ja0Snb+QGNEc/8zA+vRh7GPPox99GHsa44+DGX/IQfThIQE/fWvf9UjjzyiHTt2SJK6desW1ix6Y4xuvvlmLViwQB9//LG6dOkS8j6iAXd/AgAAaLywZ+okJiaqf//+jTr49OnTNW/ePL355ptKTk5Wbm6uJCk1NVXx8fGN2ndzqn33JwAAAIQnoqvBz507V4WFhRozZozatm0bfPz73/+OZFkhY8QUAACg8SK6tlGI866iVuDuT15GTAEAAMLG/TMtEFczYsoC+wAAAOEjmFqAEVMAAIDGI5hawOOsCaaMmAIAAISNYGqBuJp1TBkxBQAACB/B1AKMmAIAADQewdQCgeWiWMcUAAAgfARTC8S7A8GUEVMAAIBwEUwtELjG9AgjpgAAAGEjmFogoWbEtKyCYAoAABAugqkF4l1cYwoAANBYBFMLBE7ll1VURrgSAACA2EUwtUDgVP4RJj8BAACEjWBqgaOz8jmVDwAAEC6CqQXiOZUPAADQaARTCwRGTI8wKx8AACBsBFMLHJ2VzzWmAAAA4SKYWiAw+amiyq/KKsIpAABAOAimFggsFyVx9ycAAIBwEUwt4HHaZbNVP+c6UwAAgPAQTC1gs9mU4AqsZUowBQAACAfB1CLBmfkEUwAAgLAQTC1y9LakBFMAAIBwEEwtEpiZX04wBQAACAvB1CLxjJgCAAA0CsHUIlxjCgAA0DgEU4vEMysfAACgUQimFgmOmHIqHwAAICwEU4vEu5ySGDEFAAAIF8HUIvHu6l8lI6YAAADhIZhahGtMAQAAGodgapF4d82pfEZMAQAAwkIwtQjrmAIAADQOwdQiwTs/cSofAAAgLARTixwdMa2McCUAAACxiWBqkaS46mtMS7wEUwAAgHAQTC2S5KkOpsXlBFMAAIBwEEwtkhxHMAUAAGgMgqlFkuNckqTicl+EKwEAAIhNBFOLJNe6xtQYE+FqAAAAYg/B1CKBYOo3rGUKAAAQDoKpReJdDjnsNklcZwoAABAOgqlFbDZbcGZ+iZfrTAEAAEJFMLVQ4HR+ESOmAAAAISOYWujozHyCKQAAQKgIphYKzswnmAIAAISMYGqh5ODdn7jGFAAAIFQEUwtx9ycAAIDwEUwtxN2fAAAAwkcwtVBSYMTUy4gpAABAqAimFuJUPgAAQPgIphbiVD4AAED4CKYWSg7e+YkRUwAAgFARTC3EqXwAAIDwEUwtlBJffSq/8Ain8gEAAEJFMLVQiwS3JOlQaUWEKwEAAIg9BFMLtUysDqbF5ZWqqPRHuBoAAIDYQjC1UGq8Sw67TZJ0uIxRUwAAgFAQTC1kt9vUIqH6OtODJQRTAACAUEQ0mC5btkwXXnih2rVrJ5vNpjfeeCOS5VgiPZHrTAEAAMIR0WBaWlqqAQMG6C9/+Usky7BUIJgeLPVGuBIAAIDY4ozkwSdOnKiJEydGsgTLtUzySJLyOZUPAAAQkogG01B5vV55vUdHIouKiiRJPp9PPl/Trx0aOMaJjtUmqXrEdN/h0mapCaFpSB8iutGHsY8+jH30Yexrzj4M5Rg2Y4xpwloazGazacGCBbr44ouPu82sWbM0e/bseu3z5s1TQkJCE1bXcEv22fTmbofOaunXtJ4sGQUAAE5vZWVluvrqq1VYWKiUlJQTbhtTI6Z33323Zs6cGXxdVFSkrKwsTZgw4aRf1Ao+n0/Z2dkaP368XC7XMbfxf56jN3d/IXtSuiZNGtLkNSE0DelDRDf6MPbRh7GPPox9zdmHgTPcDRFTwdTj8cjj8dRrd7lczfqHcaLjtU9PkiTlFVfwxxrFmvufGViPPox99GHsow9jX3P0YSj7Zx1Ti7VNjZMk5RaVy++PiqskAAAAYkJER0xLSkq0ffv24OtvvvlGGzZsUHp6ujp27BjBysLXNjVOTrtNFZV+5RaVq11afKRLAgAAiAkRHTFds2aNBg0apEGDBkmSZs6cqUGDBul3v/tdJMtqFKfDrg4tqsPo7oNlEa4GAAAgdkR0xHTMmDGKkkUBLNWpZaJ2HSzT7oOlGtatZaTLAQAAiAlcY9oEOresXrpqZ35phCsBAACIHQTTJtArs3rpqq9yGr48AgAAwOmOYNoE+rSrDqZf7is6JS9VAAAAaAoE0ybQKyNZdpt0sLRCuUXlkS4HAAAgJhBMm0C826Ez26VKkj775lCEqwEAAIgNBNMmMrRLuiRp5c6DEa4EAAAgNhBMm8ionq0lSR9+lccdoAAAABqAYNpEhnVtqeQ4pw4Ue/XpjvxIlwMAABD1CKZNxO2069JB7SVJzy7bGeFqAAAAoh/BtAndMKqr7Dbpk2352rinINLlAAAARDWCaRPKSk/Q5IHVo6Z3zN+ocl9VhCsCAACIXgTTJvbbC85QqyS3vt5fol/P/1xVTIQCAAA4JoJpE2uZ5NGffjpQTrtNb23cpxnz1qnUWxnpsgAAAKIOwbQZjOrRWk9cNUguh03vb8rVZXP/oy25RZEuCwAAIKoQTJvJpH5t9dLPz1WrJI+25BbrwieX6/EPv1ZFpT/SpQEAAEQFgmkzOrtzut67ZaTG98mQr8ro8Q+3afyflmrhplwZw7WnAADg9EYwbWZtUuL07DWD9eRVg9Q62aPdB8t00z/X6qq/rdSmvYWRLg8AACBiCKYRYLPZdOGAdvr49jG6+Ufd5XHatXLnIf34yeW66f/WamtucaRLBAAAaHYE0whK9Dj1qwm9tOT2Mbp4YDvZbNLCzbk6/8/LdMtL67XzQEmkSwQAAGg2BNMo0D4tXo9fOUgf3DZak/plyhjprY37NO6xpZr5ygZtz2MEFQAAnPoIplGkZ0ay/jplsN65eaTG9m4jv5FeX7dX4/+0TP/1f2u4rSkAADilEUyjUN/2qfrfa8/RG9NHaEKfDBkjfbB5vyb/5VNN+ftKfbo9n1n8AADglOOMdAE4voFZaXp26tnatr9Yc5fu0Fsb9unT7Qf16faD6tM2RdeO6KyLBrRTnMsR6VIBAAAajRHTGNAjI1mPXTFQH98xRtcO76w4l11f5hTp1/M/1/AHl+h/Ptiq/UXlkS4TAACgUQimMaRDiwTNuuhMrbx7rO6a2FvtUuN0qLRCT320XSMeXKKbX1qv1bsOcZofAADEJE7lx6C0BLdu+kE33TCyi7K/3K/n/7NLn31zSG9v3Ke3N+5T9zZJuvKcLF0yqL1aJnkiXS4AAECDEExjmNNh18R+bTWxX1tt2luoF1fs0tsbc7Q9r0T3v/uVHlq4RRP6ZOrKIVka0a2V7HZbpEsGAAA4LoLpKaJv+1Q9fPkA3fvjPnp7Y45eXv2tPv+uUO9+kaN3v8hR+7R4XTignS4e1E69M1MiXS4AAEA9BNNTTHKcS1cP7airh3bU5n2FemX1Hi1Yv1d7C47o6aU79PTSHeqdmazJA9tr8sB2apcWH+mSAQAAJBFMT2lntkvV7MmpunvSGVqyJU9vrN+rj7bmaUtusbYs3KKHFm7RkC7pmtQ3UxPOzCSkAgCAiCKYngbiXA5N6tdWk/q1VWGZT+9tytEb6/dq1TeH9FnNY9bbX2pAVprOPzNT5/fNVJdWiZEuGwAAnGYIpqeZ1ASXrhrSUVcN6ah9BUf03hc5+mBzrtbsPqyNewq0cU+BHlq4Rb0zkzWhT4bG9G6jAR3S5GDiFAAAaGIE09NYu7R43TCqq24Y1VV5xeXK/nK/Fm7K1YodB6tP9+cW64kl29UiwaXRPVtrTK/WGt2jNUtQAQCAJkEwhSSpTXKcpgztpClDO6mwzKcPv9qvJVvztOzrAzpc5tObG/bpzQ37ZLNJ/TukaUzP1hrRvZUGZqXJ7eQ+DQAAoPEIpqgnNcGlywZ30GWDO6iyyq/1ewr00ZY8fbz1gL7MKQqe8v/z4m2Kdzl0ducWGtatpYZ3a6W+7VLkdBBUAQBA6AimOCGnw65zOqfrnM7p+vX5vbW/qFxLtx7Qsm0HtHLnQeWXVOiTbfn6ZFu+pK1K8jg1pEu6hnRJ1+BOLdSvfariXI5Ifw0AABADCKYISUZKnK44J0tXnJMlY4y25ZXoP9vztWLnQa3ceUiFR3xasiVPS7bkSZJcDpv6tk/V4I4tdHbnFjqrUwu1SY6L8LcAAADRiGCKsNlsNvXMSFbPjGRdO6KLqvxGX+UUaeXOg1qz67DW7D6s/BKv1n9boPXfFujvy7+RJGWlx2tAhzT1a5+qfh1S1bd9qlLiXBH+NgAAINIIprCMw149Otq3fapuGCUZY7Tn0BGt/faQ1uw6rLW7D2vr/mLtOXREew4d0Tuf5wQ/26VVovq1T1X/mqB6ZrsUJRNWAQA4rRBM0WRsNps6tkxQx5YJumRQB0lSUblPG/cU6PPvCrVpb6E+/65QewuO6Jv8Un2TX6q3Nu4Lfr5Di3j1zkxWr8xk9cpMUe/MZHVplSgXk6sAADglEUzRrFLiXBrVo7VG9WgdbDtUWqEv9hbqi+8Kan4Wal9hub47fETfHT6iD7/KC27rdtjVrU1SMLD2aJOkrq2TlNUintUAAACIcQRTRFx6ols/6NlaP+h5NKwWlFVoS26xttYs9L81t0hbc4tVWlGlr3KK9FVOUZ19uBw2dWqZqK6tEtWtTZK6tkpU19ZJ6t46SakJXBIAAEAsIJgiKqUluHVu15Y6t2vLYJvfb7S34EgwqG7JLdaOA6X6Jr9E5T6/tueVaHteifTl/jr7apnoVudWieqYnqD2qR4dzrOp9a7D6paRotZJHtm53SoAAFGBYIqYYbfblJWeoKz0BI3vkxFs9/uNcorKtSOvRDsPlGjHgVLtzC/RzgOlyiks18HSCh0srdDa3YdrPuHQv3asliR5nHZlpSeoY80jKz1BWS3i1S4tXm1T45Se6JbNRnAFAKA5EEwR8+x2m9qnxat9WrxG17ocQJJKvZX6Jr9Uuw+W6dtDZdqVX6L1275VmT1ROYXl8lbWGmk9Bo/THgyp7dLi1S41Tm1rXrdPi1fbtHglefgzAgDACvwXFae0RI8zuISVJPl8Pr333i5NmjRKsjuUU1Cubw+V1XqUau/hI9pXWK4DxV55K/3BFQOOJznOqYyUOLVJ9lQ/ap63TvYcbU+JI8ACAHAS/JcSpy2Xwx5czupYvJVV2l/o1d6CI8opPKKcwvLq5wVHnxeXV9Y8jj/qGpDgdtSE1zi1TvGodZJHrZLcSk/0KD3RrZZJbrVMdKtlokcp8U4uIQAAnHYIpsBxeJyOEwZXSSrxViqn4Ijyir3KKy5XXpG35rlX+4uqR13zispVWlGlsooq7TpYpl0Hy056bKfdpvREdzCwpid6akKrW+k1ATY13q20BFf1I96tOJedMAsAiGkEU6ARkjxO9chIVo+M5BNuV+qtrA6sReXB4Jpf4tWhkoqayVleHSqt0KGSChV7K1XpN8HtGsrttCs13qW0+OqwGgyuwdcupSa4g6/T4t1KjnMqOc7JGrAAgKhAMAWaQaLHqS4ep7q0Sjzptt7KKh0qrdDBkorqsFpaUR1ia54frPlZeMSngjKfCo9UyFdlVFHp14Firw6EEGYD4l2OYEhNjnMpOc6plDiXkjx12wLPU77XlhTnlMfpCOdXAwBAEMEUiDIep0NtU+PVNjW+QdsbY1RWUaWCIz4VlFUH1sIyX81rnwqOVFS/rnleUOZT0RGfDpf5dMRXJUk64qvSEV9VSCO03+d22pXkcSrB7Qj+TKz1M9HtVILHoSS3UwkepxLdDiV4nEryOJTgrn4/0XP0MwlupxysMQsApxWCKRDjbDZbdfDzONU+rWFhNsBX5VdJzQSuonJfzUSu7/30Vh67veZ5aUV1uK2o9OtQZYUOHX8Bg5DFuxxK9DgU73Yo3lX98DjtKi6w6/2ijUrwOIPt8W6H4mo9j3fVvK712Xi3vc42cU4HN1gAgChCMAVOYy6HXS0S3WqR6A57H1V+o5KaYFtWUaXSikqVeat/lnorqyd+eWs9r6hUqbeq5nVl9We8NW01n/Gb6n0HRnLrs+urgv3HaA+dx2mvE2Q9TnvNwyGPq/bPmudO+9H2mm2Dnzvm56ufx31vX24Hk9UA4PsIpgAaxWG3KTXBpdQElyX7M8bIW+lXqbcyGHRLvVXy1oTUkiMVWrV2vXqecaYq/NKRCr+O+KpU7qvSkYrqbcoqal7XtAWf17z2VvqDx/NW+uWt9KtAPkvqD0UwxLoccjvsctcEVpfTVv2zdlvN86NttjqvXY7qfZ1wO4ddrpr9HT1Wzevg52xMhgMQMQRTAFHFZrMprmb0suUx3vf5fNIeo0lDO8rlCi8M+/1G5ZVHg2x5TZj1Vvrl9fnlrax5Xlklr8+vcl9VMMAG2gLPy2tvX+eztT5X6/O1BdvKK8P6Hk3FZpNc9qMh1eWwyWm3y+mwyeWwy2mv3V53m9rbuh3VP50Ou1w12zkdNtll9M0em3Yv3SmPy3mMYwT2VauGWp93fW87h90mp8NW/TPw2m6r85PRaSA2EEwBnHbsdpsS3E4luJv3X4HGGFVU1QqttQJuYGUFX5VfFZV+VdT89NX66a30y1dljtFWa9sqvyoqzTHaqn8ebTd1jlO3TlW3V0nSsS6lsIJDC7/b3kT7PsbRvhdUq3/a5bCrXpg9GnTt9QJu4HN1tq3zmeOFY3ut949+9vv7tNttcthsctglu636/aNttmBbnfdtR/cVfG6zyW5Xree1ftZ+30ZwR3QhmAJAM7HZbDXXpjqUEmfNpQ9WMMao0n80zFZU+uXzG1VWVQfYSr9flTWBOLBdZU17RWX992t/zldlgtsGQ7WvUjt27Va79lnyG530WNX7qH/s2u1V/urvcDxVNdtUNOPvNZbYbKoTYKtDruoFXnut946UOfTUjk9rAv7xg3Hdtlr7t9vksKlem91WHbqPPqq3CdZY02arVYvNFjhO9WdttqP1B57bbdXHsQX2bz/2cey1tq9dT+Bz9Y75vX06bN87pr3W+/WOe4xj2uoe83T7nwaCKQCc5my26tPiLoddCeHPg2swn8+n9977RpMmnRn25RjH468JqNVB1R8MrMGfVcdp9/tV5Vfd96pOtq+jobjKfH/76n3WP3b99kDNgWP4/aren9/IX/Oz9nO/0THaam+nYE3+mp/m+JldUvUoeaUxCs48bBCb9h+xcBkOHFPtwGqzHQ37tYOyTaoThoPB2S7ZVD9c2202SUb/1SXS364+gikA4JRht9vkDi4Bxk0fAowxtcJqreD7vQDbsGBs5K2o1H9WrNQ5Q4bIZncc3UdwO9Vpq32Mo22qc1xjqkO1P/CzZl9+c7T+wPvG1Oyr5r1Azf6aEO4P7jOwv+qajDm6z0C731/r+UmPX2v/NZ81399f4Ln/GO219tlQgX1IofxPQ8PYCKbH9pe//EWPPPKIcnNzNWDAAD355JMaMmRIpMsCAOCUYLNVXwNr1X/0fT6fDnxpNLxbS8tHvU8X9cN2rXDtrxV+jxu2VS8sf/9n7WBdOyQbI1X4KlW4dVWkfw31RDyY/vvf/9bMmTP19NNPa+jQoXr88cd13nnnaevWrWrTpk2kywMAALBc4H8WIsXn8+m9ryN2+OOK+GJ1jz32mH7+85/ruuuuU58+ffT0008rISFBzz33XKRLAwAAQDOK6IhpRUWF1q5dq7vvvjvYZrfbNW7cOK1YsaLe9l6vV17v0Xt5FxUVSapO/T5f0y+OHThGcxwLTYM+jH30YeyjD2MffRj7mrMPQzlGRINpfn6+qqqqlJGRUac9IyNDW7Zsqbf9nDlzNHv27HrtixYtUkJCQpPV+X3Z2dnNdiw0Dfow9tGHsY8+jH30Yexrjj4sKytr8LYRv8Y0FHfffbdmzpwZfF1UVKSsrCxNmDBBKSkpTX58n8+n7OxsjR8/nou9YxR9GPvow9hHH8Y++jD2NWcfBs5wN0REg2mrVq3kcDi0f//+Ou379+9XZmZmve09Ho88Hk+9dpfL1ax/GM19PFiPPox99GHsow9jH30Y+5qjD0PZf0QnP7ndbg0ePFiLFy8Otvn9fi1evFjDhg2LYGUAAABobhE/lT9z5kxNmzZNZ599toYMGaLHH39cpaWluu666yJdGgAAAJpRxIPpT3/6Ux04cEC/+93vlJubq4EDB2rhwoX1JkQBAADg1BbxYCpJM2bM0IwZMyJdBgAAACIo4gvsAwAAABLBFAAAAFGCYAoAAICoQDAFAABAVCCYAgAAICpExaz8cBljJIV2q6vG8Pl8KisrU1FREXe6iFH0YeyjD2MffRj76MPY15x9GMhpgdx2IjEdTIuLiyVJWVlZEa4EAAAAJ1JcXKzU1NQTbmMzDYmvUcrv92vfvn1KTk6WzWZr8uMVFRUpKytLe/bsUUpKSpMfD9ajD2MffRj76MPYRx/GvubsQ2OMiouL1a5dO9ntJ76KNKZHTO12uzp06NDsx01JSeEPMcbRh7GPPox99GHsow9jX3P14clGSgOY/AQAAICoQDAFAABAVCCYhsDj8ei+++6Tx+OJdCkIE30Y++jD2Ecfxj76MPZFax/G9OQnAAAAnDoYMQUAAEBUIJgCAAAgKhBMAQAAEBUIpgAAAIgKBNMQ/OUvf1Hnzp0VFxenoUOH6rPPPot0SZA0Z84cnXPOOUpOTlabNm108cUXa+vWrXW2KS8v1/Tp09WyZUslJSXpsssu0/79++ts8+233+qCCy5QQkKC2rRpozvuuEOVlZXN+VVQ48EHH5TNZtNtt90WbKMPo9/evXv1s5/9TC1btlR8fLz69eunNWvWBN83xuh3v/ud2rZtq/j4eI0bN07btm2rs49Dhw5pypQpSklJUVpamq6//nqVlJQ091c5LVVVVenee+9Vly5dFB8fr27duukPf/hDnfub04fRZdmyZbrwwgvVrl072Ww2vfHGG3Xet6q/Pv/8c40aNUpxcXHKysrSww8/3HRfyqBBXn75ZeN2u81zzz1nNm/ebH7+85+btLQ0s3///kiXdto777zzzPPPP282bdpkNmzYYCZNmmQ6duxoSkpKgtvcdNNNJisryyxevNisWbPGnHvuuWb48OHB9ysrK03fvn3NuHHjzPr16817771nWrVqZe6+++5IfKXT2meffWY6d+5s+vfvb2699dZgO30Y3Q4dOmQ6depkrr32WrNq1Sqzc+dO88EHH5jt27cHt3nwwQdNamqqeeONN8zGjRvNRRddZLp06WKOHDkS3Ob88883AwYMMCtXrjSffPKJ6d69u7nqqqsi8ZVOOw888IBp2bKleeedd8w333xjXn31VZOUlGT+/Oc/B7ehD6PLe++9Z+655x7z+uuvG0lmwYIFdd63or8KCwtNRkaGmTJlitm0aZN56aWXTHx8vHnmmWea5DsRTBtoyJAhZvr06cHXVVVVpl27dmbOnDkRrArHkpeXZySZpUuXGmOMKSgoMC6Xy7z66qvBbb766isjyaxYscIYU/3HbbfbTW5ubnCbuXPnmpSUFOP1epv3C5zGiouLTY8ePUx2drb5wQ9+EAym9GH0u/POO83IkSOP+77f7zeZmZnmkUceCbYVFBQYj8djXnrpJWOMMV9++aWRZFavXh3c5v333zc2m83s3bu36YqHMcaYCy64wPy///f/6rRdeumlZsqUKcYY+jDafT+YWtVff/3rX02LFi3q/Hv0zjvvNL169WqS78Gp/AaoqKjQ2rVrNW7cuGCb3W7XuHHjtGLFighWhmMpLCyUJKWnp0uS1q5dK5/PV6f/evfurY4dOwb7b8WKFerXr58yMjKC25x33nkqKirS5s2bm7H609v06dN1wQUX1OkriT6MBW+99ZbOPvts/eQnP1GbNm00aNAg/e1vfwu+/8033yg3N7dOH6ampmro0KF1+jAtLU1nn312cJtx48bJbrdr1apVzfdlTlPDhw/X4sWL9fXXX0uSNm7cqOXLl2vixImS6MNYY1V/rVixQqNHj5bb7Q5uc95552nr1q06fPiw5XU7Ld/jKSg/P19VVVV1/oMnSRkZGdqyZUuEqsKx+P1+3XbbbRoxYoT69u0rScrNzZXb7VZaWlqdbTMyMpSbmxvc5lj9G3gPTe/ll1/WunXrtHr16nrv0YfRb+fOnZo7d65mzpyp3/zmN1q9erVuueUWud1uTZs2LdgHx+qj2n3Ypk2bOu87nU6lp6fTh83grrvuUlFRkXr37i2Hw6Gqqio98MADmjJliiTRhzHGqv7Kzc1Vly5d6u0j8F6LFi0srZtgilPK9OnTtWnTJi1fvjzSpSAEe/bs0a233qrs7GzFxcVFuhyEwe/36+yzz9Yf//hHSdKgQYO0adMmPf3005o2bVqEq0NDvPLKK/rXv/6lefPm6cwzz9SGDRt02223qV27dvQhmg2n8hugVatWcjgc9WYA79+/X5mZmRGqCt83Y8YMvfPOO/roo4/UoUOHYHtmZqYqKipUUFBQZ/va/ZeZmXnM/g28h6a1du1a5eXl6ayzzpLT6ZTT6dTSpUv1xBNPyOl0KiMjgz6Mcm3btlWfPn3qtJ1xxhn69ttvJR3tgxP9ezQzM1N5eXl13q+srNShQ4fow2Zwxx136K677tKVV16pfv366ZprrtF///d/a86cOZLow1hjVX81979bCaYN4Ha7NXjwYC1evDjY5vf7tXjxYg0bNiyClUGqXg5jxowZWrBggZYsWVLvlMPgwYPlcrnq9N/WrVv17bffBvtv2LBh+uKLL+r8gWZnZyslJaXef2xhvbFjx+qLL77Qhg0bgo+zzz5bU6ZMCT6nD6PbiBEj6i3T9vXXX6tTp06SpC5duigzM7NOHxYVFWnVqlV1+rCgoEBr164NbrNkyRL5/X4NHTq0Gb7F6a2srEx2e91Y4HA45Pf7JdGHscaq/ho2bJiWLVsmn88X3CY7O1u9evWy/DS+JJaLaqiXX37ZeDwe849//MN8+eWX5sYbbzRpaWl1ZgAjMn7xi1+Y1NRU8/HHH5ucnJzgo6ysLLjNTTfdZDp27GiWLFli1qxZY4YNG2aGDRsWfD+w1NCECRPMhg0bzMKFC03r1q1ZaiiCas/KN4Y+jHafffaZcTqd5oEHHjDbtm0z//rXv0xCQoL55z//GdzmwQcfNGlpaebNN980n3/+uZk8efIxl64ZNGiQWbVqlVm+fLnp0aMHSw01k2nTppn27dsHl4t6/fXXTatWrcyvf/3r4Db0YXQpLi4269evN+vXrzeSzGOPPWbWr19vdu/ebYyxpr8KCgpMRkaGueaaa8ymTZvMyy+/bBISElguKho8+eSTpmPHjsbtdpshQ4aYlStXRrokmOolMo71eP7554PbHDlyxPzyl780LVq0MAkJCeaSSy4xOTk5dfaza9cuM3HiRBMfH29atWplfvWrXxmfz9fM3wYB3w+m9GH0e/vtt03fvn2Nx+MxvXv3Ns8++2yd9/1+v7n33ntNRkaG8Xg8ZuzYsWbr1q11tjl48KC56qqrTFJSkklJSTHXXXedKS4ubs6vcdoqKioyt956q+nYsaOJi4szXbt2Nffcc0+dZYLow+jy0UcfHfO/f9OmTTPGWNdfGzduNCNHjjQej8e0b9/ePPjgg032nWzG1LqlAwAAABAhXGMKAACAqEAwBQAAQFQgmAIAACAqEEwBAAAQFQimAAAAiAoEUwAAAEQFgikAAACiAsEUAAAAUYFgCgAxyGaz6Y033oh0GQBgKYIpAITo2muvlc1mq/c4//zzI10aAMQ0Z6QLAIBYdP755+v555+v0+bxeCJUDQCcGhgxBYAweDweZWZm1nm0aNFCUvVp9rlz52rixImKj49X165dNX/+/Dqf/+KLL/SjH/1I8fHxatmypW688UaVlJTU2ea5557TmWeeKY/Ho7Zt22rGjBl13s/Pz9cll1yihIQE9ejRQ2+99Vad9zdt2qSJEycqKSlJGRkZuuaaa5Sfn98Evw0AsAbBFACawL333qvLLrtMGzdu1JQpU3TllVfqq6++kiSVlpbqvPPOU4sWLbR69Wq9+uqr+vDDD+sEz7lz52r69Om68cYb9cUXX+itt95S9+7d6xxj9uzZuuKKK/T5559r0qRJmjJlig4dOiRJKigo0I9+9CMNGjRIa9as0cKFC7V//35dccUVzfdLAIBQGQBASKZNm2YcDodJTEys83jggQeMMcZIMjfddFOdzwwdOtT84he/MMYY8+yzz5oWLVqYkpKS4PvvvvuusdvtJjc31xhjTLt27cw999xz3Bokmd/+9rfB1yUlJUaSef/9940xxvzhD38wEyZMqPOZPXv2GElm69atjfj2ANB0uMYUAMLwwx/+UHPnzq3Tlp6eHnw+bNiwOu8NGzZMGzZskCR99dVXGjBggBITE4PvjxgxQn6/X1u3bpXNZtO+ffs0duzYE9bQv3//4PPExESlpKQoLy9PkrRx40Z99NFHSkpKqve5HTt2qGfPng37ogDQjAimABCGxMTEeqfWrRIfH9+g7VwuV53XNptNfr9fklRSUqILL7xQDz30UL3PtW3btvFFAkAT4BpTAGgCK1eurPf6jDPOkCSdccYZ2rhxo0pLS4Pvf/rpp7Lb7erVq5eSk5PVuXNnLV68OOzjn3XWWdq8ebM6d+6s7t2713nUHqkFgGhCMAWAMHi9XuXm5tZ51J7x/uqrr+q5557T119/rfvuu0+fffZZcHLTlClTFBcXp2nTpmnTpk366KOPdPPNN+uaa65RRkaGJGnWrFl69NFH9cQTT2jbtm1at26dnnzyyQbXN336dB06dEhXXXWVVq9erR07duiDDz7Qddddp6qqKmt/GQBgEU7lA0AYFi5cWO+UeK9evbRlyxZJ1TPmX375Zf3yl79U27Zt9dJLL6lPnz6SpISEBH3wwQe69dZbdc455yghIUGXXXaZHnvsseC+pk2bpvLycv3pT3/S7bffrlatWunyyy9vcH3t2rXTp59+qjvvvFMTJkyQ1+tVp06ddP7558tuZ0wCQHSyGWNMpIsAgFOJzWbTggULdPHFF0e6FACIKfxvMwAAAKICwRQAAABRgWtMAcBiXCEFAOFhxBQAAABRgWAKAACAqEAwBQAAQFQgmAIAACAqEEwBAAAQFQimAAAAiAoEUwAAAEQFgikAAACiwv8HXBbQMmmz51IAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Implement\n",
    "\n",
    "def visualize_error(errors):\n",
    "\n",
    "\n",
    "    loss_value = []\n",
    "    for err in errors:\n",
    "        loss_value.append(err.item())\n",
    "        \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(loss_value)\n",
    "    plt.title(\"Loss pro Epoche\")\n",
    "    plt.xlabel(\"Epoche\")\n",
    "    plt.ylabel(\"der bce Loss\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "w_history, l_history = gdi(logistic, bce, tensor_X, tensor_Y, w_init, alpha, 1000)\n",
    "visualize_error(l_history)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "656c5dbf",
   "metadata": {},
   "source": [
    "13. Train 50 epochs of gdi for different learning rates (at least 3), which ones work better than others? Create a method ``visualize_loss_multi`` that takes a list of tuples ``(lr, loss_history)`` as input and visualize the different loss curves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "082b0095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqYAAAHWCAYAAAClsUvDAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAb7hJREFUeJzt3XmcU+W9P/DPyZ5Mkllhhh0UXEABBUHErQVBRKvWtfVWym319goupXqrbRG1WlwqP+pyXW4vLrcX94u1VRHErSoqi1BFRTYBhVmZmSSTyf78/jhzziQzk5ksJ8mZ8Hn3ldckJyfnPJkD9sNznuf7SEIIASIiIiKiAjMUugFERERERACDKRERERHpBIMpEREREekCgykRERER6QKDKRERERHpAoMpEREREekCgykRERER6QKDKRERERHpAoMpEREREekCgykREWnqm2++gSRJ+OMf/1jophBRP8NgSkS68eSTT0KSJGzcuLHQTdE1Jfgle9x9992FbiIRUUZMhW4AERFl5kc/+hHOOeecbttPOOGEArSGiCh7DKZERHkUiUQQi8VgsViyPtaJJ56If/mXf9GgVURE+sBb+UTU73z66aeYM2cO3G43nE4nZsyYgY8++ihhn3A4jNtvvx1jxoyBzWZDZWUlTj31VKxdu1bdp7a2FvPnz8fQoUNhtVoxaNAgnH/++fjmm296Pf9Pf/pTOJ1O7N69G7Nnz0ZJSQkGDx6MO+64A0IIdb/4sZbLly/HkUceCavVii+++AIA8NZbb+G0005DSUkJysrKcP755+PLL7/U7hcFYOTIkTj33HOxZs0aTJw4ETabDWPHjsX//d//ddt39+7duOSSS1BRUQGHw4GTTz4Zr776arf9AoEAbrvtNhx11FGw2WwYNGgQfvjDH2LXrl3d9n388cfV733SSSdhw4YN3fb56quvcPHFF6OiogI2mw2TJ0/GK6+8os0vgIj6FfaYElG/sm3bNpx22mlwu934j//4D5jNZjz22GM488wz8e6772Lq1KkAgNtuuw1Lly7Fz3/+c0yZMgUejwcbN27E5s2bcdZZZwEALrroImzbtg3XXnstRo4cifr6eqxduxb79u3DyJEje21HNBrF2WefjZNPPhn33nsvVq9ejSVLliASieCOO+5I2PeJJ55AIBDA1VdfDavVioqKCrz55puYM2cOjjjiCNx2221ob2/Hgw8+iOnTp2Pz5s19nh8A/H4/Ghsbu20vKyuDydT5n/cdO3bgsssuwy9+8QvMmzcPTzzxBC655BKsXr1a/V3U1dXhlFNOgd/vx3XXXYfKyko89dRT+MEPfoAXX3wRF154ofq9zz33XKxbtw6XX345rr/+eni9Xqxduxaff/45jjzySPW8K1euhNfrxb/9279BkiTce++9+OEPf4jdu3fDbDar13P69OkYMmQIbr75ZpSUlOD555/HBRdcgJdeekk9LxEdJgQRkU488cQTAoDYsGFD0n0uuOACYbFYxK5du9RtBw4cEC6XS5x++unqtgkTJoi5c+cmPU5zc7MAIO6777602zlv3jwBQFx77bXqtlgsJubOnSssFotoaGgQQgixZ88eAUC43W5RX1+fcIyJEyeKgQMHiqamJnXb1q1bhcFgEFdeeWWv51eOm+yxfv16dd8RI0YIAOKll15St7W2topBgwaJE044Qd12ww03CADiH//4h7rN6/WKUaNGiZEjR4poNCqEEGLFihUCgFi2bFm3dsVisYT2VVZWikOHDqnv//WvfxUAxN/+9jd124wZM8Txxx8vAoFAwnFOOeUUMWbMmF5/D0RUfHgrn4j6jWg0ijVr1uCCCy7AEUccoW4fNGgQfvzjH+P999+Hx+MBIPcabtu2DTt27OjxWHa7HRaLBe+88w6am5szas/ChQvV55IkYeHChQiFQnjzzTcT9rvoooswYMAA9fXBgwexZcsW/PSnP0VFRYW6ffz48TjrrLPw2muvpXT+q6++GmvXru32GDt2bMJ+gwcPTuh5dLvduPLKK/Hpp5+itrYWAPDaa69hypQpOPXUU9X9nE4nrr76anzzzTfq8IOXXnoJVVVVuPbaa7u1R5KkhNeXXXYZysvL1dennXYaAHnIAAAcOnQIb731Fi699FJ4vV40NjaisbERTU1NmD17Nnbs2IHvvvsupd8FERUHBlMi6jcaGhrg9/tx9NFHd3vv2GOPRSwWw/79+wEAd9xxB1paWnDUUUfh+OOPx0033YR//vOf6v5WqxX33HMPXn/9dVRXV+P000/Hvffeqwa1vhgMhoRwDABHHXUUAHQbozpq1KiE13v37gWApN+jsbERbW1tfbZhzJgxmDlzZreH2+1O2G/06NHdQmPXtu7duzdpe+LbvGvXLhx99NEJQwWSGT58eMJrJaQq/xDYuXMnhBBYvHgxBgwYkPBYsmQJAKC+vr7P8xBR8WAwJaKidPrpp2PXrl1YsWIFjjvuOPz5z3/GiSeeiD//+c/qPjfccAO+/vprLF26FDabDYsXL8axxx6LTz/9VNO22O12TY/XXxiNxh63i44JYrFYDABw44039tjzu3btWowePTpv7SWiwuPkJyLqNwYMGACHw4Ht27d3e++rr76CwWDAsGHD1G0VFRWYP38+5s+fD5/Ph9NPPx233XYbfv7zn6v7HHnkkfjVr36FX/3qV9ixYwcmTpyI+++/H3/5y196bUssFsPu3bvVnkcA+PrrrwGgz4lLI0aMAICk36OqqgolJSW9HiMdSs9kfK9p17aOGDEiaXvi23zkkUfi448/RjgcVicwZUrpcTabzZg5c2ZWxyKi4sAeUyLqN4xGI2bNmoW//vWvCbfL6+rqsHLlSpx66qnqbeympqaEzzqdTowePRrBYBCAPKM9EAgk7HPkkUfC5XKp+/TloYceUp8LIfDQQw/BbDZjxowZvX5u0KBBmDhxIp566im0tLSo2z///HOsWbOmx6L52Thw4ABWrVqlvvZ4PHj66acxceJE1NTUAADOOeccfPLJJ1i/fr26X1tbGx5//HGMHDlSHbd60UUXobGxMeG7K0RcqaxUDBw4EGeeeSYee+wxHDx4sNv7DQ0NaR2PiPo/9pgSke6sWLECq1ev7rb9+uuvx5133om1a9fi1FNPxTXXXAOTyYTHHnsMwWAQ9957r7rv2LFjceaZZ2LSpEmoqKjAxo0b8eKLL6oTlr7++mvMmDEDl156KcaOHQuTyYRVq1ahrq4Ol19+eZ9ttNlsWL16NebNm4epU6fi9ddfx6uvvorf/OY3CROdkrnvvvswZ84cTJs2DT/72c/UclGlpaW47bbbUvo9bd68ucee3SOPPBLTpk1TXx911FH42c9+hg0bNqC6uhorVqxAXV0dnnjiCXWfm2++Gc888wzmzJmD6667DhUVFXjqqaewZ88evPTSSzAY5H6MK6+8Ek8//TQWLVqETz75BKeddhra2trw5ptv4pprrsH555+fUtsVDz/8ME499VQcf/zxuOqqq3DEEUegrq4O69evx7fffoutW7emdTwi6ucKWhOAiCiOUi4q2WP//v1CCCE2b94sZs+eLZxOp3A4HOJ73/ue+PDDDxOOdeedd4opU6aIsrIyYbfbxTHHHCPuuusuEQqFhBBCNDY2igULFohjjjlGlJSUiNLSUjF16lTx/PPP99nOefPmiZKSErFr1y4xa9Ys4XA4RHV1tViyZIlaVkmIzrJJyUpSvfnmm2L69OnCbrcLt9stzjvvPPHFF1/0ef6+ykXNmzdP3XfEiBFi7ty54o033hDjx48XVqtVHHPMMeKFF17odtxdu3aJiy++WJSVlQmbzSamTJki/v73v3fbz+/3i9/+9rdi1KhRwmw2i5qaGnHxxRerJbx6+94AxJIlS7qd98orrxQ1NTXCbDaLIUOGiHPPPVe8+OKLff4uiKi4SEKkee+FiOgw99Of/hQvvvgifD5foZvSp5EjR+K4447D3//+90I3hYioTxxjSkRERES6wGBKRERERLrAYEpEREREusAxpkRERESkC+wxJSIiIiJdYDAlIiIiIl3o1wX2Y7EYDhw4AJfLlbDUHhERERHpgxACXq8XgwcPVhfrSKZfB9MDBw4krItNRERERPq0f/9+DB06tNd9+nUwdblcAOQvqqyPnUvhcBhr1qzBrFmzYDabc34+yh1ey+LBa1k8eC2LB69l8dDiWno8HgwbNkzNbb3p18FUuX3vdrvzFkwdDgfcbjf/ovVzvJbFg9eyePBaFg9ey+Kh5bVMZdglJz8RERERkS4wmBIRERGRLjCYEhEREZEu9OsxpkRERESpikajCIfDhW5GvxIOh2EymRAIBBCNRnvcx2g0wmQyaVK6k8GUiIiIip7P58O3334LrsSeHiEEampqsH///l6Dp8PhwKBBg2CxWLI6H4MpERERFbVoNIpvv/0WDocDAwYM4KI8aYjFYvD5fHA6nT0WxxdCIBQKoaGhAXv27MGYMWP6LKLfGwZTIiIiKmrhcBhCCAwYMAB2u73QzelXYrEYQqEQbDZb0sBpt9thNpuxd+9edd9McfITERERHRbYU5o72fSSJhxHk6MQEREREWWJwZSIiIiIdIHBlIiIiIh0gcGUiIiISMcefvhhjBw5EjabDVOnTsUnn3zS6/4vvPACjjnmGNhsNhx//PF47bXXEt4XQuDWW2/FoEGDYLfbMXPmTOzYsSNhn7vuugunnHIKnE4nRowYofl3SobBlIiIiEinnnvuOSxatAhLlizB5s2bMWHCBMyePRv19fU97v/hhx/iRz/6EX72s5/h008/xQUXXIALLrgAn3/+ubrPvffeiwceeACPPvooPv74Y5SUlGD27NkIBALqPqFQCJdccgl+8Ytf5Pw7xmMwzZFwLIxfvfMr/O+X/1vophAREVEcIQT8oUhBHukW+F+2bBmuuuoqzJ8/H2PHjsWjjz4Kh8OBFStW9Lj/n/70J5x99tm46aabcOyxx+L3v/89TjzxRDz00EPqd1++fDl+97vf4fzzz8f48ePx9NNP48CBA3j55ZfV49x+++345S9/ieOOOy7j33MmWMc0R7Y1bsOavWuwpX4Lrjj2ikI3h4iIiDq0h6MYe+sbBTn3F3fMhsOSWvwKhULYtGkTbrnlFnWbwWDAzJkzsX79+h4/s379eixatChh2+zZs9XQuWfPHtTW1mLmzJnq+6WlpZg6dSrWr1+Pyy+/PM1vpC32mOZIc6AZANASbOHyZ0RERJS2xsZGRKNRVFdXJ2yvrq5GbW1tj5+pra3tdX/lZzrHzCf2mOZIa6gVABCKhRCIBmA3caUJIiIiPbCbjfjijtkFOzclx2CaI63B1oTnDKZERET6IElSyrfTC6mqqgpGoxF1dXUJ2+vq6lBTU9PjZ2pqanrdX/lZV1eHQYMGJewzceJEDVufGd7Kz5GuwZSIiIgoHRaLBZMmTcK6devUbbFYDOvWrcO0adN6/My0adMS9geAtWvXqvuPGjUKNTU1Cft4PB58/PHHSY+ZT/r/50I/1RJsUZ8zmBIREVEmFi1ahHnz5mHy5MmYMmUKli9fjra2NsyfPx8AcOWVV2LIkCFYunQpAOD666/HGWecgfvvvx9z587Fs88+i40bN+Lxxx8HIPcW33DDDbjzzjsxZswYjBo1CosXL8bgwYNxwQUXqOfdt28fDh06hP379yMWi2HLli0wGAwYPXo0nE5nzr4vg2mOJPSYhhhMiYiIKH2XXXYZGhoacOutt6K2thYTJ07E6tWr1clL+/btg8HQeQP8lFNOwcqVK/G73/0Ov/nNbzBmzBi8/PLLCWWf/uM//gNtbW24+uqr0dLSglNPPRWrV6+GzWZT97n11lvx1FNPqa8nTZoEAHj77bdx5pln5uz7MpjmCG/lExERkRYWLlyIhQsX9vjeO++8023bJZdcgksuuSTp8SRJwh133IE77rgj6T5PPvkknnzyScRiMXg8Hrjd7oQAnCscY5oj8b2k8bf1iYiIiKhnDKY5Eh9GPUFP4RpCRERE1E8wmOYIx5gSERERpYfBNAdC0RDaI+3qa44xJSIiIuobg2kOdA2iDKZEREREfWMwzYFuwZS38omIiIj6xGCaA11n4bcGGEyJiIiI+sJgmgNKD2mVvSrhNRERERElx2CaA8qt/OGu4QCAYDSIQCRQyCYRERER6R6DaQ4owXSwczBMkilhGxERERH1jME0B5QxpmXWMritbgC8nU9ERESZefjhhzFy5EjYbDZMnToVn3zySdJ9t23bhosuuggjR46EJElYvnx5/hqqAQbTHFB6R0utpSi1liZsIyIiIkrVc889h0WLFmHJkiXYvHkzJkyYgNmzZ6O+vr7H/f1+P4444gjcfffdqKmpyXNrs2cqdAOKUUIwtTCYEhER6YoQQNhfmHObHYAkpbz7smXLcNVVV2H+/PkAgEcffRSvvvoqVqxYgZtvvrnb/ieddBJOOukkAOjxfb1jMM0B5bZ9mbWMPaZERER6E/YDfxhcmHP/5gBgKUlp11AohE2bNuGWW25RtxkMBsycORPr16/PVQsLirfyc0AZY1pqibuVzzGmRERElIbGxkZEo1FUV1cnbK+urkZtbW2BWpVb7DHNAfVWvo1jTImIiHTH7JB7Lgt1bkqKwTQH1GBq4RhTIiIi3ZGklG+nF1JVVRWMRiPq6uoSttfV1fXLiU2p4K18jQUiAQSjQQAcY0pERESZs1gsmDRpEtatW6dui8ViWLduHaZNm1bAluUOe0w1powvNUkmlJhLOMaUiIiIMrZo0SLMmzcPkydPxpQpU7B8+XK0tbWps/SvvPJKDBkyBEuXLgUgT5j64osv1OffffcdtmzZAqfTidGjRxfse6SKwVRjSs+o2+qGJEm8lU9EREQZu+yyy9DQ0IBbb70VtbW1mDhxIlavXq1OiNq3bx8Mhs4b4AcOHMAJJ5ygvv7jH/+IP/7xjzjjjDPwzjvv5Lv5aWMw1Vh8DVNAngAVv52IiIgoHQsXLsTChQt7fK9r2Bw5ciSEEHloVW5wjKnG4muYAmCPKREREVGKGEw1Fl/DFOjsOQ1EAwhEAoVqFhEREZHuMZhqrOutfKfZCaNkBAB4Qp6CtYuIiIhI7xhMNeYJyuFTCaaSJMFtcQPg7XwiIiKi3jCYaky5la+MMQXAWqZEREREKWAw1VjXW/nxzxlMiYiIiJJjMNWYOvmpp2DKIvtERERESTGYakyZ4JQQTFkyioiIiKhPDKYa4xhTIiIioswwmGpICNE5xtTS2WPqtnbMyuetfCIiIqKkGEw11B5pRzgWBpB4K1/pPWWPKREREaXjvffew3nnnYfBgwdDkiS8/PLLhW5STjGYakgJnmaDGXaTXd3OMaZERESUiba2NkyYMAEPP/xwoZuSF6ZCN6CYxM/IlyRJ3c4xpkRERPohhEB7pL0g57ab7AkZoS9z5szBnDlzctgifWEw1ZAyhjR+4hPAclFERER60h5px9SVUwty7o9//DEcZkdBzt0f8Fa+hpQeU2UJUgVv5RMRERH1jT2mGvIE5Rqm3XpMbXIwbY+0IxQNwWK05LtpRERE1MFusuPjH39csHNTcgymGupp1ScAcJqdMEgGxEQMrcFWDHAMKEDriIiICAAkSeLtdJ3irXwNKbfqu/aYGiSDenuft/OJiIiIelbQYBqNRrF48WKMGjUKdrsdRx55JH7/+99DCFHIZmVMHWNqdXd7jxOgiIiIKF0+nw9btmzBli1bAAB79uzBli1bsG/fvsI2LEcKeiv/nnvuwSOPPIKnnnoK48aNw8aNGzF//nyUlpbiuuuuK2TTMpJsjCnACVBERESUvo0bN+J73/ue+nrRokUAgHnz5uHJJ58sUKtyp6DB9MMPP8T555+PuXPnAgBGjhyJZ555Bp988kkhm5WxZGNM47cxmBIREVGqzjzzzH57JzkTBQ2mp5xyCh5//HF8/fXXOOqoo7B161a8//77WLZsWY/7B4NBBINB9bXHI/dQhsNhhMPhnLdXOUeycynB1Gl0dtvHZXYBAA61H8pLW6l3fV1L6j94LYsHr2Xx0Nu1DIfDEEIgFoshFosVujn9ihKKld9fMrFYDEIIhMNhGI3GhPfS+XNQ0GB68803w+Px4JhjjoHRaEQ0GsVdd92FK664osf9ly5dittvv73b9jVr1sDhyN/surVr1/a4vcHbAAD45yf/RL2xPuG9Zn8zAGDzF5tRtacqtw2klCW7ltT/8FoWD17L4qGXa2kymVBTUwOfz4dQKFTo5vRLXq+31/dDoRDa29vx3nvvIRKJJLzn9/tTPk9Bg+nzzz+P//3f/8XKlSsxbtw4bNmyBTfccAMGDx6MefPmddv/lltuUcdWAHKP6bBhwzBr1iy43d0nHGktHA5j7dq1OOuss2A2mxPeE0JgybNLAADnzjgXAx0DE97f/9l+rP9sPQYMG4BzppyT87ZS73q7ltS/8FoWD17L4qG3axkIBLB//344nU7YbLZCN6dfEULA6/XC5XL1upRqIBCA3W7H6aef3u13rNzhTkVBg+lNN92Em2++GZdffjkA4Pjjj8fevXuxdOnSHoOp1WqF1Wrttt1sNuf1D35P5/OFfIiKKACgsqQSZlPi++X2cgCAN+zVxV9SkuX7zw7lDq9l8eC1LB56uZbRaBSSJMFgMMBgYKXMdCi375XfXzIGgwGSJPV4zdP5M1DQq+P3+7t9SaPR2C/HfyjjS21GG2ym7v8aU2bqs1wUERFRYRxOk4jyTavfbUF7TM877zzcddddGD58OMaNG4dPP/0Uy5Ytw7/+678WslkZUQJnTzVMAc7KJyIiKhRlMk4oFILdziVBc0EZR5ptD3lBg+mDDz6IxYsX45prrkF9fT0GDx6Mf/u3f8Ott95ayGZlpDXQ86pPCtYxJSIiKgyTyQSHw4GGhgaYzWbezk9DLBZDKBRCIBDo8fcmhIDf70d9fT3Kysq6zchPV0GDqcvlwvLly7F8+fJCNkMTSo9pTzVM47czmBIREeWXJEkYNGgQ9uzZg7179xa6Of2KEALt7e2w2+29Tn4qKytDTU1N1ucraDAtJsoY06Q9ph3B1B/xIxwNw2ws/GBwIiKiw4XFYsGYMWNYLipN4XAY7733Hk4//fSkt+nNZnPWPaUKBlONKD2hbkvPY0xdFhckSBAQaA21osrOWqZERET5ZDAYWC4qTUajEZFIBDabLS8VFjjIQiNKME3WY2qQDOrEKN7OJyIiIuqOwVQjSthMNsYU4AQoIiIiot4wmGpEGWPaazDlBCgiIiKipBhMNdLXrHygs8ap3ovsB6NBxET/W+SAiIiI+jcGU42ot/It/ftWfmuwFTNemIHr376+0E0hIiKiwwyDqUb6mvwU/56eg+mO5h1oDbZic93mQjeFiIiIDjMMphqIiRg8IQ+A/j/GVBkr6w15EY1FC9sYIiIiOqwwmGrAG/KqYzJTCqY6HmOqBFMBAW/IW9jGEBER0WGFwVQDSg+o3WSHxWhJup9SfL8/9JgC+g7QREREVHwYTDWQyvhSoH/cyo9vm57bSURERMWHwVQDqdQwBTqDqzIeVY8SekwZTImIiCiPGEw1kEoN0/j348Of3rQEWjqf67idREREVHwYTDWQSg3T+Pfbwm0Ix8I5b1cm4sOonnt2iYiIqPgwmGog1TGmLotLfe4J6jP08VY+ERERFQqDqQbUHtM+buUbDUY1nOp1xjsnPxEREVGhMJhqINXJT0DcBCgd9pjGRCwhMOs1PBMREVFxYjDVQKqTn4DOcaZ6nFgUv1AAoM82EhERUfFiMNVAayC1MaaAvmuZdg2ieuzVJSIiouLFYKqBdHpM3Vb9rv7UNZjqsY1ERERUvBhMNZDOGFPlVr4ex2/GL60K6LONREREVLwYTLMUjUXhDXkB9F3HFADKbGUA9NkbqQTs4a7hAORb+fFjTomIiIhyicE0S/FF6NPqMdVhMG0ONAMAhrvlYCog1NBNRERElGsMpllSAqbT7ITJYOpzfz1PflLaVGWvgsPkSNhGRERElGsMpllKZ3xp/H56HL+pfJcya5muAzQREREVJwbTLCm38lMNpm6L/mfll1pLdR2giYiIqDgxmGZJDXMpTHwC9L3ykxKWy63l7DElIiKivGMwzZIS3FIprg909qx6w15EYpFcNSsjzUF58lOZtUzXK1QRERFRcWIwzZIS3JTC+X1xWVzq8/gZ/XqgrGBVauu8la/Hnl0iIiIqTgymWUq3x9RkMMFldiV8Vg+EED1PfuIYUyIiIsoTBtMsKeEy1clPgD6XJW2PtCMUCwFIvJWvpzYSERFRcWMwzVK6PaZAZ4jV06185XuYDWY4TA5OfiIiIqK8YzDNUrp1TIHOEKuniUXxE58kSWIwJSIiorxjMM1SunVMAX0uS9o1YHOMKREREeUbg2mW1DGmKdYxBfQ5xrTrkAQ9hmciIiIqbgymWQjHwvCFfQAyG2Oqp9AXPyMfSBwHGxOxArWKiIiIDicMpllQanxKkBLqk/ZF7Y3U0W1yNZjaygB0BtOYiKnhm4iIiCiXGEyzoPR4uiwuGA3GlD+nhD89Fa9vCbQA6OwxtRgtsJvsAPTVs0tERETFi8E0C0qPZzoTnwDocrnPrrfyAX0OOSAiIqLixWCaha69jKnSY+DraaEAToAiIiKifGIwzYLSY6rMsk+VOitfj2NM2WNKREREBcJgmoVMVn0COnsivSEvorGo1s3KSK/BVEcBmoiIiIoXg2kWMqlhCiTeLveGvJq2KVPsMSUiIqJCYzDNQibLkQKAyWCC0+xMOEYhhaNhtIXbAHQJphxjSkRERHnEYJqFniYMpUpPt8mVNnStx8oeUyIiIsonBtMsZBNM3Rb9LEuqVBdwW90J9Vj1FJ6JiIio+DGYZkEJbOlOfgL01RupDCcot5YnbOetfCIiIsonBtMsqGNM05z8BHSGWU+o8Ks/JRsrq6fwTERERMWPwTQLmZaLAjpDnx4mP/U0Ix9gMCUiIqL8YjDNUCgaQnukHUD6BfYBnY0x7avHNNSKmIjlu1lERER0mGEwzZASKA2SIWEme6r01BuZrOdXCc8xEVPLSRERERHlCoNphpReRrfFDYOU/q9RTzPe1clPtsTJTzaTDTajDYA+AjQREREVNwbTDGUzvjT+c56gDiY/dZSL6qnslZ4CNBERERU3BtMMKcE0k/GlQP+Y/ATEBdMAgykRERHlFoNphrKpYQroq0ZoSsGUPaZERESUYwymGVJXfcqghinQ2dPqDXkRjUU1a1cmelvBSk8BmoiIiIobg2mGkpVYSpUS+AQEfGGfVs1KW0zE1N7Qris/AfqqHkBERETFjcE0Q731MqbCbDTDYXIkHKsQvCGvWqO0p1v5Ss8ub+UTERFRrjGYZijbWfnxny3kBCjl3A6TA2ajudv7ShvZY0pERES5xmCaIaUHMdMe0/jPFjL09TbxCeAYUyIiIsofBtMMZTvGFNDHbfK+hiToITwTERHR4YHBNEPZjjEF9NEbmWzVJwXLRREREVG+MJhmSIsxpkroK+TqT82B5oS2dOW2dPTqsseUiIiIcqzgwfS7777Dv/zLv6CyshJ2ux3HH388Nm7cWOhm9SoQCSAYDQLIvI4pEDexSAe38pMF7PilU4UQeWoVERERHY5MhTx5c3Mzpk+fju9973t4/fXXMWDAAOzYsQPl5T3fVtYLJUiaJBNKzCUZH0cPy5L2Ofmpo40REUFbuA1OizNPLSMiIqLDTUGD6T333INhw4bhiSeeULeNGjWqgC1KjdLL6La6IUlSxsfRw23yviZx2Uw2WI1WBKNBtIZaGUyJiIgoZwoaTF955RXMnj0bl1xyCd59910MGTIE11xzDa666qoe9w8GgwgGg+prj0cemxkOhxEOh3PeXuUcTf4mAHKwzOa8TpMc8loCLXlpf0+UMaZuU/Lv4ra40dDegKa2Jgy0Dsxn83JG+a6F+r2TdngtiwevZfHgtSweWlzLdD5b0GC6e/duPPLII1i0aBF+85vfYMOGDbjuuutgsVgwb968bvsvXboUt99+e7fta9asgcPhyEeTAQDvb3gfABBri+G1117L+DjfRL4BABxsPpjVcbKx37MfALB963bEvoj1uI8hKA9FXvuPtdhj3pO3tuXD2rVrC90E0givZfHgtSwevJbFI5tr6ff7U95XEgWc0WKxWDB58mR8+OGH6rbrrrsOGzZswPr167vt31OP6bBhw9DY2Ai3253z9obDYaxduxa+I324e9PdOH3I6Vh+xvKMj7e7dTcufvVilFnL8NZFb2nX0DTMXjUbDe0N+MvZf8HYirE97nPVm1dhU/0m3D39bswaMSvPLcwN5VqeddZZMJu7r3hF/QevZfHgtSwevJbFQ4tr6fF4UFVVhdbW1j7zWkF7TAcNGoSxYxPD0LHHHouXXnqpx/2tViusVmu37WazOa9/8NsibQDk2p/ZnLeypBIA4Al5YDQZYZDyWyRBCKGOb60qqUr6XcpsZQAAX8RXdP+ByfefHcodXsviwWtZPHgti0c21zKdzxW0XNT06dOxffv2hG1ff/01RowYUaAWpaYl1AIgu+L6QOfkp5iIwRvyZtustLVH2hGKhQD0Xo+VRfaJiIgoHwoaTH/5y1/io48+wh/+8Afs3LkTK1euxOOPP44FCxYUsll9UgriZ1NcHwAsRgvsJnvCMfNJ6S01G8xwmJKP0dXDClVERERU/AoaTE866SSsWrUKzzzzDI477jj8/ve/x/Lly3HFFVcUsll9UnoOs+0xjT9GIXojm4PyjPwya1mvZa/c1sKXtSIiIqLiV9AxpgBw7rnn4txzzy10M9KiBDQtgmmZtQy1bbUFCX191TBV6GGFKiIiIip+afeYtre3J0z737t3L5YvX441a9Zo2jA907TH1FK41Z/6Wo5UofbqsseUiIiIcijtYHr++efj6aefBgC0tLRg6tSpuP/++3H++efjkUce0byBeqTVGFOgsLfJ+1qOVMExpkRERJQPaQfTzZs347TTTgMAvPjii6iursbevXvx9NNP44EHHtC8gXojhOjsMbX07zGmajDtKAeVDHtMiYiIKB/SDqZ+vx8ulwuAvOLSD3/4QxgMBpx88snYu3ev5g3UmxBCCMfkpbW0vJVfiFn5LYEWAGncyg+1ooDrMRAREVGRSzuYjh49Gi+//DL279+PN954A7NmySsB1dfX52X1pUJrF+0A5BJLSqmnbBSyNzLVW/lKvdVILIL2SHuOW0VERESHq7SD6a233oobb7wRI0eOxNSpUzFt2jQAcu/pCSecoHkD9cYfkyd+9VViKVVKKCzk5Ke+en7tJjssBguAwrSTiIiIDg9pl4u6+OKLceqpp+LgwYOYMGGCun3GjBm48MILNW2cHik9plrcxgfiJj8VcoxpHz2mkiSh1FqKhvYGtAZbMdg5OPeNIyIiosNORgX2a2pqcMIJJ8BgMMDj8eDll1+Gy+XCMccco3X7dMcv5B5TrYJpQceYphhMAS5LSkRERLmXdjC99NJL8dBDDwGQa5pOnjwZl156KcaPH4+XXnpJ8wbqjdpjqsGMfKB/jDEFOseZcmY+ERER5UrawfS9995Ty0WtWrUKQgi0tLTggQcewJ133ql5A/VG6THtq8RSquJ7ImMipskxUxGOhtEWbgOQZo8pgykRERHlSNrBtLW1FRUVFQCA1atX46KLLoLD4cDcuXOxY8cOzRuoN7nqMY2JGHxhnybHTIVyS16CBJfF1ef+6rKkDKZERESUI2kH02HDhmH9+vVoa2vD6tWr1XJRzc3NsNlsmjdQb5RZ+cqkpWxZjVa17FQ+Q59Sw9RtdcNoMPa5P3tMiYiIKNfSDqY33HADrrjiCgwdOhSDBw/GmWeeCUC+xX/88cdr3T7dUXpMtViOVKGM38znBChlfGm5tTyl/Tn5iYiIiHIt7XJR11xzDaZMmYL9+/fjrLPOgsEgZ9sjjjjisBpjqtWsfOVYdf66/PaYdgTTVL8HJz8RERFRrqUdTAFg8uTJmDx5MoQQEEJAkiTMnTtX67bpUi56TAvRG5nOjHyAt/KJiIgo9zKqY/r000/j+OOPh91uh91ux/jx4/E///M/WrdNl5QeU6UHUQuFmFiUbo8pJz8RERFRrqXdY7ps2TIsXrwYCxcuxPTp0wEA77//Pn7xi1+gsbERv/zlLzVvpF4IIXI6xjSfy30qATPtHlOOMSUiIqIcSTuYPvjgg3jkkUdw5ZVXqtt+8IMfYNy4cbjtttuKOpj6wj7EINca1XqMKVCYHtNyW4qTnyydbVSGbxARERFpKe1b+QcPHsQpp5zSbfspp5yCgwcPatIovfKE5FnzNqMNNpN2pbGUYKocPx+UclGpBmxlv3AsjPZIe66aRURERIextIPp6NGj8fzzz3fb/txzz2HMmDGaNEqvlB5NLceXAom9kfmS7uQnu8kOk0HuYM9ngCYiIqLDR9q38m+//XZcdtlleO+999Qxph988AHWrVvXY2AtJsr4Si1v4wOFnfyUajCVJAll1jI0tjeiJdiCmpKa3DWOiIiIDktp95hedNFF+Pjjj1FVVYWXX34ZL7/8MqqqqvDJJ5/gwgsvzEUbdUMJjlotR6pQVpEqxOSndEJ2IXp2iYiI6PCRUR3TSZMm4S9/+UvCtvr6evzhD3/Ab37zG00apke56jHN9xjTmIip3yXVlZ8A1jIlIiKi3MqojmlPDh48iMWLF2t1OF1SlgzN5RhTIYSmx+6JN+RFTMjVBdIpe6X07LJkFBEREeWCZsH0cNASagGgbQ1ToLMnMiqiaAu3aXrsnihDBhwmB8xGc8qf4618IiIiyiUG0zR8s/czAMCh2mZs2d+C2tYAorHsezhtJhtsRrn8VD56I9Od+KTgrXwiIiLKpYzGmB6u2lu2AzZg57ZduOCDDwAARoOEAU4rqkttqHFbUeO2oabUjppSK6rdto7XNjgsvf+q3VY3Av4AWoItGOIcktPvkcnEJ4DLkhIREVFupRxMFy1a1Ov7DQ0NWTdG744zVGJA225UWk34xm1DvVfuMa31BFDrCWBrL59120yoKbUlhNWaUvl5tdsGp8mNetTnJfSlu+qTgj2mRERElEspB9NPP/20z31OP/30rBqjdzcOPxnG9Z8gelI1fjt3BqIxgUZfEAdbA6htDaCuI6DWtQZwMO61PxSFJxCBJ+DD13W+Ho9tHx6FqQS44YUPMdyCjh5YGwYpYbbj9UC3FVaTMavvke6qTwpOfiIiIqJcSjmYvv3227lsR//grAYASL46APJt/OqOHk8M6/kjQgh4gxHUtcohtbYjxNZ6OoNrbWsQbTEHAKA50IL6g829NqOyxKKG1c4eWHnowKBSO2rcNrjtpqTr2Wc8xpSTn4iIiCiHOMY0DaIjmKIjmKZCkiS4bWa4bWaMqXYl3e/WD/6BVTu34ccnV2FK+YmdwTU+0HoCCEViaGoLoakthC8OJq97ajMb1GEC8UMGBpXasLNJbr/LnF6PqVpvNcglSYmIiEh7DKbp6NJjqqUymxz6ShwhzB0/qMd9hBBo8YcTgmr8EALlebM/jEA4hm+a/Pimyd/tOLYhe2B2Aw+++R2efv3NuABrxaBSe7deWJdNLiml9LC2BFsghEjaI0tERESUCQbTNCT0mAoBaBjMUrlNLkkSykssKC+x4NhByYv8B8LRhN7Wuo7hAnWeAA62tmO3KYAogFikBA3eIBq8QXz2XfLzlliMqC61YYAbgAUIxUJY8eF2DC0rUydyVTmtMBoYVImIiChzDKbpUHpMw34g6AVs2q0ApWUpJpvZiBGVJRhRWdLj+xe9sgxfNwMPXHoqhtsnypO3OiZtxffG1rUG4A1G0BaKYndDG3Y3CDiPMUCSYrjz9c0Qkc6hAErZLGXYgDr+Nc2yWURERHT4YkpIh6UEYYMd5lg74K3VNJjmsxSTMit/RHkVxlWW4rghyceatgUjCaH17m0utMdaccoYO3zeUtR6AmjwBhPKZvXGZTN1VhroNoFLflQ4LDCw95WIiOiwk1Ew/cc//oHHHnsMu3btwosvvoghQ4bgf/7nfzBq1CiceuqpWrdRVwLmMpiD7YCvFhhwlGbHVYKpMmM+V4QQac3KL7GacOQAJ44c4AQAPLmvAntaW3HD7KE4qeYkAEAkGkOjL5QwzlUtl9WlbJY3EIG3l7JZAGA2ShjoSpy01bXqwEC3FTZzdmWziIiISF/SDqYvvfQSfvKTn+CKK67Ap59+imAwCABobW3FH/7wB7z22muaN1JPAuYyuIIHAa+2E6DUGe+h3M54b4+0IxQLAUi/XFT8Z+IDtMloUHs7Uy2bdbC1sxc2vmxWU1sQ4ajAdy3t+K6lvde2lDvM3aoOxC9cUOO2ocxh5iQtIiKifiLtYHrnnXfi0UcfxZVXXolnn31W3T59+nTceeedmjZOj4JKiSVfrabHjZ/8lMsZ78pQAbPBDIfJkfbnM61lmmrZrHA0hnpvELWt7ahtDXYrm6U8D0ZiaPaH0ewP46tab9LjWU0GdaiAumxsqR0DSkzY4wW+a2nH4HIjLCZDWt+HiIiItJd2MN2+fXuPKzyVlpaipaVFizbpWsBUJj/xahxMO3pMoyIKX9gHlyV5eMtG/G38TMKvuvpTjsbCmo0GDCmzY0iZPek+Qgi0tocTy2X1EGIPtYUQjMSw75Af+w51L5sFmLD8838AAKqcli4Btvvz3hYtICIiouylHUxramqwc+dOjBw5MmH7+++/jyOOOEKrdulWwFwmP9G4lqnNZIPNaEMgGkBrsDVnwbQ5KK8qle5ypAp1klYBlyWVJAllDgvKHBYcU5N8AlowEkW9J9glwCrDBtqxu7YZ3ogB4ahAoy+ERl8I2w5ktmiBEmAHuKwwG9n7SkRElIm0g+lVV12F66+/HitWrIAkSThw4ADWr1+PG2+8EYsXL85FG3UlqARTjXtMAbk3MuAPoDXUiqEYqvnxgc6ezkzGlwKdt/L7w+pPVpMRwyocGFbRfchCOBzGa6+9hjlzZsEbEgn1XuOrECjjX1v6WLRAIUlAldOaMGmrW5gttcFlZe8rERFRV2kH05tvvhmxWAwzZsyA3+/H6aefDqvVihtvvBHXXnttLtqoK7nqMQXksFjvr0drIHe9kenMyO9JvqoH5IskSah0WlDptGLc4OS9yF0XLeg65rXOIy9gEImJlBYtcFiMCYFVHkZgjav/asMApxUm9r4SEdFhJO1gKkkSfvvb3+Kmm27Czp074fP5MHbsWDidzly0T3cCyuQnjWflA/m5Ta4GU1tZRp/XciGA/qSvRQsAIBYTaGoLqeWyuvW8djz3BiLwh6LY3diG3Y1tSY9nUHpfe6j7OiguwDqtLEdMRETFIe3/R2ttbUU0GkVFRQXGjh2rbj906BBMJhPcbu2KzuuROvkp2AqE/IAl/ZntyWQ64z0d2d7KVyc/FXCMqV4ZDBIGuKwY4LL2umiBPxTpcbnY+G31HYsW1HuDqPcGAST/fTutJlS7ew6wXDKWiIj6k7SD6eWXX47zzjsP11xzTcL2559/Hq+88krR1zGNGB0QJjukSEeR/QrtJnzl4zZ5c0Ce/JTtrfzDrcdUSw6LCUcMcOKIAcnvMkRjAk2+LhO34kNs3JKxvmAEvoYIdjUk731VloxVS2b1UH2g2s3eVyIiKqy0/1/o448/xrJly7ptP/PMM/Hb3/5Wk0bpmiQBzmqg5Rv5dn4Ogmk+ekwznpXfjyY/9WdGg4SBbhsGum0Y38s8uK5LxiY+D6KuNYAGX+KSsVt7OW9Pva/xwwZq3DZUsveViIhyJO1gGgwGEYlEum0Ph8Nob+99pZ5iIZzVkFq+0b7Ifh5Wf9Jq8lMgGkAgEoDNZNOoZZSJrkvG9iQaE2j0BbtN2Oo6ecuXRu/rQJe1+7CB0s5t1W4bStj7SkREaUr7/zmmTJmCxx9/HA8++GDC9kcffRSTJk3SrGG65qyWf2o8Aaqn5T61lm0wdZqdMEpGREUUrcFWBtN+wGiQUN0RFif0sp8vGOlW77Wuy1CCho6xrwdb5QlevXFZTepwgWSls9j7SkRE8TJaknTmzJnYunUrZsyYAQBYt24dNmzYgDVr1mjeQD0SSjDN4bKkuZLt5CdJklBqLcWhwCG0hlpRXVKtYeuokJxWE0YPdGL0wOS9r5FoDI2+ULexr3U99L56gxF4633YWe9Lery+el+V7ex9JSI6PKT9X/vp06dj/fr1uPfee/H888/Dbrdj/Pjx+O///m+MGTMmF23Unxz1mOZ6jGk4GoYvLIeETIMpALgtbjmYcgLUYcdkNMi9naU2YFjy/fLV+zrQbUOVw4TWkDxkwazx9yUiovzKqBti4sSJWLlypdZt6Tdy1mOa42CqlHiSIGW15Kk6FpYToCiJrHpfW+N7YVPtfTXh9k/f7LPyAHtfiYj0LaP/QkejUaxatQpffvklAGDs2LE4//zzYTIdJv/Bz3WPaagVMRGDQdJ21Z+WQAsAuRap0WDM+DjFtvoTFYZmva+tAdR7A4jGkFLlAaX3tdrdwxAC1n0lIiqotJPktm3b8IMf/AC1tbU4+uijAQD33HMPBgwYgL/97W847rjjNG+k3uS6xzQmYvCFfXBbtF2sQAmS5dbyrI6jrv7EIvuUB331vobDYfzt1ddw0mnfR5M/mjDetafKA6mMfTVIwACXtYdlYxPHwLpsHDxARKSltIPpz3/+c4wbNw4bN25EebkccJqbm/HTn/4UV199NT788EPNG6k7SjD1NwGREGCyaHJYq9EKu8mO9kg7WoOtmgfTbGuYKpR2cYwp6YVRAmrcNgyr7D0o+oIRObimUPe1zhNEnaf3VbdKLMaE4QID3R3DCOJqvw5wWmEyanv3g4ioWKUdTLds2ZIQSgGgvLwcd911F0466SRNG6dbjgrAYAZiYcBXB5T1ch8yTW6LG+2Rdnn8ZubDQHvUHMxu1ScFV3+i/sppNcGZQd3XhKVj41bdagtFsbuhDbt7qftqkIAqZ1yVgR7KZg102+C2mSBJHD5ARIe3tIPpUUcdhbq6OowbNy5he319PUaPHq1Zw3RNMsi9pp5vNQ+mZdYy1PnrcjJ+Uzlmtj2m+VgIgKhQUq372tbR+xo/UavrJK56bxCRmEC9N4h6bxCffZf8H3N2s7Gjp7UzuMYPI1DGxJrZ+0pERSylYOrxdAaQpUuX4rrrrsNtt92Gk08+GQDw0Ucf4Y477sA999yTm1bqkasjmHr7z8z8bGuYKpR6q5z8RIezEqsJRwxw4oheel9jMYHGtiDqPclX3qrzBNHaHkZ7OIo9jW3Y05i89xUAqpyWzvGuagkta0IPbKndzN5XIuqXUgqmZWVlCf+RE0Lg0ksvVbcJIQAA5513HqLRaA6aqUPOGvlnrkpG5WBikTr5yabR5CfeyifqlcEgYaDLhoEuG44bkvxORXsomtD7qgTXek9QLadV7w0gHBVo9IXQ6Ath24HkdyysJrniQbXLppbPqu4yfGCAywqbOfPqHEREuZBSMH377bdz3Y7+x5XbklH94VY+gymRNuwWI0ZWlWBkVUnSfWIxgUP+kBpSa1uD6pCBOm9n+axmfxjBSAx7m/zY2+Tv9bzlDnPCCls99cBWOCwwsHQWEeVJSsH0jDPOyHU7+p9c9Zhacle8Xqljmu2tfLdVnpXPMaZE+WMwSKhyWlHltAJI/o/LQDiq9rQmLBXrDSZUIwhFYmj2h9HsD+OrWm/S45mNcq9vdXy1gS5jYGvcNtgt7H0louwdJhXxcyBHPaZKaMxlj6lWs/LbI+0IRoOwGq1ZtoyItGIzGzG80oHhlY6k+wgh0OIPJ/S01rYGUedNXHmr0RdCOCrwXUs7vmtp7/W8Lpup22IFXce+VnLhAiLqA4NppnI9xjSHk5+yvZXvNDthkAyIiRg8QQ8GOAZo0TwiyhNJklBeYkF5iQXH1CSvlxyKxNDgCyasshUfXpWeWX8oCm8gAm/Ahx29LFxgNEjqsrHVLmtcxYGO4Oowoj3SOW+BiA4/DKaZylGPqXKbXOvJTzERU4+Z7cpPBskAt8WNlmALWoItDKZERcpiMmBImR1DyuxJ9xFCwBuMyGNdexpC0FF5QF42VqhDCZIz4Y6tb3XUd7WqY1+rXTa1nFa1W55QZjGxdBZRsUkrmAohsH//fgwcOBA2my1XbeoflB7TtnogFgWyWHs+Xq5mvHtDXsRELOEc2SizlqEl2MIJUESHOUmS4LaZ4baZMaY6+aogysIFXQNrbZcQ6wlE4A9FsbuxDbv7KJ1VWWJRa7wmG/9a7mDpLKL+JO1gOnr0aGzbtg1jxozRtCF33303brnlFlx//fVYvny5psfOiZIBACRAxIC2BsBVo8lhlclPWgc+ZXypw+SA2Zj9+t656tklouIUv3DB+KE97xMOh7Hqb6/hhFPOQJM/GhdYO1fdii+d1dQWQlNbCF8cTH5ei9HQ2fMat/pWtTtxGAEnbxHpQ1rB1GAwYMyYMWhqatI0mG7YsAGPPfYYxo8fr9kxc85oApwD5ZWfvLXaBdO4VZViIgaDpM2tKq0mPilyWT2AiA5fViMwsrIEY2qS/wM6FhNo9ocSxrkmDh+Qg2xTWwihaAzfNrfj2+beJ2+5bSa1l3Wgq3Pp2IFxvbBVTgtMXHmLKKfSHmN6991346abbsIjjzyC4447LusG+Hw+XHHFFfiv//ov3HnnnVkfL6+c1XIw9Wk3zlQJpjERgzfkzXqikkKriU8K1jIlokIxGCRUOq2odFoxbnDy/UKRGOq9XZaMTTJ5yxOIwNPH5C2DBAxwxfe29rB8rMsGt93E4QNEGUo7mF555ZXw+/2YMGECLBYL7PbEQfGHDh1K63gLFizA3LlzMXPmzD6DaTAYRDAYVF8rS6WGw2GEw+G0zpsJ5RzKT2PJQBgARFq+g9Do/BIk2E12tEfa0dTWBIchecmXdDS1NQGQezq1+F25TPJYskPth/Lyu9da12tJ/RevZfHQ+lpKAKqdZlQ7zcDgnse/CiHgC8rDBuq88vKxyvM6j1xCq94TRIMvhGhMdPTGBgEk/0e5zWzAQJcyScuKGrc14XW124pqlxXWIl55i38vi4cW1zKdz6YdTLUc//nss89i8+bN2LBhQ0r7L126FLfffnu37WvWrIHDoU2AS8XatWsBABNbwhgBYMen/8DXBys1O74lakE72vH6269jqCnJYKw0rQ+sBwD4m/x47bXXsj5eXUDuJf5s52d47UD2xysU5VpS/8drWTwKeS2tAIYDGG4AUNbxABATgC8MtIaAlpCE1hDQqv7seB4G/BEJgXAM+w61Y9+h3ocPOEwCpRag1Nzx0wKUWuTnZRYBtwVwmeWe2v6Kfy+LRzbX0u/vfRW6eGkH03nz5qX7kR7t378f119/PdauXZvyDP9bbrkFixYtUl97PB4MGzYMs2bNgtudvBafVsLhMNauXYuzzjoLZrMZhne2Ah+8i6MGlWL0nHM0O8//vP4/aG1uxbjJ4zB98HRNjrl7625gG3DsqGNxzuTs2+rZ7sFbm95CWXUZzjlNu++eL12vJfVfvJbFoxiuZSAcRb3S2+oJdD73BuNKZwURjMTgj0jwR4CDSJ48jQYJVU5LRy+rPHxA6XVVVuSqdlnhsulr+EAxXEuSaXEtlTvcqciojumuXbvwxBNPYNeuXfjTn/6EgQMH4vXXX8fw4cMxbty4lI6xadMm1NfX48QTT1S3RaNRvPfee3jooYcQDAZhNCbe5rBarbBau68yZDab8/oHXz1f6SAAgNHfAKOG51cmKLVF2zT7Xt6wvORghb1Ck2NWOCrU4/bn/+jk+88O5Q6vZfHoz9fSbDbD5bDhyOrk+wgh0NoeTqz72jH+tbZVrvla2xpAoy/YZfhA8v9zt5uNao3XzklciWW0BrissOV5+EB/vpaUKJtrmc7n0g6m7777LubMmYPp06fjvffew1133YWBAwdi69at+O///m+8+OKLKR1nxowZ+OyzzxK2zZ8/H8cccwx+/etfdwuluqTMxPfmZvUnLZclVY6l+eQnlosiIkqLJEkoc1hQ5rDg6JrktV8j0RgafSE1vNZ7lOVig2oVgjpPEK3tYbSHo/imyY9vmnq/ZVrmMMdVG+gY9xq3hCyXjqVCSzuY3nzzzbjzzjuxaNEiuFydf6G+//3v46GHHkr5OC6Xq9us/pKSElRWVmoy2z8v1GVJtV39SS0ZpWEpJmX2fLarPimUclFahmciIupkMhpQUyr3fvamPRRVe1lrPQE0eIPq8/hyWsFIDC3+MFr8YXxV6016PHXpWLc1IbSy+gDlQ9rB9LPPPsPKlSu7bR84cCAaGxs1aVS/oS5LWgsIAWj0FzQXvZFa1zHN1QpVRESUHrvFiBGVJRhRWZJ0n2TDB2o9nUvG1nWE2sSlY3uvPlDtlkOqvGysPHRgoNuGKocJjQF5zC1v5VM60g6mZWVlOHjwIEaNGpWw/dNPP8WQIUOyasw777yT1efzztkRTGNhwH8IKNFmZr4S+jS9lR+Qj1Vq0+ZWvrLyU3ukHaFoCBajRZPjEhGR9tIZPtDUFopbNjZx5S2lB7a1PYxAOIa9TX7sTTp8wITff7oOpXZzQo9r4nP59QCnlYsXEIAMgunll1+OX//613jhhRcgSRJisRg++OAD3Hjjjbjyyitz0Ub9MlkBewXQfgjw1WoWTN2WjuU+NeqNFEJo3mPqsrggQYKAgCfkQZW9SpPjEhFR4ZiMBjUw9iYQjnZbdSshxLYGcKClDeGYhNb2MFrbw/i6LvniBZIEVHUMH1DGwCpVCKpLO5+XOywwcPxrUUs7mP7hD3/AggULMGzYMESjUYwdOxbRaBQ//vGP8bvf/S4XbdQ3V40cTL21QHVqFQn6ovUY0/ZIO0KxEADtgqlBMsBtdaM12IrWYCuDKRHRYcRmNmJ4pQPDK3uuIR4Oh/Hqq6/h9Blnockf7dLrGlCHFNR3lNSKxAQavEE0eIP4/Lvk/99nNkqdZbK69LqqgdZthcvG4QP9VdrB1GKx4L/+67+wePFifP755/D5fDjhhBMwZsyYXLRP/5zVQP0Xmk6A0vpWvtLzajaY4TBptxBBqaUUrcFWToAiIqJuJAlw2cyocDkwpjr58IFYTKCpLdRR91UumdX5vHMMbKMvhHBU4LuWdnzX0vviBSUWY0fFgc5lYwe6E5eRLUT5LOpbRnVMAWD48OEYPny4lm3pn3JQMkrryU/xt/G1nEFZZi3DPu8+ToAiIqKMGQwSBrisGOCyAkg+DyIUiaHBF+ys+6ouHZs4jMAbiKAtFMXuxjbsbmzr9dxlDjOqXXKArY6rQDDQ3Vn/tcpp4fjXPEopmMavttSXZcuWZdyYfkmZAKVhj2n8rfyYiMEgZfcXojnYnHBcrSgToBhMiYgo1ywmA4aU2TGkzN7rfv5QpEut187Qmqx81va65OWzOP41v1IKpp9++mnC682bNyMSieDoo48GAHz99dcwGo2YNGmS9i3Uu1z0mHbUCBUQ8Ia8WQdKJThqNb5UoQbokHb1VomIiLLhsJgwqsqEUVW9l8/ytEc6VtsKxC0f2/HaG1THv0bTHP86MH752B7GwLp1tnys3qQUTN9++231+bJly+ByufDUU0+hvFwu1t7c3Iz58+fjtNNOy00r9SwHPaZmozwW1B/xozXYmnUw1XpGvkIJ0OwxJSKi/kSSJJQ6zCh1mHFUL+NfozGBQ0nGv9Z55IUM6r1BNLUFUx7/Gl//NXEMbGJJLYcl49GW/Vra3/r+++/HmjVr1FAKAOXl5bjzzjsxa9Ys/OpXv9K0gbqXo2VJy6xlajDNlhpMbWVZHyteLpZOJSIi0gtjiuNfw9EYGtTxrsFuE7fil4/tu/6rzGUzddZ9dXVO3lK2Kb2zVlNxTeBKO5h6PB40NDR0297Q0ACvN/kYjaIV32Oq8epPB9oOaBL6cn0rnz2mRER0ODMbDRhcZsfgPsa/KvVfexpCED8G1h+KwhuIwBvwYWd98vqvAFDuMHdWHXDFBde43tcqpxXmfjKBK+1geuGFF2L+/Pm4//77MWXKFADAxx9/jJtuugk//OEPNW+g7ik9pmE/EPQAGq+spMXM/OaAPPkpZ8FUw6VTiYiIilVf9V8VvmCkY5iAHFbjJ3DJ1Qjk16FIDM3+MJr9YXxV2/sErsoSa7ce13874wjdDRlIuzWPPvoobrzxRvz4xz9GOByWD2Iy4Wc/+xnuu+8+zRuoe5YSwOqWQ6m3TrNgquVa9EowLbeV97FnepQxplotBEBERESA02rC6IFOjB7oTLqPEAKt7eGExQsaupTPil/AoNEXRKMviG0HOv8/e8H3Rufj66Ql7WDqcDjwn//5n7jvvvuwa9cuAMCRRx6JkpLks9+KnrNaDqa+WmDAUZocUsuJRbV+efxrtaM662PF4618IiKiwpAkCWUOC8ocFhxd0/sCBof8IXWogBJaPYEwLCb93d7PuP+2pKQE48eP17It/ZerBmjaIfeYakSr0CeEQG1bboMpJz8RERHpk8EgocopjzMdN7jQremb/qJyf6ROgNJ+9adsQ58v7EN7RC5dUV2icTDt6NX1R/wIR8OaHpuIiIgOPwymWtDxsqR1bXXq8eym3mcLpstlcUGCXIWAE6CIiIgoWwymWsjFsqQaTSzK1fhSADAajHBZ5HEtnABFRERE2WIw1UIOekyVYvjZ3spXekxzEUwBlowiIiIi7TCYaiGHPabZTn6q83cEU43Hlyq4LCkRERFphcFUC2qPqfaz8r0hL6KxaMbHUYJpjaNGk3Z1xZn5REREpBUGUy0oPabBViDU+9q3qVJWfhIQ8IYyX+pVLRWVox7TClsFAOBQ4FBOjk9ERESHDwZTLdhKAWXGu0Ylo8wGM0rM8qIF2YzfzPUY0yp7FQCgsb0xJ8cnIiKiwweDqRYkCXB1BD8Nb+cry5Jmc5s812NMK+2VABhMiYiIKHsMplpxdozh1LDIvtsi387PdGKRL+SDL+wDkLsxpkqPaVN7U06OT0RERIcPBlOt5KDHNNtlSZXeUpfFBYfZoVm74vFWPhEREWmFwVQrOegxVW7lZxxMczy+FGAwJSIiIu0wmGollz2mGU5+UktFleTmNj7QGUw9IQ9C0VDOzkNERETFj8FUKzocY6qWisphj6nb4obJYALAcaZERESUHQZTrehwVn6uZ+QDgCRJvJ1PREREmmAw1UoOekyVW/meoCejz9f65bbkaka+osrGYEpERETZYzDVirIsqb8JiGgz1lKzyU857DEF4iZABRhMiYiIKHMMplqxVwAGs/zcp83t/GzXoVeCaa57TFlkn4iIiLTAYKoVgwFwdvRMahRM3daOyU8ZzMpvC7fBG/YCyF+PKSc/ERERUTYYTLWkToDSZpypcivfG/IiGoum9Vll4pPT7ESJuUST9iTDyU9ERESkBQZTLWk8AUopFwXIdULTod7Gz2ENUwWDKREREWmBwVRLGpeMMhlMcJqdANKfAJWPGqYKBlMiIiLSAoOplnJYMirdCVD5qGGqUCY/NbU3QQiR8/MRERFRcWIw1VIOlyVN+1a+Ekzz0GNaaZODaSAaQFu4LefnIyIiouLEYKqlXPSYWuRgmu6t/HyOMXWYHeoEK97OJyIiokwxmGpJR8uSKqs+5aPHFOA4UyIiIsoeg6mWlB7TtnogzfJOyai1TDPsMc1XMFVu53P1JyIiIsoUg6mWSgYAkgEQMaCtQZNDZrIsqT/sV8ek5mPyE8Ai+0RERJQ9BlMtGU1yOAU0K7KvTH5KJ5gqE59KzCVwWVyatKMvvJVPRERE2WIw1ZrGy5KqwTSNZUnzOSNfwWBKRERE2WIw1ZqrY5ypxsuSptVjmufxpQCDKREREWWPwVRrGveYKsuSpjMrP5/F9RXxRfaJiIiIMsFgqjWNe0zVAvvB1AvsK8uR5qOGqYI9pkRERJQtBlOtadxjqtzK94a9iMQiKX2mkGNMDwUOIapRqSwiIiI6vDCYak3jHtP4WfWpLktaiDGm5bZySJAQFdG0FwMgIiIiAhhMtacuS6pNj6nJYILLLIfTVCdAKT2m+byVbzaYUW4rB8Db+URERJQZBlOtqcuS1gJCaHLIdGqZtkfa1R7LfE5+AjgBioiIiLLDYKo1ZYxpLAz4D2lyyHSCab2/HgBgN9nVntZ8qbJ1TIDisqRERESUAQZTrZmsgL1Cfu7TuJZpCkX248eXSpKkyflTxZn5RERElA0G01zQeAKU29pRyzTQ0ue+hRhfqmAwJSIiomwwmOaC1suSWlJfllSpYZrPGfkKZYwpgykRERFlgsE0F7ReltRWBiC1MaaFWPVJofSYcvITERERZYLBNBdy1WOaSjAtQA1TBW/lExERUTYYTHMhR8uSphJMa/35X45UwWBKRERE2WAwzQWte0ytqY8x1UOPqSfkQSgayvv5iYiIqH9jMM2FAvWYBqNBNAebARSmx9RtccNkMAHgOFMiIiJKH4NpLsT3mGqw+lOqY0zr2+Ti+jajDW6LO+vzpkuSJN7OJyIioowxmOaC0mMa9gNBT9aHUwrs+8I+hGPhpPvFjy/Nd3F9hbr6E4MpERERpYnBNBcsJUBHUXx4sx9n6rJ0Li3q6SXoFrKGqULtMeWypERERJQmBtNcUW/nZz/O1GgwquG0twlQhaxhqmCRfSIiIsoUg2muqBOgtJmZr9zO722caSFn5CtYZJ+IiIgyVdBgunTpUpx00klwuVwYOHAgLrjgAmzfvr2QTdKOhj2mQGoToApZw1TByU9ERESUqYIG03fffRcLFizARx99hLVr1yIcDmPWrFloa2srZLO0oXXJKFvfwVRPPaYMpkRERJQuUyFPvnr16oTXTz75JAYOHIhNmzbh9NNPL1CrNJKjZUlbgi1J99HDGFMGUyIiIspUQYNpV62tcm9gRUVFj+8Hg0EEg0H1tccjz1APh8MIh5OXUdKKco5UziU5qmACEPMcRFSDtrnM8uSn5vbmHs8fioZwKHAIAFBpqczL76MnpWY5QDe1NyEUChWsbFVf0rmWpG+8lsWD17J48FoWDy2uZTqflYTQoAK8BmKxGH7wgx+gpaUF77//fo/73Hbbbbj99tu7bV+5ciUcDkeum5iWKu8XmL7zbvisNVg39t6sj7eufR3eDr6NKZYp+IHjB93ePxQ9hGXeZTDBhCWlSwoWCEMihDta7wAA/K70d7BJtoK0g4iIiPTB7/fjxz/+MVpbW+F2974AkG6C6b//+7/j9ddfx/vvv4+hQ4f2uE9PPabDhg1DY2Njn19UC+FwGGvXrsVZZ50Fs9nc+87eWpgfOA4CEiKLdgD2sqzO/cz2Z3Dfpvtw1vCzcM+p93R7f1P9Jlz15lUY5hyGv/7gr1mdK1unPX8a2iJtWHXuKoxwjyhoW5JJ61qSrvFaFg9ey+LBa1k8tLiWHo8HVVVVKQVTXdzKX7hwIf7+97/jvffeSxpKAcBqtcJqtXbbbjab8/oHP6XzVQwDqo6C1Pg1zN99DBx7blbnLLeXAwC8YW+P524KyuWZapw1Bf+PQJWjCm2eNrSEWzDaPLqgbelLvv/sUO7wWhYPXsviwWtZPLK5lul8rqCz8oUQWLhwIVatWoW33noLo0aNKmRztDfyNPnnN//I+lB91TFVVn2qcRSuVJSi0tZRZJ+rPxEREVEaChpMFyxYgL/85S9YuXIlXC4XamtrUVtbi/b29kI2SzujOioL7Hkv60OVWnsvF6WHGfkKFtknIiKiTBQ0mD7yyCNobW3FmWeeiUGDBqmP5557rpDN0o7SY1r/BeBryOpQajBNsiSpHmqYKlgyioiIiDJR0DGmOpl3lTsllUD1cUDd5/Lt/ON+mPGhlFv5beE2hKNhmI2J4zXUHlMGUyIiIuqnCtpjeljQ6Ha+0+yEBLkEVE+9puoY0wIuR6pgMCUiIqJMMJjmmkbB1Ggwwm2VSyx4gp6E98LRMJoC8nhOPYwxrbTLk584xpSIiIjSwWCaayNOASQDcGgX0PpdVodKtixpfXs9AMBsMKPcWp7VObTAHlMiIiLKBINprtlKgUET5edZlo1KNjM/fuKTHpYAVYLpocAhRGPRAreGiIiI+gsG03zQ6HZ+spn5ehpfCgDltnJIkBAV0W69u0RERETJMJjmw6iOslF73gOyqESQtMdURzVMgY4hBTZ5SAFv5xMREVGqGEzzYfg0wGACWvcDzd9kfBhljGnSYKqDUlEKToAiIiKidDGY5oOlBBh6kvw8i9v5Si3TrrfH9VRcX1Fl65gAxWVJiYiIKEUMpvmirAKVxQQopVxU1x5TvY0xBTgzn4iIiNLHYJov8ROgMhxnmmzyk97GmAKdwZS38omIiChVDKb5MvQkwGQDfHVA49cZHUK5lR/fYxqOhdVeST3dylfGmLLHlIiIiFLFYJovZhswbIr8PMNxpj1NfmrwN0BAwGQwocJWkXUztcIeUyIiIkoXg2k+ZVnPtKce0/gZ+QZJP5eTY0yJiIgoXfpJMoeDUWfIP7/5BxCLpf1xZfKTP+JHOBoGoM8Z+UBcMOWsfCIiIkoRg2k+DT4BsDiB9magflvaH3dZXGqvqDIBSo8Tn4DOYNoabEUoGipwa4iIiKg/YDDNJ6NZLrYPZHQ73yAZ4LYklozSY6koAHBb3DAZTACAQ4FDBW4NERER9QcMpvmW5ThTpWSUUmRfj6s+AYAkSRxnSkRERGlhMM03JZju/RCIRtL+eNeZ+coY0xqHvnpMgbjVnxhMiYiIKAUMpvlWczxgKwWCHuDg1rQ/rhbZV27l++Vb+XobYwpwZj4RERGlh8E03wzGzuVJ97yb9sfjg2kkFlFDn97GmAIssk9ERETpYTAtBOV2/jf/SPuj8cuSNrY3IiZiMEn6Kq6vYI8pERERpYPBtBCUHtO964FIeqWU4ic/KTPyBzoG6qq4voKrPxEREVE69JdmDgcDjwUcVUCkHfhuY1ofjZ/8pNcapgr2mBIREVE6GEwLQZLiykaldztfWZbUE/R01jDV4Yx8gMGUiIiI0sNgWiijlAlQ6dUzjb+Vr/ceU2XyU1OgCUKIAreGiIiI9I7BtFBGnSH//PYTINye8sfiJz8pNUz1VlxfUWmTg2l7pB3+iL/ArSEiIiK9YzAtlIojAPcQIBoC9n+c8sfiy0XpuYYpADjMDpSYSwDwdj4RERH1jcG0UCQprp5p6rfzlWDaHmnHt95vAeh3jCnAcaZERESUOgbTQlInQKUeTJ1mp1oa6lDgEAD99pgCnbfzGUyJiIioLwymhaRMgPpuMxD0pvQRg2RQS0YBgFEyquFPj9hjSkRERKliMC2ksuFA+UhAROVi+ylSbucDwADHABgNxhw0Thsssk9ERESpYjAtNPV2/rspf8RtdavP9Ty+FGCPKREREaWOwbTQlLJR36ReaF8psg/oe3wp0FnLlMGUiIiI+sJgWmjKzPyD/wT8h1L6SPwYU73WMFWwx5SIiIhSxWBaaK5qoOpoAALY+0FKH4kfY1pTou9b+erqTxxjSkRERH1gMNUDdZxparfz44Op7ntMbR2TnwJNiIlYgVtDREREesZgqgdp1jNNCKY6H2NaYa8AAERFFC3BlsI2hoiIiHSNwVQPRp4KQAIavgRav+1z94TJTzrvMTUbzCi3lgPgOFMiIiLqHYOpHjgqgJrj5OfLjwf+8xTglWuBTU8BdduAWDRhd2Xyk1EyYoB9QL5bmzbOzCciIqJUmArdAOpw+k3A6t8Anm+B+m3yY/PT8nsWJzD4BGDIJGDoSahxy2F0iHOIrovrK6rsVdjZspMToIiIiKhXDKZ6MfZ8+eGtBb7dCHy3Uf554FMg5JPrnHbUOj0CwB+qhmKU0Qi88VugcrT8qBoDOKsBSSrsd+mCJaOIiIgoFQymeuOqAY49V34A8m38hq/iwuomoOFLnNf4LdD4LbCzy4pRFidQeWRHWB3T8bPjtc3d/Xx5wGBKREREqWAw1TuDEageJz8mzZO3Bb3AgS1A43agaRfQuANo2gm07JV7Vw9ulR9dOaqAilFAxRFAecfPilHy85KqnPW0MpgSERFRKhhM+yOrCxh1mvyIFwkBzd8ATR1BtWkn0Njxs60e8DfKj283dD+mxQVUjOwMreUjgfIRQNkIoHQoYLJm3FwW2SciIqJUMJgWE5MFGHCU/Ogq4AGa9wCH9gCHdsc93wN4vgNCXqD2M/nRjQS4BnUE1eFyWC0b3vnaPRQwJv+jxB5TIiIiSgWD6eHC5gYGTZAfXYUDQMu+uMC6G2jeK29r2QuE/YD3gPzYt7775yUD4Bos96z28KiSLACAxgCDKRERESXHYEqA2Za8p1UIwN/UEVSVx7641/uBaFAuc+X5Ftjf/RBVBgMwYihag60IPX0BLGXD5CDrHgS4h8i9se7BgL1cdxUFiIiIKH8YTKl3kiRPjCqpAoZO6v5+LCaPX239FmjdD7R+F/f8W6D1W7j9jTAJgYgk4dDe91CzO9r9OABgsnWGVPfgzufOarlagfLTUpLb70xEREQFwWBK2TEY5LDoqgGGTu55l3A7Kv9vDuoCTWj83s2oiQh5WIDnIODpGCLgbwIiAXkoQfOe3s9pcQGuasBZ0/2ncwBQMhBwDgQclXJVAyIiIuoXGEwp98x2VJXUyMF0xBRg2Jnd9wkHAO9B+eE50BFYO5776uSFB3x18njXkBdo8srVBnojGeRwWjJAfjgHdoTWAZBsFRjYuhfSgRrAXSP3CJsdHEpARERUQAymlBd9zsw32zpqrI5KfhAh5Bqu8UHVWwv4agFvnfzT19BRGusQIGJAW4P86MIEYBoA7L4/bqNNrvVaUin/dFTKgTX+p70CcFTIP+3lciUEIiIi0gSDKeWFJiWjJEmuLmBzy8uv9iYakYcHtNUDvno5nPrq5ddtjYh56+A5uBOlpggkf5M8gSsS6JzElSqLC3CUJwbW+OBqLwNsZZ3P7eXyawZaIiKibhhMKS+UIvt5q2VqNMnjTl3VPb4dDYfx7muv4ZxzzoHZZJJXzGprlHta/Y0dzxs7wm1T53P/IaD9ENDeAkDIwwpCXrlSQTrMjs6Qai8HbKWpP6xueWwvERFRkWEwpbxQekx1ufqTJMmraVldvQ8liBeLAoHWzqDa089Aixxg25s7nwdaAQh5rGzYLy9ukAlLR3ttbjmoqs9d8mtbaedzqwuwOuXnFmfHc5f8nJPDiIhIRxhMKS+KbvUng1G+Ze+oSO9zsRgQbO0SWJvlwBpolVfoUp/38Ii0y8dRemq9B7L7HuYSOahanJ3h3FIiv1Z+WpXnynZnl30c8nEsJYDZzglkRESUMQZTyouiC6aZMhg6xpuWA0ixdzZeJCiH16Dy8Ma99ia+pz73yUMVlOdBLxALy8cLt8kP1Gn0BaWOgOqQA6vF2fE8LriaHZ3vm+1yqFW297TNbOv4aQdMdg5jICIqYgymlBdVto5b+YEmCCEgsVctMyarXKvVOSC740SCckBVHiFf3PO2jkdHoFVeJ7zX1tFr65efKz25EJ2fa8v62/bMaI0LrXaYTDac5gvAeOhxOdiabPLDbJODbLKfpo7jmKydn1E/Z+vY3vE+/7wSEeUFgynlhTL5qT3SDn/EjxIzV28qKJNVfpRUaXO8WLSjxqxf7oENtXV/HvIB4faOR5v8M9TWw7aOz4UD8jEjAfmhiAblR6AFACABqACAvbu0+S49MVo7f2dKaDV2ea08jFa56oLJ1vk8/vNGS+J+8T+Nlp6fmyzya6NVHkbCoExERYrBlPLCYXbAYXLAH/Gjsb2RwbTYGIydY1RzIRaTe2XD8Q8/EG5HJODDpo/+gUkTxsEkwvJ7kYAcbCPtSX4G5F7jSHvHz0D37SLWeX4lDAdz8/XSI3UGXKO5I8Sa4wJvx/OEhznup7mH7RbAYIrb3vHcYO7yGXPiNoM5yTZTx8+OzzBIE1GKGEwpb6rsVdjn3YfG9kaMcI8odHOoPzEYOsepdiHCYdR+5YcYdw5gNmtzPiGAWKQzsEaDnQE2EgAiobgQGwCi8a/jtwXj3gt1Hqfrtmgo7v2Q/Fr9fNc0LLr3IuudZOwMrQZjDwFWfm00GHFaqxfGxv+Ue4kN8e8bOz5v6vycwRT3nqnL+6a4bca4fU1x+3d5P/4RfwzJ2MM+PXyG45+JssZgSnkTH0yJdE2SOnsAc9ULnCohgGi4I8CGO0NrNNwZctXtcftEgnK4jt+/2/Nw3LE79o2F47Z37BNTnscdLxaJey/us7FID98hCkSiAHoP0wZ0DMvw53BYRq6pQTYurPYYcI29bDMk2ccYd2xjx37J9onf19DDtrjPS10/19P2rsfo2C/Ze9EYHMEGoPVbwGKN27djKEr8/ur5DOxdJwZTyp+8F9knKgaS1DFmtZ+sFqb0NivBNiHAhuXxyOrzxPcioQA2bfgYk06YAJMUd5xYpMvzjuP09bqnz4to53vxj2j862jiMeL3F9Gew7ciFgEQ6aGn+/BiBnAWAHyR7ielLqFXeW5IDMzqc6mHcKuEZUMP73U9Vtw+kqH757qG5h6Pp7Qj2fENXd7voS09fb7XYyR79LVP3PuQgJrjdfePAQZTyhtdF9knIm3E9zbDkdZHRTiM2h0RiGM1HJaRC0LIY5C7BttuoTfaGWTVR6wz9KrvxRJDbyza5f1o3LG7bo/1cK5Y5/69blM+H+3yXqyHc8d/vsvzrp8XMYhYFNFICEZJgiSUz8T6/t1C9B78SVu3HpKDso7oIpg+/PDDuO+++1BbW4sJEybgwQcfxJQpUwrdLNIYa5kSUVGIvxUNa6Fbo0uRcBivKcs+K//IUAN9Z4BNDL6x7ttFrDMUq9tjXd7rITR3fU8Jxuo+Isn2Lo+ux0w4bpft6nGTHa/je0IkOUfc53s7drJHT8fu9hCJz6Gv3lJAB8H0ueeew6JFi/Doo49i6tSpWL58OWbPno3t27dj4MCBhW4eaYjBlIjoMJYQ6Il6VvBgumzZMlx11VWYP38+AODRRx/Fq6++ihUrVuDmm28ucOtIS0ow3dGyA09tewpWoxVWoxU2k03+abTBaur4abTCapLfN0gGGCQDjJIRkiTJPyHBaDDCAIP6Pov2ExER9W8FDaahUAibNm3CLbfcom4zGAyYOXMm1q9f323/YDCIYLBzQLnH4wEAhMNhhMPhnLdXOUc+zlWMBljl1Ypq22rxx41/zMk5DJIBkvI/KfFn/PsAEI1Ecc8L96iBVtlXEf9aOWbHC3Vbwk8p8XVXXYNz/H6pfqYvPR1Hi2Mk3VcP/xgQQFtbG/78tz/roj16aIPepPpnSggBn8+HFX9fwd9jF+n8vdQD5Vo+8fcn+ue17IdNzsQzZz8DYx892Fpkn3Q+W9Bg2tjYiGg0iurq6oTt1dXV+Oqrr7rtv3TpUtx+++3dtq9ZswYOR3qD7LOxdu3avJ2rmAghMNc+F7XRWkREBGGE1Z9h0eU5IgiLMKKIIoZUBszLYvGD60Xf+wfC/agWJPWqwdtQ6CaQRuo99YVuAmmkzlNX6CZQL15//XUYpNTq72aTffx+f8r7FvxWfjpuueUWLFq0SH3t8XgwbNgwzJo1C263O+fnD4fDWLt2Lc4666zOwdyUlrmYm9HnhBCIimjnT3R5HfdT/Z8QcqgVSNgmhEA4Esb7H7yPU045BSaTCSIuxcYfQ3md0JYu2xM+qzzvEopFlw3xx+z2Xi/7pqvrsfo6ZrL9tZDWsdPYNRKNYOPGjZg8eTJMRu3/k5bL34le6OU7RiIRbNq4CZMmT4LJVNj/e8rm7x0B0WhU/XtpNPY9plQvfwYPN1Oqp/TZo61F9lHucKeioH/zq6qqYDQaUVeX+C+quro61NTUdNvfarXCau0+A9JsNuc1KOb7fKS9cDiM7cbtGFM5hteynwuHw2gyNWHq4Km8lv1cOBxG89ZmTBsyjdeyn+O1LD7ZZJ90PlfQ9dMsFgsmTZqEdevWqdtisRjWrVuHadOmFbBlRERERJRvBb+Vv2jRIsybNw+TJ0/GlClTsHz5crS1tamz9ImIiIjo8FDwYHrZZZehoaEBt956K2prazFx4kSsXr2624QoIiIiIipuBQ+mALBw4UIsXLiw0M0gIiIiogIq6BhTIiIiIiIFgykRERER6QKDKRERERHpAoMpEREREekCgykRERER6QKDKRERERHpAoMpEREREekCgykRERER6QKDKRERERHpAoMpEREREemCLpYkzZQQAgDg8Xjycr5wOAy/3w+PxwOz2ZyXc1Ju8FoWD17L4sFrWTx4LYuHFtdSyWlKbutNvw6mXq8XADBs2LACt4SIiIiIeuP1elFaWtrrPpJIJb7qVCwWw4EDB+ByuSBJUs7P5/F4MGzYMOzfvx9utzvn56Pc4bUsHryWxYPXsnjwWhYPLa6lEAJerxeDBw+GwdD7KNJ+3WNqMBgwdOjQvJ/X7XbzL1qR4LUsHryWxYPXsnjwWhaPbK9lXz2lCk5+IiIiIiJdYDAlIiIiIl1gME2D1WrFkiVLYLVaC90UyhKvZfHgtSwevJbFg9eyeOT7WvbryU9EREREVDzYY0pEREREusBgSkRERES6wGBKRERERLrAYEpEREREusBgmoaHH34YI0eOhM1mw9SpU/HJJ58UuknUh/feew/nnXceBg8eDEmS8PLLLye8L4TArbfeikGDBsFut2PmzJnYsWNHYRpLvVq6dClOOukkuFwuDBw4EBdccAG2b9+esE8gEMCCBQtQWVkJp9OJiy66CHV1dQVqMSXzyCOPYPz48WrB7mnTpuH1119X3+d17J/uvvtuSJKEG264Qd3Ga9l/3HbbbZAkKeFxzDHHqO/n61oymKboueeew6JFi7BkyRJs3rwZEyZMwOzZs1FfX1/oplEv2traMGHCBDz88MM9vn/vvffigQcewKOPPoqPP/4YJSUlmD17NgKBQJ5bSn159913sWDBAnz00UdYu3YtwuEwZs2ahba2NnWfX/7yl/jb3/6GF154Ae+++y4OHDiAH/7whwVsNfVk6NChuPvuu7Fp0yZs3LgR3//+93H++edj27ZtAHgd+6MNGzbgsccew/jx4xO281r2L+PGjcPBgwfVx/vvv6++l7drKSglU6ZMEQsWLFBfR6NRMXjwYLF06dICtorSAUCsWrVKfR2LxURNTY2477771G0tLS3CarWKZ555pgAtpHTU19cLAOLdd98VQsjXzmw2ixdeeEHd58svvxQAxPr16wvVTEpReXm5+POf/8zr2A95vV4xZswYsXbtWnHGGWeI66+/XgjBv5P9zZIlS8SECRN6fC+f15I9pikIhULYtGkTZs6cqW4zGAyYOXMm1q9fX8CWUTb27NmD2trahOtaWlqKqVOn8rr2A62trQCAiooKAMCmTZsQDocTrucxxxyD4cOH83rqWDQaxbPPPou2tjZMmzaN17EfWrBgAebOnZtwzQD+neyPduzYgcGDB+OII47AFVdcgX379gHI77U0aXq0ItXY2IhoNIrq6uqE7dXV1fjqq68K1CrKVm1tLQD0eF2V90ifYrEYbrjhBkyfPh3HHXccAPl6WiwWlJWVJezL66lPn332GaZNm4ZAIACn04lVq1Zh7Nix2LJlC69jP/Lss89i8+bN2LBhQ7f3+Heyf5k6dSqefPJJHH300Th48CBuv/12nHbaafj888/zei0ZTImo31mwYAE+//zzhPFP1L8cffTR2LJlC1pbW/Hiiy9i3rx5ePfddwvdLErD/v37cf3112Pt2rWw2WyFbg5lac6cOerz8ePHY+rUqRgxYgSef/552O32vLWDt/JTUFVVBaPR2G32WV1dHWpqagrUKsqWcu14XfuXhQsX4u9//zvefvttDB06VN1eU1ODUCiElpaWhP15PfXJYrFg9OjRmDRpEpYuXYoJEybgT3/6E69jP7Jp0ybU19fjxBNPhMlkgslkwrvvvosHHngAJpMJ1dXVvJb9WFlZGY466ijs3Lkzr38vGUxTYLFYMGnSJKxbt07dFovFsG7dOkybNq2ALaNsjBo1CjU1NQnX1ePx4OOPP+Z11SEhBBYuXIhVq1bhrbfewqhRoxLenzRpEsxmc8L13L59O/bt28fr2Q/EYjEEg0Fex35kxowZ+Oyzz7Blyxb1MXnyZFxxxRXqc17L/svn82HXrl0YNGhQXv9e8lZ+ihYtWoR58+Zh8uTJmDJlCpYvX462tjbMnz+/0E2jXvh8PuzcuVN9vWfPHmzZsgUVFRUYPnw4brjhBtx5550YM2YMRo0ahcWLF2Pw4MG44IILCtdo6tGCBQuwcuVK/PWvf4XL5VLHNZWWlsJut6O0tBQ/+9nPsGjRIlRUVMDtduPaa6/FtGnTcPLJJxe49RTvlltuwZw5czB8+HB4vV6sXLkS77zzDt544w1ex37E5XKpY7wVJSUlqKysVLfzWvYfN954I8477zyMGDECBw4cwJIlS2A0GvGjH/0ov38vNZ3jX+QefPBBMXz4cGGxWMSUKVPERx99VOgmUR/efvttAaDbY968eUIIuWTU4sWLRXV1tbBarWLGjBli+/bthW009ain6whAPPHEE+o+7e3t4pprrhHl5eXC4XCICy+8UBw8eLBwjaYe/eu//qsYMWKEsFgsYsCAAWLGjBlizZo16vu8jv1XfLkoIXgt+5PLLrtMDBo0SFgsFjFkyBBx2WWXiZ07d6rv5+taSkIIoW3UJSIiIiJKH8eYEhEREZEuMJgSERERkS4wmBIRERGRLjCYEhEREZEuMJgSERERkS4wmBIRERGRLjCYEhEREZEuMJgSERERkS4wmBIR9UOSJOHll18udDOIiDTFYEpElKaf/vSnkCSp2+Pss88udNOIiPo1U6EbQETUH5199tl44oknErZZrdYCtYaIqDiwx5SIKANWqxU1NTUJj/LycgDybfZHHnkEc+bMgd1uxxFHHIEXX3wx4fOfffYZvv/978Nut6OyshJXX301fD5fwj4rVqzAuHHjYLVaMWjQICxcuDDh/cbGRlx44YVwOBwYM2YMXnnllYT3P//8c8yZMwdOpxPV1dX4yU9+gsbGxhz8NoiItMFgSkSUA4sXL8ZFF12ErVu34oorrsDll1+OL7/8EgDQ1taG2bNno7y8HBs2bMALL7yAN998MyF4PvLII1iwYAGuvvpqfPbZZ3jllVcwevTohHPcfvvtuPTSS/HPf/4T55xzDq644gocOnQIANDS0oLvf//7OOGEE7Bx40asXr0adXV1uPTSS/P3SyAiSpcgIqK0zJs3TxiNRlFSUpLwuOuuu4QQQgAQv/jFLxI+M3XqVPHv//7vQgghHn/8cVFeXi58Pp/6/quvvioMBoOora0VQggxePBg8dvf/jZpGwCI3/3ud+prn88nAIjXX39dCCHE73//ezFr1qyEz+zfv18AENu3b8/i2xMR5Q7HmBIRZeB73/seHnnkkYRtFRUV6vNp06YlvDdt2jRs2bIFAPDll19iwoQJKCkpUd+fPn06YrEYtm/fDkmScODAAcyYMaPXNowfP159XlJSArfbjfr6egDA1q1b8fbbb8PpdHb73K5du3DUUUel9kWJiPKIwZSIKAMlJSXdbq1rxW63p7Sf2WxOeC1JEmKxGADA5/PhvPPOwz333NPtc4MGDcq+kUREOcAxpkREOfDRRx91e33ssccCAI499lhs3boVbW1t6vsffPABDAYDjj76aLhcLowcORLr1q3L+Pwnnngitm3bhpEjR2L06NEJj/ieWiIiPWEwJSLKQDAYRG1tbcIjfsb7Cy+8gBUrVuDrr7/GkiVL8Mknn6iTm6644grYbDbMmzcPn3/+Od5++21ce+21+MlPfoLq6moAwG233Yb7778fDzzwAHbs2IHNmzfjwQcfTLl9CxYswKFDh/CjH/0IGzZswK5du/DGG29g/vz5iEaj2v4yiIg0wlv5REQZWL16dbdb4kcffTS++uorAPKM+WeffRbXXHMNBg0ahGeeeQZjx44FADgcDrzxxhu4/vrrcdJJJ8HhcOCiiy7CsmXL1GPNmzcPgUAA/+///T/ceOONqKqqwsUXX5xy+wYPHowPPvgAv/71rzFr1iwEg0GMGDECZ599NgwG9kkQkT5JQghR6EYQERUTSZKwatUqXHDBBYVuChFRv8J/NhMRERGRLjCYEhEREZEucIwpEZHGOEKKiCgz7DElIiIiIl1gMCUiIiIiXWAwJSIiIiJdYDAlIiIiIl1gMCUiIiIiXWAwJSIiIiJdYDAlIiIiIl1gMCUiIiIiXfj/SZet39Woia4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Implement\n",
    "def visualize_loss_multi(tuples):\n",
    "\n",
    "        \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    for t in tuples:\n",
    "        loss_value = []\n",
    "        for err in t[1]:\n",
    "            loss_value.append(err.item())\n",
    "        plt.plot(loss_value, label=f\"{t[0]}\")\n",
    "    plt.title(\"Loss pro Epoche\")\n",
    "    plt.xlabel(\"Epoche\")\n",
    "    plt.ylabel(\"der bce Loss\")\n",
    "    #plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "#w_history, l_history = gdi(logistic, bce, tensor_X, tensor_Y, w_init, alpha, 1000)\n",
    "listl = []\n",
    "listl.append((0.001, gdi(logistic, bce, tensor_X, tensor_Y, w_init, 0.001, 50)[1] ))\n",
    "listl.append((0.1, gdi(logistic, bce, tensor_X, tensor_Y, w_init, 0.1, 50)[1] ))\n",
    "listl.append((1, gdi(logistic, bce, tensor_X, tensor_Y, w_init, 1, 50)[1] ))\n",
    "\n",
    "visualize_loss_multi(listl)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cfa01dd8-5352-478a-a78c-916612aef99c",
   "metadata": {},
   "source": [
    "### 2.3:  Shallow neural network for Iris Dataset\n",
    "\n",
    "A shallow neural network has exactly one hidden (fully-connected) layer between the input and output layers.\n",
    "\n",
    "We therefore train two \"layers\" of weights, one connecting each input feature to each neuron of the hidden layer and one connecting each hidden layer neuron to the final output layer, which in our case consists of only one neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55a674d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_neuron = 10\n",
    "n_features = biris_X.shape[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e7ac54b",
   "metadata": {},
   "source": [
    "1. Initialize the two random weight tensors ``w1`` and ``w2``. Note: These `w` matrices need to be transposed compared to the lecture. Here, `n_features` is the number of rows of the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5e9f9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7146, -0.8213, -0.3711, -0.4993,  0.4212,  1.5046,  1.2716,  0.6187,\n",
      "          0.8700, -1.8476],\n",
      "        [ 0.9002,  1.2831,  0.0840,  0.3900, -0.5798,  0.8759,  0.4573,  0.5177,\n",
      "         -0.2771, -0.6641],\n",
      "        [ 0.6551,  0.6285, -1.2405, -0.3207,  0.4428, -0.2321, -0.0327, -2.4472,\n",
      "         -0.4420, -0.9017],\n",
      "        [-1.0639,  0.6492,  0.0309, -1.3457,  1.1755, -2.6328,  0.5781,  0.3467,\n",
      "         -0.9123, -0.4753]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement\n",
    "w1 = torch.randn((n_features, n_hidden_neuron), dtype=torch.double)\n",
    "w2 = torch.randn((n_hidden_neuron, 1), dtype=torch.double)\n",
    "\n",
    "# n_features = input dann n_features -> n_hidden_neuron dann n_hidden_neuron -> output (ein ergebnis)\n",
    "print(w1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7f13b34",
   "metadata": {},
   "source": [
    "2. Define a python method to calculate the outputs of the neural network (predictions). \n",
    "This is quite easy, just predict like you previously did, but chain the output of the first layer to the second layer and use w1 and w2 respectively. \n",
    "[Squeeze](https://pytorch.org/docs/stable/generated/torch.squeeze.html) the output to remove unnecessary lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c8279df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_shallow(w1, w2, x):\n",
    "    # TODO: Implement\n",
    "    y_pred_w1 = logistic(w1, x)\n",
    "    y_pred_w2 = logistic(w2, y_pred_w1)\n",
    "    return torch.squeeze(y_pred_w2)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9cd28f0f",
   "metadata": {},
   "source": [
    "3. Run your shallow network on biris and the two random weights. Print the output shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f38a2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150])\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement\n",
    "pred = nn_shallow(w1, w2, tensor_X)\n",
    "print(pred.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46599334",
   "metadata": {},
   "source": [
    "4. Calculate BCE loss on these predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f34f7eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8320, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement\n",
    "\n",
    "#tensor(0.7958)\n",
    "#print(tensor_Y.shape, pred.shape)\n",
    "print(torch.nn.functional.binary_cross_entropy(pred, tensor_Y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38d8c495",
   "metadata": {},
   "source": [
    "5. Create a copy of the gradient descend ``gdi`` method called ``gdi_two_w`` to allow updating both weights w1 and w2 (using the respective gradients). It will return the history for both weights separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ca8d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement\n",
    "def gdi_two_w(modelfunc, lossfunc, X, y, w1_0, w2_0, alpha, max_epochs=500):\n",
    "    w1_history = []\n",
    "    w2_history = []\n",
    "    l_history = []\n",
    "\n",
    "    w1 = w1_0.clone().detach().requires_grad_()\n",
    "    w2 = w2_0.clone().detach().requires_grad_()\n",
    "    for k in range(max_epochs):\n",
    "        pred = modelfunc(w1, w2, X)\n",
    "        loss = lossfunc(y, pred)\n",
    "        loss.backward()\n",
    "\n",
    "        w1 = w1 - alpha * w1.grad\n",
    "        w2 = w2 - alpha * w2.grad\n",
    "\n",
    "        w1.grad = None\n",
    "        w2.grad = None\n",
    "        w1.retain_grad()\n",
    "        w2.retain_grad()\n",
    "        w1_history.append(w1)\n",
    "        w2_history.append(w2)\n",
    "        l_history.append(loss)\n",
    "    return w1_history, w2_history, l_history\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4869056",
   "metadata": {},
   "source": [
    "6. Initialize random weights with ``requires_grad=True`` and train 1000 epochs of ``gdi_two_w`` using your shallow network as ``modelfunc``, the biris dataset and a learning rate of 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee75db39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 0.0605, -0.1687,  1.4173,  0.9893,  1.3603, -0.0939,  1.7963, -2.7218,\n",
      "          0.5412, -0.8270],\n",
      "        [ 0.1072,  0.6840, -0.6507, -0.5983,  1.1049,  0.0729,  0.7497, -0.7880,\n",
      "         -0.4237, -1.2933],\n",
      "        [-0.3371, -1.7329, -0.8420, -0.5398, -0.6986,  0.2145,  0.1076,  0.6572,\n",
      "          0.4980,  0.7066],\n",
      "        [-1.8170, -1.4611,  2.4478, -1.2868,  1.4204,  0.0435, -0.6199, -0.6909,\n",
      "          0.1801,  0.6228]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.0644, -0.1672,  1.4171,  0.9892,  1.3603, -0.0942,  1.7963, -2.7218,\n",
      "          0.5409, -0.8271],\n",
      "        [ 0.1099,  0.6851, -0.6508, -0.5983,  1.1049,  0.0724,  0.7497, -0.7880,\n",
      "         -0.4240, -1.2933],\n",
      "        [-0.3361, -1.7324, -0.8420, -0.5400, -0.6986,  0.2150,  0.1076,  0.6572,\n",
      "          0.4979,  0.7065],\n",
      "        [-1.8169, -1.4610,  2.4478, -1.2869,  1.4204,  0.0438, -0.6199, -0.6909,\n",
      "          0.1801,  0.6228]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.0683, -0.1657,  1.4168,  0.9890,  1.3603, -0.0945,  1.7963, -2.7218,\n",
      "          0.5405, -0.8271],\n",
      "        [ 0.1127,  0.6861, -0.6510, -0.5983,  1.1049,  0.0719,  0.7497, -0.7880,\n",
      "         -0.4242, -1.2933],\n",
      "        [-0.3352, -1.7320, -0.8421, -0.5402, -0.6986,  0.2154,  0.1076,  0.6572,\n",
      "          0.4979,  0.7065],\n",
      "        [-1.8167, -1.4610,  2.4478, -1.2870,  1.4204,  0.0440, -0.6199, -0.6909,\n",
      "          0.1801,  0.6228]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.0721, -0.1642,  1.4166,  0.9889,  1.3603, -0.0948,  1.7963, -2.7218,\n",
      "          0.5401, -0.8272],\n",
      "        [ 0.1154,  0.6871, -0.6511, -0.5983,  1.1049,  0.0715,  0.7497, -0.7880,\n",
      "         -0.4245, -1.2933],\n",
      "        [-0.3342, -1.7316, -0.8422, -0.5404, -0.6986,  0.2159,  0.1076,  0.6572,\n",
      "          0.4978,  0.7064],\n",
      "        [-1.8166, -1.4609,  2.4478, -1.2870,  1.4204,  0.0442, -0.6199, -0.6909,\n",
      "          0.1801,  0.6228]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.0759, -0.1627,  1.4164,  0.9888,  1.3603, -0.0951,  1.7963, -2.7218,\n",
      "          0.5398, -0.8272],\n",
      "        [ 0.1181,  0.6882, -0.6513, -0.5983,  1.1049,  0.0710,  0.7497, -0.7880,\n",
      "         -0.4248, -1.2934],\n",
      "        [-0.3333, -1.7311, -0.8422, -0.5406, -0.6986,  0.2164,  0.1076,  0.6572,\n",
      "          0.4977,  0.7064],\n",
      "        [-1.8165, -1.4608,  2.4478, -1.2871,  1.4204,  0.0445, -0.6199, -0.6909,\n",
      "          0.1800,  0.6227]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.0796, -0.1612,  1.4162,  0.9886,  1.3603, -0.0953,  1.7963, -2.7218,\n",
      "          0.5394, -0.8273],\n",
      "        [ 0.1207,  0.6892, -0.6514, -0.5983,  1.1049,  0.0706,  0.7497, -0.7880,\n",
      "         -0.4250, -1.2934],\n",
      "        [-0.3324, -1.7307, -0.8423, -0.5408, -0.6986,  0.2169,  0.1076,  0.6572,\n",
      "          0.4976,  0.7063],\n",
      "        [-1.8164, -1.4608,  2.4478, -1.2872,  1.4204,  0.0447, -0.6199, -0.6909,\n",
      "          0.1800,  0.6227]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.0833, -0.1597,  1.4160,  0.9885,  1.3603, -0.0956,  1.7963, -2.7218,\n",
      "          0.5391, -0.8273],\n",
      "        [ 0.1233,  0.6902, -0.6516, -0.5983,  1.1049,  0.0702,  0.7497, -0.7880,\n",
      "         -0.4253, -1.2934],\n",
      "        [-0.3315, -1.7303, -0.8423, -0.5410, -0.6986,  0.2174,  0.1076,  0.6572,\n",
      "          0.4975,  0.7063],\n",
      "        [-1.8163, -1.4607,  2.4478, -1.2873,  1.4204,  0.0449, -0.6199, -0.6909,\n",
      "          0.1800,  0.6227]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.0870, -0.1582,  1.4158,  0.9883,  1.3603, -0.0958,  1.7963, -2.7218,\n",
      "          0.5387, -0.8274],\n",
      "        [ 0.1259,  0.6912, -0.6517, -0.5984,  1.1049,  0.0697,  0.7497, -0.7880,\n",
      "         -0.4255, -1.2934],\n",
      "        [-0.3307, -1.7299, -0.8424, -0.5412, -0.6986,  0.2179,  0.1076,  0.6572,\n",
      "          0.4974,  0.7062],\n",
      "        [-1.8162, -1.4606,  2.4477, -1.2874,  1.4204,  0.0452, -0.6199, -0.6909,\n",
      "          0.1800,  0.6227]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.0906, -0.1567,  1.4156,  0.9882,  1.3603, -0.0960,  1.7963, -2.7218,\n",
      "          0.5384, -0.8274],\n",
      "        [ 0.1285,  0.6922, -0.6518, -0.5984,  1.1049,  0.0693,  0.7497, -0.7880,\n",
      "         -0.4258, -1.2934],\n",
      "        [-0.3298, -1.7294, -0.8424, -0.5414, -0.6986,  0.2184,  0.1076,  0.6572,\n",
      "          0.4973,  0.7062],\n",
      "        [-1.8161, -1.4605,  2.4477, -1.2874,  1.4204,  0.0454, -0.6199, -0.6909,\n",
      "          0.1800,  0.6227]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.0942, -0.1553,  1.4154,  0.9880,  1.3603, -0.0962,  1.7963, -2.7218,\n",
      "          0.5380, -0.8275],\n",
      "        [ 0.1311,  0.6932, -0.6520, -0.5984,  1.1049,  0.0689,  0.7497, -0.7880,\n",
      "         -0.4260, -1.2935],\n",
      "        [-0.3290, -1.7290, -0.8425, -0.5416, -0.6986,  0.2189,  0.1076,  0.6572,\n",
      "          0.4972,  0.7062],\n",
      "        [-1.8161, -1.4605,  2.4477, -1.2875,  1.4204,  0.0457, -0.6199, -0.6909,\n",
      "          0.1800,  0.6227]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.0977, -0.1538,  1.4152,  0.9879,  1.3603, -0.0964,  1.7963, -2.7218,\n",
      "          0.5377, -0.8276],\n",
      "        [ 0.1336,  0.6942, -0.6521, -0.5984,  1.1049,  0.0686,  0.7497, -0.7880,\n",
      "         -0.4262, -1.2935],\n",
      "        [-0.3282, -1.7286, -0.8425, -0.5419, -0.6986,  0.2195,  0.1076,  0.6572,\n",
      "          0.4971,  0.7061],\n",
      "        [-1.8160, -1.4604,  2.4477, -1.2876,  1.4204,  0.0459, -0.6199, -0.6909,\n",
      "          0.1800,  0.6227]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1011, -0.1523,  1.4150,  0.9877,  1.3603, -0.0965,  1.7963, -2.7218,\n",
      "          0.5373, -0.8276],\n",
      "        [ 0.1360,  0.6952, -0.6523, -0.5985,  1.1049,  0.0682,  0.7497, -0.7880,\n",
      "         -0.4265, -1.2935],\n",
      "        [-0.3274, -1.7282, -0.8426, -0.5421, -0.6986,  0.2200,  0.1076,  0.6572,\n",
      "          0.4971,  0.7061],\n",
      "        [-1.8159, -1.4603,  2.4477, -1.2877,  1.4204,  0.0462, -0.6199, -0.6909,\n",
      "          0.1800,  0.6226]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1045, -0.1509,  1.4149,  0.9876,  1.3603, -0.0967,  1.7963, -2.7218,\n",
      "          0.5370, -0.8277],\n",
      "        [ 0.1385,  0.6962, -0.6524, -0.5985,  1.1049,  0.0678,  0.7497, -0.7880,\n",
      "         -0.4267, -1.2935],\n",
      "        [-0.3267, -1.7278, -0.8426, -0.5423, -0.6986,  0.2205,  0.1076,  0.6572,\n",
      "          0.4970,  0.7060],\n",
      "        [-1.8158, -1.4603,  2.4477, -1.2878,  1.4204,  0.0464, -0.6199, -0.6909,\n",
      "          0.1800,  0.6226]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1079, -0.1494,  1.4147,  0.9874,  1.3603, -0.0968,  1.7963, -2.7218,\n",
      "          0.5367, -0.8277],\n",
      "        [ 0.1409,  0.6972, -0.6525, -0.5985,  1.1049,  0.0675,  0.7497, -0.7880,\n",
      "         -0.4269, -1.2936],\n",
      "        [-0.3260, -1.7273, -0.8426, -0.5425, -0.6986,  0.2211,  0.1076,  0.6572,\n",
      "          0.4969,  0.7060],\n",
      "        [-1.8158, -1.4602,  2.4477, -1.2878,  1.4204,  0.0467, -0.6199, -0.6909,\n",
      "          0.1799,  0.6226]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1111, -0.1480,  1.4145,  0.9872,  1.3603, -0.0969,  1.7963, -2.7218,\n",
      "          0.5363, -0.8278],\n",
      "        [ 0.1433,  0.6982, -0.6527, -0.5985,  1.1049,  0.0671,  0.7497, -0.7880,\n",
      "         -0.4272, -1.2936],\n",
      "        [-0.3253, -1.7269, -0.8427, -0.5427, -0.6986,  0.2216,  0.1076,  0.6572,\n",
      "          0.4968,  0.7059],\n",
      "        [-1.8157, -1.4601,  2.4477, -1.2879,  1.4204,  0.0469, -0.6199, -0.6909,\n",
      "          0.1799,  0.6226]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1144, -0.1465,  1.4143,  0.9871,  1.3603, -0.0970,  1.7963, -2.7218,\n",
      "          0.5360, -0.8278],\n",
      "        [ 0.1456,  0.6992, -0.6528, -0.5986,  1.1049,  0.0668,  0.7497, -0.7880,\n",
      "         -0.4274, -1.2936],\n",
      "        [-0.3246, -1.7265, -0.8427, -0.5430, -0.6986,  0.2222,  0.1076,  0.6572,\n",
      "          0.4967,  0.7059],\n",
      "        [-1.8157, -1.4601,  2.4477, -1.2880,  1.4204,  0.0472, -0.6199, -0.6909,\n",
      "          0.1799,  0.6226]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1176, -0.1451,  1.4141,  0.9869,  1.3603, -0.0971,  1.7963, -2.7218,\n",
      "          0.5357, -0.8279],\n",
      "        [ 0.1479,  0.7002, -0.6529, -0.5986,  1.1049,  0.0664,  0.7497, -0.7880,\n",
      "         -0.4276, -1.2936],\n",
      "        [-0.3239, -1.7261, -0.8428, -0.5432, -0.6986,  0.2227,  0.1076,  0.6572,\n",
      "          0.4967,  0.7058],\n",
      "        [-1.8156, -1.4600,  2.4477, -1.2881,  1.4204,  0.0474, -0.6199, -0.6909,\n",
      "          0.1799,  0.6226]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1207, -0.1436,  1.4139,  0.9867,  1.3603, -0.0972,  1.7963, -2.7218,\n",
      "          0.5354, -0.8279],\n",
      "        [ 0.1502,  0.7012, -0.6531, -0.5986,  1.1049,  0.0661,  0.7497, -0.7880,\n",
      "         -0.4279, -1.2937],\n",
      "        [-0.3233, -1.7257, -0.8428, -0.5434, -0.6986,  0.2233,  0.1076,  0.6572,\n",
      "          0.4966,  0.7058],\n",
      "        [-1.8156, -1.4599,  2.4477, -1.2882,  1.4204,  0.0477, -0.6199, -0.6909,\n",
      "          0.1799,  0.6225]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1237, -0.1422,  1.4137,  0.9865,  1.3603, -0.0972,  1.7963, -2.7218,\n",
      "          0.5351, -0.8280],\n",
      "        [ 0.1525,  0.7022, -0.6532, -0.5987,  1.1049,  0.0658,  0.7497, -0.7880,\n",
      "         -0.4281, -1.2937],\n",
      "        [-0.3227, -1.7253, -0.8429, -0.5436, -0.6986,  0.2239,  0.1076,  0.6572,\n",
      "          0.4965,  0.7058],\n",
      "        [-1.8156, -1.4599,  2.4477, -1.2883,  1.4204,  0.0479, -0.6199, -0.6909,\n",
      "          0.1799,  0.6225]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1267, -0.1408,  1.4136,  0.9864,  1.3603, -0.0973,  1.7963, -2.7218,\n",
      "          0.5347, -0.8280],\n",
      "        [ 0.1547,  0.7032, -0.6533, -0.5987,  1.1049,  0.0655,  0.7497, -0.7880,\n",
      "         -0.4283, -1.2937],\n",
      "        [-0.3221, -1.7248, -0.8429, -0.5439, -0.6986,  0.2244,  0.1076,  0.6572,\n",
      "          0.4964,  0.7057],\n",
      "        [-1.8155, -1.4598,  2.4477, -1.2883,  1.4204,  0.0482, -0.6199, -0.6909,\n",
      "          0.1799,  0.6225]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1297, -0.1393,  1.4134,  0.9862,  1.3603, -0.0973,  1.7963, -2.7218,\n",
      "          0.5344, -0.8281],\n",
      "        [ 0.1568,  0.7042, -0.6534, -0.5988,  1.1049,  0.0652,  0.7497, -0.7880,\n",
      "         -0.4285, -1.2937],\n",
      "        [-0.3216, -1.7244, -0.8430, -0.5441, -0.6986,  0.2250,  0.1076,  0.6572,\n",
      "          0.4963,  0.7057],\n",
      "        [-1.8155, -1.4597,  2.4477, -1.2884,  1.4204,  0.0484, -0.6199, -0.6909,\n",
      "          0.1799,  0.6225]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1326, -0.1379,  1.4132,  0.9860,  1.3603, -0.0973,  1.7963, -2.7218,\n",
      "          0.5341, -0.8281],\n",
      "        [ 0.1590,  0.7051, -0.6536, -0.5988,  1.1049,  0.0649,  0.7497, -0.7880,\n",
      "         -0.4288, -1.2938],\n",
      "        [-0.3210, -1.7240, -0.8430, -0.5443, -0.6986,  0.2256,  0.1076,  0.6572,\n",
      "          0.4963,  0.7056],\n",
      "        [-1.8155, -1.4596,  2.4477, -1.2885,  1.4204,  0.0487, -0.6199, -0.6909,\n",
      "          0.1799,  0.6225]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1354, -0.1365,  1.4130,  0.9858,  1.3603, -0.0974,  1.7963, -2.7218,\n",
      "          0.5338, -0.8282],\n",
      "        [ 0.1611,  0.7061, -0.6537, -0.5988,  1.1049,  0.0646,  0.7497, -0.7880,\n",
      "         -0.4290, -1.2938],\n",
      "        [-0.3205, -1.7236, -0.8431, -0.5446, -0.6986,  0.2262,  0.1076,  0.6572,\n",
      "          0.4962,  0.7056],\n",
      "        [-1.8155, -1.4596,  2.4477, -1.2886,  1.4204,  0.0489, -0.6199, -0.6909,\n",
      "          0.1799,  0.6225]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1382, -0.1351,  1.4129,  0.9856,  1.3603, -0.0974,  1.7963, -2.7218,\n",
      "          0.5335, -0.8282],\n",
      "        [ 0.1631,  0.7071, -0.6538, -0.5989,  1.1049,  0.0643,  0.7497, -0.7880,\n",
      "         -0.4292, -1.2938],\n",
      "        [-0.3201, -1.7232, -0.8431, -0.5448, -0.6986,  0.2268,  0.1076,  0.6572,\n",
      "          0.4961,  0.7055],\n",
      "        [-1.8155, -1.4595,  2.4477, -1.2887,  1.4204,  0.0492, -0.6199, -0.6909,\n",
      "          0.1799,  0.6224]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1409, -0.1337,  1.4127,  0.9854,  1.3603, -0.0974,  1.7963, -2.7218,\n",
      "          0.5332, -0.8283],\n",
      "        [ 0.1652,  0.7081, -0.6539, -0.5989,  1.1049,  0.0641,  0.7497, -0.7880,\n",
      "         -0.4294, -1.2938],\n",
      "        [-0.3196, -1.7228, -0.8431, -0.5450, -0.6986,  0.2273,  0.1076,  0.6572,\n",
      "          0.4960,  0.7055],\n",
      "        [-1.8155, -1.4594,  2.4477, -1.2888,  1.4204,  0.0495, -0.6199, -0.6909,\n",
      "          0.1798,  0.6224]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1436, -0.1322,  1.4125,  0.9852,  1.3603, -0.0973,  1.7963, -2.7218,\n",
      "          0.5329, -0.8284],\n",
      "        [ 0.1672,  0.7090, -0.6541, -0.5990,  1.1049,  0.0638,  0.7497, -0.7880,\n",
      "         -0.4296, -1.2938],\n",
      "        [-0.3192, -1.7224, -0.8432, -0.5453, -0.6986,  0.2279,  0.1076,  0.6572,\n",
      "          0.4960,  0.7054],\n",
      "        [-1.8155, -1.4594,  2.4477, -1.2889,  1.4204,  0.0497, -0.6199, -0.6909,\n",
      "          0.1798,  0.6224]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1462, -0.1308,  1.4123,  0.9850,  1.3603, -0.0973,  1.7963, -2.7218,\n",
      "          0.5326, -0.8284],\n",
      "        [ 0.1691,  0.7100, -0.6542, -0.5990,  1.1049,  0.0635,  0.7497, -0.7880,\n",
      "         -0.4298, -1.2939],\n",
      "        [-0.3188, -1.7220, -0.8432, -0.5455, -0.6986,  0.2285,  0.1076,  0.6572,\n",
      "          0.4959,  0.7054],\n",
      "        [-1.8155, -1.4593,  2.4477, -1.2889,  1.4204,  0.0500, -0.6199, -0.6909,\n",
      "          0.1798,  0.6224]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1487, -0.1294,  1.4122,  0.9848,  1.3603, -0.0973,  1.7963, -2.7218,\n",
      "          0.5323, -0.8285],\n",
      "        [ 0.1711,  0.7110, -0.6543, -0.5991,  1.1049,  0.0633,  0.7497, -0.7880,\n",
      "         -0.4301, -1.2939],\n",
      "        [-0.3184, -1.7216, -0.8433, -0.5458, -0.6986,  0.2291,  0.1076,  0.6572,\n",
      "          0.4958,  0.7054],\n",
      "        [-1.8156, -1.4592,  2.4477, -1.2890,  1.4204,  0.0502, -0.6199, -0.6909,\n",
      "          0.1798,  0.6224]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1512, -0.1280,  1.4120,  0.9846,  1.3603, -0.0972,  1.7963, -2.7218,\n",
      "          0.5320, -0.8285],\n",
      "        [ 0.1730,  0.7119, -0.6544, -0.5991,  1.1049,  0.0631,  0.7497, -0.7880,\n",
      "         -0.4303, -1.2939],\n",
      "        [-0.3180, -1.7212, -0.8433, -0.5460, -0.6986,  0.2297,  0.1076,  0.6572,\n",
      "          0.4958,  0.7053],\n",
      "        [-1.8156, -1.4592,  2.4477, -1.2891,  1.4204,  0.0505, -0.6199, -0.6909,\n",
      "          0.1798,  0.6224]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1537, -0.1266,  1.4118,  0.9844,  1.3603, -0.0972,  1.7963, -2.7218,\n",
      "          0.5317, -0.8286],\n",
      "        [ 0.1748,  0.7129, -0.6545, -0.5992,  1.1049,  0.0628,  0.7497, -0.7880,\n",
      "         -0.4305, -1.2939],\n",
      "        [-0.3177, -1.7208, -0.8433, -0.5462, -0.6986,  0.2303,  0.1076,  0.6572,\n",
      "          0.4957,  0.7053],\n",
      "        [-1.8156, -1.4591,  2.4477, -1.2892,  1.4204,  0.0508, -0.6199, -0.6909,\n",
      "          0.1798,  0.6224]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1561, -0.1252,  1.4117,  0.9842,  1.3603, -0.0971,  1.7963, -2.7218,\n",
      "          0.5314, -0.8286],\n",
      "        [ 0.1767,  0.7138, -0.6547, -0.5992,  1.1049,  0.0626,  0.7497, -0.7880,\n",
      "         -0.4307, -1.2940],\n",
      "        [-0.3174, -1.7203, -0.8434, -0.5465, -0.6986,  0.2310,  0.1076,  0.6572,\n",
      "          0.4956,  0.7052],\n",
      "        [-1.8157, -1.4590,  2.4477, -1.2893,  1.4204,  0.0510, -0.6199, -0.6909,\n",
      "          0.1798,  0.6223]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1584, -0.1238,  1.4115,  0.9840,  1.3603, -0.0970,  1.7963, -2.7218,\n",
      "          0.5311, -0.8287],\n",
      "        [ 0.1785,  0.7148, -0.6548, -0.5993,  1.1049,  0.0624,  0.7497, -0.7880,\n",
      "         -0.4309, -1.2940],\n",
      "        [-0.3171, -1.7199, -0.8434, -0.5467, -0.6986,  0.2316,  0.1076,  0.6572,\n",
      "          0.4955,  0.7052],\n",
      "        [-1.8157, -1.4590,  2.4476, -1.2894,  1.4204,  0.0513, -0.6199, -0.6909,\n",
      "          0.1798,  0.6223]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1607, -0.1224,  1.4113,  0.9838,  1.3603, -0.0970,  1.7963, -2.7218,\n",
      "          0.5308, -0.8287],\n",
      "        [ 0.1802,  0.7157, -0.6549, -0.5993,  1.1049,  0.0621,  0.7497, -0.7880,\n",
      "         -0.4311, -1.2940],\n",
      "        [-0.3168, -1.7195, -0.8435, -0.5470, -0.6986,  0.2322,  0.1076,  0.6572,\n",
      "          0.4955,  0.7051],\n",
      "        [-1.8158, -1.4589,  2.4476, -1.2895,  1.4204,  0.0516, -0.6199, -0.6909,\n",
      "          0.1798,  0.6223]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1629, -0.1210,  1.4112,  0.9836,  1.3603, -0.0969,  1.7963, -2.7218,\n",
      "          0.5305, -0.8288],\n",
      "        [ 0.1820,  0.7167, -0.6550, -0.5994,  1.1049,  0.0619,  0.7497, -0.7880,\n",
      "         -0.4313, -1.2940],\n",
      "        [-0.3166, -1.7191, -0.8435, -0.5472, -0.6986,  0.2328,  0.1076,  0.6572,\n",
      "          0.4954,  0.7051],\n",
      "        [-1.8158, -1.4588,  2.4476, -1.2896,  1.4204,  0.0518, -0.6199, -0.6909,\n",
      "          0.1798,  0.6223]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1651, -0.1197,  1.4110,  0.9834,  1.3603, -0.0968,  1.7963, -2.7218,\n",
      "          0.5302, -0.8288],\n",
      "        [ 0.1837,  0.7177, -0.6551, -0.5995,  1.1049,  0.0617,  0.7497, -0.7880,\n",
      "         -0.4315, -1.2941],\n",
      "        [-0.3164, -1.7187, -0.8435, -0.5475, -0.6986,  0.2334,  0.1076,  0.6572,\n",
      "          0.4953,  0.7050],\n",
      "        [-1.8159, -1.4588,  2.4476, -1.2897,  1.4204,  0.0521, -0.6199, -0.6909,\n",
      "          0.1798,  0.6223]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1673, -0.1183,  1.4109,  0.9831,  1.3603, -0.0967,  1.7963, -2.7218,\n",
      "          0.5300, -0.8289],\n",
      "        [ 0.1853,  0.7186, -0.6552, -0.5995,  1.1049,  0.0615,  0.7497, -0.7880,\n",
      "         -0.4317, -1.2941],\n",
      "        [-0.3162, -1.7183, -0.8436, -0.5477, -0.6986,  0.2340,  0.1076,  0.6572,\n",
      "          0.4953,  0.7050],\n",
      "        [-1.8160, -1.4587,  2.4476, -1.2898,  1.4204,  0.0524, -0.6199, -0.6909,\n",
      "          0.1798,  0.6223]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1694, -0.1169,  1.4107,  0.9829,  1.3603, -0.0966,  1.7963, -2.7218,\n",
      "          0.5297, -0.8290],\n",
      "        [ 0.1870,  0.7196, -0.6554, -0.5996,  1.1049,  0.0613,  0.7497, -0.7880,\n",
      "         -0.4319, -1.2941],\n",
      "        [-0.3160, -1.7179, -0.8436, -0.5480, -0.6986,  0.2347,  0.1076,  0.6572,\n",
      "          0.4952,  0.7049],\n",
      "        [-1.8160, -1.4586,  2.4476, -1.2899,  1.4204,  0.0526, -0.6199, -0.6909,\n",
      "          0.1798,  0.6222]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1714, -0.1155,  1.4106,  0.9827,  1.3603, -0.0964,  1.7963, -2.7218,\n",
      "          0.5294, -0.8290],\n",
      "        [ 0.1886,  0.7205, -0.6555, -0.5996,  1.1049,  0.0611,  0.7497, -0.7880,\n",
      "         -0.4321, -1.2941],\n",
      "        [-0.3159, -1.7175, -0.8436, -0.5482, -0.6986,  0.2353,  0.1076,  0.6572,\n",
      "          0.4951,  0.7049],\n",
      "        [-1.8161, -1.4586,  2.4476, -1.2899,  1.4204,  0.0529, -0.6199, -0.6909,\n",
      "          0.1798,  0.6222]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1734, -0.1141,  1.4104,  0.9825,  1.3603, -0.0963,  1.7963, -2.7218,\n",
      "          0.5291, -0.8291],\n",
      "        [ 0.1902,  0.7215, -0.6556, -0.5997,  1.1049,  0.0609,  0.7497, -0.7880,\n",
      "         -0.4323, -1.2942],\n",
      "        [-0.3157, -1.7171, -0.8437, -0.5485, -0.6986,  0.2359,  0.1076,  0.6572,\n",
      "          0.4951,  0.7049],\n",
      "        [-1.8162, -1.4585,  2.4476, -1.2900,  1.4204,  0.0531, -0.6199, -0.6909,\n",
      "          0.1797,  0.6222]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1753, -0.1127,  1.4102,  0.9823,  1.3603, -0.0962,  1.7963, -2.7218,\n",
      "          0.5288, -0.8291],\n",
      "        [ 0.1918,  0.7224, -0.6557, -0.5997,  1.1049,  0.0607,  0.7497, -0.7880,\n",
      "         -0.4325, -1.2942],\n",
      "        [-0.3156, -1.7167, -0.8437, -0.5488, -0.6986,  0.2365,  0.1076,  0.6572,\n",
      "          0.4950,  0.7048],\n",
      "        [-1.8163, -1.4584,  2.4476, -1.2901,  1.4204,  0.0534, -0.6199, -0.6909,\n",
      "          0.1797,  0.6222]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1772, -0.1113,  1.4101,  0.9820,  1.3603, -0.0961,  1.7963, -2.7218,\n",
      "          0.5286, -0.8292],\n",
      "        [ 0.1933,  0.7233, -0.6558, -0.5998,  1.1049,  0.0605,  0.7497, -0.7880,\n",
      "         -0.4327, -1.2942],\n",
      "        [-0.3155, -1.7163, -0.8438, -0.5490, -0.6986,  0.2372,  0.1076,  0.6572,\n",
      "          0.4950,  0.7048],\n",
      "        [-1.8164, -1.4584,  2.4476, -1.2902,  1.4204,  0.0537, -0.6199, -0.6909,\n",
      "          0.1797,  0.6222]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1791, -0.1100,  1.4099,  0.9818,  1.3603, -0.0959,  1.7963, -2.7218,\n",
      "          0.5283, -0.8292],\n",
      "        [ 0.1948,  0.7243, -0.6559, -0.5999,  1.1049,  0.0604,  0.7497, -0.7880,\n",
      "         -0.4329, -1.2942],\n",
      "        [-0.3155, -1.7159, -0.8438, -0.5493, -0.6986,  0.2378,  0.1076,  0.6572,\n",
      "          0.4949,  0.7047],\n",
      "        [-1.8165, -1.4583,  2.4476, -1.2903,  1.4204,  0.0539, -0.6199, -0.6909,\n",
      "          0.1797,  0.6222]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1809, -0.1086,  1.4098,  0.9816,  1.3603, -0.0958,  1.7963, -2.7218,\n",
      "          0.5280, -0.8293],\n",
      "        [ 0.1963,  0.7252, -0.6560, -0.5999,  1.1049,  0.0602,  0.7497, -0.7880,\n",
      "         -0.4331, -1.2943],\n",
      "        [-0.3154, -1.7155, -0.8438, -0.5495, -0.6986,  0.2384,  0.1076,  0.6572,\n",
      "          0.4948,  0.7047],\n",
      "        [-1.8166, -1.4582,  2.4476, -1.2904,  1.4204,  0.0542, -0.6199, -0.6909,\n",
      "          0.1797,  0.6221]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1827, -0.1072,  1.4096,  0.9813,  1.3603, -0.0956,  1.7963, -2.7218,\n",
      "          0.5277, -0.8293],\n",
      "        [ 0.1977,  0.7262, -0.6561, -0.6000,  1.1049,  0.0600,  0.7497, -0.7880,\n",
      "         -0.4333, -1.2943],\n",
      "        [-0.3154, -1.7151, -0.8439, -0.5498, -0.6986,  0.2391,  0.1076,  0.6572,\n",
      "          0.4948,  0.7046],\n",
      "        [-1.8167, -1.4582,  2.4476, -1.2905,  1.4204,  0.0545, -0.6199, -0.6909,\n",
      "          0.1797,  0.6221]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1844, -0.1058,  1.4095,  0.9811,  1.3603, -0.0955,  1.7963, -2.7218,\n",
      "          0.5275, -0.8294],\n",
      "        [ 0.1992,  0.7271, -0.6562, -0.6001,  1.1049,  0.0598,  0.7497, -0.7880,\n",
      "         -0.4335, -1.2943],\n",
      "        [-0.3154, -1.7147, -0.8439, -0.5500, -0.6986,  0.2397,  0.1076,  0.6572,\n",
      "          0.4947,  0.7046],\n",
      "        [-1.8168, -1.4581,  2.4476, -1.2906,  1.4204,  0.0547, -0.6199, -0.6909,\n",
      "          0.1797,  0.6221]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1861, -0.1045,  1.4093,  0.9809,  1.3603, -0.0953,  1.7963, -2.7218,\n",
      "          0.5272, -0.8295],\n",
      "        [ 0.2006,  0.7281, -0.6564, -0.6001,  1.1049,  0.0597,  0.7497, -0.7880,\n",
      "         -0.4337, -1.2943],\n",
      "        [-0.3154, -1.7143, -0.8439, -0.5503, -0.6986,  0.2403,  0.1076,  0.6572,\n",
      "          0.4946,  0.7045],\n",
      "        [-1.8169, -1.4580,  2.4476, -1.2907,  1.4204,  0.0550, -0.6199, -0.6909,\n",
      "          0.1797,  0.6221]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1877, -0.1031,  1.4092,  0.9806,  1.3603, -0.0951,  1.7963, -2.7218,\n",
      "          0.5269, -0.8295],\n",
      "        [ 0.2020,  0.7290, -0.6565, -0.6002,  1.1049,  0.0595,  0.7497, -0.7880,\n",
      "         -0.4339, -1.2944],\n",
      "        [-0.3154, -1.7139, -0.8440, -0.5506, -0.6986,  0.2410,  0.1076,  0.6572,\n",
      "          0.4946,  0.7045],\n",
      "        [-1.8171, -1.4580,  2.4476, -1.2908,  1.4204,  0.0553, -0.6199, -0.6909,\n",
      "          0.1797,  0.6221]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1894, -0.1017,  1.4090,  0.9804,  1.3603, -0.0950,  1.7963, -2.7218,\n",
      "          0.5266, -0.8296],\n",
      "        [ 0.2033,  0.7299, -0.6566, -0.6003,  1.1049,  0.0593,  0.7497, -0.7880,\n",
      "         -0.4341, -1.2944],\n",
      "        [-0.3154, -1.7135, -0.8440, -0.5508, -0.6986,  0.2416,  0.1076,  0.6572,\n",
      "          0.4945,  0.7044],\n",
      "        [-1.8172, -1.4579,  2.4476, -1.2909,  1.4204,  0.0555, -0.6199, -0.6909,\n",
      "          0.1797,  0.6221]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1909, -0.1003,  1.4089,  0.9802,  1.3603, -0.0948,  1.7963, -2.7218,\n",
      "          0.5264, -0.8296],\n",
      "        [ 0.2046,  0.7309, -0.6567, -0.6003,  1.1049,  0.0592,  0.7497, -0.7880,\n",
      "         -0.4343, -1.2944],\n",
      "        [-0.3155, -1.7131, -0.8440, -0.5511, -0.6986,  0.2422,  0.1076,  0.6572,\n",
      "          0.4945,  0.7044],\n",
      "        [-1.8173, -1.4578,  2.4476, -1.2910,  1.4204,  0.0558, -0.6199, -0.6909,\n",
      "          0.1797,  0.6221]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1925, -0.0990,  1.4087,  0.9799,  1.3603, -0.0946,  1.7963, -2.7218,\n",
      "          0.5261, -0.8297],\n",
      "        [ 0.2060,  0.7318, -0.6568, -0.6004,  1.1049,  0.0590,  0.7497, -0.7880,\n",
      "         -0.4345, -1.2944],\n",
      "        [-0.3156, -1.7127, -0.8441, -0.5514, -0.6986,  0.2429,  0.1076,  0.6572,\n",
      "          0.4944,  0.7044],\n",
      "        [-1.8175, -1.4578,  2.4476, -1.2911,  1.4204,  0.0561, -0.6199, -0.6909,\n",
      "          0.1797,  0.6220]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1940, -0.0976,  1.4086,  0.9797,  1.3603, -0.0945,  1.7963, -2.7218,\n",
      "          0.5258, -0.8297],\n",
      "        [ 0.2073,  0.7328, -0.6569, -0.6005,  1.1049,  0.0589,  0.7497, -0.7880,\n",
      "         -0.4347, -1.2944],\n",
      "        [-0.3157, -1.7123, -0.8441, -0.5516, -0.6986,  0.2435,  0.1076,  0.6572,\n",
      "          0.4943,  0.7043],\n",
      "        [-1.8176, -1.4577,  2.4476, -1.2912,  1.4204,  0.0563, -0.6199, -0.6909,\n",
      "          0.1797,  0.6220]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1954, -0.0962,  1.4084,  0.9795,  1.3603, -0.0943,  1.7963, -2.7218,\n",
      "          0.5256, -0.8298],\n",
      "        [ 0.2085,  0.7337, -0.6570, -0.6005,  1.1049,  0.0587,  0.7497, -0.7880,\n",
      "         -0.4349, -1.2945],\n",
      "        [-0.3158, -1.7119, -0.8441, -0.5519, -0.6986,  0.2442,  0.1076,  0.6572,\n",
      "          0.4943,  0.7043],\n",
      "        [-1.8178, -1.4576,  2.4476, -1.2913,  1.4204,  0.0566, -0.6199, -0.6909,\n",
      "          0.1797,  0.6220]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1968, -0.0948,  1.4083,  0.9792,  1.3603, -0.0941,  1.7963, -2.7218,\n",
      "          0.5253, -0.8298],\n",
      "        [ 0.2098,  0.7346, -0.6571, -0.6006,  1.1049,  0.0586,  0.7497, -0.7880,\n",
      "         -0.4350, -1.2945],\n",
      "        [-0.3159, -1.7115, -0.8442, -0.5522, -0.6986,  0.2448,  0.1076,  0.6572,\n",
      "          0.4942,  0.7042],\n",
      "        [-1.8179, -1.4576,  2.4476, -1.2914,  1.4204,  0.0569, -0.6199, -0.6909,\n",
      "          0.1797,  0.6220]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1982, -0.0935,  1.4081,  0.9790,  1.3603, -0.0939,  1.7963, -2.7218,\n",
      "          0.5250, -0.8299],\n",
      "        [ 0.2110,  0.7356, -0.6572, -0.6007,  1.1049,  0.0584,  0.7497, -0.7880,\n",
      "         -0.4352, -1.2945],\n",
      "        [-0.3160, -1.7111, -0.8442, -0.5524, -0.6986,  0.2454,  0.1076,  0.6572,\n",
      "          0.4942,  0.7042],\n",
      "        [-1.8181, -1.4575,  2.4476, -1.2915,  1.4204,  0.0571, -0.6199, -0.6909,\n",
      "          0.1797,  0.6220]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.1996, -0.0921,  1.4080,  0.9787,  1.3603, -0.0937,  1.7963, -2.7218,\n",
      "          0.5248, -0.8299],\n",
      "        [ 0.2122,  0.7365, -0.6573, -0.6007,  1.1049,  0.0583,  0.7497, -0.7880,\n",
      "         -0.4354, -1.2945],\n",
      "        [-0.3162, -1.7107, -0.8442, -0.5527, -0.6986,  0.2461,  0.1076,  0.6572,\n",
      "          0.4941,  0.7041],\n",
      "        [-1.8182, -1.4574,  2.4476, -1.2916,  1.4204,  0.0574, -0.6199, -0.6909,\n",
      "          0.1797,  0.6220]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2009, -0.0907,  1.4078,  0.9785,  1.3603, -0.0935,  1.7963, -2.7218,\n",
      "          0.5245, -0.8300],\n",
      "        [ 0.2134,  0.7375, -0.6574, -0.6008,  1.1049,  0.0581,  0.7497, -0.7880,\n",
      "         -0.4356, -1.2946],\n",
      "        [-0.3164, -1.7103, -0.8443, -0.5530, -0.6986,  0.2467,  0.1076,  0.6572,\n",
      "          0.4940,  0.7041],\n",
      "        [-1.8184, -1.4574,  2.4476, -1.2917,  1.4204,  0.0577, -0.6199, -0.6909,\n",
      "          0.1796,  0.6219]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2022, -0.0894,  1.4077,  0.9783,  1.3603, -0.0933,  1.7963, -2.7218,\n",
      "          0.5243, -0.8301],\n",
      "        [ 0.2146,  0.7384, -0.6575, -0.6009,  1.1049,  0.0580,  0.7497, -0.7880,\n",
      "         -0.4358, -1.2946],\n",
      "        [-0.3165, -1.7100, -0.8443, -0.5532, -0.6986,  0.2473,  0.1076,  0.6572,\n",
      "          0.4940,  0.7040],\n",
      "        [-1.8186, -1.4573,  2.4476, -1.2918,  1.4204,  0.0579, -0.6199, -0.6909,\n",
      "          0.1796,  0.6219]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2035, -0.0880,  1.4076,  0.9780,  1.3603, -0.0931,  1.7963, -2.7218,\n",
      "          0.5240, -0.8301],\n",
      "        [ 0.2157,  0.7393, -0.6576, -0.6009,  1.1049,  0.0579,  0.7497, -0.7880,\n",
      "         -0.4360, -1.2946],\n",
      "        [-0.3167, -1.7096, -0.8443, -0.5535, -0.6986,  0.2480,  0.1076,  0.6572,\n",
      "          0.4939,  0.7040],\n",
      "        [-1.8187, -1.4572,  2.4476, -1.2919,  1.4204,  0.0582, -0.6199, -0.6909,\n",
      "          0.1796,  0.6219]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2047, -0.0866,  1.4074,  0.9778,  1.3603, -0.0929,  1.7963, -2.7218,\n",
      "          0.5237, -0.8302],\n",
      "        [ 0.2169,  0.7403, -0.6577, -0.6010,  1.1049,  0.0577,  0.7497, -0.7880,\n",
      "         -0.4362, -1.2946],\n",
      "        [-0.3169, -1.7092, -0.8444, -0.5538, -0.6986,  0.2486,  0.1076,  0.6572,\n",
      "          0.4939,  0.7040],\n",
      "        [-1.8189, -1.4572,  2.4476, -1.2919,  1.4204,  0.0584, -0.6199, -0.6909,\n",
      "          0.1796,  0.6219]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2059, -0.0852,  1.4073,  0.9775,  1.3603, -0.0927,  1.7963, -2.7218,\n",
      "          0.5235, -0.8302],\n",
      "        [ 0.2180,  0.7412, -0.6578, -0.6011,  1.1049,  0.0576,  0.7497, -0.7880,\n",
      "         -0.4364, -1.2947],\n",
      "        [-0.3172, -1.7088, -0.8444, -0.5540, -0.6986,  0.2492,  0.1076,  0.6572,\n",
      "          0.4938,  0.7039],\n",
      "        [-1.8191, -1.4571,  2.4476, -1.2920,  1.4204,  0.0587, -0.6199, -0.6909,\n",
      "          0.1796,  0.6219]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2071, -0.0839,  1.4071,  0.9773,  1.3603, -0.0925,  1.7963, -2.7218,\n",
      "          0.5232, -0.8303],\n",
      "        [ 0.2191,  0.7421, -0.6579, -0.6012,  1.1049,  0.0575,  0.7497, -0.7880,\n",
      "         -0.4366, -1.2947],\n",
      "        [-0.3174, -1.7084, -0.8444, -0.5543, -0.6986,  0.2499,  0.1076,  0.6572,\n",
      "          0.4937,  0.7039],\n",
      "        [-1.8193, -1.4570,  2.4476, -1.2921,  1.4204,  0.0590, -0.6199, -0.6909,\n",
      "          0.1796,  0.6219]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2083, -0.0825,  1.4070,  0.9770,  1.3603, -0.0923,  1.7963, -2.7218,\n",
      "          0.5229, -0.8303],\n",
      "        [ 0.2202,  0.7431, -0.6580, -0.6012,  1.1049,  0.0573,  0.7497, -0.7880,\n",
      "         -0.4367, -1.2947],\n",
      "        [-0.3177, -1.7080, -0.8445, -0.5546, -0.6986,  0.2505,  0.1076,  0.6572,\n",
      "          0.4937,  0.7038],\n",
      "        [-1.8194, -1.4570,  2.4476, -1.2922,  1.4204,  0.0592, -0.6199, -0.6909,\n",
      "          0.1796,  0.6219]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2094, -0.0811,  1.4068,  0.9768,  1.3603, -0.0921,  1.7963, -2.7218,\n",
      "          0.5227, -0.8304],\n",
      "        [ 0.2212,  0.7440, -0.6581, -0.6013,  1.1049,  0.0572,  0.7497, -0.7880,\n",
      "         -0.4369, -1.2947],\n",
      "        [-0.3179, -1.7076, -0.8445, -0.5548, -0.6986,  0.2511,  0.1076,  0.6572,\n",
      "          0.4936,  0.7038],\n",
      "        [-1.8196, -1.4569,  2.4476, -1.2923,  1.4204,  0.0595, -0.6199, -0.6909,\n",
      "          0.1796,  0.6218]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2105, -0.0798,  1.4067,  0.9765,  1.3603, -0.0919,  1.7963, -2.7218,\n",
      "          0.5224, -0.8304],\n",
      "        [ 0.2223,  0.7450, -0.6582, -0.6014,  1.1049,  0.0571,  0.7497, -0.7880,\n",
      "         -0.4371, -1.2948],\n",
      "        [-0.3182, -1.7072, -0.8445, -0.5551, -0.6986,  0.2518,  0.1076,  0.6572,\n",
      "          0.4936,  0.7037],\n",
      "        [-1.8198, -1.4568,  2.4476, -1.2924,  1.4204,  0.0598, -0.6199, -0.6909,\n",
      "          0.1796,  0.6218]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2116, -0.0784,  1.4066,  0.9763,  1.3603, -0.0917,  1.7963, -2.7218,\n",
      "          0.5222, -0.8305],\n",
      "        [ 0.2233,  0.7459, -0.6583, -0.6015,  1.1049,  0.0569,  0.7497, -0.7880,\n",
      "         -0.4373, -1.2948],\n",
      "        [-0.3185, -1.7068, -0.8446, -0.5554, -0.6986,  0.2524,  0.1076,  0.6572,\n",
      "          0.4935,  0.7037],\n",
      "        [-1.8200, -1.4568,  2.4476, -1.2925,  1.4204,  0.0600, -0.6199, -0.6909,\n",
      "          0.1796,  0.6218]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2126, -0.0770,  1.4064,  0.9760,  1.3603, -0.0915,  1.7963, -2.7218,\n",
      "          0.5219, -0.8305],\n",
      "        [ 0.2243,  0.7468, -0.6584, -0.6015,  1.1049,  0.0568,  0.7497, -0.7880,\n",
      "         -0.4375, -1.2948],\n",
      "        [-0.3188, -1.7064, -0.8446, -0.5557, -0.6986,  0.2530,  0.1076,  0.6572,\n",
      "          0.4935,  0.7036],\n",
      "        [-1.8202, -1.4567,  2.4476, -1.2926,  1.4204,  0.0603, -0.6199, -0.6909,\n",
      "          0.1796,  0.6218]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2136, -0.0756,  1.4063,  0.9758,  1.3603, -0.0913,  1.7963, -2.7218,\n",
      "          0.5217, -0.8306],\n",
      "        [ 0.2253,  0.7478, -0.6585, -0.6016,  1.1049,  0.0567,  0.7497, -0.7880,\n",
      "         -0.4377, -1.2948],\n",
      "        [-0.3191, -1.7060, -0.8446, -0.5559, -0.6986,  0.2537,  0.1076,  0.6572,\n",
      "          0.4934,  0.7036],\n",
      "        [-1.8204, -1.4566,  2.4476, -1.2927,  1.4204,  0.0605, -0.6199, -0.6909,\n",
      "          0.1796,  0.6218]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2146, -0.0743,  1.4061,  0.9755,  1.3603, -0.0911,  1.7963, -2.7218,\n",
      "          0.5214, -0.8306],\n",
      "        [ 0.2263,  0.7487, -0.6586, -0.6017,  1.1049,  0.0566,  0.7497, -0.7880,\n",
      "         -0.4379, -1.2949],\n",
      "        [-0.3194, -1.7056, -0.8446, -0.5562, -0.6986,  0.2543,  0.1076,  0.6572,\n",
      "          0.4933,  0.7036],\n",
      "        [-1.8206, -1.4566,  2.4476, -1.2928,  1.4204,  0.0608, -0.6199, -0.6909,\n",
      "          0.1796,  0.6218]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2156, -0.0729,  1.4060,  0.9753,  1.3603, -0.0909,  1.7963, -2.7218,\n",
      "          0.5212, -0.8307],\n",
      "        [ 0.2273,  0.7496, -0.6587, -0.6017,  1.1049,  0.0564,  0.7497, -0.7880,\n",
      "         -0.4380, -1.2949],\n",
      "        [-0.3197, -1.7052, -0.8447, -0.5565, -0.6986,  0.2549,  0.1076,  0.6572,\n",
      "          0.4933,  0.7035],\n",
      "        [-1.8208, -1.4565,  2.4476, -1.2929,  1.4204,  0.0611, -0.6199, -0.6909,\n",
      "          0.1796,  0.6217]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2166, -0.0715,  1.4059,  0.9750,  1.3603, -0.0907,  1.7963, -2.7218,\n",
      "          0.5209, -0.8308],\n",
      "        [ 0.2283,  0.7506, -0.6588, -0.6018,  1.1049,  0.0563,  0.7497, -0.7880,\n",
      "         -0.4382, -1.2949],\n",
      "        [-0.3200, -1.7048, -0.8447, -0.5567, -0.6986,  0.2556,  0.1076,  0.6572,\n",
      "          0.4932,  0.7035],\n",
      "        [-1.8210, -1.4564,  2.4476, -1.2930,  1.4204,  0.0613, -0.6199, -0.6909,\n",
      "          0.1796,  0.6217]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2175, -0.0702,  1.4057,  0.9748,  1.3603, -0.0905,  1.7963, -2.7218,\n",
      "          0.5206, -0.8308],\n",
      "        [ 0.2292,  0.7515, -0.6589, -0.6019,  1.1049,  0.0562,  0.7497, -0.7880,\n",
      "         -0.4384, -1.2949],\n",
      "        [-0.3204, -1.7044, -0.8447, -0.5570, -0.6986,  0.2562,  0.1076,  0.6572,\n",
      "          0.4932,  0.7034],\n",
      "        [-1.8212, -1.4564,  2.4476, -1.2931,  1.4204,  0.0616, -0.6199, -0.6909,\n",
      "          0.1796,  0.6217]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2184, -0.0688,  1.4056,  0.9745,  1.3603, -0.0903,  1.7963, -2.7218,\n",
      "          0.5204, -0.8309],\n",
      "        [ 0.2302,  0.7525, -0.6590, -0.6020,  1.1049,  0.0561,  0.7497, -0.7880,\n",
      "         -0.4386, -1.2950],\n",
      "        [-0.3207, -1.7040, -0.8448, -0.5573, -0.6986,  0.2568,  0.1076,  0.6572,\n",
      "          0.4931,  0.7034],\n",
      "        [-1.8214, -1.4563,  2.4476, -1.2932,  1.4204,  0.0618, -0.6199, -0.6909,\n",
      "          0.1796,  0.6217]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2193, -0.0674,  1.4055,  0.9743,  1.3603, -0.0900,  1.7963, -2.7218,\n",
      "          0.5201, -0.8309],\n",
      "        [ 0.2311,  0.7534, -0.6591, -0.6020,  1.1049,  0.0560,  0.7497, -0.7880,\n",
      "         -0.4388, -1.2950],\n",
      "        [-0.3211, -1.7036, -0.8448, -0.5576, -0.6986,  0.2574,  0.1076,  0.6572,\n",
      "          0.4931,  0.7033],\n",
      "        [-1.8216, -1.4562,  2.4476, -1.2933,  1.4204,  0.0621, -0.6199, -0.6909,\n",
      "          0.1796,  0.6217]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2202, -0.0660,  1.4053,  0.9740,  1.3603, -0.0898,  1.7963, -2.7218,\n",
      "          0.5199, -0.8310],\n",
      "        [ 0.2320,  0.7543, -0.6592, -0.6021,  1.1049,  0.0558,  0.7497, -0.7880,\n",
      "         -0.4389, -1.2950],\n",
      "        [-0.3215, -1.7032, -0.8448, -0.5578, -0.6986,  0.2581,  0.1076,  0.6572,\n",
      "          0.4930,  0.7033],\n",
      "        [-1.8218, -1.4562,  2.4476, -1.2934,  1.4204,  0.0623, -0.6199, -0.6909,\n",
      "          0.1796,  0.6217]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2210, -0.0647,  1.4052,  0.9738,  1.3603, -0.0896,  1.7963, -2.7218,\n",
      "          0.5196, -0.8310],\n",
      "        [ 0.2329,  0.7553, -0.6593, -0.6022,  1.1049,  0.0557,  0.7497, -0.7880,\n",
      "         -0.4391, -1.2950],\n",
      "        [-0.3219, -1.7028, -0.8449, -0.5581, -0.6986,  0.2587,  0.1076,  0.6572,\n",
      "          0.4930,  0.7032],\n",
      "        [-1.8221, -1.4561,  2.4476, -1.2935,  1.4204,  0.0626, -0.6199, -0.6909,\n",
      "          0.1796,  0.6217]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2219, -0.0633,  1.4050,  0.9735,  1.3603, -0.0894,  1.7963, -2.7218,\n",
      "          0.5194, -0.8311],\n",
      "        [ 0.2338,  0.7562, -0.6594, -0.6023,  1.1049,  0.0556,  0.7497, -0.7880,\n",
      "         -0.4393, -1.2950],\n",
      "        [-0.3222, -1.7024, -0.8449, -0.5584, -0.6986,  0.2593,  0.1076,  0.6572,\n",
      "          0.4929,  0.7032],\n",
      "        [-1.8223, -1.4560,  2.4476, -1.2936,  1.4204,  0.0628, -0.6199, -0.6909,\n",
      "          0.1796,  0.6216]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2227, -0.0619,  1.4049,  0.9733,  1.3603, -0.0892,  1.7963, -2.7218,\n",
      "          0.5191, -0.8311],\n",
      "        [ 0.2347,  0.7572, -0.6595, -0.6023,  1.1049,  0.0555,  0.7497, -0.7880,\n",
      "         -0.4395, -1.2951],\n",
      "        [-0.3226, -1.7020, -0.8449, -0.5587, -0.6986,  0.2599,  0.1076,  0.6572,\n",
      "          0.4928,  0.7032],\n",
      "        [-1.8225, -1.4560,  2.4476, -1.2937,  1.4204,  0.0631, -0.6199, -0.6909,\n",
      "          0.1795,  0.6216]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2235, -0.0605,  1.4048,  0.9730,  1.3603, -0.0890,  1.7963, -2.7218,\n",
      "          0.5189, -0.8312],\n",
      "        [ 0.2355,  0.7581, -0.6596, -0.6024,  1.1049,  0.0554,  0.7497, -0.7880,\n",
      "         -0.4397, -1.2951],\n",
      "        [-0.3230, -1.7016, -0.8449, -0.5589, -0.6986,  0.2605,  0.1076,  0.6572,\n",
      "          0.4928,  0.7031],\n",
      "        [-1.8227, -1.4559,  2.4475, -1.2938,  1.4204,  0.0634, -0.6199, -0.6909,\n",
      "          0.1795,  0.6216]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2243, -0.0592,  1.4046,  0.9728,  1.3603, -0.0888,  1.7963, -2.7218,\n",
      "          0.5186, -0.8312],\n",
      "        [ 0.2364,  0.7590, -0.6597, -0.6025,  1.1049,  0.0553,  0.7497, -0.7880,\n",
      "         -0.4399, -1.2951],\n",
      "        [-0.3235, -1.7012, -0.8450, -0.5592, -0.6986,  0.2612,  0.1076,  0.6572,\n",
      "          0.4927,  0.7031],\n",
      "        [-1.8229, -1.4558,  2.4475, -1.2939,  1.4204,  0.0636, -0.6199, -0.6909,\n",
      "          0.1795,  0.6216]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2250, -0.0578,  1.4045,  0.9725,  1.3603, -0.0886,  1.7963, -2.7218,\n",
      "          0.5184, -0.8313],\n",
      "        [ 0.2372,  0.7600, -0.6598, -0.6026,  1.1049,  0.0551,  0.7497, -0.7880,\n",
      "         -0.4400, -1.2951],\n",
      "        [-0.3239, -1.7008, -0.8450, -0.5595, -0.6986,  0.2618,  0.1076,  0.6572,\n",
      "          0.4927,  0.7030],\n",
      "        [-1.8232, -1.4558,  2.4475, -1.2940,  1.4204,  0.0639, -0.6199, -0.6909,\n",
      "          0.1795,  0.6216]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2258, -0.0564,  1.4044,  0.9723,  1.3603, -0.0883,  1.7963, -2.7218,\n",
      "          0.5181, -0.8313],\n",
      "        [ 0.2381,  0.7609, -0.6599, -0.6026,  1.1049,  0.0550,  0.7497, -0.7880,\n",
      "         -0.4402, -1.2952],\n",
      "        [-0.3243, -1.7004, -0.8450, -0.5598, -0.6986,  0.2624,  0.1076,  0.6572,\n",
      "          0.4926,  0.7030],\n",
      "        [-1.8234, -1.4557,  2.4475, -1.2941,  1.4204,  0.0641, -0.6199, -0.6909,\n",
      "          0.1795,  0.6216]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2265, -0.0550,  1.4042,  0.9720,  1.3603, -0.0881,  1.7963, -2.7218,\n",
      "          0.5179, -0.8314],\n",
      "        [ 0.2389,  0.7619, -0.6600, -0.6027,  1.1049,  0.0549,  0.7497, -0.7880,\n",
      "         -0.4404, -1.2952],\n",
      "        [-0.3247, -1.7000, -0.8451, -0.5600, -0.6986,  0.2630,  0.1076,  0.6572,\n",
      "          0.4926,  0.7029],\n",
      "        [-1.8236, -1.4556,  2.4475, -1.2942,  1.4204,  0.0644, -0.6199, -0.6909,\n",
      "          0.1795,  0.6215]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2272, -0.0537,  1.4041,  0.9718,  1.3603, -0.0879,  1.7963, -2.7218,\n",
      "          0.5176, -0.8314],\n",
      "        [ 0.2397,  0.7628, -0.6601, -0.6028,  1.1049,  0.0548,  0.7497, -0.7880,\n",
      "         -0.4406, -1.2952],\n",
      "        [-0.3252, -1.6996, -0.8451, -0.5603, -0.6986,  0.2636,  0.1076,  0.6572,\n",
      "          0.4925,  0.7029],\n",
      "        [-1.8239, -1.4556,  2.4475, -1.2943,  1.4204,  0.0646, -0.6199, -0.6909,\n",
      "          0.1795,  0.6215]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2279, -0.0523,  1.4040,  0.9715,  1.3603, -0.0877,  1.7963, -2.7218,\n",
      "          0.5174, -0.8315],\n",
      "        [ 0.2405,  0.7637, -0.6602, -0.6029,  1.1049,  0.0547,  0.7497, -0.7880,\n",
      "         -0.4408, -1.2952],\n",
      "        [-0.3256, -1.6992, -0.8451, -0.5606, -0.6986,  0.2642,  0.1076,  0.6572,\n",
      "          0.4925,  0.7029],\n",
      "        [-1.8241, -1.4555,  2.4475, -1.2944,  1.4204,  0.0649, -0.6199, -0.6909,\n",
      "          0.1795,  0.6215]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2286, -0.0509,  1.4038,  0.9713,  1.3603, -0.0875,  1.7963, -2.7218,\n",
      "          0.5171, -0.8316],\n",
      "        [ 0.2413,  0.7647, -0.6603, -0.6029,  1.1049,  0.0546,  0.7497, -0.7880,\n",
      "         -0.4409, -1.2953],\n",
      "        [-0.3261, -1.6988, -0.8452, -0.5608, -0.6986,  0.2648,  0.1076,  0.6572,\n",
      "          0.4924,  0.7028],\n",
      "        [-1.8243, -1.4554,  2.4475, -1.2945,  1.4204,  0.0651, -0.6199, -0.6909,\n",
      "          0.1795,  0.6215]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2293, -0.0495,  1.4037,  0.9710,  1.3603, -0.0873,  1.7963, -2.7218,\n",
      "          0.5169, -0.8316],\n",
      "        [ 0.2421,  0.7656, -0.6604, -0.6030,  1.1049,  0.0544,  0.7497, -0.7880,\n",
      "         -0.4411, -1.2953],\n",
      "        [-0.3265, -1.6984, -0.8452, -0.5611, -0.6986,  0.2654,  0.1076,  0.6572,\n",
      "          0.4924,  0.7028],\n",
      "        [-1.8246, -1.4554,  2.4475, -1.2946,  1.4204,  0.0654, -0.6199, -0.6909,\n",
      "          0.1795,  0.6215]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2299, -0.0482,  1.4036,  0.9708,  1.3603, -0.0871,  1.7963, -2.7218,\n",
      "          0.5166, -0.8317],\n",
      "        [ 0.2429,  0.7665, -0.6605, -0.6031,  1.1049,  0.0543,  0.7497, -0.7880,\n",
      "         -0.4413, -1.2953],\n",
      "        [-0.3270, -1.6980, -0.8452, -0.5614, -0.6986,  0.2660,  0.1076,  0.6572,\n",
      "          0.4923,  0.7027],\n",
      "        [-1.8248, -1.4553,  2.4475, -1.2947,  1.4204,  0.0656, -0.6199, -0.6909,\n",
      "          0.1795,  0.6215]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2306, -0.0468,  1.4034,  0.9705,  1.3603, -0.0869,  1.7963, -2.7218,\n",
      "          0.5164, -0.8317],\n",
      "        [ 0.2436,  0.7675, -0.6606, -0.6032,  1.1049,  0.0542,  0.7497, -0.7880,\n",
      "         -0.4415, -1.2953],\n",
      "        [-0.3275, -1.6976, -0.8452, -0.5617, -0.6986,  0.2666,  0.1076,  0.6572,\n",
      "          0.4922,  0.7027],\n",
      "        [-1.8250, -1.4552,  2.4475, -1.2948,  1.4204,  0.0659, -0.6199, -0.6909,\n",
      "          0.1795,  0.6215]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2312, -0.0454,  1.4033,  0.9703,  1.3603, -0.0867,  1.7963, -2.7218,\n",
      "          0.5161, -0.8318],\n",
      "        [ 0.2444,  0.7684, -0.6607, -0.6032,  1.1049,  0.0541,  0.7497, -0.7880,\n",
      "         -0.4417, -1.2953],\n",
      "        [-0.3279, -1.6972, -0.8453, -0.5619, -0.6986,  0.2672,  0.1076,  0.6572,\n",
      "          0.4922,  0.7026],\n",
      "        [-1.8253, -1.4552,  2.4475, -1.2949,  1.4204,  0.0661, -0.6199, -0.6909,\n",
      "          0.1795,  0.6214]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2318, -0.0440,  1.4032,  0.9700,  1.3603, -0.0865,  1.7963, -2.7218,\n",
      "          0.5159, -0.8318],\n",
      "        [ 0.2452,  0.7694, -0.6608, -0.6033,  1.1049,  0.0540,  0.7497, -0.7880,\n",
      "         -0.4418, -1.2954],\n",
      "        [-0.3284, -1.6968, -0.8453, -0.5622, -0.6986,  0.2678,  0.1076,  0.6572,\n",
      "          0.4921,  0.7026],\n",
      "        [-1.8255, -1.4551,  2.4475, -1.2950,  1.4204,  0.0663, -0.6199, -0.6909,\n",
      "          0.1795,  0.6214]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2324, -0.0427,  1.4030,  0.9697,  1.3603, -0.0863,  1.7963, -2.7218,\n",
      "          0.5156, -0.8319],\n",
      "        [ 0.2459,  0.7703, -0.6609, -0.6034,  1.1049,  0.0539,  0.7497, -0.7880,\n",
      "         -0.4420, -1.2954],\n",
      "        [-0.3289, -1.6964, -0.8453, -0.5625, -0.6986,  0.2684,  0.1076,  0.6572,\n",
      "          0.4921,  0.7026],\n",
      "        [-1.8257, -1.4550,  2.4475, -1.2951,  1.4204,  0.0666, -0.6199, -0.6909,\n",
      "          0.1795,  0.6214]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2330, -0.0413,  1.4029,  0.9695,  1.3603, -0.0861,  1.7963, -2.7218,\n",
      "          0.5154, -0.8319],\n",
      "        [ 0.2466,  0.7712, -0.6610, -0.6035,  1.1049,  0.0538,  0.7497, -0.7880,\n",
      "         -0.4422, -1.2954],\n",
      "        [-0.3294, -1.6959, -0.8454, -0.5628, -0.6986,  0.2690,  0.1076,  0.6572,\n",
      "          0.4920,  0.7025],\n",
      "        [-1.8260, -1.4550,  2.4475, -1.2952,  1.4204,  0.0668, -0.6199, -0.6909,\n",
      "          0.1795,  0.6214]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2336, -0.0399,  1.4028,  0.9692,  1.3603, -0.0859,  1.7963, -2.7218,\n",
      "          0.5151, -0.8320],\n",
      "        [ 0.2474,  0.7722, -0.6611, -0.6035,  1.1049,  0.0537,  0.7497, -0.7880,\n",
      "         -0.4424, -1.2954],\n",
      "        [-0.3299, -1.6955, -0.8454, -0.5630, -0.6986,  0.2696,  0.1076,  0.6572,\n",
      "          0.4920,  0.7025],\n",
      "        [-1.8262, -1.4549,  2.4475, -1.2953,  1.4204,  0.0671, -0.6199, -0.6909,\n",
      "          0.1795,  0.6214]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2342, -0.0385,  1.4026,  0.9690,  1.3603, -0.0857,  1.7963, -2.7218,\n",
      "          0.5149, -0.8320],\n",
      "        [ 0.2481,  0.7731, -0.6612, -0.6036,  1.1049,  0.0535,  0.7497, -0.7880,\n",
      "         -0.4426, -1.2955],\n",
      "        [-0.3304, -1.6951, -0.8454, -0.5633, -0.6986,  0.2702,  0.1076,  0.6572,\n",
      "          0.4919,  0.7024],\n",
      "        [-1.8265, -1.4548,  2.4475, -1.2954,  1.4204,  0.0673, -0.6199, -0.6909,\n",
      "          0.1795,  0.6214]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2347, -0.0372,  1.4025,  0.9687,  1.3603, -0.0855,  1.7963, -2.7218,\n",
      "          0.5146, -0.8321],\n",
      "        [ 0.2488,  0.7741, -0.6613, -0.6037,  1.1049,  0.0534,  0.7497, -0.7880,\n",
      "         -0.4427, -1.2955],\n",
      "        [-0.3309, -1.6947, -0.8454, -0.5636, -0.6986,  0.2708,  0.1076,  0.6572,\n",
      "          0.4919,  0.7024],\n",
      "        [-1.8267, -1.4548,  2.4475, -1.2955,  1.4204,  0.0676, -0.6199, -0.6909,\n",
      "          0.1795,  0.6214]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2353, -0.0358,  1.4024,  0.9685,  1.3603, -0.0853,  1.7963, -2.7218,\n",
      "          0.5144, -0.8321],\n",
      "        [ 0.2495,  0.7750, -0.6614, -0.6038,  1.1049,  0.0533,  0.7497, -0.7880,\n",
      "         -0.4429, -1.2955],\n",
      "        [-0.3314, -1.6943, -0.8455, -0.5639, -0.6986,  0.2714,  0.1076,  0.6572,\n",
      "          0.4918,  0.7023],\n",
      "        [-1.8270, -1.4547,  2.4475, -1.2956,  1.4204,  0.0678, -0.6199, -0.6909,\n",
      "          0.1795,  0.6213]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2358, -0.0344,  1.4022,  0.9682,  1.3603, -0.0851,  1.7963, -2.7218,\n",
      "          0.5141, -0.8322],\n",
      "        [ 0.2502,  0.7759, -0.6615, -0.6038,  1.1049,  0.0532,  0.7497, -0.7880,\n",
      "         -0.4431, -1.2955],\n",
      "        [-0.3319, -1.6939, -0.8455, -0.5641, -0.6986,  0.2720,  0.1076,  0.6572,\n",
      "          0.4918,  0.7023],\n",
      "        [-1.8272, -1.4546,  2.4475, -1.2957,  1.4204,  0.0680, -0.6199, -0.6909,\n",
      "          0.1795,  0.6213]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2363, -0.0330,  1.4021,  0.9680,  1.3603, -0.0849,  1.7963, -2.7218,\n",
      "          0.5139, -0.8322],\n",
      "        [ 0.2509,  0.7769, -0.6616, -0.6039,  1.1049,  0.0531,  0.7497, -0.7880,\n",
      "         -0.4433, -1.2956],\n",
      "        [-0.3324, -1.6935, -0.8455, -0.5644, -0.6986,  0.2726,  0.1076,  0.6572,\n",
      "          0.4917,  0.7023],\n",
      "        [-1.8275, -1.4546,  2.4475, -1.2958,  1.4204,  0.0683, -0.6199, -0.6909,\n",
      "          0.1795,  0.6213]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2368, -0.0317,  1.4020,  0.9677,  1.3603, -0.0847,  1.7963, -2.7218,\n",
      "          0.5136, -0.8323],\n",
      "        [ 0.2516,  0.7778, -0.6617, -0.6040,  1.1049,  0.0530,  0.7497, -0.7880,\n",
      "         -0.4435, -1.2956],\n",
      "        [-0.3329, -1.6931, -0.8456, -0.5647, -0.6986,  0.2731,  0.1076,  0.6572,\n",
      "          0.4917,  0.7022],\n",
      "        [-1.8277, -1.4545,  2.4475, -1.2959,  1.4204,  0.0685, -0.6199, -0.6909,\n",
      "          0.1795,  0.6213]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2374, -0.0303,  1.4019,  0.9675,  1.3603, -0.0845,  1.7963, -2.7218,\n",
      "          0.5134, -0.8323],\n",
      "        [ 0.2523,  0.7787, -0.6618, -0.6041,  1.1049,  0.0529,  0.7497, -0.7880,\n",
      "         -0.4436, -1.2956],\n",
      "        [-0.3334, -1.6927, -0.8456, -0.5649, -0.6986,  0.2737,  0.1076,  0.6572,\n",
      "          0.4916,  0.7022],\n",
      "        [-1.8279, -1.4544,  2.4475, -1.2960,  1.4204,  0.0688, -0.6199, -0.6909,\n",
      "          0.1795,  0.6213]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2379, -0.0289,  1.4017,  0.9672,  1.3603, -0.0843,  1.7963, -2.7218,\n",
      "          0.5131, -0.8324],\n",
      "        [ 0.2530,  0.7797, -0.6618, -0.6041,  1.1049,  0.0527,  0.7497, -0.7880,\n",
      "         -0.4438, -1.2956],\n",
      "        [-0.3340, -1.6923, -0.8456, -0.5652, -0.6986,  0.2743,  0.1076,  0.6572,\n",
      "          0.4916,  0.7021],\n",
      "        [-1.8282, -1.4544,  2.4475, -1.2960,  1.4204,  0.0690, -0.6199, -0.6909,\n",
      "          0.1795,  0.6213]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2383, -0.0276,  1.4016,  0.9670,  1.3603, -0.0841,  1.7963, -2.7218,\n",
      "          0.5129, -0.8324],\n",
      "        [ 0.2536,  0.7806, -0.6619, -0.6042,  1.1049,  0.0526,  0.7497, -0.7880,\n",
      "         -0.4440, -1.2956],\n",
      "        [-0.3345, -1.6919, -0.8456, -0.5655, -0.6986,  0.2749,  0.1076,  0.6572,\n",
      "          0.4915,  0.7021],\n",
      "        [-1.8284, -1.4543,  2.4475, -1.2961,  1.4204,  0.0692, -0.6199, -0.6909,\n",
      "          0.1794,  0.6213]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2388, -0.0262,  1.4015,  0.9667,  1.3603, -0.0839,  1.7963, -2.7218,\n",
      "          0.5126, -0.8325],\n",
      "        [ 0.2543,  0.7815, -0.6620, -0.6043,  1.1049,  0.0525,  0.7497, -0.7880,\n",
      "         -0.4442, -1.2957],\n",
      "        [-0.3350, -1.6915, -0.8457, -0.5658, -0.6986,  0.2755,  0.1076,  0.6572,\n",
      "          0.4915,  0.7021],\n",
      "        [-1.8287, -1.4542,  2.4475, -1.2962,  1.4204,  0.0695, -0.6199, -0.6909,\n",
      "          0.1794,  0.6212]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2393, -0.0248,  1.4013,  0.9665,  1.3603, -0.0837,  1.7963, -2.7218,\n",
      "          0.5124, -0.8325],\n",
      "        [ 0.2550,  0.7825, -0.6621, -0.6044,  1.1049,  0.0524,  0.7497, -0.7880,\n",
      "         -0.4444, -1.2957],\n",
      "        [-0.3355, -1.6911, -0.8457, -0.5660, -0.6986,  0.2760,  0.1076,  0.6572,\n",
      "          0.4914,  0.7020],\n",
      "        [-1.8290, -1.4542,  2.4475, -1.2963,  1.4204,  0.0697, -0.6199, -0.6909,\n",
      "          0.1794,  0.6212]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2397, -0.0234,  1.4012,  0.9662,  1.3603, -0.0835,  1.7963, -2.7218,\n",
      "          0.5121, -0.8326],\n",
      "        [ 0.2556,  0.7834, -0.6622, -0.6044,  1.1049,  0.0523,  0.7497, -0.7880,\n",
      "         -0.4445, -1.2957],\n",
      "        [-0.3361, -1.6907, -0.8457, -0.5663, -0.6986,  0.2766,  0.1076,  0.6572,\n",
      "          0.4913,  0.7020],\n",
      "        [-1.8292, -1.4541,  2.4475, -1.2964,  1.4204,  0.0699, -0.6199, -0.6909,\n",
      "          0.1794,  0.6212]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2402, -0.0221,  1.4011,  0.9660,  1.3603, -0.0833,  1.7963, -2.7218,\n",
      "          0.5119, -0.8326],\n",
      "        [ 0.2563,  0.7844, -0.6623, -0.6045,  1.1049,  0.0522,  0.7497, -0.7880,\n",
      "         -0.4447, -1.2957],\n",
      "        [-0.3366, -1.6903, -0.8457, -0.5666, -0.6986,  0.2772,  0.1076,  0.6572,\n",
      "          0.4913,  0.7019],\n",
      "        [-1.8295, -1.4540,  2.4475, -1.2965,  1.4204,  0.0702, -0.6199, -0.6909,\n",
      "          0.1794,  0.6212]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2406, -0.0207,  1.4010,  0.9657,  1.3603, -0.0831,  1.7963, -2.7218,\n",
      "          0.5117, -0.8327],\n",
      "        [ 0.2569,  0.7853, -0.6624, -0.6046,  1.1049,  0.0521,  0.7497, -0.7880,\n",
      "         -0.4449, -1.2958],\n",
      "        [-0.3371, -1.6899, -0.8458, -0.5668, -0.6986,  0.2777,  0.1076,  0.6572,\n",
      "          0.4912,  0.7019],\n",
      "        [-1.8297, -1.4540,  2.4475, -1.2966,  1.4204,  0.0704, -0.6199, -0.6909,\n",
      "          0.1794,  0.6212]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2411, -0.0193,  1.4008,  0.9655,  1.3603, -0.0830,  1.7963, -2.7218,\n",
      "          0.5114, -0.8327],\n",
      "        [ 0.2575,  0.7862, -0.6625, -0.6046,  1.1049,  0.0519,  0.7497, -0.7880,\n",
      "         -0.4451, -1.2958],\n",
      "        [-0.3377, -1.6895, -0.8458, -0.5671, -0.6986,  0.2783,  0.1076,  0.6572,\n",
      "          0.4912,  0.7018],\n",
      "        [-1.8300, -1.4539,  2.4475, -1.2967,  1.4204,  0.0706, -0.6199, -0.6909,\n",
      "          0.1794,  0.6212]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2415, -0.0180,  1.4007,  0.9652,  1.3603, -0.0828,  1.7963, -2.7218,\n",
      "          0.5112, -0.8328],\n",
      "        [ 0.2582,  0.7871, -0.6626, -0.6047,  1.1049,  0.0518,  0.7497, -0.7880,\n",
      "         -0.4452, -1.2958],\n",
      "        [-0.3382, -1.6891, -0.8458, -0.5674, -0.6986,  0.2789,  0.1076,  0.6572,\n",
      "          0.4911,  0.7018],\n",
      "        [-1.8302, -1.4538,  2.4475, -1.2968,  1.4204,  0.0709, -0.6199, -0.6909,\n",
      "          0.1794,  0.6212]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2419, -0.0166,  1.4006,  0.9650,  1.3603, -0.0826,  1.7963, -2.7218,\n",
      "          0.5109, -0.8328],\n",
      "        [ 0.2588,  0.7881, -0.6627, -0.6048,  1.1049,  0.0517,  0.7497, -0.7880,\n",
      "         -0.4454, -1.2958],\n",
      "        [-0.3388, -1.6887, -0.8459, -0.5676, -0.6986,  0.2794,  0.1076,  0.6572,\n",
      "          0.4911,  0.7018],\n",
      "        [-1.8305, -1.4538,  2.4475, -1.2969,  1.4204,  0.0711, -0.6199, -0.6909,\n",
      "          0.1794,  0.6211]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2423, -0.0152,  1.4004,  0.9648,  1.3603, -0.0824,  1.7963, -2.7218,\n",
      "          0.5107, -0.8329],\n",
      "        [ 0.2594,  0.7890, -0.6628, -0.6049,  1.1049,  0.0516,  0.7497, -0.7880,\n",
      "         -0.4456, -1.2958],\n",
      "        [-0.3393, -1.6883, -0.8459, -0.5679, -0.6986,  0.2800,  0.1076,  0.6572,\n",
      "          0.4910,  0.7017],\n",
      "        [-1.8307, -1.4537,  2.4475, -1.2970,  1.4204,  0.0713, -0.6199, -0.6909,\n",
      "          0.1794,  0.6211]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2428, -0.0139,  1.4003,  0.9645,  1.3603, -0.0822,  1.7963, -2.7218,\n",
      "          0.5104, -0.8329],\n",
      "        [ 0.2600,  0.7899, -0.6629, -0.6049,  1.1049,  0.0515,  0.7497, -0.7880,\n",
      "         -0.4458, -1.2959],\n",
      "        [-0.3399, -1.6879, -0.8459, -0.5682, -0.6986,  0.2806,  0.1076,  0.6572,\n",
      "          0.4910,  0.7017],\n",
      "        [-1.8310, -1.4536,  2.4475, -1.2971,  1.4204,  0.0716, -0.6199, -0.6909,\n",
      "          0.1794,  0.6211]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2432, -0.0125,  1.4002,  0.9643,  1.3603, -0.0820,  1.7963, -2.7218,\n",
      "          0.5102, -0.8330],\n",
      "        [ 0.2606,  0.7909, -0.6630, -0.6050,  1.1049,  0.0514,  0.7497, -0.7880,\n",
      "         -0.4460, -1.2959],\n",
      "        [-0.3404, -1.6875, -0.8459, -0.5684, -0.6986,  0.2811,  0.1076,  0.6572,\n",
      "          0.4909,  0.7016],\n",
      "        [-1.8312, -1.4536,  2.4475, -1.2972,  1.4204,  0.0718, -0.6199, -0.6909,\n",
      "          0.1794,  0.6211]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2435, -0.0112,  1.4001,  0.9640,  1.3603, -0.0819,  1.7963, -2.7218,\n",
      "          0.5099, -0.8330],\n",
      "        [ 0.2612,  0.7918, -0.6631, -0.6051,  1.1049,  0.0512,  0.7497, -0.7880,\n",
      "         -0.4461, -1.2959],\n",
      "        [-0.3410, -1.6871, -0.8460, -0.5687, -0.6986,  0.2817,  0.1076,  0.6572,\n",
      "          0.4909,  0.7016],\n",
      "        [-1.8315, -1.4535,  2.4475, -1.2973,  1.4204,  0.0720, -0.6199, -0.6909,\n",
      "          0.1794,  0.6211]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2439, -0.0098,  1.3999,  0.9638,  1.3603, -0.0817,  1.7963, -2.7218,\n",
      "          0.5097, -0.8331],\n",
      "        [ 0.2618,  0.7927, -0.6632, -0.6051,  1.1049,  0.0511,  0.7497, -0.7880,\n",
      "         -0.4463, -1.2959],\n",
      "        [-0.3415, -1.6867, -0.8460, -0.5690, -0.6986,  0.2822,  0.1076,  0.6572,\n",
      "          0.4908,  0.7016],\n",
      "        [-1.8317, -1.4534,  2.4475, -1.2974,  1.4204,  0.0723, -0.6199, -0.6909,\n",
      "          0.1794,  0.6211]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2443, -0.0084,  1.3998,  0.9635,  1.3603, -0.0815,  1.7963, -2.7218,\n",
      "          0.5094, -0.8331],\n",
      "        [ 0.2624,  0.7936, -0.6632, -0.6052,  1.1049,  0.0510,  0.7497, -0.7880,\n",
      "         -0.4465, -1.2960],\n",
      "        [-0.3421, -1.6863, -0.8460, -0.5693, -0.6986,  0.2828,  0.1076,  0.6572,\n",
      "          0.4908,  0.7015],\n",
      "        [-1.8320, -1.4534,  2.4475, -1.2975,  1.4204,  0.0725, -0.6199, -0.6909,\n",
      "          0.1794,  0.6211]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2447, -0.0071,  1.3997,  0.9633,  1.3603, -0.0813,  1.7963, -2.7218,\n",
      "          0.5092, -0.8332],\n",
      "        [ 0.2630,  0.7946, -0.6633, -0.6053,  1.1049,  0.0509,  0.7497, -0.7880,\n",
      "         -0.4467, -1.2960],\n",
      "        [-0.3427, -1.6859, -0.8460, -0.5695, -0.6986,  0.2833,  0.1076,  0.6572,\n",
      "          0.4907,  0.7015],\n",
      "        [-1.8323, -1.4533,  2.4475, -1.2976,  1.4204,  0.0727, -0.6199, -0.6909,\n",
      "          0.1794,  0.6210]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2451, -0.0057,  1.3995,  0.9630,  1.3603, -0.0812,  1.7963, -2.7218,\n",
      "          0.5089, -0.8332],\n",
      "        [ 0.2636,  0.7955, -0.6634, -0.6054,  1.1049,  0.0508,  0.7497, -0.7880,\n",
      "         -0.4469, -1.2960],\n",
      "        [-0.3432, -1.6855, -0.8461, -0.5698, -0.6986,  0.2839,  0.1076,  0.6572,\n",
      "          0.4907,  0.7014],\n",
      "        [-1.8325, -1.4532,  2.4475, -1.2977,  1.4204,  0.0729, -0.6199, -0.6909,\n",
      "          0.1794,  0.6210]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2454, -0.0044,  1.3994,  0.9628,  1.3603, -0.0810,  1.7963, -2.7218,\n",
      "          0.5087, -0.8333],\n",
      "        [ 0.2642,  0.7964, -0.6635, -0.6054,  1.1049,  0.0507,  0.7497, -0.7880,\n",
      "         -0.4470, -1.2960],\n",
      "        [-0.3438, -1.6851, -0.8461, -0.5701, -0.6986,  0.2844,  0.1076,  0.6572,\n",
      "          0.4906,  0.7014],\n",
      "        [-1.8328, -1.4532,  2.4475, -1.2978,  1.4204,  0.0732, -0.6199, -0.6909,\n",
      "          0.1794,  0.6210]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2458, -0.0030,  1.3993,  0.9625,  1.3603, -0.0808,  1.7963, -2.7218,\n",
      "          0.5085, -0.8333],\n",
      "        [ 0.2648,  0.7973, -0.6636, -0.6055,  1.1049,  0.0505,  0.7497, -0.7880,\n",
      "         -0.4472, -1.2960],\n",
      "        [-0.3444, -1.6847, -0.8461, -0.5703, -0.6986,  0.2850,  0.1076,  0.6572,\n",
      "          0.4906,  0.7014],\n",
      "        [-1.8330, -1.4531,  2.4475, -1.2979,  1.4204,  0.0734, -0.6199, -0.6909,\n",
      "          0.1794,  0.6210]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4612e-01, -1.6633e-03,  1.3992e+00,  9.6230e-01,  1.3603e+00,\n",
      "         -8.0663e-02,  1.7963e+00, -2.7218e+00,  5.0821e-01, -8.3337e-01],\n",
      "        [ 2.6537e-01,  7.9826e-01, -6.6371e-01, -6.0557e-01,  1.1049e+00,\n",
      "          5.0422e-02,  7.4966e-01, -7.8798e-01, -4.4738e-01, -1.2961e+00],\n",
      "        [-3.4492e-01, -1.6844e+00, -8.4615e-01, -5.7059e-01, -6.9856e-01,\n",
      "          2.8551e-01,  1.0762e-01,  6.5721e-01,  4.9052e-01,  7.0132e-01],\n",
      "        [-1.8333e+00, -1.4530e+00,  2.4475e+00, -1.2980e+00,  1.4204e+00,\n",
      "          7.3610e-02, -6.1993e-01, -6.9090e-01,  1.7938e-01,  6.2099e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4647e-01, -3.1308e-04,  1.3990e+00,  9.6206e-01,  1.3603e+00,\n",
      "         -8.0497e-02,  1.7963e+00, -2.7218e+00,  5.0797e-01, -8.3342e-01],\n",
      "        [ 2.6594e-01,  7.9918e-01, -6.6380e-01, -6.0564e-01,  1.1049e+00,\n",
      "          5.0303e-02,  7.4966e-01, -7.8798e-01, -4.4756e-01, -1.2961e+00],\n",
      "        [-3.4549e-01, -1.6840e+00, -8.4618e-01, -5.7085e-01, -6.9856e-01,\n",
      "          2.8605e-01,  1.0762e-01,  6.5721e-01,  4.9047e-01,  7.0128e-01],\n",
      "        [-1.8335e+00, -1.4530e+00,  2.4475e+00, -1.2981e+00,  1.4204e+00,\n",
      "          7.3832e-02, -6.1993e-01, -6.9090e-01,  1.7938e-01,  6.2097e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4681e-01,  1.0356e-03,  1.3989e+00,  9.6181e-01,  1.3603e+00,\n",
      "         -8.0332e-02,  1.7963e+00, -2.7218e+00,  5.0772e-01, -8.3347e-01],\n",
      "        [ 2.6651e-01,  8.0010e-01, -6.6389e-01, -6.0571e-01,  1.1049e+00,\n",
      "          5.0184e-02,  7.4966e-01, -7.8798e-01, -4.4774e-01, -1.2961e+00],\n",
      "        [-3.4606e-01, -1.6836e+00, -8.4621e-01, -5.7112e-01, -6.9856e-01,\n",
      "          2.8659e-01,  1.0762e-01,  6.5721e-01,  4.9042e-01,  7.0124e-01],\n",
      "        [-1.8338e+00, -1.4529e+00,  2.4475e+00, -1.2982e+00,  1.4204e+00,\n",
      "          7.4055e-02, -6.1993e-01, -6.9090e-01,  1.7938e-01,  6.2096e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4715e-01,  2.3826e-03,  1.3988e+00,  9.6157e-01,  1.3603e+00,\n",
      "         -8.0168e-02,  1.7963e+00, -2.7218e+00,  5.0748e-01, -8.3351e-01],\n",
      "        [ 2.6708e-01,  8.0102e-01, -6.6398e-01, -6.0578e-01,  1.1049e+00,\n",
      "          5.0065e-02,  7.4966e-01, -7.8798e-01, -4.4792e-01, -1.2961e+00],\n",
      "        [-3.4663e-01, -1.6832e+00, -8.4623e-01, -5.7138e-01, -6.9856e-01,\n",
      "          2.8713e-01,  1.0762e-01,  6.5721e-01,  4.9037e-01,  7.0120e-01],\n",
      "        [-1.8341e+00, -1.4528e+00,  2.4475e+00, -1.2983e+00,  1.4204e+00,\n",
      "          7.4276e-02, -6.1993e-01, -6.9090e-01,  1.7938e-01,  6.2095e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2475,  0.0037,  1.3987,  0.9613,  1.3603, -0.0800,  1.7963, -2.7218,\n",
      "          0.5072, -0.8336],\n",
      "        [ 0.2676,  0.8019, -0.6641, -0.6059,  1.1049,  0.0499,  0.7497, -0.7880,\n",
      "         -0.4481, -1.2961],\n",
      "        [-0.3472, -1.6828, -0.8463, -0.5716, -0.6986,  0.2877,  0.1076,  0.6572,\n",
      "          0.4903,  0.7012],\n",
      "        [-1.8343, -1.4528,  2.4475, -1.2984,  1.4204,  0.0745, -0.6199, -0.6909,\n",
      "          0.1794,  0.6209]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2478,  0.0051,  1.3985,  0.9611,  1.3603, -0.0798,  1.7963, -2.7218,\n",
      "          0.5070, -0.8336],\n",
      "        [ 0.2682,  0.8029, -0.6642, -0.6059,  1.1049,  0.0498,  0.7497, -0.7880,\n",
      "         -0.4483, -1.2962],\n",
      "        [-0.3478, -1.6824, -0.8463, -0.5719, -0.6986,  0.2882,  0.1076,  0.6572,\n",
      "          0.4903,  0.7011],\n",
      "        [-1.8346, -1.4527,  2.4475, -1.2984,  1.4204,  0.0747, -0.6199, -0.6909,\n",
      "          0.1794,  0.6209]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2481,  0.0064,  1.3984,  0.9608,  1.3603, -0.0797,  1.7963, -2.7218,\n",
      "          0.5067, -0.8337],\n",
      "        [ 0.2688,  0.8038, -0.6643, -0.6060,  1.1049,  0.0497,  0.7497, -0.7880,\n",
      "         -0.4485, -1.2962],\n",
      "        [-0.3483, -1.6820, -0.8463, -0.5722, -0.6986,  0.2887,  0.1076,  0.6572,\n",
      "          0.4902,  0.7011],\n",
      "        [-1.8348, -1.4526,  2.4475, -1.2985,  1.4204,  0.0749, -0.6199, -0.6909,\n",
      "          0.1794,  0.6209]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2484,  0.0078,  1.3983,  0.9606,  1.3603, -0.0795,  1.7963, -2.7218,\n",
      "          0.5065, -0.8337],\n",
      "        [ 0.2693,  0.8047, -0.6644, -0.6061,  1.1049,  0.0496,  0.7497, -0.7880,\n",
      "         -0.4486, -1.2962],\n",
      "        [-0.3489, -1.6816, -0.8463, -0.5724, -0.6986,  0.2893,  0.1076,  0.6572,\n",
      "          0.4902,  0.7010],\n",
      "        [-1.8351, -1.4526,  2.4475, -1.2986,  1.4204,  0.0752, -0.6199, -0.6909,\n",
      "          0.1794,  0.6209]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2487,  0.0091,  1.3982,  0.9604,  1.3603, -0.0794,  1.7963, -2.7218,\n",
      "          0.5062, -0.8338],\n",
      "        [ 0.2699,  0.8056, -0.6644, -0.6061,  1.1049,  0.0495,  0.7497, -0.7880,\n",
      "         -0.4488, -1.2962],\n",
      "        [-0.3495, -1.6812, -0.8464, -0.5727, -0.6986,  0.2898,  0.1076,  0.6572,\n",
      "          0.4901,  0.7010],\n",
      "        [-1.8353, -1.4525,  2.4475, -1.2987,  1.4204,  0.0754, -0.6199, -0.6909,\n",
      "          0.1794,  0.6209]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2491,  0.0104,  1.3980,  0.9601,  1.3603, -0.0792,  1.7963, -2.7218,\n",
      "          0.5060, -0.8338],\n",
      "        [ 0.2704,  0.8065, -0.6645, -0.6062,  1.1049,  0.0493,  0.7497, -0.7880,\n",
      "         -0.4490, -1.2963],\n",
      "        [-0.3501, -1.6808, -0.8464, -0.5730, -0.6986,  0.2903,  0.1076,  0.6572,\n",
      "          0.4901,  0.7010],\n",
      "        [-1.8356, -1.4524,  2.4475, -1.2988,  1.4204,  0.0756, -0.6199, -0.6909,\n",
      "          0.1794,  0.6209]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2494,  0.0118,  1.3979,  0.9599,  1.3603, -0.0791,  1.7963, -2.7218,\n",
      "          0.5058, -0.8339],\n",
      "        [ 0.2709,  0.8074, -0.6646, -0.6063,  1.1049,  0.0492,  0.7497, -0.7880,\n",
      "         -0.4492, -1.2963],\n",
      "        [-0.3506, -1.6804, -0.8464, -0.5732, -0.6986,  0.2908,  0.1076,  0.6572,\n",
      "          0.4900,  0.7009],\n",
      "        [-1.8359, -1.4524,  2.4475, -1.2989,  1.4204,  0.0758, -0.6199, -0.6909,\n",
      "          0.1794,  0.6209]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2497,  0.0131,  1.3978,  0.9596,  1.3603, -0.0789,  1.7963, -2.7218,\n",
      "          0.5055, -0.8339],\n",
      "        [ 0.2715,  0.8083, -0.6647, -0.6063,  1.1049,  0.0491,  0.7497, -0.7880,\n",
      "         -0.4493, -1.2963],\n",
      "        [-0.3512, -1.6800, -0.8464, -0.5735, -0.6986,  0.2914,  0.1076,  0.6572,\n",
      "          0.4900,  0.7009],\n",
      "        [-1.8361, -1.4523,  2.4475, -1.2990,  1.4204,  0.0760, -0.6199, -0.6909,\n",
      "          0.1794,  0.6208]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2499,  0.0144,  1.3977,  0.9594,  1.3603, -0.0788,  1.7963, -2.7218,\n",
      "          0.5053, -0.8339],\n",
      "        [ 0.2720,  0.8092, -0.6648, -0.6064,  1.1049,  0.0490,  0.7497, -0.7880,\n",
      "         -0.4495, -1.2963],\n",
      "        [-0.3518, -1.6796, -0.8465, -0.5738, -0.6986,  0.2919,  0.1076,  0.6572,\n",
      "          0.4899,  0.7009],\n",
      "        [-1.8364, -1.4522,  2.4475, -1.2991,  1.4204,  0.0762, -0.6199, -0.6909,\n",
      "          0.1793,  0.6208]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2502,  0.0158,  1.3975,  0.9592,  1.3603, -0.0786,  1.7963, -2.7218,\n",
      "          0.5050, -0.8340],\n",
      "        [ 0.2725,  0.8101, -0.6649, -0.6065,  1.1049,  0.0489,  0.7497, -0.7880,\n",
      "         -0.4497, -1.2963],\n",
      "        [-0.3524, -1.6792, -0.8465, -0.5740, -0.6986,  0.2924,  0.1076,  0.6572,\n",
      "          0.4899,  0.7008],\n",
      "        [-1.8366, -1.4522,  2.4475, -1.2992,  1.4204,  0.0765, -0.6199, -0.6909,\n",
      "          0.1793,  0.6208]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2505,  0.0171,  1.3974,  0.9589,  1.3603, -0.0785,  1.7963, -2.7218,\n",
      "          0.5048, -0.8340],\n",
      "        [ 0.2731,  0.8110, -0.6650, -0.6065,  1.1049,  0.0487,  0.7497, -0.7880,\n",
      "         -0.4499, -1.2964],\n",
      "        [-0.3529, -1.6789, -0.8465, -0.5743, -0.6986,  0.2929,  0.1076,  0.6572,\n",
      "          0.4898,  0.7008],\n",
      "        [-1.8369, -1.4521,  2.4475, -1.2993,  1.4204,  0.0767, -0.6199, -0.6909,\n",
      "          0.1793,  0.6208]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2508,  0.0184,  1.3973,  0.9587,  1.3603, -0.0783,  1.7963, -2.7218,\n",
      "          0.5045, -0.8341],\n",
      "        [ 0.2736,  0.8119, -0.6651, -0.6066,  1.1049,  0.0486,  0.7497, -0.7880,\n",
      "         -0.4501, -1.2964],\n",
      "        [-0.3535, -1.6785, -0.8466, -0.5745, -0.6986,  0.2934,  0.1076,  0.6572,\n",
      "          0.4898,  0.7007],\n",
      "        [-1.8371, -1.4520,  2.4475, -1.2994,  1.4204,  0.0769, -0.6199, -0.6909,\n",
      "          0.1793,  0.6208]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2511,  0.0197,  1.3972,  0.9585,  1.3603, -0.0782,  1.7963, -2.7218,\n",
      "          0.5043, -0.8341],\n",
      "        [ 0.2741,  0.8128, -0.6652, -0.6067,  1.1049,  0.0485,  0.7497, -0.7880,\n",
      "         -0.4502, -1.2964],\n",
      "        [-0.3541, -1.6781, -0.8466, -0.5748, -0.6986,  0.2939,  0.1076,  0.6572,\n",
      "          0.4897,  0.7007],\n",
      "        [-1.8374, -1.4520,  2.4475, -1.2995,  1.4204,  0.0771, -0.6199, -0.6909,\n",
      "          0.1793,  0.6208]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2514,  0.0210,  1.3970,  0.9582,  1.3603, -0.0780,  1.7963, -2.7218,\n",
      "          0.5040, -0.8342],\n",
      "        [ 0.2746,  0.8137, -0.6653, -0.6067,  1.1049,  0.0484,  0.7497, -0.7880,\n",
      "         -0.4504, -1.2964],\n",
      "        [-0.3547, -1.6777, -0.8466, -0.5751, -0.6986,  0.2945,  0.1076,  0.6572,\n",
      "          0.4897,  0.7007],\n",
      "        [-1.8377, -1.4519,  2.4475, -1.2996,  1.4204,  0.0773, -0.6199, -0.6909,\n",
      "          0.1793,  0.6208]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2516,  0.0224,  1.3969,  0.9580,  1.3603, -0.0779,  1.7963, -2.7218,\n",
      "          0.5038, -0.8342],\n",
      "        [ 0.2752,  0.8146, -0.6653, -0.6068,  1.1049,  0.0482,  0.7497, -0.7880,\n",
      "         -0.4506, -1.2964],\n",
      "        [-0.3553, -1.6773, -0.8466, -0.5753, -0.6986,  0.2950,  0.1076,  0.6572,\n",
      "          0.4896,  0.7006],\n",
      "        [-1.8379, -1.4518,  2.4475, -1.2997,  1.4204,  0.0775, -0.6199, -0.6909,\n",
      "          0.1793,  0.6207]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2519,  0.0237,  1.3968,  0.9578,  1.3603, -0.0777,  1.7963, -2.7218,\n",
      "          0.5036, -0.8343],\n",
      "        [ 0.2757,  0.8155, -0.6654, -0.6069,  1.1049,  0.0481,  0.7497, -0.7880,\n",
      "         -0.4508, -1.2965],\n",
      "        [-0.3558, -1.6769, -0.8467, -0.5756, -0.6986,  0.2955,  0.1076,  0.6572,\n",
      "          0.4896,  0.7006],\n",
      "        [-1.8382, -1.4518,  2.4475, -1.2998,  1.4204,  0.0777, -0.6199, -0.6909,\n",
      "          0.1793,  0.6207]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2522,  0.0250,  1.3967,  0.9575,  1.3603, -0.0776,  1.7963, -2.7218,\n",
      "          0.5033, -0.8343],\n",
      "        [ 0.2762,  0.8164, -0.6655, -0.6069,  1.1049,  0.0480,  0.7497, -0.7880,\n",
      "         -0.4509, -1.2965],\n",
      "        [-0.3564, -1.6765, -0.8467, -0.5758, -0.6986,  0.2960,  0.1076,  0.6572,\n",
      "          0.4895,  0.7005],\n",
      "        [-1.8384, -1.4517,  2.4475, -1.2998,  1.4204,  0.0779, -0.6199, -0.6909,\n",
      "          0.1793,  0.6207]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2524,  0.0263,  1.3965,  0.9573,  1.3603, -0.0775,  1.7963, -2.7218,\n",
      "          0.5031, -0.8344],\n",
      "        [ 0.2767,  0.8173, -0.6656, -0.6070,  1.1049,  0.0479,  0.7497, -0.7880,\n",
      "         -0.4511, -1.2965],\n",
      "        [-0.3570, -1.6761, -0.8467, -0.5761, -0.6986,  0.2965,  0.1076,  0.6572,\n",
      "          0.4895,  0.7005],\n",
      "        [-1.8387, -1.4517,  2.4475, -1.2999,  1.4204,  0.0781, -0.6199, -0.6909,\n",
      "          0.1793,  0.6207]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2527,  0.0276,  1.3964,  0.9571,  1.3603, -0.0773,  1.7963, -2.7218,\n",
      "          0.5028, -0.8344],\n",
      "        [ 0.2772,  0.8182, -0.6657, -0.6071,  1.1049,  0.0477,  0.7497, -0.7880,\n",
      "         -0.4513, -1.2965],\n",
      "        [-0.3576, -1.6758, -0.8467, -0.5764, -0.6986,  0.2970,  0.1076,  0.6572,\n",
      "          0.4894,  0.7005],\n",
      "        [-1.8389, -1.4516,  2.4475, -1.3000,  1.4204,  0.0784, -0.6199, -0.6909,\n",
      "          0.1793,  0.6207]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2529,  0.0289,  1.3963,  0.9568,  1.3603, -0.0772,  1.7963, -2.7218,\n",
      "          0.5026, -0.8345],\n",
      "        [ 0.2777,  0.8191, -0.6658, -0.6071,  1.1049,  0.0476,  0.7497, -0.7880,\n",
      "         -0.4515, -1.2965],\n",
      "        [-0.3581, -1.6754, -0.8468, -0.5766, -0.6986,  0.2975,  0.1076,  0.6572,\n",
      "          0.4894,  0.7004],\n",
      "        [-1.8392, -1.4515,  2.4475, -1.3001,  1.4204,  0.0786, -0.6199, -0.6909,\n",
      "          0.1793,  0.6207]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2532,  0.0302,  1.3962,  0.9566,  1.3603, -0.0771,  1.7963, -2.7218,\n",
      "          0.5023, -0.8345],\n",
      "        [ 0.2782,  0.8200, -0.6659, -0.6072,  1.1049,  0.0475,  0.7497, -0.7880,\n",
      "         -0.4517, -1.2966],\n",
      "        [-0.3587, -1.6750, -0.8468, -0.5769, -0.6986,  0.2980,  0.1076,  0.6572,\n",
      "          0.4893,  0.7004],\n",
      "        [-1.8394, -1.4515,  2.4475, -1.3002,  1.4204,  0.0788, -0.6199, -0.6909,\n",
      "          0.1793,  0.6207]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2534,  0.0315,  1.3961,  0.9564,  1.3603, -0.0769,  1.7963, -2.7218,\n",
      "          0.5021, -0.8346],\n",
      "        [ 0.2787,  0.8208, -0.6660, -0.6073,  1.1049,  0.0474,  0.7497, -0.7880,\n",
      "         -0.4518, -1.2966],\n",
      "        [-0.3593, -1.6746, -0.8468, -0.5771, -0.6986,  0.2985,  0.1076,  0.6572,\n",
      "          0.4893,  0.7004],\n",
      "        [-1.8397, -1.4514,  2.4475, -1.3003,  1.4204,  0.0790, -0.6199, -0.6909,\n",
      "          0.1793,  0.6207]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2537,  0.0328,  1.3959,  0.9561,  1.3603, -0.0768,  1.7963, -2.7218,\n",
      "          0.5018, -0.8346],\n",
      "        [ 0.2792,  0.8217, -0.6661, -0.6073,  1.1049,  0.0472,  0.7497, -0.7880,\n",
      "         -0.4520, -1.2966],\n",
      "        [-0.3599, -1.6742, -0.8468, -0.5774, -0.6986,  0.2990,  0.1076,  0.6572,\n",
      "          0.4892,  0.7003],\n",
      "        [-1.8400, -1.4513,  2.4475, -1.3004,  1.4204,  0.0792, -0.6199, -0.6909,\n",
      "          0.1793,  0.6206]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2539,  0.0341,  1.3958,  0.9559,  1.3603, -0.0767,  1.7963, -2.7218,\n",
      "          0.5016, -0.8346],\n",
      "        [ 0.2797,  0.8226, -0.6662, -0.6074,  1.1049,  0.0471,  0.7497, -0.7880,\n",
      "         -0.4522, -1.2966],\n",
      "        [-0.3605, -1.6739, -0.8469, -0.5776, -0.6986,  0.2995,  0.1076,  0.6572,\n",
      "          0.4892,  0.7003],\n",
      "        [-1.8402, -1.4513,  2.4475, -1.3005,  1.4204,  0.0794, -0.6199, -0.6909,\n",
      "          0.1793,  0.6206]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2542,  0.0354,  1.3957,  0.9557,  1.3603, -0.0765,  1.7963, -2.7218,\n",
      "          0.5014, -0.8347],\n",
      "        [ 0.2802,  0.8235, -0.6662, -0.6075,  1.1049,  0.0470,  0.7497, -0.7880,\n",
      "         -0.4524, -1.2966],\n",
      "        [-0.3610, -1.6735, -0.8469, -0.5779, -0.6986,  0.3000,  0.1076,  0.6572,\n",
      "          0.4891,  0.7002],\n",
      "        [-1.8405, -1.4512,  2.4475, -1.3006,  1.4204,  0.0796, -0.6199, -0.6909,\n",
      "          0.1793,  0.6206]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2544,  0.0367,  1.3956,  0.9554,  1.3603, -0.0764,  1.7963, -2.7218,\n",
      "          0.5011, -0.8347],\n",
      "        [ 0.2807,  0.8244, -0.6663, -0.6075,  1.1049,  0.0468,  0.7497, -0.7880,\n",
      "         -0.4525, -1.2967],\n",
      "        [-0.3616, -1.6731, -0.8469, -0.5782, -0.6986,  0.3005,  0.1076,  0.6572,\n",
      "          0.4891,  0.7002],\n",
      "        [-1.8407, -1.4511,  2.4475, -1.3007,  1.4204,  0.0798, -0.6199, -0.6909,\n",
      "          0.1793,  0.6206]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2546,  0.0379,  1.3954,  0.9552,  1.3603, -0.0763,  1.7963, -2.7218,\n",
      "          0.5009, -0.8348],\n",
      "        [ 0.2812,  0.8252, -0.6664, -0.6076,  1.1049,  0.0467,  0.7497, -0.7880,\n",
      "         -0.4527, -1.2967],\n",
      "        [-0.3622, -1.6727, -0.8469, -0.5784, -0.6986,  0.3010,  0.1076,  0.6572,\n",
      "          0.4890,  0.7002],\n",
      "        [-1.8410, -1.4511,  2.4475, -1.3008,  1.4204,  0.0800, -0.6199, -0.6909,\n",
      "          0.1793,  0.6206]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2549,  0.0392,  1.3953,  0.9550,  1.3603, -0.0762,  1.7963, -2.7218,\n",
      "          0.5006, -0.8348],\n",
      "        [ 0.2817,  0.8261, -0.6665, -0.6076,  1.1049,  0.0466,  0.7497, -0.7880,\n",
      "         -0.4529, -1.2967],\n",
      "        [-0.3628, -1.6723, -0.8470, -0.5787, -0.6986,  0.3014,  0.1076,  0.6572,\n",
      "          0.4890,  0.7001],\n",
      "        [-1.8412, -1.4510,  2.4475, -1.3009,  1.4204,  0.0802, -0.6199, -0.6909,\n",
      "          0.1793,  0.6206]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2551,  0.0405,  1.3952,  0.9547,  1.3603, -0.0760,  1.7963, -2.7218,\n",
      "          0.5004, -0.8349],\n",
      "        [ 0.2821,  0.8270, -0.6666, -0.6077,  1.1049,  0.0465,  0.7497, -0.7880,\n",
      "         -0.4531, -1.2967],\n",
      "        [-0.3634, -1.6720, -0.8470, -0.5789, -0.6986,  0.3019,  0.1076,  0.6572,\n",
      "          0.4889,  0.7001],\n",
      "        [-1.8415, -1.4509,  2.4475, -1.3010,  1.4204,  0.0804, -0.6199, -0.6909,\n",
      "          0.1793,  0.6206]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2553,  0.0418,  1.3951,  0.9545,  1.3603, -0.0759,  1.7963, -2.7218,\n",
      "          0.5001, -0.8349],\n",
      "        [ 0.2826,  0.8278, -0.6667, -0.6078,  1.1049,  0.0463,  0.7497, -0.7880,\n",
      "         -0.4533, -1.2967],\n",
      "        [-0.3639, -1.6716, -0.8470, -0.5792, -0.6986,  0.3024,  0.1076,  0.6572,\n",
      "          0.4889,  0.7001],\n",
      "        [-1.8417, -1.4509,  2.4475, -1.3010,  1.4204,  0.0806, -0.6199, -0.6909,\n",
      "          0.1793,  0.6205]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2556,  0.0431,  1.3950,  0.9543,  1.3603, -0.0758,  1.7963, -2.7218,\n",
      "          0.4999, -0.8350],\n",
      "        [ 0.2831,  0.8287, -0.6668, -0.6078,  1.1049,  0.0462,  0.7497, -0.7880,\n",
      "         -0.4534, -1.2968],\n",
      "        [-0.3645, -1.6712, -0.8470, -0.5794, -0.6986,  0.3029,  0.1076,  0.6572,\n",
      "          0.4888,  0.7000],\n",
      "        [-1.8420, -1.4508,  2.4475, -1.3011,  1.4204,  0.0808, -0.6199, -0.6909,\n",
      "          0.1793,  0.6205]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2558,  0.0443,  1.3948,  0.9541,  1.3603, -0.0757,  1.7963, -2.7218,\n",
      "          0.4996, -0.8350],\n",
      "        [ 0.2836,  0.8296, -0.6669, -0.6079,  1.1049,  0.0461,  0.7497, -0.7880,\n",
      "         -0.4536, -1.2968],\n",
      "        [-0.3651, -1.6708, -0.8471, -0.5797, -0.6986,  0.3034,  0.1076,  0.6572,\n",
      "          0.4888,  0.7000],\n",
      "        [-1.8422, -1.4508,  2.4475, -1.3012,  1.4204,  0.0810, -0.6199, -0.6909,\n",
      "          0.1793,  0.6205]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2560,  0.0456,  1.3947,  0.9538,  1.3603, -0.0756,  1.7963, -2.7218,\n",
      "          0.4994, -0.8351],\n",
      "        [ 0.2840,  0.8304, -0.6670, -0.6080,  1.1049,  0.0459,  0.7497, -0.7880,\n",
      "         -0.4538, -1.2968],\n",
      "        [-0.3657, -1.6705, -0.8471, -0.5799, -0.6986,  0.3039,  0.1076,  0.6572,\n",
      "          0.4887,  0.6999],\n",
      "        [-1.8425, -1.4507,  2.4475, -1.3013,  1.4204,  0.0812, -0.6199, -0.6909,\n",
      "          0.1793,  0.6205]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2562,  0.0468,  1.3946,  0.9536,  1.3603, -0.0754,  1.7963, -2.7218,\n",
      "          0.4991, -0.8351],\n",
      "        [ 0.2845,  0.8313, -0.6670, -0.6080,  1.1049,  0.0458,  0.7497, -0.7880,\n",
      "         -0.4540, -1.2968],\n",
      "        [-0.3662, -1.6701, -0.8471, -0.5802, -0.6986,  0.3043,  0.1076,  0.6572,\n",
      "          0.4887,  0.6999],\n",
      "        [-1.8427, -1.4506,  2.4475, -1.3014,  1.4204,  0.0814, -0.6199, -0.6909,\n",
      "          0.1793,  0.6205]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2564,  0.0481,  1.3945,  0.9534,  1.3603, -0.0753,  1.7963, -2.7218,\n",
      "          0.4989, -0.8351],\n",
      "        [ 0.2850,  0.8321, -0.6671, -0.6081,  1.1049,  0.0457,  0.7497, -0.7880,\n",
      "         -0.4541, -1.2968],\n",
      "        [-0.3668, -1.6697, -0.8471, -0.5804, -0.6986,  0.3048,  0.1076,  0.6572,\n",
      "          0.4886,  0.6999],\n",
      "        [-1.8430, -1.4506,  2.4475, -1.3015,  1.4204,  0.0816, -0.6199, -0.6909,\n",
      "          0.1793,  0.6205]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2566,  0.0494,  1.3943,  0.9532,  1.3603, -0.0752,  1.7963, -2.7218,\n",
      "          0.4987, -0.8352],\n",
      "        [ 0.2855,  0.8330, -0.6672, -0.6081,  1.1049,  0.0456,  0.7497, -0.7880,\n",
      "         -0.4543, -1.2969],\n",
      "        [-0.3674, -1.6694, -0.8472, -0.5807, -0.6986,  0.3053,  0.1076,  0.6572,\n",
      "          0.4886,  0.6998],\n",
      "        [-1.8432, -1.4505,  2.4475, -1.3016,  1.4204,  0.0818, -0.6199, -0.6909,\n",
      "          0.1793,  0.6205]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2569,  0.0506,  1.3942,  0.9529,  1.3603, -0.0751,  1.7963, -2.7218,\n",
      "          0.4984, -0.8352],\n",
      "        [ 0.2859,  0.8339, -0.6673, -0.6082,  1.1049,  0.0454,  0.7497, -0.7880,\n",
      "         -0.4545, -1.2969],\n",
      "        [-0.3680, -1.6690, -0.8472, -0.5809, -0.6986,  0.3058,  0.1076,  0.6572,\n",
      "          0.4885,  0.6998],\n",
      "        [-1.8435, -1.4504,  2.4475, -1.3017,  1.4204,  0.0820, -0.6199, -0.6909,\n",
      "          0.1793,  0.6205]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2571,  0.0519,  1.3941,  0.9527,  1.3603, -0.0750,  1.7963, -2.7218,\n",
      "          0.4982, -0.8353],\n",
      "        [ 0.2864,  0.8347, -0.6674, -0.6083,  1.1049,  0.0453,  0.7497, -0.7880,\n",
      "         -0.4547, -1.2969],\n",
      "        [-0.3685, -1.6686, -0.8472, -0.5812, -0.6986,  0.3062,  0.1076,  0.6572,\n",
      "          0.4885,  0.6998],\n",
      "        [-1.8437, -1.4504,  2.4475, -1.3018,  1.4204,  0.0822, -0.6199, -0.6909,\n",
      "          0.1793,  0.6204]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2573,  0.0531,  1.3940,  0.9525,  1.3603, -0.0749,  1.7963, -2.7218,\n",
      "          0.4979, -0.8353],\n",
      "        [ 0.2869,  0.8355, -0.6675, -0.6083,  1.1049,  0.0452,  0.7497, -0.7880,\n",
      "         -0.4549, -1.2969],\n",
      "        [-0.3691, -1.6683, -0.8472, -0.5815, -0.6986,  0.3067,  0.1076,  0.6572,\n",
      "          0.4884,  0.6997],\n",
      "        [-1.8440, -1.4503,  2.4475, -1.3019,  1.4204,  0.0824, -0.6199, -0.6909,\n",
      "          0.1793,  0.6204]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2575,  0.0544,  1.3939,  0.9523,  1.3603, -0.0748,  1.7963, -2.7218,\n",
      "          0.4977, -0.8354],\n",
      "        [ 0.2873,  0.8364, -0.6676, -0.6084,  1.1049,  0.0450,  0.7497, -0.7880,\n",
      "         -0.4550, -1.2969],\n",
      "        [-0.3697, -1.6679, -0.8473, -0.5817, -0.6986,  0.3072,  0.1076,  0.6572,\n",
      "          0.4884,  0.6997],\n",
      "        [-1.8442, -1.4503,  2.4475, -1.3019,  1.4204,  0.0826, -0.6199, -0.6909,\n",
      "          0.1793,  0.6204]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2577,  0.0556,  1.3937,  0.9520,  1.3603, -0.0747,  1.7963, -2.7218,\n",
      "          0.4974, -0.8354],\n",
      "        [ 0.2878,  0.8372, -0.6677, -0.6084,  1.1049,  0.0449,  0.7497, -0.7880,\n",
      "         -0.4552, -1.2970],\n",
      "        [-0.3703, -1.6675, -0.8473, -0.5820, -0.6986,  0.3076,  0.1076,  0.6572,\n",
      "          0.4883,  0.6997],\n",
      "        [-1.8445, -1.4502,  2.4475, -1.3020,  1.4204,  0.0828, -0.6199, -0.6909,\n",
      "          0.1793,  0.6204]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2579,  0.0568,  1.3936,  0.9518,  1.3603, -0.0746,  1.7963, -2.7218,\n",
      "          0.4972, -0.8355],\n",
      "        [ 0.2882,  0.8381, -0.6678, -0.6085,  1.1049,  0.0448,  0.7497, -0.7880,\n",
      "         -0.4554, -1.2970],\n",
      "        [-0.3708, -1.6672, -0.8473, -0.5822, -0.6986,  0.3081,  0.1076,  0.6572,\n",
      "          0.4883,  0.6996],\n",
      "        [-1.8447, -1.4501,  2.4475, -1.3021,  1.4204,  0.0830, -0.6199, -0.6909,\n",
      "          0.1793,  0.6204]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2581,  0.0581,  1.3935,  0.9516,  1.3603, -0.0744,  1.7963, -2.7218,\n",
      "          0.4969, -0.8355],\n",
      "        [ 0.2887,  0.8389, -0.6678, -0.6086,  1.1049,  0.0446,  0.7497, -0.7880,\n",
      "         -0.4556, -1.2970],\n",
      "        [-0.3714, -1.6668, -0.8473, -0.5825, -0.6986,  0.3086,  0.1076,  0.6572,\n",
      "          0.4882,  0.6996],\n",
      "        [-1.8450, -1.4501,  2.4474, -1.3022,  1.4204,  0.0832, -0.6199, -0.6909,\n",
      "          0.1793,  0.6204]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2583,  0.0593,  1.3934,  0.9514,  1.3603, -0.0743,  1.7963, -2.7218,\n",
      "          0.4967, -0.8355],\n",
      "        [ 0.2891,  0.8398, -0.6679, -0.6086,  1.1049,  0.0445,  0.7497, -0.7880,\n",
      "         -0.4557, -1.2970],\n",
      "        [-0.3720, -1.6664, -0.8474, -0.5827, -0.6986,  0.3090,  0.1076,  0.6572,\n",
      "          0.4882,  0.6995],\n",
      "        [-1.8452, -1.4500,  2.4474, -1.3023,  1.4204,  0.0834, -0.6199, -0.6909,\n",
      "          0.1792,  0.6204]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2585,  0.0605,  1.3933,  0.9512,  1.3603, -0.0742,  1.7963, -2.7218,\n",
      "          0.4965, -0.8356],\n",
      "        [ 0.2896,  0.8406, -0.6680, -0.6087,  1.1049,  0.0444,  0.7497, -0.7880,\n",
      "         -0.4559, -1.2970],\n",
      "        [-0.3726, -1.6661, -0.8474, -0.5829, -0.6986,  0.3095,  0.1076,  0.6572,\n",
      "          0.4881,  0.6995],\n",
      "        [-1.8455, -1.4500,  2.4474, -1.3024,  1.4204,  0.0836, -0.6199, -0.6909,\n",
      "          0.1792,  0.6204]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2587,  0.0617,  1.3931,  0.9509,  1.3603, -0.0741,  1.7963, -2.7218,\n",
      "          0.4962, -0.8356],\n",
      "        [ 0.2900,  0.8414, -0.6681, -0.6087,  1.1049,  0.0442,  0.7497, -0.7880,\n",
      "         -0.4561, -1.2971],\n",
      "        [-0.3731, -1.6657, -0.8474, -0.5832, -0.6986,  0.3099,  0.1076,  0.6572,\n",
      "          0.4881,  0.6995],\n",
      "        [-1.8457, -1.4499,  2.4474, -1.3025,  1.4204,  0.0837, -0.6199, -0.6909,\n",
      "          0.1792,  0.6203]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2589,  0.0630,  1.3930,  0.9507,  1.3603, -0.0740,  1.7963, -2.7218,\n",
      "          0.4960, -0.8357],\n",
      "        [ 0.2905,  0.8422, -0.6682, -0.6088,  1.1049,  0.0441,  0.7497, -0.7880,\n",
      "         -0.4563, -1.2971],\n",
      "        [-0.3737, -1.6654, -0.8474, -0.5834, -0.6986,  0.3104,  0.1076,  0.6572,\n",
      "          0.4880,  0.6994],\n",
      "        [-1.8460, -1.4498,  2.4474, -1.3026,  1.4204,  0.0839, -0.6199, -0.6909,\n",
      "          0.1792,  0.6203]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2591,  0.0642,  1.3929,  0.9505,  1.3603, -0.0739,  1.7963, -2.7218,\n",
      "          0.4957, -0.8357],\n",
      "        [ 0.2909,  0.8431, -0.6683, -0.6089,  1.1049,  0.0439,  0.7497, -0.7880,\n",
      "         -0.4565, -1.2971],\n",
      "        [-0.3743, -1.6650, -0.8475, -0.5837, -0.6986,  0.3109,  0.1076,  0.6572,\n",
      "          0.4880,  0.6994],\n",
      "        [-1.8462, -1.4498,  2.4474, -1.3027,  1.4204,  0.0841, -0.6199, -0.6909,\n",
      "          0.1792,  0.6203]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2592,  0.0654,  1.3928,  0.9503,  1.3603, -0.0738,  1.7963, -2.7218,\n",
      "          0.4955, -0.8358],\n",
      "        [ 0.2914,  0.8439, -0.6684, -0.6089,  1.1049,  0.0438,  0.7497, -0.7880,\n",
      "         -0.4566, -1.2971],\n",
      "        [-0.3748, -1.6647, -0.8475, -0.5839, -0.6986,  0.3113,  0.1076,  0.6572,\n",
      "          0.4879,  0.6994],\n",
      "        [-1.8465, -1.4497,  2.4474, -1.3027,  1.4204,  0.0843, -0.6199, -0.6909,\n",
      "          0.1792,  0.6203]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2594,  0.0666,  1.3927,  0.9501,  1.3603, -0.0738,  1.7963, -2.7218,\n",
      "          0.4952, -0.8358],\n",
      "        [ 0.2918,  0.8447, -0.6685, -0.6090,  1.1049,  0.0437,  0.7497, -0.7880,\n",
      "         -0.4568, -1.2971],\n",
      "        [-0.3754, -1.6643, -0.8475, -0.5842, -0.6986,  0.3118,  0.1076,  0.6572,\n",
      "          0.4879,  0.6993],\n",
      "        [-1.8467, -1.4497,  2.4474, -1.3028,  1.4204,  0.0845, -0.6199, -0.6909,\n",
      "          0.1792,  0.6203]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2596,  0.0678,  1.3925,  0.9499,  1.3603, -0.0737,  1.7963, -2.7218,\n",
      "          0.4950, -0.8358],\n",
      "        [ 0.2923,  0.8455, -0.6685, -0.6090,  1.1049,  0.0435,  0.7497, -0.7880,\n",
      "         -0.4570, -1.2972],\n",
      "        [-0.3760, -1.6639, -0.8475, -0.5844, -0.6986,  0.3122,  0.1076,  0.6572,\n",
      "          0.4878,  0.6993],\n",
      "        [-1.8470, -1.4496,  2.4474, -1.3029,  1.4204,  0.0847, -0.6199, -0.6909,\n",
      "          0.1792,  0.6203]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2598,  0.0690,  1.3924,  0.9496,  1.3603, -0.0736,  1.7963, -2.7218,\n",
      "          0.4947, -0.8359],\n",
      "        [ 0.2927,  0.8463, -0.6686, -0.6091,  1.1049,  0.0434,  0.7497, -0.7880,\n",
      "         -0.4572, -1.2972],\n",
      "        [-0.3765, -1.6636, -0.8476, -0.5847, -0.6986,  0.3127,  0.1076,  0.6572,\n",
      "          0.4878,  0.6993],\n",
      "        [-1.8472, -1.4495,  2.4474, -1.3030,  1.4204,  0.0849, -0.6199, -0.6909,\n",
      "          0.1792,  0.6203]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2600,  0.0702,  1.3923,  0.9494,  1.3603, -0.0735,  1.7963, -2.7218,\n",
      "          0.4945, -0.8359],\n",
      "        [ 0.2932,  0.8472, -0.6687, -0.6091,  1.1049,  0.0433,  0.7497, -0.7880,\n",
      "         -0.4574, -1.2972],\n",
      "        [-0.3771, -1.6632, -0.8476, -0.5849, -0.6986,  0.3131,  0.1076,  0.6572,\n",
      "          0.4877,  0.6992],\n",
      "        [-1.8475, -1.4495,  2.4474, -1.3031,  1.4204,  0.0851, -0.6199, -0.6909,\n",
      "          0.1792,  0.6203]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2602,  0.0714,  1.3922,  0.9492,  1.3603, -0.0734,  1.7963, -2.7218,\n",
      "          0.4942, -0.8360],\n",
      "        [ 0.2936,  0.8480, -0.6688, -0.6092,  1.1049,  0.0431,  0.7497, -0.7880,\n",
      "         -0.4575, -1.2972],\n",
      "        [-0.3777, -1.6629, -0.8476, -0.5852, -0.6986,  0.3136,  0.1076,  0.6572,\n",
      "          0.4877,  0.6992],\n",
      "        [-1.8477, -1.4494,  2.4474, -1.3032,  1.4204,  0.0853, -0.6199, -0.6909,\n",
      "          0.1792,  0.6202]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2604,  0.0726,  1.3921,  0.9490,  1.3603, -0.0733,  1.7963, -2.7218,\n",
      "          0.4940, -0.8360],\n",
      "        [ 0.2940,  0.8488, -0.6689, -0.6093,  1.1049,  0.0430,  0.7497, -0.7880,\n",
      "         -0.4577, -1.2972],\n",
      "        [-0.3782, -1.6625, -0.8476, -0.5854, -0.6986,  0.3140,  0.1076,  0.6572,\n",
      "          0.4876,  0.6992],\n",
      "        [-1.8480, -1.4494,  2.4474, -1.3033,  1.4204,  0.0855, -0.6199, -0.6909,\n",
      "          0.1792,  0.6202]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2605,  0.0737,  1.3919,  0.9488,  1.3603, -0.0732,  1.7963, -2.7218,\n",
      "          0.4938, -0.8361],\n",
      "        [ 0.2945,  0.8496, -0.6690, -0.6093,  1.1049,  0.0429,  0.7497, -0.7880,\n",
      "         -0.4579, -1.2973],\n",
      "        [-0.3788, -1.6622, -0.8477, -0.5857, -0.6986,  0.3144,  0.1076,  0.6572,\n",
      "          0.4876,  0.6991],\n",
      "        [-1.8482, -1.4493,  2.4474, -1.3034,  1.4204,  0.0856, -0.6199, -0.6909,\n",
      "          0.1792,  0.6202]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2607,  0.0749,  1.3918,  0.9486,  1.3603, -0.0731,  1.7963, -2.7218,\n",
      "          0.4935, -0.8361],\n",
      "        [ 0.2949,  0.8504, -0.6691, -0.6094,  1.1049,  0.0427,  0.7497, -0.7880,\n",
      "         -0.4581, -1.2973],\n",
      "        [-0.3794, -1.6618, -0.8477, -0.5859, -0.6986,  0.3149,  0.1076,  0.6572,\n",
      "          0.4875,  0.6991],\n",
      "        [-1.8484, -1.4492,  2.4474, -1.3035,  1.4204,  0.0858, -0.6199, -0.6909,\n",
      "          0.1792,  0.6202]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2609,  0.0761,  1.3917,  0.9483,  1.3603, -0.0730,  1.7963, -2.7218,\n",
      "          0.4933, -0.8361],\n",
      "        [ 0.2953,  0.8512, -0.6691, -0.6094,  1.1049,  0.0426,  0.7497, -0.7880,\n",
      "         -0.4582, -1.2973],\n",
      "        [-0.3799, -1.6615, -0.8477, -0.5861, -0.6986,  0.3153,  0.1076,  0.6572,\n",
      "          0.4875,  0.6991],\n",
      "        [-1.8487, -1.4492,  2.4474, -1.3035,  1.4204,  0.0860, -0.6199, -0.6909,\n",
      "          0.1792,  0.6202]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2611,  0.0773,  1.3916,  0.9481,  1.3603, -0.0729,  1.7963, -2.7218,\n",
      "          0.4930, -0.8362],\n",
      "        [ 0.2958,  0.8520, -0.6692, -0.6095,  1.1049,  0.0424,  0.7497, -0.7880,\n",
      "         -0.4584, -1.2973],\n",
      "        [-0.3805, -1.6612, -0.8477, -0.5864, -0.6986,  0.3158,  0.1076,  0.6572,\n",
      "          0.4874,  0.6990],\n",
      "        [-1.8489, -1.4491,  2.4474, -1.3036,  1.4204,  0.0862, -0.6199, -0.6909,\n",
      "          0.1792,  0.6202]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2612,  0.0784,  1.3915,  0.9479,  1.3603, -0.0729,  1.7963, -2.7218,\n",
      "          0.4928, -0.8362],\n",
      "        [ 0.2962,  0.8528, -0.6693, -0.6095,  1.1049,  0.0423,  0.7497, -0.7880,\n",
      "         -0.4586, -1.2973],\n",
      "        [-0.3811, -1.6608, -0.8478, -0.5866, -0.6986,  0.3162,  0.1076,  0.6572,\n",
      "          0.4874,  0.6990],\n",
      "        [-1.8492, -1.4491,  2.4474, -1.3037,  1.4204,  0.0864, -0.6199, -0.6909,\n",
      "          0.1792,  0.6202]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2614,  0.0796,  1.3914,  0.9477,  1.3603, -0.0728,  1.7963, -2.7218,\n",
      "          0.4925, -0.8363],\n",
      "        [ 0.2966,  0.8536, -0.6694, -0.6096,  1.1049,  0.0422,  0.7497, -0.7880,\n",
      "         -0.4588, -1.2973],\n",
      "        [-0.3816, -1.6605, -0.8478, -0.5869, -0.6986,  0.3166,  0.1076,  0.6572,\n",
      "          0.4873,  0.6990],\n",
      "        [-1.8494, -1.4490,  2.4474, -1.3038,  1.4204,  0.0866, -0.6199, -0.6909,\n",
      "          0.1792,  0.6202]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2616,  0.0808,  1.3912,  0.9475,  1.3603, -0.0727,  1.7963, -2.7218,\n",
      "          0.4923, -0.8363],\n",
      "        [ 0.2970,  0.8544, -0.6695, -0.6096,  1.1049,  0.0420,  0.7497, -0.7880,\n",
      "         -0.4590, -1.2974],\n",
      "        [-0.3822, -1.6601, -0.8478, -0.5871, -0.6986,  0.3171,  0.1076,  0.6572,\n",
      "          0.4873,  0.6989],\n",
      "        [-1.8497, -1.4490,  2.4474, -1.3039,  1.4204,  0.0867, -0.6199, -0.6909,\n",
      "          0.1792,  0.6202]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2618,  0.0819,  1.3911,  0.9473,  1.3603, -0.0726,  1.7963, -2.7218,\n",
      "          0.4920, -0.8364],\n",
      "        [ 0.2975,  0.8551, -0.6696, -0.6097,  1.1049,  0.0419,  0.7497, -0.7880,\n",
      "         -0.4591, -1.2974],\n",
      "        [-0.3827, -1.6598, -0.8478, -0.5874, -0.6986,  0.3175,  0.1076,  0.6572,\n",
      "          0.4872,  0.6989],\n",
      "        [-1.8499, -1.4489,  2.4474, -1.3040,  1.4204,  0.0869, -0.6199, -0.6909,\n",
      "          0.1792,  0.6201]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2619,  0.0831,  1.3910,  0.9471,  1.3603, -0.0725,  1.7963, -2.7218,\n",
      "          0.4918, -0.8364],\n",
      "        [ 0.2979,  0.8559, -0.6697, -0.6097,  1.1049,  0.0417,  0.7497, -0.7880,\n",
      "         -0.4593, -1.2974],\n",
      "        [-0.3833, -1.6594, -0.8479, -0.5876, -0.6986,  0.3180,  0.1076,  0.6572,\n",
      "          0.4872,  0.6988],\n",
      "        [-1.8501, -1.4488,  2.4474, -1.3041,  1.4204,  0.0871, -0.6199, -0.6909,\n",
      "          0.1792,  0.6201]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2621,  0.0842,  1.3909,  0.9469,  1.3603, -0.0725,  1.7963, -2.7218,\n",
      "          0.4915, -0.8364],\n",
      "        [ 0.2983,  0.8567, -0.6698, -0.6098,  1.1049,  0.0416,  0.7497, -0.7880,\n",
      "         -0.4595, -1.2974],\n",
      "        [-0.3839, -1.6591, -0.8479, -0.5878, -0.6986,  0.3184,  0.1076,  0.6572,\n",
      "          0.4871,  0.6988],\n",
      "        [-1.8504, -1.4488,  2.4474, -1.3041,  1.4204,  0.0873, -0.6199, -0.6909,\n",
      "          0.1792,  0.6201]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2623,  0.0854,  1.3908,  0.9467,  1.3603, -0.0724,  1.7963, -2.7218,\n",
      "          0.4913, -0.8365],\n",
      "        [ 0.2987,  0.8575, -0.6698, -0.6099,  1.1049,  0.0415,  0.7497, -0.7880,\n",
      "         -0.4597, -1.2974],\n",
      "        [-0.3844, -1.6588, -0.8479, -0.5881, -0.6986,  0.3188,  0.1076,  0.6572,\n",
      "          0.4871,  0.6988],\n",
      "        [-1.8506, -1.4487,  2.4474, -1.3042,  1.4204,  0.0875, -0.6199, -0.6909,\n",
      "          0.1792,  0.6201]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2624,  0.0865,  1.3906,  0.9465,  1.3603, -0.0723,  1.7963, -2.7218,\n",
      "          0.4911, -0.8365],\n",
      "        [ 0.2992,  0.8583, -0.6699, -0.6099,  1.1049,  0.0413,  0.7497, -0.7880,\n",
      "         -0.4599, -1.2975],\n",
      "        [-0.3850, -1.6584, -0.8479, -0.5883, -0.6986,  0.3192,  0.1076,  0.6572,\n",
      "          0.4870,  0.6987],\n",
      "        [-1.8509, -1.4487,  2.4474, -1.3043,  1.4204,  0.0877, -0.6199, -0.6909,\n",
      "          0.1792,  0.6201]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2626,  0.0877,  1.3905,  0.9462,  1.3603, -0.0722,  1.7963, -2.7218,\n",
      "          0.4908, -0.8366],\n",
      "        [ 0.2996,  0.8590, -0.6700, -0.6100,  1.1049,  0.0412,  0.7497, -0.7880,\n",
      "         -0.4600, -1.2975],\n",
      "        [-0.3855, -1.6581, -0.8480, -0.5886, -0.6986,  0.3197,  0.1076,  0.6572,\n",
      "          0.4870,  0.6987],\n",
      "        [-1.8511, -1.4486,  2.4474, -1.3044,  1.4204,  0.0878, -0.6199, -0.6909,\n",
      "          0.1792,  0.6201]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2628,  0.0888,  1.3904,  0.9460,  1.3603, -0.0722,  1.7963, -2.7218,\n",
      "          0.4906, -0.8366],\n",
      "        [ 0.3000,  0.8598, -0.6701, -0.6100,  1.1049,  0.0410,  0.7497, -0.7880,\n",
      "         -0.4602, -1.2975],\n",
      "        [-0.3861, -1.6578, -0.8480, -0.5888, -0.6986,  0.3201,  0.1076,  0.6572,\n",
      "          0.4869,  0.6987],\n",
      "        [-1.8513, -1.4486,  2.4474, -1.3045,  1.4204,  0.0880, -0.6199, -0.6909,\n",
      "          0.1792,  0.6201]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2629,  0.0899,  1.3903,  0.9458,  1.3603, -0.0721,  1.7963, -2.7218,\n",
      "          0.4903, -0.8366],\n",
      "        [ 0.3004,  0.8606, -0.6702, -0.6101,  1.1049,  0.0409,  0.7497, -0.7880,\n",
      "         -0.4604, -1.2975],\n",
      "        [-0.3866, -1.6574, -0.8480, -0.5890, -0.6986,  0.3205,  0.1076,  0.6572,\n",
      "          0.4869,  0.6986],\n",
      "        [-1.8516, -1.4485,  2.4474, -1.3046,  1.4204,  0.0882, -0.6199, -0.6909,\n",
      "          0.1792,  0.6201]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2631,  0.0911,  1.3902,  0.9456,  1.3603, -0.0720,  1.7963, -2.7218,\n",
      "          0.4901, -0.8367],\n",
      "        [ 0.3008,  0.8613, -0.6703, -0.6101,  1.1049,  0.0408,  0.7497, -0.7880,\n",
      "         -0.4606, -1.2975],\n",
      "        [-0.3872, -1.6571, -0.8480, -0.5893, -0.6986,  0.3209,  0.1076,  0.6572,\n",
      "          0.4868,  0.6986],\n",
      "        [-1.8518, -1.4485,  2.4474, -1.3047,  1.4204,  0.0884, -0.6199, -0.6909,\n",
      "          0.1792,  0.6200]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2633,  0.0922,  1.3901,  0.9454,  1.3603, -0.0719,  1.7963, -2.7218,\n",
      "          0.4898, -0.8367],\n",
      "        [ 0.3012,  0.8621, -0.6704, -0.6102,  1.1049,  0.0406,  0.7497, -0.7880,\n",
      "         -0.4608, -1.2976],\n",
      "        [-0.3877, -1.6568, -0.8481, -0.5895, -0.6986,  0.3214,  0.1076,  0.6572,\n",
      "          0.4868,  0.6986],\n",
      "        [-1.8520, -1.4484,  2.4474, -1.3047,  1.4204,  0.0886, -0.6199, -0.6909,\n",
      "          0.1792,  0.6200]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2634,  0.0933,  1.3899,  0.9452,  1.3603, -0.0719,  1.7963, -2.7218,\n",
      "          0.4896, -0.8368],\n",
      "        [ 0.3017,  0.8629, -0.6704, -0.6102,  1.1049,  0.0405,  0.7497, -0.7880,\n",
      "         -0.4609, -1.2976],\n",
      "        [-0.3883, -1.6564, -0.8481, -0.5898, -0.6986,  0.3218,  0.1076,  0.6572,\n",
      "          0.4867,  0.6985],\n",
      "        [-1.8523, -1.4483,  2.4474, -1.3048,  1.4204,  0.0887, -0.6199, -0.6909,\n",
      "          0.1792,  0.6200]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2636,  0.0944,  1.3898,  0.9450,  1.3603, -0.0718,  1.7963, -2.7218,\n",
      "          0.4893, -0.8368],\n",
      "        [ 0.3021,  0.8636, -0.6705, -0.6103,  1.1049,  0.0403,  0.7497, -0.7880,\n",
      "         -0.4611, -1.2976],\n",
      "        [-0.3889, -1.6561, -0.8481, -0.5900, -0.6986,  0.3222,  0.1076,  0.6572,\n",
      "          0.4867,  0.6985],\n",
      "        [-1.8525, -1.4483,  2.4474, -1.3049,  1.4204,  0.0889, -0.6199, -0.6909,\n",
      "          0.1792,  0.6200]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2637,  0.0955,  1.3897,  0.9448,  1.3603, -0.0717,  1.7963, -2.7218,\n",
      "          0.4891, -0.8369],\n",
      "        [ 0.3025,  0.8644, -0.6706, -0.6103,  1.1049,  0.0402,  0.7497, -0.7880,\n",
      "         -0.4613, -1.2976],\n",
      "        [-0.3894, -1.6558, -0.8481, -0.5902, -0.6986,  0.3226,  0.1076,  0.6572,\n",
      "          0.4866,  0.6985],\n",
      "        [-1.8528, -1.4482,  2.4474, -1.3050,  1.4204,  0.0891, -0.6199, -0.6909,\n",
      "          0.1792,  0.6200]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2639,  0.0966,  1.3896,  0.9446,  1.3603, -0.0717,  1.7963, -2.7218,\n",
      "          0.4888, -0.8369],\n",
      "        [ 0.3029,  0.8651, -0.6707, -0.6104,  1.1049,  0.0400,  0.7497, -0.7880,\n",
      "         -0.4615, -1.2976],\n",
      "        [-0.3900, -1.6555, -0.8482, -0.5905, -0.6986,  0.3230,  0.1076,  0.6572,\n",
      "          0.4866,  0.6984],\n",
      "        [-1.8530, -1.4482,  2.4474, -1.3051,  1.4204,  0.0893, -0.6199, -0.6909,\n",
      "          0.1792,  0.6200]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2641,  0.0977,  1.3895,  0.9444,  1.3603, -0.0716,  1.7963, -2.7218,\n",
      "          0.4886, -0.8369],\n",
      "        [ 0.3033,  0.8659, -0.6708, -0.6104,  1.1049,  0.0399,  0.7497, -0.7880,\n",
      "         -0.4616, -1.2976],\n",
      "        [-0.3905, -1.6551, -0.8482, -0.5907, -0.6986,  0.3235,  0.1076,  0.6572,\n",
      "          0.4865,  0.6984],\n",
      "        [-1.8532, -1.4481,  2.4474, -1.3052,  1.4204,  0.0894, -0.6199, -0.6909,\n",
      "          0.1792,  0.6200]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2642,  0.0988,  1.3893,  0.9442,  1.3603, -0.0715,  1.7963, -2.7218,\n",
      "          0.4884, -0.8370],\n",
      "        [ 0.3037,  0.8666, -0.6709, -0.6105,  1.1049,  0.0397,  0.7497, -0.7880,\n",
      "         -0.4618, -1.2977],\n",
      "        [-0.3910, -1.6548, -0.8482, -0.5909, -0.6986,  0.3239,  0.1076,  0.6572,\n",
      "          0.4865,  0.6984],\n",
      "        [-1.8535, -1.4481,  2.4474, -1.3053,  1.4204,  0.0896, -0.6199, -0.6909,\n",
      "          0.1792,  0.6200]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2644,  0.0999,  1.3892,  0.9440,  1.3603, -0.0715,  1.7963, -2.7218,\n",
      "          0.4881, -0.8370],\n",
      "        [ 0.3041,  0.8674, -0.6710, -0.6105,  1.1049,  0.0396,  0.7497, -0.7880,\n",
      "         -0.4620, -1.2977],\n",
      "        [-0.3916, -1.6545, -0.8482, -0.5912, -0.6986,  0.3243,  0.1076,  0.6572,\n",
      "          0.4864,  0.6983],\n",
      "        [-1.8537, -1.4480,  2.4474, -1.3053,  1.4204,  0.0898, -0.6199, -0.6909,\n",
      "          0.1792,  0.6200]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2645,  0.1010,  1.3891,  0.9438,  1.3603, -0.0714,  1.7963, -2.7218,\n",
      "          0.4879, -0.8371],\n",
      "        [ 0.3045,  0.8681, -0.6710, -0.6106,  1.1049,  0.0395,  0.7497, -0.7880,\n",
      "         -0.4622, -1.2977],\n",
      "        [-0.3921, -1.6542, -0.8483, -0.5914, -0.6986,  0.3247,  0.1076,  0.6572,\n",
      "          0.4864,  0.6983],\n",
      "        [-1.8539, -1.4480,  2.4474, -1.3054,  1.4204,  0.0900, -0.6199, -0.6909,\n",
      "          0.1792,  0.6199]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2647,  0.1021,  1.3890,  0.9436,  1.3603, -0.0714,  1.7963, -2.7218,\n",
      "          0.4876, -0.8371],\n",
      "        [ 0.3049,  0.8689, -0.6711, -0.6106,  1.1049,  0.0393,  0.7497, -0.7880,\n",
      "         -0.4624, -1.2977],\n",
      "        [-0.3927, -1.6539, -0.8483, -0.5916, -0.6986,  0.3251,  0.1076,  0.6572,\n",
      "          0.4863,  0.6983],\n",
      "        [-1.8542, -1.4479,  2.4474, -1.3055,  1.4204,  0.0901, -0.6199, -0.6909,\n",
      "          0.1792,  0.6199]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2648,  0.1032,  1.3889,  0.9434,  1.3603, -0.0713,  1.7963, -2.7218,\n",
      "          0.4874, -0.8371],\n",
      "        [ 0.3053,  0.8696, -0.6712, -0.6107,  1.1049,  0.0392,  0.7497, -0.7880,\n",
      "         -0.4625, -1.2977],\n",
      "        [-0.3932, -1.6535, -0.8483, -0.5919, -0.6986,  0.3255,  0.1076,  0.6572,\n",
      "          0.4863,  0.6982],\n",
      "        [-1.8544, -1.4479,  2.4474, -1.3056,  1.4204,  0.0903, -0.6199, -0.6909,\n",
      "          0.1792,  0.6199]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2650,  0.1043,  1.3888,  0.9432,  1.3603, -0.0712,  1.7963, -2.7218,\n",
      "          0.4871, -0.8372],\n",
      "        [ 0.3057,  0.8703, -0.6713, -0.6107,  1.1049,  0.0390,  0.7497, -0.7880,\n",
      "         -0.4627, -1.2977],\n",
      "        [-0.3938, -1.6532, -0.8483, -0.5921, -0.6986,  0.3259,  0.1076,  0.6572,\n",
      "          0.4862,  0.6982],\n",
      "        [-1.8546, -1.4478,  2.4474, -1.3057,  1.4204,  0.0905, -0.6199, -0.6909,\n",
      "          0.1792,  0.6199]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2651,  0.1053,  1.3886,  0.9430,  1.3603, -0.0712,  1.7963, -2.7218,\n",
      "          0.4869, -0.8372],\n",
      "        [ 0.3061,  0.8711, -0.6714, -0.6108,  1.1049,  0.0389,  0.7497, -0.7880,\n",
      "         -0.4629, -1.2978],\n",
      "        [-0.3943, -1.6529, -0.8484, -0.5923, -0.6986,  0.3263,  0.1076,  0.6572,\n",
      "          0.4862,  0.6982],\n",
      "        [-1.8549, -1.4478,  2.4474, -1.3058,  1.4204,  0.0907, -0.6199, -0.6909,\n",
      "          0.1792,  0.6199]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2653,  0.1064,  1.3885,  0.9428,  1.3603, -0.0711,  1.7963, -2.7218,\n",
      "          0.4866, -0.8373],\n",
      "        [ 0.3065,  0.8718, -0.6715, -0.6108,  1.1049,  0.0387,  0.7497, -0.7880,\n",
      "         -0.4631, -1.2978],\n",
      "        [-0.3949, -1.6526, -0.8484, -0.5926, -0.6986,  0.3267,  0.1076,  0.6572,\n",
      "          0.4861,  0.6981],\n",
      "        [-1.8551, -1.4477,  2.4474, -1.3058,  1.4204,  0.0908, -0.6199, -0.6909,\n",
      "          0.1792,  0.6199]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2654,  0.1075,  1.3884,  0.9426,  1.3603, -0.0711,  1.7963, -2.7218,\n",
      "          0.4864, -0.8373],\n",
      "        [ 0.3069,  0.8725, -0.6716, -0.6109,  1.1049,  0.0386,  0.7497, -0.7880,\n",
      "         -0.4633, -1.2978],\n",
      "        [-0.3954, -1.6523, -0.8484, -0.5928, -0.6986,  0.3271,  0.1076,  0.6572,\n",
      "          0.4861,  0.6981],\n",
      "        [-1.8553, -1.4476,  2.4474, -1.3059,  1.4204,  0.0910, -0.6199, -0.6909,\n",
      "          0.1792,  0.6199]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2656,  0.1085,  1.3883,  0.9424,  1.3603, -0.0710,  1.7963, -2.7218,\n",
      "          0.4861, -0.8373],\n",
      "        [ 0.3073,  0.8732, -0.6716, -0.6109,  1.1049,  0.0384,  0.7497, -0.7880,\n",
      "         -0.4634, -1.2978],\n",
      "        [-0.3959, -1.6520, -0.8484, -0.5930, -0.6986,  0.3275,  0.1076,  0.6572,\n",
      "          0.4860,  0.6981],\n",
      "        [-1.8556, -1.4476,  2.4474, -1.3060,  1.4204,  0.0912, -0.6199, -0.6909,\n",
      "          0.1791,  0.6199]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2657,  0.1096,  1.3882,  0.9422,  1.3603, -0.0710,  1.7963, -2.7218,\n",
      "          0.4859, -0.8374],\n",
      "        [ 0.3077,  0.8739, -0.6717, -0.6110,  1.1049,  0.0383,  0.7497, -0.7880,\n",
      "         -0.4636, -1.2978],\n",
      "        [-0.3965, -1.6517, -0.8485, -0.5933, -0.6986,  0.3280,  0.1076,  0.6572,\n",
      "          0.4860,  0.6980],\n",
      "        [-1.8558, -1.4475,  2.4474, -1.3061,  1.4204,  0.0913, -0.6199, -0.6909,\n",
      "          0.1791,  0.6199]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2659,  0.1106,  1.3881,  0.9420,  1.3603, -0.0709,  1.7963, -2.7218,\n",
      "          0.4856, -0.8374],\n",
      "        [ 0.3081,  0.8747, -0.6718, -0.6110,  1.1049,  0.0381,  0.7497, -0.7880,\n",
      "         -0.4638, -1.2979],\n",
      "        [-0.3970, -1.6514, -0.8485, -0.5935, -0.6986,  0.3284,  0.1076,  0.6572,\n",
      "          0.4859,  0.6980],\n",
      "        [-1.8560, -1.4475,  2.4474, -1.3062,  1.4204,  0.0915, -0.6199, -0.6909,\n",
      "          0.1791,  0.6198]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2660,  0.1117,  1.3879,  0.9418,  1.3603, -0.0709,  1.7963, -2.7218,\n",
      "          0.4854, -0.8375],\n",
      "        [ 0.3085,  0.8754, -0.6719, -0.6111,  1.1049,  0.0380,  0.7497, -0.7880,\n",
      "         -0.4640, -1.2979],\n",
      "        [-0.3976, -1.6510, -0.8485, -0.5937, -0.6986,  0.3288,  0.1076,  0.6572,\n",
      "          0.4859,  0.6980],\n",
      "        [-1.8563, -1.4474,  2.4474, -1.3063,  1.4204,  0.0917, -0.6199, -0.6909,\n",
      "          0.1791,  0.6198]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2662,  0.1127,  1.3878,  0.9416,  1.3603, -0.0708,  1.7963, -2.7218,\n",
      "          0.4851, -0.8375],\n",
      "        [ 0.3089,  0.8761, -0.6720, -0.6111,  1.1049,  0.0378,  0.7497, -0.7880,\n",
      "         -0.4642, -1.2979],\n",
      "        [-0.3981, -1.6507, -0.8485, -0.5940, -0.6986,  0.3291,  0.1076,  0.6572,\n",
      "          0.4858,  0.6979],\n",
      "        [-1.8565, -1.4474,  2.4474, -1.3063,  1.4204,  0.0918, -0.6199, -0.6909,\n",
      "          0.1791,  0.6198]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2663,  0.1138,  1.3877,  0.9414,  1.3603, -0.0708,  1.7963, -2.7218,\n",
      "          0.4849, -0.8375],\n",
      "        [ 0.3093,  0.8768, -0.6721, -0.6111,  1.1049,  0.0377,  0.7497, -0.7880,\n",
      "         -0.4644, -1.2979],\n",
      "        [-0.3986, -1.6504, -0.8486, -0.5942, -0.6986,  0.3295,  0.1076,  0.6572,\n",
      "          0.4858,  0.6979],\n",
      "        [-1.8567, -1.4473,  2.4474, -1.3064,  1.4204,  0.0920, -0.6199, -0.6909,\n",
      "          0.1791,  0.6198]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2665,  0.1148,  1.3876,  0.9412,  1.3603, -0.0707,  1.7963, -2.7218,\n",
      "          0.4846, -0.8376],\n",
      "        [ 0.3097,  0.8775, -0.6721, -0.6112,  1.1049,  0.0375,  0.7497, -0.7880,\n",
      "         -0.4645, -1.2979],\n",
      "        [-0.3992, -1.6501, -0.8486, -0.5944, -0.6986,  0.3299,  0.1076,  0.6572,\n",
      "          0.4857,  0.6979],\n",
      "        [-1.8569, -1.4473,  2.4474, -1.3065,  1.4204,  0.0922, -0.6199, -0.6909,\n",
      "          0.1791,  0.6198]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2666,  0.1159,  1.3875,  0.9410,  1.3603, -0.0707,  1.7963, -2.7218,\n",
      "          0.4844, -0.8376],\n",
      "        [ 0.3101,  0.8782, -0.6722, -0.6112,  1.1049,  0.0374,  0.7497, -0.7880,\n",
      "         -0.4647, -1.2979],\n",
      "        [-0.3997, -1.6498, -0.8486, -0.5947, -0.6986,  0.3303,  0.1076,  0.6572,\n",
      "          0.4857,  0.6979],\n",
      "        [-1.8572, -1.4472,  2.4474, -1.3066,  1.4204,  0.0924, -0.6199, -0.6909,\n",
      "          0.1791,  0.6198]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2668,  0.1169,  1.3874,  0.9408,  1.3603, -0.0706,  1.7963, -2.7218,\n",
      "          0.4842, -0.8377],\n",
      "        [ 0.3105,  0.8789, -0.6723, -0.6113,  1.1049,  0.0373,  0.7497, -0.7880,\n",
      "         -0.4649, -1.2980],\n",
      "        [-0.4002, -1.6495, -0.8486, -0.5949, -0.6986,  0.3307,  0.1076,  0.6572,\n",
      "          0.4856,  0.6978],\n",
      "        [-1.8574, -1.4472,  2.4474, -1.3067,  1.4204,  0.0925, -0.6199, -0.6909,\n",
      "          0.1791,  0.6198]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2669,  0.1179,  1.3872,  0.9407,  1.3603, -0.0706,  1.7963, -2.7218,\n",
      "          0.4839, -0.8377],\n",
      "        [ 0.3109,  0.8796, -0.6724, -0.6113,  1.1049,  0.0371,  0.7497, -0.7880,\n",
      "         -0.4651, -1.2980],\n",
      "        [-0.4008, -1.6492, -0.8487, -0.5951, -0.6986,  0.3311,  0.1076,  0.6572,\n",
      "          0.4856,  0.6978],\n",
      "        [-1.8576, -1.4471,  2.4474, -1.3068,  1.4204,  0.0927, -0.6199, -0.6909,\n",
      "          0.1791,  0.6198]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2671,  0.1189,  1.3871,  0.9405,  1.3603, -0.0705,  1.7963, -2.7218,\n",
      "          0.4837, -0.8377],\n",
      "        [ 0.3113,  0.8803, -0.6725, -0.6114,  1.1049,  0.0370,  0.7497, -0.7880,\n",
      "         -0.4653, -1.2980],\n",
      "        [-0.4013, -1.6489, -0.8487, -0.5953, -0.6986,  0.3315,  0.1076,  0.6572,\n",
      "          0.4855,  0.6978],\n",
      "        [-1.8579, -1.4471,  2.4474, -1.3068,  1.4204,  0.0929, -0.6199, -0.6909,\n",
      "          0.1791,  0.6198]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2672,  0.1200,  1.3870,  0.9403,  1.3603, -0.0705,  1.7963, -2.7218,\n",
      "          0.4834, -0.8378],\n",
      "        [ 0.3116,  0.8810, -0.6726, -0.6114,  1.1049,  0.0368,  0.7497, -0.7880,\n",
      "         -0.4654, -1.2980],\n",
      "        [-0.4018, -1.6486, -0.8487, -0.5956, -0.6986,  0.3319,  0.1076,  0.6572,\n",
      "          0.4855,  0.6977],\n",
      "        [-1.8581, -1.4470,  2.4474, -1.3069,  1.4204,  0.0930, -0.6199, -0.6909,\n",
      "          0.1791,  0.6197]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2673,  0.1210,  1.3869,  0.9401,  1.3603, -0.0704,  1.7963, -2.7218,\n",
      "          0.4832, -0.8378],\n",
      "        [ 0.3120,  0.8817, -0.6727, -0.6115,  1.1049,  0.0367,  0.7497, -0.7880,\n",
      "         -0.4656, -1.2980],\n",
      "        [-0.4023, -1.6483, -0.8487, -0.5958, -0.6986,  0.3323,  0.1076,  0.6572,\n",
      "          0.4854,  0.6977],\n",
      "        [-1.8583, -1.4470,  2.4474, -1.3070,  1.4204,  0.0932, -0.6199, -0.6909,\n",
      "          0.1791,  0.6197]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2675,  0.1220,  1.3868,  0.9399,  1.3603, -0.0704,  1.7963, -2.7218,\n",
      "          0.4829, -0.8378],\n",
      "        [ 0.3124,  0.8824, -0.6727, -0.6115,  1.1049,  0.0365,  0.7497, -0.7880,\n",
      "         -0.4658, -1.2980],\n",
      "        [-0.4029, -1.6480, -0.8487, -0.5960, -0.6986,  0.3327,  0.1076,  0.6572,\n",
      "          0.4854,  0.6977],\n",
      "        [-1.8585, -1.4469,  2.4474, -1.3071,  1.4204,  0.0934, -0.6199, -0.6909,\n",
      "          0.1791,  0.6197]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2676,  0.1230,  1.3867,  0.9397,  1.3603, -0.0704,  1.7963, -2.7218,\n",
      "          0.4827, -0.8379],\n",
      "        [ 0.3128,  0.8830, -0.6728, -0.6116,  1.1049,  0.0364,  0.7497, -0.7880,\n",
      "         -0.4660, -1.2981],\n",
      "        [-0.4034, -1.6477, -0.8488, -0.5962, -0.6986,  0.3331,  0.1076,  0.6572,\n",
      "          0.4854,  0.6976],\n",
      "        [-1.8588, -1.4469,  2.4474, -1.3072,  1.4204,  0.0935, -0.6199, -0.6909,\n",
      "          0.1791,  0.6197]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2678,  0.1240,  1.3866,  0.9395,  1.3603, -0.0703,  1.7963, -2.7218,\n",
      "          0.4824, -0.8379],\n",
      "        [ 0.3132,  0.8837, -0.6729, -0.6116,  1.1049,  0.0362,  0.7497, -0.7880,\n",
      "         -0.4662, -1.2981],\n",
      "        [-0.4039, -1.6474, -0.8488, -0.5965, -0.6986,  0.3335,  0.1076,  0.6572,\n",
      "          0.4853,  0.6976],\n",
      "        [-1.8590, -1.4468,  2.4474, -1.3073,  1.4204,  0.0937, -0.6199, -0.6909,\n",
      "          0.1791,  0.6197]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2679,  0.1250,  1.3864,  0.9393,  1.3603, -0.0703,  1.7963, -2.7218,\n",
      "          0.4822, -0.8380],\n",
      "        [ 0.3136,  0.8844, -0.6730, -0.6116,  1.1049,  0.0360,  0.7497, -0.7880,\n",
      "         -0.4663, -1.2981],\n",
      "        [-0.4045, -1.6472, -0.8488, -0.5967, -0.6986,  0.3338,  0.1076,  0.6572,\n",
      "          0.4853,  0.6976],\n",
      "        [-1.8592, -1.4468,  2.4474, -1.3073,  1.4204,  0.0939, -0.6199, -0.6909,\n",
      "          0.1791,  0.6197]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2680,  0.1260,  1.3863,  0.9391,  1.3603, -0.0702,  1.7963, -2.7218,\n",
      "          0.4819, -0.8380],\n",
      "        [ 0.3139,  0.8851, -0.6731, -0.6117,  1.1049,  0.0359,  0.7497, -0.7880,\n",
      "         -0.4665, -1.2981],\n",
      "        [-0.4050, -1.6469, -0.8488, -0.5969, -0.6986,  0.3342,  0.1076,  0.6572,\n",
      "          0.4852,  0.6975],\n",
      "        [-1.8594, -1.4467,  2.4474, -1.3074,  1.4204,  0.0940, -0.6199, -0.6909,\n",
      "          0.1791,  0.6197]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2682,  0.1270,  1.3862,  0.9389,  1.3603, -0.0702,  1.7963, -2.7218,\n",
      "          0.4817, -0.8380],\n",
      "        [ 0.3143,  0.8858, -0.6732, -0.6117,  1.1049,  0.0357,  0.7497, -0.7880,\n",
      "         -0.4667, -1.2981],\n",
      "        [-0.4055, -1.6466, -0.8489, -0.5971, -0.6986,  0.3346,  0.1076,  0.6572,\n",
      "          0.4852,  0.6975],\n",
      "        [-1.8597, -1.4467,  2.4474, -1.3075,  1.4204,  0.0942, -0.6199, -0.6909,\n",
      "          0.1791,  0.6197]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2683,  0.1280,  1.3861,  0.9388,  1.3603, -0.0702,  1.7963, -2.7218,\n",
      "          0.4814, -0.8381],\n",
      "        [ 0.3147,  0.8864, -0.6732, -0.6118,  1.1049,  0.0356,  0.7497, -0.7880,\n",
      "         -0.4669, -1.2981],\n",
      "        [-0.4060, -1.6463, -0.8489, -0.5974, -0.6986,  0.3350,  0.1076,  0.6572,\n",
      "          0.4851,  0.6975],\n",
      "        [-1.8599, -1.4466,  2.4474, -1.3076,  1.4204,  0.0943, -0.6199, -0.6909,\n",
      "          0.1791,  0.6197]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2685,  0.1289,  1.3860,  0.9386,  1.3603, -0.0701,  1.7963, -2.7218,\n",
      "          0.4812, -0.8381],\n",
      "        [ 0.3151,  0.8871, -0.6733, -0.6118,  1.1049,  0.0354,  0.7497, -0.7880,\n",
      "         -0.4671, -1.2982],\n",
      "        [-0.4065, -1.6460, -0.8489, -0.5976, -0.6986,  0.3354,  0.1076,  0.6572,\n",
      "          0.4851,  0.6974],\n",
      "        [-1.8601, -1.4466,  2.4474, -1.3077,  1.4204,  0.0945, -0.6199, -0.6909,\n",
      "          0.1791,  0.6196]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2686,  0.1299,  1.3859,  0.9384,  1.3603, -0.0701,  1.7963, -2.7218,\n",
      "          0.4809, -0.8382],\n",
      "        [ 0.3155,  0.8878, -0.6734, -0.6119,  1.1049,  0.0353,  0.7497, -0.7880,\n",
      "         -0.4673, -1.2982],\n",
      "        [-0.4071, -1.6457, -0.8489, -0.5978, -0.6986,  0.3358,  0.1076,  0.6572,\n",
      "          0.4850,  0.6974],\n",
      "        [-1.8603, -1.4466,  2.4474, -1.3077,  1.4204,  0.0947, -0.6199, -0.6909,\n",
      "          0.1791,  0.6196]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2687,  0.1309,  1.3857,  0.9382,  1.3603, -0.0701,  1.7963, -2.7218,\n",
      "          0.4807, -0.8382],\n",
      "        [ 0.3158,  0.8884, -0.6735, -0.6119,  1.1049,  0.0351,  0.7497, -0.7880,\n",
      "         -0.4674, -1.2982],\n",
      "        [-0.4076, -1.6454, -0.8490, -0.5980, -0.6986,  0.3361,  0.1076,  0.6572,\n",
      "          0.4850,  0.6974],\n",
      "        [-1.8606, -1.4465,  2.4474, -1.3078,  1.4204,  0.0948, -0.6199, -0.6909,\n",
      "          0.1791,  0.6196]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2689,  0.1319,  1.3856,  0.9380,  1.3603, -0.0700,  1.7963, -2.7218,\n",
      "          0.4804, -0.8382],\n",
      "        [ 0.3162,  0.8891, -0.6736, -0.6119,  1.1049,  0.0350,  0.7497, -0.7880,\n",
      "         -0.4676, -1.2982],\n",
      "        [-0.4081, -1.6451, -0.8490, -0.5983, -0.6986,  0.3365,  0.1076,  0.6572,\n",
      "          0.4849,  0.6973],\n",
      "        [-1.8608, -1.4465,  2.4474, -1.3079,  1.4204,  0.0950, -0.6199, -0.6909,\n",
      "          0.1791,  0.6196]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2690,  0.1328,  1.3855,  0.9378,  1.3603, -0.0700,  1.7963, -2.7218,\n",
      "          0.4802, -0.8383],\n",
      "        [ 0.3166,  0.8897, -0.6737, -0.6120,  1.1049,  0.0348,  0.7497, -0.7880,\n",
      "         -0.4678, -1.2982],\n",
      "        [-0.4086, -1.6449, -0.8490, -0.5985, -0.6986,  0.3369,  0.1076,  0.6572,\n",
      "          0.4849,  0.6973],\n",
      "        [-1.8610, -1.4464,  2.4474, -1.3080,  1.4204,  0.0952, -0.6199, -0.6909,\n",
      "          0.1791,  0.6196]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2692,  0.1338,  1.3854,  0.9376,  1.3603, -0.0700,  1.7963, -2.7218,\n",
      "          0.4799, -0.8383],\n",
      "        [ 0.3170,  0.8904, -0.6738, -0.6120,  1.1049,  0.0347,  0.7497, -0.7880,\n",
      "         -0.4680, -1.2983],\n",
      "        [-0.4091, -1.6446, -0.8490, -0.5987, -0.6986,  0.3373,  0.1076,  0.6572,\n",
      "          0.4848,  0.6973],\n",
      "        [-1.8612, -1.4464,  2.4474, -1.3081,  1.4204,  0.0953, -0.6199, -0.6909,\n",
      "          0.1791,  0.6196]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2693,  0.1347,  1.3853,  0.9375,  1.3603, -0.0700,  1.7963, -2.7218,\n",
      "          0.4797, -0.8383],\n",
      "        [ 0.3174,  0.8910, -0.6738, -0.6121,  1.1049,  0.0345,  0.7497, -0.7880,\n",
      "         -0.4682, -1.2983],\n",
      "        [-0.4097, -1.6443, -0.8491, -0.5989, -0.6986,  0.3376,  0.1076,  0.6572,\n",
      "          0.4848,  0.6973],\n",
      "        [-1.8614, -1.4463,  2.4474, -1.3081,  1.4204,  0.0955, -0.6199, -0.6909,\n",
      "          0.1791,  0.6196]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2694,  0.1357,  1.3852,  0.9373,  1.3603, -0.0699,  1.7963, -2.7218,\n",
      "          0.4794, -0.8384],\n",
      "        [ 0.3177,  0.8917, -0.6739, -0.6121,  1.1049,  0.0344,  0.7497, -0.7880,\n",
      "         -0.4683, -1.2983],\n",
      "        [-0.4102, -1.6440, -0.8491, -0.5992, -0.6986,  0.3380,  0.1076,  0.6572,\n",
      "          0.4847,  0.6972],\n",
      "        [-1.8617, -1.4463,  2.4474, -1.3082,  1.4204,  0.0956, -0.6199, -0.6909,\n",
      "          0.1791,  0.6196]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2696,  0.1367,  1.3851,  0.9371,  1.3603, -0.0699,  1.7963, -2.7218,\n",
      "          0.4792, -0.8384],\n",
      "        [ 0.3181,  0.8923, -0.6740, -0.6121,  1.1049,  0.0342,  0.7497, -0.7880,\n",
      "         -0.4685, -1.2983],\n",
      "        [-0.4107, -1.6437, -0.8491, -0.5994, -0.6986,  0.3384,  0.1076,  0.6572,\n",
      "          0.4847,  0.6972],\n",
      "        [-1.8619, -1.4462,  2.4474, -1.3083,  1.4204,  0.0958, -0.6199, -0.6909,\n",
      "          0.1791,  0.6196]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2697,  0.1376,  1.3849,  0.9369,  1.3603, -0.0699,  1.7963, -2.7218,\n",
      "          0.4789, -0.8385],\n",
      "        [ 0.3185,  0.8930, -0.6741, -0.6122,  1.1049,  0.0341,  0.7497, -0.7880,\n",
      "         -0.4687, -1.2983],\n",
      "        [-0.4112, -1.6435, -0.8491, -0.5996, -0.6986,  0.3388,  0.1076,  0.6572,\n",
      "          0.4846,  0.6972],\n",
      "        [-1.8621, -1.4462,  2.4474, -1.3084,  1.4204,  0.0960, -0.6199, -0.6909,\n",
      "          0.1791,  0.6195]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2698,  0.1385,  1.3848,  0.9367,  1.3603, -0.0698,  1.7963, -2.7218,\n",
      "          0.4787, -0.8385],\n",
      "        [ 0.3188,  0.8936, -0.6742, -0.6122,  1.1049,  0.0339,  0.7497, -0.7880,\n",
      "         -0.4689, -1.2983],\n",
      "        [-0.4117, -1.6432, -0.8492, -0.5998, -0.6986,  0.3391,  0.1076,  0.6572,\n",
      "          0.4846,  0.6971],\n",
      "        [-1.8623, -1.4461,  2.4474, -1.3085,  1.4204,  0.0961, -0.6199, -0.6909,\n",
      "          0.1791,  0.6195]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2700,  0.1395,  1.3847,  0.9365,  1.3603, -0.0698,  1.7963, -2.7218,\n",
      "          0.4784, -0.8385],\n",
      "        [ 0.3192,  0.8943, -0.6743, -0.6123,  1.1049,  0.0337,  0.7497, -0.7880,\n",
      "         -0.4691, -1.2984],\n",
      "        [-0.4122, -1.6429, -0.8492, -0.6000, -0.6986,  0.3395,  0.1076,  0.6572,\n",
      "          0.4845,  0.6971],\n",
      "        [-1.8626, -1.4461,  2.4474, -1.3085,  1.4204,  0.0963, -0.6199, -0.6909,\n",
      "          0.1791,  0.6195]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2701,  0.1404,  1.3846,  0.9364,  1.3603, -0.0698,  1.7963, -2.7218,\n",
      "          0.4782, -0.8386],\n",
      "        [ 0.3196,  0.8949, -0.6743, -0.6123,  1.1049,  0.0336,  0.7497, -0.7880,\n",
      "         -0.4693, -1.2984],\n",
      "        [-0.4127, -1.6426, -0.8492, -0.6003, -0.6986,  0.3399,  0.1076,  0.6572,\n",
      "          0.4845,  0.6971],\n",
      "        [-1.8628, -1.4460,  2.4474, -1.3086,  1.4204,  0.0964, -0.6199, -0.6909,\n",
      "          0.1791,  0.6195]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2702,  0.1414,  1.3845,  0.9362,  1.3603, -0.0698,  1.7963, -2.7218,\n",
      "          0.4779, -0.8386],\n",
      "        [ 0.3200,  0.8955, -0.6744, -0.6123,  1.1049,  0.0334,  0.7497, -0.7880,\n",
      "         -0.4694, -1.2984],\n",
      "        [-0.4133, -1.6424, -0.8492, -0.6005, -0.6986,  0.3402,  0.1076,  0.6572,\n",
      "          0.4844,  0.6970],\n",
      "        [-1.8630, -1.4460,  2.4474, -1.3087,  1.4204,  0.0966, -0.6199, -0.6909,\n",
      "          0.1791,  0.6195]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2704,  0.1423,  1.3844,  0.9360,  1.3603, -0.0698,  1.7963, -2.7218,\n",
      "          0.4777, -0.8386],\n",
      "        [ 0.3203,  0.8962, -0.6745, -0.6124,  1.1049,  0.0333,  0.7497, -0.7880,\n",
      "         -0.4696, -1.2984],\n",
      "        [-0.4138, -1.6421, -0.8492, -0.6007, -0.6986,  0.3406,  0.1076,  0.6572,\n",
      "          0.4844,  0.6970],\n",
      "        [-1.8632, -1.4460,  2.4474, -1.3088,  1.4204,  0.0967, -0.6199, -0.6909,\n",
      "          0.1791,  0.6195]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2705,  0.1432,  1.3843,  0.9358,  1.3603, -0.0697,  1.7963, -2.7218,\n",
      "          0.4774, -0.8387],\n",
      "        [ 0.3207,  0.8968, -0.6746, -0.6124,  1.1049,  0.0331,  0.7497, -0.7880,\n",
      "         -0.4698, -1.2984],\n",
      "        [-0.4143, -1.6418, -0.8493, -0.6009, -0.6986,  0.3410,  0.1076,  0.6572,\n",
      "          0.4843,  0.6970],\n",
      "        [-1.8634, -1.4459,  2.4474, -1.3089,  1.4204,  0.0969, -0.6199, -0.6909,\n",
      "          0.1791,  0.6195]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2706,  0.1441,  1.3841,  0.9356,  1.3603, -0.0697,  1.7963, -2.7218,\n",
      "          0.4772, -0.8387],\n",
      "        [ 0.3211,  0.8974, -0.6747, -0.6125,  1.1049,  0.0330,  0.7497, -0.7880,\n",
      "         -0.4700, -1.2984],\n",
      "        [-0.4148, -1.6416, -0.8493, -0.6011, -0.6986,  0.3413,  0.1076,  0.6572,\n",
      "          0.4843,  0.6969],\n",
      "        [-1.8636, -1.4459,  2.4474, -1.3089,  1.4204,  0.0971, -0.6199, -0.6909,\n",
      "          0.1791,  0.6195]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2708,  0.1450,  1.3840,  0.9355,  1.3603, -0.0697,  1.7963, -2.7218,\n",
      "          0.4769, -0.8388],\n",
      "        [ 0.3214,  0.8981, -0.6748, -0.6125,  1.1049,  0.0328,  0.7497, -0.7880,\n",
      "         -0.4702, -1.2985],\n",
      "        [-0.4153, -1.6413, -0.8493, -0.6014, -0.6986,  0.3417,  0.1076,  0.6572,\n",
      "          0.4842,  0.6969],\n",
      "        [-1.8639, -1.4458,  2.4474, -1.3090,  1.4204,  0.0972, -0.6199, -0.6909,\n",
      "          0.1791,  0.6195]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2709,  0.1460,  1.3839,  0.9353,  1.3603, -0.0697,  1.7963, -2.7218,\n",
      "          0.4767, -0.8388],\n",
      "        [ 0.3218,  0.8987, -0.6748, -0.6125,  1.1049,  0.0327,  0.7497, -0.7880,\n",
      "         -0.4704, -1.2985],\n",
      "        [-0.4158, -1.6410, -0.8493, -0.6016, -0.6986,  0.3420,  0.1076,  0.6572,\n",
      "          0.4842,  0.6969],\n",
      "        [-1.8641, -1.4458,  2.4474, -1.3091,  1.4204,  0.0974, -0.6199, -0.6909,\n",
      "          0.1791,  0.6195]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2710,  0.1469,  1.3838,  0.9351,  1.3603, -0.0697,  1.7963, -2.7218,\n",
      "          0.4764, -0.8388],\n",
      "        [ 0.3222,  0.8993, -0.6749, -0.6126,  1.1049,  0.0325,  0.7497, -0.7880,\n",
      "         -0.4705, -1.2985],\n",
      "        [-0.4163, -1.6408, -0.8494, -0.6018, -0.6986,  0.3424,  0.1076,  0.6572,\n",
      "          0.4841,  0.6969],\n",
      "        [-1.8643, -1.4457,  2.4474, -1.3092,  1.4204,  0.0975, -0.6199, -0.6909,\n",
      "          0.1791,  0.6194]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2712,  0.1478,  1.3837,  0.9349,  1.3603, -0.0696,  1.7963, -2.7218,\n",
      "          0.4762, -0.8389],\n",
      "        [ 0.3225,  0.8999, -0.6750, -0.6126,  1.1049,  0.0323,  0.7497, -0.7880,\n",
      "         -0.4707, -1.2985],\n",
      "        [-0.4168, -1.6405, -0.8494, -0.6020, -0.6986,  0.3428,  0.1076,  0.6572,\n",
      "          0.4841,  0.6968],\n",
      "        [-1.8645, -1.4457,  2.4474, -1.3093,  1.4204,  0.0977, -0.6199, -0.6909,\n",
      "          0.1791,  0.6194]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2713,  0.1487,  1.3836,  0.9348,  1.3603, -0.0696,  1.7963, -2.7218,\n",
      "          0.4759, -0.8389],\n",
      "        [ 0.3229,  0.9005, -0.6751, -0.6126,  1.1049,  0.0322,  0.7497, -0.7880,\n",
      "         -0.4709, -1.2985],\n",
      "        [-0.4173, -1.6402, -0.8494, -0.6022, -0.6986,  0.3431,  0.1076,  0.6572,\n",
      "          0.4840,  0.6968],\n",
      "        [-1.8647, -1.4457,  2.4474, -1.3093,  1.4204,  0.0978, -0.6199, -0.6909,\n",
      "          0.1791,  0.6194]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2714,  0.1496,  1.3835,  0.9346,  1.3603, -0.0696,  1.7963, -2.7218,\n",
      "          0.4757, -0.8389],\n",
      "        [ 0.3233,  0.9011, -0.6752, -0.6127,  1.1049,  0.0320,  0.7497, -0.7880,\n",
      "         -0.4711, -1.2985],\n",
      "        [-0.4178, -1.6400, -0.8494, -0.6024, -0.6986,  0.3435,  0.1076,  0.6572,\n",
      "          0.4840,  0.6968],\n",
      "        [-1.8649, -1.4456,  2.4474, -1.3094,  1.4204,  0.0980, -0.6199, -0.6909,\n",
      "          0.1791,  0.6194]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2716,  0.1505,  1.3833,  0.9344,  1.3603, -0.0696,  1.7963, -2.7218,\n",
      "          0.4754, -0.8390],\n",
      "        [ 0.3236,  0.9017, -0.6753, -0.6127,  1.1049,  0.0319,  0.7497, -0.7880,\n",
      "         -0.4713, -1.2985],\n",
      "        [-0.4183, -1.6397, -0.8495, -0.6027, -0.6986,  0.3438,  0.1076,  0.6572,\n",
      "          0.4839,  0.6967],\n",
      "        [-1.8652, -1.4456,  2.4474, -1.3095,  1.4204,  0.0981, -0.6199, -0.6909,\n",
      "          0.1791,  0.6194]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2717,  0.1514,  1.3832,  0.9342,  1.3603, -0.0696,  1.7963, -2.7218,\n",
      "          0.4752, -0.8390],\n",
      "        [ 0.3240,  0.9023, -0.6753, -0.6128,  1.1049,  0.0317,  0.7497, -0.7880,\n",
      "         -0.4715, -1.2986],\n",
      "        [-0.4188, -1.6395, -0.8495, -0.6029, -0.6986,  0.3442,  0.1076,  0.6572,\n",
      "          0.4839,  0.6967],\n",
      "        [-1.8654, -1.4455,  2.4474, -1.3096,  1.4204,  0.0983, -0.6199, -0.6909,\n",
      "          0.1791,  0.6194]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2718,  0.1522,  1.3831,  0.9341,  1.3603, -0.0696,  1.7963, -2.7218,\n",
      "          0.4749, -0.8391],\n",
      "        [ 0.3243,  0.9029, -0.6754, -0.6128,  1.1049,  0.0315,  0.7497, -0.7880,\n",
      "         -0.4716, -1.2986],\n",
      "        [-0.4193, -1.6392, -0.8495, -0.6031, -0.6986,  0.3446,  0.1076,  0.6572,\n",
      "          0.4838,  0.6967],\n",
      "        [-1.8656, -1.4455,  2.4474, -1.3096,  1.4204,  0.0985, -0.6199, -0.6909,\n",
      "          0.1791,  0.6194]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2719,  0.1531,  1.3830,  0.9339,  1.3603, -0.0696,  1.7963, -2.7218,\n",
      "          0.4747, -0.8391],\n",
      "        [ 0.3247,  0.9036, -0.6755, -0.6128,  1.1049,  0.0314,  0.7497, -0.7880,\n",
      "         -0.4718, -1.2986],\n",
      "        [-0.4198, -1.6390, -0.8495, -0.6033, -0.6986,  0.3449,  0.1076,  0.6572,\n",
      "          0.4838,  0.6966],\n",
      "        [-1.8658, -1.4454,  2.4474, -1.3097,  1.4204,  0.0986, -0.6199, -0.6909,\n",
      "          0.1791,  0.6194]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2721,  0.1540,  1.3829,  0.9337,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4744, -0.8391],\n",
      "        [ 0.3251,  0.9041, -0.6756, -0.6129,  1.1049,  0.0312,  0.7497, -0.7880,\n",
      "         -0.4720, -1.2986],\n",
      "        [-0.4203, -1.6387, -0.8496, -0.6035, -0.6986,  0.3453,  0.1076,  0.6572,\n",
      "          0.4837,  0.6966],\n",
      "        [-1.8660, -1.4454,  2.4474, -1.3098,  1.4204,  0.0988, -0.6199, -0.6909,\n",
      "          0.1791,  0.6194]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2722,  0.1549,  1.3828,  0.9335,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4742, -0.8392],\n",
      "        [ 0.3254,  0.9047, -0.6757, -0.6129,  1.1049,  0.0311,  0.7497, -0.7880,\n",
      "         -0.4722, -1.2986],\n",
      "        [-0.4208, -1.6384, -0.8496, -0.6037, -0.6986,  0.3456,  0.1076,  0.6572,\n",
      "          0.4837,  0.6966],\n",
      "        [-1.8662, -1.4454,  2.4474, -1.3099,  1.4204,  0.0989, -0.6199, -0.6909,\n",
      "          0.1791,  0.6193]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2723,  0.1558,  1.3827,  0.9334,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4739, -0.8392],\n",
      "        [ 0.3258,  0.9053, -0.6758, -0.6129,  1.1049,  0.0309,  0.7497, -0.7880,\n",
      "         -0.4724, -1.2986],\n",
      "        [-0.4213, -1.6382, -0.8496, -0.6039, -0.6986,  0.3460,  0.1076,  0.6572,\n",
      "          0.4836,  0.6966],\n",
      "        [-1.8664, -1.4453,  2.4474, -1.3100,  1.4204,  0.0991, -0.6199, -0.6909,\n",
      "          0.1791,  0.6193]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2725,  0.1566,  1.3825,  0.9332,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4737, -0.8392],\n",
      "        [ 0.3261,  0.9059, -0.6758, -0.6130,  1.1049,  0.0307,  0.7497, -0.7880,\n",
      "         -0.4726, -1.2987],\n",
      "        [-0.4218, -1.6379, -0.8496, -0.6042, -0.6986,  0.3463,  0.1076,  0.6572,\n",
      "          0.4836,  0.6965],\n",
      "        [-1.8666, -1.4453,  2.4474, -1.3100,  1.4204,  0.0992, -0.6199, -0.6909,\n",
      "          0.1791,  0.6193]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2726,  0.1575,  1.3824,  0.9330,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4734, -0.8393],\n",
      "        [ 0.3265,  0.9065, -0.6759, -0.6130,  1.1049,  0.0306,  0.7497, -0.7880,\n",
      "         -0.4728, -1.2987],\n",
      "        [-0.4223, -1.6377, -0.8497, -0.6044, -0.6986,  0.3467,  0.1076,  0.6572,\n",
      "          0.4836,  0.6965],\n",
      "        [-1.8669, -1.4452,  2.4474, -1.3101,  1.4204,  0.0994, -0.6199, -0.6909,\n",
      "          0.1791,  0.6193]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2727,  0.1584,  1.3823,  0.9329,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4732, -0.8393],\n",
      "        [ 0.3269,  0.9071, -0.6760, -0.6130,  1.1049,  0.0304,  0.7497, -0.7880,\n",
      "         -0.4729, -1.2987],\n",
      "        [-0.4228, -1.6374, -0.8497, -0.6046, -0.6986,  0.3470,  0.1076,  0.6572,\n",
      "          0.4835,  0.6965],\n",
      "        [-1.8671, -1.4452,  2.4474, -1.3102,  1.4204,  0.0995, -0.6199, -0.6909,\n",
      "          0.1791,  0.6193]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2729,  0.1592,  1.3822,  0.9327,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4729, -0.8393],\n",
      "        [ 0.3272,  0.9077, -0.6761, -0.6131,  1.1049,  0.0303,  0.7497, -0.7880,\n",
      "         -0.4731, -1.2987],\n",
      "        [-0.4233, -1.6372, -0.8497, -0.6048, -0.6986,  0.3474,  0.1076,  0.6572,\n",
      "          0.4835,  0.6964],\n",
      "        [-1.8673, -1.4452,  2.4474, -1.3103,  1.4204,  0.0997, -0.6199, -0.6909,\n",
      "          0.1791,  0.6193]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2730,  0.1601,  1.3821,  0.9325,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4727, -0.8394],\n",
      "        [ 0.3276,  0.9083, -0.6762, -0.6131,  1.1049,  0.0301,  0.7497, -0.7880,\n",
      "         -0.4733, -1.2987],\n",
      "        [-0.4238, -1.6369, -0.8497, -0.6050, -0.6986,  0.3477,  0.1076,  0.6572,\n",
      "          0.4834,  0.6964],\n",
      "        [-1.8675, -1.4451,  2.4474, -1.3103,  1.4204,  0.0998, -0.6199, -0.6909,\n",
      "          0.1791,  0.6193]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2731,  0.1609,  1.3820,  0.9324,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4724, -0.8394],\n",
      "        [ 0.3279,  0.9089, -0.6763, -0.6131,  1.1049,  0.0299,  0.7497, -0.7880,\n",
      "         -0.4735, -1.2987],\n",
      "        [-0.4243, -1.6367, -0.8497, -0.6052, -0.6986,  0.3481,  0.1076,  0.6572,\n",
      "          0.4834,  0.6964],\n",
      "        [-1.8677, -1.4451,  2.4474, -1.3104,  1.4204,  0.1000, -0.6199, -0.6909,\n",
      "          0.1790,  0.6193]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2732,  0.1618,  1.3819,  0.9322,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4721, -0.8394],\n",
      "        [ 0.3283,  0.9094, -0.6763, -0.6132,  1.1049,  0.0298,  0.7497, -0.7880,\n",
      "         -0.4737, -1.2988],\n",
      "        [-0.4248, -1.6365, -0.8498, -0.6054, -0.6986,  0.3484,  0.1076,  0.6572,\n",
      "          0.4833,  0.6964],\n",
      "        [-1.8679, -1.4450,  2.4474, -1.3105,  1.4204,  0.1001, -0.6199, -0.6909,\n",
      "          0.1790,  0.6193]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2734,  0.1626,  1.3817,  0.9320,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4719, -0.8395],\n",
      "        [ 0.3286,  0.9100, -0.6764, -0.6132,  1.1049,  0.0296,  0.7497, -0.7880,\n",
      "         -0.4739, -1.2988],\n",
      "        [-0.4253, -1.6362, -0.8498, -0.6056, -0.6986,  0.3488,  0.1076,  0.6572,\n",
      "          0.4833,  0.6963],\n",
      "        [-1.8681, -1.4450,  2.4474, -1.3106,  1.4204,  0.1003, -0.6199, -0.6909,\n",
      "          0.1790,  0.6193]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2735,  0.1634,  1.3816,  0.9318,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4716, -0.8395],\n",
      "        [ 0.3290,  0.9106, -0.6765, -0.6132,  1.1049,  0.0295,  0.7497, -0.7880,\n",
      "         -0.4740, -1.2988],\n",
      "        [-0.4257, -1.6360, -0.8498, -0.6059, -0.6986,  0.3491,  0.1076,  0.6572,\n",
      "          0.4832,  0.6963],\n",
      "        [-1.8683, -1.4450,  2.4474, -1.3106,  1.4204,  0.1004, -0.6199, -0.6909,\n",
      "          0.1790,  0.6192]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2736,  0.1643,  1.3815,  0.9317,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4714, -0.8396],\n",
      "        [ 0.3293,  0.9111, -0.6766, -0.6133,  1.1049,  0.0293,  0.7497, -0.7880,\n",
      "         -0.4742, -1.2988],\n",
      "        [-0.4262, -1.6357, -0.8498, -0.6061, -0.6986,  0.3494,  0.1076,  0.6572,\n",
      "          0.4832,  0.6963],\n",
      "        [-1.8685, -1.4449,  2.4474, -1.3107,  1.4204,  0.1006, -0.6199, -0.6909,\n",
      "          0.1790,  0.6192]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2737,  0.1651,  1.3814,  0.9315,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4711, -0.8396],\n",
      "        [ 0.3297,  0.9117, -0.6767, -0.6133,  1.1049,  0.0291,  0.7497, -0.7880,\n",
      "         -0.4744, -1.2988],\n",
      "        [-0.4267, -1.6355, -0.8499, -0.6063, -0.6986,  0.3498,  0.1076,  0.6572,\n",
      "          0.4831,  0.6962],\n",
      "        [-1.8687, -1.4449,  2.4474, -1.3108,  1.4204,  0.1007, -0.6199, -0.6909,\n",
      "          0.1790,  0.6192]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2739,  0.1659,  1.3813,  0.9313,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4709, -0.8396],\n",
      "        [ 0.3301,  0.9123, -0.6768, -0.6133,  1.1049,  0.0290,  0.7497, -0.7880,\n",
      "         -0.4746, -1.2988],\n",
      "        [-0.4272, -1.6353, -0.8499, -0.6065, -0.6986,  0.3501,  0.1076,  0.6572,\n",
      "          0.4831,  0.6962],\n",
      "        [-1.8690, -1.4448,  2.4474, -1.3109,  1.4204,  0.1009, -0.6199, -0.6909,\n",
      "          0.1790,  0.6192]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2740,  0.1668,  1.3812,  0.9312,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4706, -0.8397],\n",
      "        [ 0.3304,  0.9128, -0.6768, -0.6134,  1.1049,  0.0288,  0.7497, -0.7880,\n",
      "         -0.4748, -1.2989],\n",
      "        [-0.4277, -1.6350, -0.8499, -0.6067, -0.6986,  0.3505,  0.1076,  0.6572,\n",
      "          0.4830,  0.6962],\n",
      "        [-1.8692, -1.4448,  2.4474, -1.3110,  1.4204,  0.1010, -0.6199, -0.6909,\n",
      "          0.1790,  0.6192]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2741,  0.1676,  1.3811,  0.9310,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4704, -0.8397],\n",
      "        [ 0.3308,  0.9134, -0.6769, -0.6134,  1.1049,  0.0287,  0.7497, -0.7880,\n",
      "         -0.4750, -1.2989],\n",
      "        [-0.4282, -1.6348, -0.8499, -0.6069, -0.6986,  0.3508,  0.1076,  0.6572,\n",
      "          0.4830,  0.6961],\n",
      "        [-1.8694, -1.4448,  2.4474, -1.3110,  1.4204,  0.1012, -0.6199, -0.6909,\n",
      "          0.1790,  0.6192]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2742,  0.1684,  1.3809,  0.9309,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4701, -0.8397],\n",
      "        [ 0.3311,  0.9140, -0.6770, -0.6134,  1.1049,  0.0285,  0.7497, -0.7880,\n",
      "         -0.4752, -1.2989],\n",
      "        [-0.4287, -1.6345, -0.8500, -0.6071, -0.6986,  0.3511,  0.1076,  0.6572,\n",
      "          0.4829,  0.6961],\n",
      "        [-1.8696, -1.4447,  2.4474, -1.3111,  1.4204,  0.1013, -0.6199, -0.6909,\n",
      "          0.1790,  0.6192]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2744,  0.1692,  1.3808,  0.9307,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4699, -0.8398],\n",
      "        [ 0.3315,  0.9145, -0.6771, -0.6135,  1.1049,  0.0283,  0.7497, -0.7880,\n",
      "         -0.4753, -1.2989],\n",
      "        [-0.4292, -1.6343, -0.8500, -0.6073, -0.6986,  0.3515,  0.1076,  0.6572,\n",
      "          0.4829,  0.6961],\n",
      "        [-1.8698, -1.4447,  2.4474, -1.3112,  1.4204,  0.1015, -0.6199, -0.6909,\n",
      "          0.1790,  0.6192]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2745,  0.1700,  1.3807,  0.9305,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4696, -0.8398],\n",
      "        [ 0.3318,  0.9151, -0.6772, -0.6135,  1.1049,  0.0282,  0.7497, -0.7880,\n",
      "         -0.4755, -1.2989],\n",
      "        [-0.4296, -1.6341, -0.8500, -0.6075, -0.6986,  0.3518,  0.1076,  0.6572,\n",
      "          0.4828,  0.6961],\n",
      "        [-1.8700, -1.4446,  2.4474, -1.3113,  1.4204,  0.1016, -0.6199, -0.6909,\n",
      "          0.1790,  0.6192]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2746,  0.1709,  1.3806,  0.9304,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4694, -0.8398],\n",
      "        [ 0.3321,  0.9156, -0.6773, -0.6135,  1.1049,  0.0280,  0.7497, -0.7880,\n",
      "         -0.4757, -1.2989],\n",
      "        [-0.4301, -1.6338, -0.8500, -0.6077, -0.6986,  0.3522,  0.1076,  0.6572,\n",
      "          0.4828,  0.6960],\n",
      "        [-1.8702, -1.4446,  2.4474, -1.3113,  1.4204,  0.1018, -0.6199, -0.6909,\n",
      "          0.1790,  0.6192]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2747,  0.1717,  1.3805,  0.9302,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4691, -0.8399],\n",
      "        [ 0.3325,  0.9162, -0.6773, -0.6135,  1.1049,  0.0278,  0.7497, -0.7880,\n",
      "         -0.4759, -1.2989],\n",
      "        [-0.4306, -1.6336, -0.8501, -0.6079, -0.6986,  0.3525,  0.1076,  0.6572,\n",
      "          0.4827,  0.6960],\n",
      "        [-1.8704, -1.4446,  2.4474, -1.3114,  1.4204,  0.1019, -0.6199, -0.6909,\n",
      "          0.1790,  0.6191]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2749,  0.1725,  1.3804,  0.9300,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4688, -0.8399],\n",
      "        [ 0.3328,  0.9167, -0.6774, -0.6136,  1.1049,  0.0277,  0.7497, -0.7880,\n",
      "         -0.4761, -1.2990],\n",
      "        [-0.4311, -1.6334, -0.8501, -0.6082, -0.6986,  0.3528,  0.1076,  0.6572,\n",
      "          0.4827,  0.6960],\n",
      "        [-1.8706, -1.4445,  2.4474, -1.3115,  1.4204,  0.1020, -0.6199, -0.6909,\n",
      "          0.1790,  0.6191]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2750,  0.1733,  1.3803,  0.9299,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4686, -0.8399],\n",
      "        [ 0.3332,  0.9173, -0.6775, -0.6136,  1.1049,  0.0275,  0.7497, -0.7880,\n",
      "         -0.4763, -1.2990],\n",
      "        [-0.4316, -1.6331, -0.8501, -0.6084, -0.6986,  0.3532,  0.1076,  0.6572,\n",
      "          0.4826,  0.6959],\n",
      "        [-1.8708, -1.4445,  2.4474, -1.3116,  1.4204,  0.1022, -0.6199, -0.6909,\n",
      "          0.1790,  0.6191]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2751,  0.1741,  1.3802,  0.9297,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4683, -0.8400],\n",
      "        [ 0.3335,  0.9178, -0.6776, -0.6136,  1.1049,  0.0273,  0.7497, -0.7880,\n",
      "         -0.4765, -1.2990],\n",
      "        [-0.4320, -1.6329, -0.8501, -0.6086, -0.6986,  0.3535,  0.1076,  0.6572,\n",
      "          0.4826,  0.6959],\n",
      "        [-1.8710, -1.4445,  2.4474, -1.3116,  1.4204,  0.1023, -0.6199, -0.6909,\n",
      "          0.1790,  0.6191]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2752,  0.1749,  1.3800,  0.9296,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4681, -0.8400],\n",
      "        [ 0.3339,  0.9184, -0.6777, -0.6137,  1.1049,  0.0272,  0.7497, -0.7880,\n",
      "         -0.4767, -1.2990],\n",
      "        [-0.4325, -1.6327, -0.8501, -0.6088, -0.6986,  0.3538,  0.1076,  0.6572,\n",
      "          0.4825,  0.6959],\n",
      "        [-1.8712, -1.4444,  2.4474, -1.3117,  1.4204,  0.1025, -0.6199, -0.6909,\n",
      "          0.1790,  0.6191]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2754,  0.1756,  1.3799,  0.9294,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4678, -0.8400],\n",
      "        [ 0.3342,  0.9189, -0.6778, -0.6137,  1.1049,  0.0270,  0.7497, -0.7880,\n",
      "         -0.4768, -1.2990],\n",
      "        [-0.4330, -1.6325, -0.8502, -0.6090, -0.6986,  0.3542,  0.1076,  0.6572,\n",
      "          0.4825,  0.6959],\n",
      "        [-1.8714, -1.4444,  2.4474, -1.3118,  1.4204,  0.1026, -0.6199, -0.6909,\n",
      "          0.1790,  0.6191]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2755,  0.1764,  1.3798,  0.9292,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4676, -0.8401],\n",
      "        [ 0.3346,  0.9194, -0.6778, -0.6137,  1.1049,  0.0268,  0.7497, -0.7880,\n",
      "         -0.4770, -1.2990],\n",
      "        [-0.4335, -1.6322, -0.8502, -0.6092, -0.6986,  0.3545,  0.1076,  0.6572,\n",
      "          0.4824,  0.6958],\n",
      "        [-1.8716, -1.4443,  2.4474, -1.3119,  1.4204,  0.1028, -0.6199, -0.6909,\n",
      "          0.1790,  0.6191]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2756,  0.1772,  1.3797,  0.9291,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4673, -0.8401],\n",
      "        [ 0.3349,  0.9200, -0.6779, -0.6138,  1.1049,  0.0267,  0.7497, -0.7880,\n",
      "         -0.4772, -1.2991],\n",
      "        [-0.4339, -1.6320, -0.8502, -0.6094, -0.6986,  0.3548,  0.1076,  0.6572,\n",
      "          0.4824,  0.6958],\n",
      "        [-1.8718, -1.4443,  2.4474, -1.3119,  1.4204,  0.1029, -0.6199, -0.6909,\n",
      "          0.1790,  0.6191]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2757,  0.1780,  1.3796,  0.9289,  1.3603, -0.0695,  1.7963, -2.7218,\n",
      "          0.4671, -0.8401],\n",
      "        [ 0.3353,  0.9205, -0.6780, -0.6138,  1.1049,  0.0265,  0.7497, -0.7880,\n",
      "         -0.4774, -1.2991],\n",
      "        [-0.4344, -1.6318, -0.8502, -0.6096, -0.6986,  0.3552,  0.1076,  0.6572,\n",
      "          0.4823,  0.6958],\n",
      "        [-1.8720, -1.4443,  2.4474, -1.3120,  1.4204,  0.1031, -0.6199, -0.6909,\n",
      "          0.1790,  0.6191]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2758,  0.1788,  1.3795,  0.9288,  1.3603, -0.0696,  1.7963, -2.7218,\n",
      "          0.4668, -0.8402],\n",
      "        [ 0.3356,  0.9210, -0.6781, -0.6138,  1.1049,  0.0264,  0.7497, -0.7880,\n",
      "         -0.4776, -1.2991],\n",
      "        [-0.4349, -1.6316, -0.8503, -0.6098, -0.6986,  0.3555,  0.1076,  0.6572,\n",
      "          0.4823,  0.6958],\n",
      "        [-1.8722, -1.4442,  2.4474, -1.3121,  1.4204,  0.1032, -0.6199, -0.6909,\n",
      "          0.1790,  0.6191]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2760,  0.1795,  1.3794,  0.9286,  1.3603, -0.0696,  1.7963, -2.7218,\n",
      "          0.4665, -0.8402],\n",
      "        [ 0.3359,  0.9215, -0.6782, -0.6138,  1.1049,  0.0262,  0.7497, -0.7880,\n",
      "         -0.4778, -1.2991],\n",
      "        [-0.4354, -1.6313, -0.8503, -0.6100, -0.6986,  0.3558,  0.1076,  0.6572,\n",
      "          0.4822,  0.6957],\n",
      "        [-1.8724, -1.4442,  2.4474, -1.3122,  1.4204,  0.1033, -0.6199, -0.6909,\n",
      "          0.1790,  0.6191]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2761,  0.1803,  1.3792,  0.9284,  1.3603, -0.0696,  1.7963, -2.7218,\n",
      "          0.4663, -0.8403],\n",
      "        [ 0.3363,  0.9221, -0.6782, -0.6139,  1.1049,  0.0260,  0.7497, -0.7880,\n",
      "         -0.4780, -1.2991],\n",
      "        [-0.4358, -1.6311, -0.8503, -0.6102, -0.6986,  0.3561,  0.1076,  0.6572,\n",
      "          0.4822,  0.6957],\n",
      "        [-1.8726, -1.4442,  2.4474, -1.3122,  1.4204,  0.1035, -0.6199, -0.6909,\n",
      "          0.1790,  0.6190]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2762,  0.1811,  1.3791,  0.9283,  1.3603, -0.0696,  1.7963, -2.7218,\n",
      "          0.4660, -0.8403],\n",
      "        [ 0.3366,  0.9226, -0.6783, -0.6139,  1.1049,  0.0259,  0.7497, -0.7880,\n",
      "         -0.4782, -1.2991],\n",
      "        [-0.4363, -1.6309, -0.8503, -0.6104, -0.6986,  0.3565,  0.1076,  0.6572,\n",
      "          0.4821,  0.6957],\n",
      "        [-1.8728, -1.4441,  2.4474, -1.3123,  1.4204,  0.1036, -0.6199, -0.6909,\n",
      "          0.1790,  0.6190]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2763,  0.1818,  1.3790,  0.9281,  1.3603, -0.0696,  1.7963, -2.7218,\n",
      "          0.4658, -0.8403],\n",
      "        [ 0.3370,  0.9231, -0.6784, -0.6139,  1.1049,  0.0257,  0.7497, -0.7880,\n",
      "         -0.4783, -1.2991],\n",
      "        [-0.4368, -1.6307, -0.8504, -0.6106, -0.6986,  0.3568,  0.1076,  0.6572,\n",
      "          0.4821,  0.6956],\n",
      "        [-1.8730, -1.4441,  2.4474, -1.3124,  1.4204,  0.1038, -0.6199, -0.6909,\n",
      "          0.1790,  0.6190]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2765,  0.1826,  1.3789,  0.9280,  1.3603, -0.0696,  1.7963, -2.7218,\n",
      "          0.4655, -0.8404],\n",
      "        [ 0.3373,  0.9236, -0.6785, -0.6139,  1.1049,  0.0255,  0.7497, -0.7880,\n",
      "         -0.4785, -1.2992],\n",
      "        [-0.4373, -1.6305, -0.8504, -0.6108, -0.6986,  0.3571,  0.1076,  0.6572,\n",
      "          0.4820,  0.6956],\n",
      "        [-1.8732, -1.4441,  2.4474, -1.3125,  1.4204,  0.1039, -0.6199, -0.6909,\n",
      "          0.1790,  0.6190]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2766,  0.1834,  1.3788,  0.9278,  1.3603, -0.0696,  1.7963, -2.7218,\n",
      "          0.4653, -0.8404],\n",
      "        [ 0.3376,  0.9242, -0.6786, -0.6140,  1.1049,  0.0254,  0.7497, -0.7880,\n",
      "         -0.4787, -1.2992],\n",
      "        [-0.4377, -1.6303, -0.8504, -0.6110, -0.6986,  0.3574,  0.1076,  0.6572,\n",
      "          0.4820,  0.6956],\n",
      "        [-1.8734, -1.4440,  2.4474, -1.3125,  1.4204,  0.1041, -0.6199, -0.6909,\n",
      "          0.1790,  0.6190]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2767,  0.1841,  1.3787,  0.9277,  1.3603, -0.0697,  1.7963, -2.7218,\n",
      "          0.4650, -0.8404],\n",
      "        [ 0.3380,  0.9247, -0.6787, -0.6140,  1.1049,  0.0252,  0.7497, -0.7880,\n",
      "         -0.4789, -1.2992],\n",
      "        [-0.4382, -1.6300, -0.8504, -0.6112, -0.6986,  0.3578,  0.1076,  0.6572,\n",
      "          0.4819,  0.6956],\n",
      "        [-1.8736, -1.4440,  2.4474, -1.3126,  1.4204,  0.1042, -0.6199, -0.6909,\n",
      "          0.1790,  0.6190]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2768,  0.1849,  1.3786,  0.9275,  1.3603, -0.0697,  1.7963, -2.7218,\n",
      "          0.4648, -0.8405],\n",
      "        [ 0.3383,  0.9252, -0.6787, -0.6140,  1.1049,  0.0250,  0.7497, -0.7880,\n",
      "         -0.4791, -1.2992],\n",
      "        [-0.4387, -1.6298, -0.8504, -0.6114, -0.6986,  0.3581,  0.1076,  0.6572,\n",
      "          0.4819,  0.6955],\n",
      "        [-1.8738, -1.4440,  2.4474, -1.3127,  1.4204,  0.1043, -0.6199, -0.6909,\n",
      "          0.1790,  0.6190]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2769,  0.1856,  1.3785,  0.9274,  1.3603, -0.0697,  1.7963, -2.7218,\n",
      "          0.4645, -0.8405],\n",
      "        [ 0.3387,  0.9257, -0.6788, -0.6141,  1.1049,  0.0249,  0.7497, -0.7880,\n",
      "         -0.4793, -1.2992],\n",
      "        [-0.4391, -1.6296, -0.8505, -0.6116, -0.6986,  0.3584,  0.1076,  0.6572,\n",
      "          0.4818,  0.6955],\n",
      "        [-1.8740, -1.4439,  2.4474, -1.3127,  1.4204,  0.1045, -0.6199, -0.6909,\n",
      "          0.1790,  0.6190]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2771,  0.1864,  1.3783,  0.9272,  1.3603, -0.0697,  1.7963, -2.7218,\n",
      "          0.4642, -0.8405],\n",
      "        [ 0.3390,  0.9262, -0.6789, -0.6141,  1.1049,  0.0247,  0.7497, -0.7880,\n",
      "         -0.4795, -1.2992],\n",
      "        [-0.4396, -1.6294, -0.8505, -0.6118, -0.6986,  0.3587,  0.1076,  0.6572,\n",
      "          0.4818,  0.6955],\n",
      "        [-1.8742, -1.4439,  2.4474, -1.3128,  1.4204,  0.1046, -0.6199, -0.6909,\n",
      "          0.1790,  0.6190]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2772,  0.1871,  1.3782,  0.9270,  1.3603, -0.0697,  1.7963, -2.7218,\n",
      "          0.4640, -0.8406],\n",
      "        [ 0.3393,  0.9267, -0.6790, -0.6141,  1.1049,  0.0245,  0.7497, -0.7880,\n",
      "         -0.4797, -1.2992],\n",
      "        [-0.4401, -1.6292, -0.8505, -0.6120, -0.6986,  0.3591,  0.1076,  0.6572,\n",
      "          0.4818,  0.6954],\n",
      "        [-1.8744, -1.4439,  2.4474, -1.3129,  1.4204,  0.1048, -0.6199, -0.6909,\n",
      "          0.1790,  0.6190]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2773,  0.1878,  1.3781,  0.9269,  1.3603, -0.0697,  1.7963, -2.7218,\n",
      "          0.4637, -0.8406],\n",
      "        [ 0.3397,  0.9272, -0.6791, -0.6141,  1.1049,  0.0244,  0.7497, -0.7880,\n",
      "         -0.4799, -1.2993],\n",
      "        [-0.4405, -1.6290, -0.8505, -0.6122, -0.6986,  0.3594,  0.1076,  0.6572,\n",
      "          0.4817,  0.6954],\n",
      "        [-1.8746, -1.4438,  2.4473, -1.3130,  1.4204,  0.1049, -0.6199, -0.6909,\n",
      "          0.1790,  0.6189]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2774,  0.1886,  1.3780,  0.9267,  1.3603, -0.0698,  1.7963, -2.7218,\n",
      "          0.4635, -0.8406],\n",
      "        [ 0.3400,  0.9277, -0.6792, -0.6142,  1.1049,  0.0242,  0.7497, -0.7880,\n",
      "         -0.4800, -1.2993],\n",
      "        [-0.4410, -1.6288, -0.8506, -0.6124, -0.6986,  0.3597,  0.1076,  0.6572,\n",
      "          0.4817,  0.6954],\n",
      "        [-1.8748, -1.4438,  2.4473, -1.3130,  1.4204,  0.1050, -0.6199, -0.6909,\n",
      "          0.1790,  0.6189]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2775,  0.1893,  1.3779,  0.9266,  1.3603, -0.0698,  1.7963, -2.7218,\n",
      "          0.4632, -0.8407],\n",
      "        [ 0.3403,  0.9282, -0.6792, -0.6142,  1.1049,  0.0240,  0.7497, -0.7880,\n",
      "         -0.4802, -1.2993],\n",
      "        [-0.4415, -1.6286, -0.8506, -0.6126, -0.6986,  0.3600,  0.1076,  0.6572,\n",
      "          0.4816,  0.6954],\n",
      "        [-1.8750, -1.4438,  2.4473, -1.3131,  1.4204,  0.1052, -0.6199, -0.6909,\n",
      "          0.1790,  0.6189]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2777,  0.1900,  1.3778,  0.9264,  1.3603, -0.0698,  1.7963, -2.7218,\n",
      "          0.4630, -0.8407],\n",
      "        [ 0.3407,  0.9287, -0.6793, -0.6142,  1.1049,  0.0238,  0.7497, -0.7880,\n",
      "         -0.4804, -1.2993],\n",
      "        [-0.4419, -1.6284, -0.8506, -0.6128, -0.6986,  0.3603,  0.1076,  0.6572,\n",
      "          0.4816,  0.6953],\n",
      "        [-1.8752, -1.4437,  2.4473, -1.3132,  1.4204,  0.1053, -0.6199, -0.6909,\n",
      "          0.1790,  0.6189]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2778,  0.1908,  1.3777,  0.9263,  1.3603, -0.0698,  1.7963, -2.7218,\n",
      "          0.4627, -0.8407],\n",
      "        [ 0.3410,  0.9292, -0.6794, -0.6142,  1.1049,  0.0237,  0.7497, -0.7880,\n",
      "         -0.4806, -1.2993],\n",
      "        [-0.4424, -1.6282, -0.8506, -0.6130, -0.6986,  0.3607,  0.1076,  0.6572,\n",
      "          0.4815,  0.6953],\n",
      "        [-1.8754, -1.4437,  2.4473, -1.3133,  1.4204,  0.1055, -0.6199, -0.6909,\n",
      "          0.1790,  0.6189]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2779,  0.1915,  1.3776,  0.9261,  1.3603, -0.0698,  1.7963, -2.7218,\n",
      "          0.4624, -0.8408],\n",
      "        [ 0.3413,  0.9297, -0.6795, -0.6143,  1.1049,  0.0235,  0.7497, -0.7880,\n",
      "         -0.4808, -1.2993],\n",
      "        [-0.4428, -1.6279, -0.8507, -0.6132, -0.6986,  0.3610,  0.1076,  0.6572,\n",
      "          0.4815,  0.6953],\n",
      "        [-1.8756, -1.4437,  2.4473, -1.3133,  1.4204,  0.1056, -0.6199, -0.6909,\n",
      "          0.1790,  0.6189]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2780,  0.1922,  1.3774,  0.9260,  1.3603, -0.0699,  1.7963, -2.7218,\n",
      "          0.4622, -0.8408],\n",
      "        [ 0.3417,  0.9302, -0.6796, -0.6143,  1.1049,  0.0233,  0.7497, -0.7880,\n",
      "         -0.4810, -1.2994],\n",
      "        [-0.4433, -1.6277, -0.8507, -0.6134, -0.6986,  0.3613,  0.1076,  0.6572,\n",
      "          0.4814,  0.6953],\n",
      "        [-1.8758, -1.4436,  2.4473, -1.3134,  1.4204,  0.1057, -0.6199, -0.6909,\n",
      "          0.1790,  0.6189]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2781,  0.1929,  1.3773,  0.9258,  1.3603, -0.0699,  1.7963, -2.7218,\n",
      "          0.4619, -0.8408],\n",
      "        [ 0.3420,  0.9307, -0.6797, -0.6143,  1.1049,  0.0232,  0.7497, -0.7880,\n",
      "         -0.4812, -1.2994],\n",
      "        [-0.4438, -1.6275, -0.8507, -0.6136, -0.6986,  0.3616,  0.1076,  0.6572,\n",
      "          0.4814,  0.6952],\n",
      "        [-1.8760, -1.4436,  2.4473, -1.3135,  1.4204,  0.1059, -0.6199, -0.6909,\n",
      "          0.1790,  0.6189]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2783,  0.1936,  1.3772,  0.9257,  1.3603, -0.0699,  1.7963, -2.7218,\n",
      "          0.4617, -0.8409],\n",
      "        [ 0.3423,  0.9312, -0.6797, -0.6143,  1.1049,  0.0230,  0.7497, -0.7880,\n",
      "         -0.4814, -1.2994],\n",
      "        [-0.4442, -1.6273, -0.8507, -0.6138, -0.6986,  0.3619,  0.1076,  0.6572,\n",
      "          0.4813,  0.6952],\n",
      "        [-1.8762, -1.4436,  2.4473, -1.3135,  1.4204,  0.1060, -0.6199, -0.6909,\n",
      "          0.1790,  0.6189]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2784,  0.1944,  1.3771,  0.9255,  1.3603, -0.0699,  1.7963, -2.7218,\n",
      "          0.4614, -0.8409],\n",
      "        [ 0.3427,  0.9317, -0.6798, -0.6143,  1.1049,  0.0228,  0.7497, -0.7880,\n",
      "         -0.4816, -1.2994],\n",
      "        [-0.4447, -1.6271, -0.8508, -0.6140, -0.6986,  0.3622,  0.1076,  0.6572,\n",
      "          0.4813,  0.6952],\n",
      "        [-1.8764, -1.4435,  2.4473, -1.3136,  1.4204,  0.1062, -0.6199, -0.6909,\n",
      "          0.1790,  0.6189]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2785,  0.1951,  1.3770,  0.9254,  1.3603, -0.0700,  1.7963, -2.7218,\n",
      "          0.4611, -0.8409],\n",
      "        [ 0.3430,  0.9321, -0.6799, -0.6144,  1.1049,  0.0227,  0.7497, -0.7880,\n",
      "         -0.4817, -1.2994],\n",
      "        [-0.4451, -1.6269, -0.8508, -0.6142, -0.6986,  0.3625,  0.1076,  0.6572,\n",
      "          0.4812,  0.6951],\n",
      "        [-1.8766, -1.4435,  2.4473, -1.3137,  1.4204,  0.1063, -0.6199, -0.6909,\n",
      "          0.1790,  0.6189]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2786,  0.1958,  1.3769,  0.9252,  1.3603, -0.0700,  1.7963, -2.7218,\n",
      "          0.4609, -0.8410],\n",
      "        [ 0.3433,  0.9326, -0.6800, -0.6144,  1.1049,  0.0225,  0.7497, -0.7880,\n",
      "         -0.4819, -1.2994],\n",
      "        [-0.4456, -1.6267, -0.8508, -0.6144, -0.6986,  0.3629,  0.1076,  0.6572,\n",
      "          0.4812,  0.6951],\n",
      "        [-1.8768, -1.4435,  2.4473, -1.3138,  1.4204,  0.1064, -0.6199, -0.6909,\n",
      "          0.1790,  0.6188]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2787,  0.1965,  1.3768,  0.9251,  1.3603, -0.0700,  1.7963, -2.7218,\n",
      "          0.4606, -0.8410],\n",
      "        [ 0.3437,  0.9331, -0.6801, -0.6144,  1.1049,  0.0223,  0.7497, -0.7880,\n",
      "         -0.4821, -1.2994],\n",
      "        [-0.4461, -1.6265, -0.8508, -0.6146, -0.6986,  0.3632,  0.1076,  0.6572,\n",
      "          0.4811,  0.6951],\n",
      "        [-1.8770, -1.4434,  2.4473, -1.3138,  1.4204,  0.1066, -0.6199, -0.6909,\n",
      "          0.1790,  0.6188]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2788,  0.1972,  1.3767,  0.9249,  1.3603, -0.0700,  1.7963, -2.7218,\n",
      "          0.4604, -0.8410],\n",
      "        [ 0.3440,  0.9336, -0.6801, -0.6144,  1.1049,  0.0222,  0.7497, -0.7880,\n",
      "         -0.4823, -1.2995],\n",
      "        [-0.4465, -1.6263, -0.8508, -0.6148, -0.6986,  0.3635,  0.1076,  0.6572,\n",
      "          0.4811,  0.6951],\n",
      "        [-1.8772, -1.4434,  2.4473, -1.3139,  1.4204,  0.1067, -0.6199, -0.6909,\n",
      "          0.1790,  0.6188]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2790,  0.1979,  1.3765,  0.9248,  1.3603, -0.0701,  1.7963, -2.7218,\n",
      "          0.4601, -0.8411],\n",
      "        [ 0.3443,  0.9341, -0.6802, -0.6145,  1.1049,  0.0220,  0.7497, -0.7880,\n",
      "         -0.4825, -1.2995],\n",
      "        [-0.4470, -1.6261, -0.8509, -0.6150, -0.6986,  0.3638,  0.1076,  0.6572,\n",
      "          0.4810,  0.6950],\n",
      "        [-1.8774, -1.4434,  2.4473, -1.3140,  1.4204,  0.1068, -0.6199, -0.6909,\n",
      "          0.1790,  0.6188]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2791,  0.1986,  1.3764,  0.9247,  1.3603, -0.0701,  1.7963, -2.7218,\n",
      "          0.4598, -0.8411],\n",
      "        [ 0.3446,  0.9345, -0.6803, -0.6145,  1.1049,  0.0218,  0.7497, -0.7880,\n",
      "         -0.4827, -1.2995],\n",
      "        [-0.4474, -1.6259, -0.8509, -0.6152, -0.6986,  0.3641,  0.1076,  0.6572,\n",
      "          0.4810,  0.6950],\n",
      "        [-1.8776, -1.4433,  2.4473, -1.3141,  1.4204,  0.1070, -0.6199, -0.6909,\n",
      "          0.1790,  0.6188]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2792,  0.1993,  1.3763,  0.9245,  1.3603, -0.0701,  1.7963, -2.7218,\n",
      "          0.4596, -0.8411],\n",
      "        [ 0.3450,  0.9350, -0.6804, -0.6145,  1.1049,  0.0216,  0.7497, -0.7880,\n",
      "         -0.4829, -1.2995],\n",
      "        [-0.4479, -1.6258, -0.8509, -0.6154, -0.6986,  0.3644,  0.1076,  0.6572,\n",
      "          0.4809,  0.6950],\n",
      "        [-1.8778, -1.4433,  2.4473, -1.3141,  1.4204,  0.1071, -0.6199, -0.6909,\n",
      "          0.1790,  0.6188]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2793,  0.1999,  1.3762,  0.9244,  1.3603, -0.0701,  1.7963, -2.7218,\n",
      "          0.4593, -0.8412],\n",
      "        [ 0.3453,  0.9355, -0.6805, -0.6145,  1.1049,  0.0215,  0.7497, -0.7880,\n",
      "         -0.4831, -1.2995],\n",
      "        [-0.4483, -1.6256, -0.8509, -0.6156, -0.6986,  0.3647,  0.1076,  0.6572,\n",
      "          0.4809,  0.6950],\n",
      "        [-1.8780, -1.4433,  2.4473, -1.3142,  1.4204,  0.1073, -0.6199, -0.6909,\n",
      "          0.1790,  0.6188]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2794,  0.2006,  1.3761,  0.9242,  1.3603, -0.0702,  1.7963, -2.7218,\n",
      "          0.4591, -0.8412],\n",
      "        [ 0.3456,  0.9360, -0.6806, -0.6145,  1.1049,  0.0213,  0.7497, -0.7880,\n",
      "         -0.4833, -1.2995],\n",
      "        [-0.4488, -1.6254, -0.8510, -0.6158, -0.6986,  0.3650,  0.1076,  0.6572,\n",
      "          0.4808,  0.6949],\n",
      "        [-1.8782, -1.4433,  2.4473, -1.3143,  1.4204,  0.1074, -0.6199, -0.6909,\n",
      "          0.1790,  0.6188]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2795,  0.2013,  1.3760,  0.9241,  1.3603, -0.0702,  1.7963, -2.7218,\n",
      "          0.4588, -0.8412],\n",
      "        [ 0.3460,  0.9364, -0.6806, -0.6146,  1.1049,  0.0211,  0.7497, -0.7880,\n",
      "         -0.4835, -1.2995],\n",
      "        [-0.4492, -1.6252, -0.8510, -0.6160, -0.6986,  0.3653,  0.1076,  0.6572,\n",
      "          0.4808,  0.6949],\n",
      "        [-1.8784, -1.4432,  2.4473, -1.3143,  1.4204,  0.1075, -0.6199, -0.6909,\n",
      "          0.1790,  0.6188]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2797,  0.2020,  1.3759,  0.9239,  1.3603, -0.0702,  1.7963, -2.7218,\n",
      "          0.4585, -0.8413],\n",
      "        [ 0.3463,  0.9369, -0.6807, -0.6146,  1.1049,  0.0210,  0.7497, -0.7880,\n",
      "         -0.4837, -1.2996],\n",
      "        [-0.4497, -1.6250, -0.8510, -0.6162, -0.6986,  0.3656,  0.1076,  0.6572,\n",
      "          0.4807,  0.6949],\n",
      "        [-1.8786, -1.4432,  2.4473, -1.3144,  1.4204,  0.1077, -0.6199, -0.6909,\n",
      "          0.1790,  0.6188]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2798,  0.2027,  1.3758,  0.9238,  1.3603, -0.0703,  1.7963, -2.7218,\n",
      "          0.4583, -0.8413],\n",
      "        [ 0.3466,  0.9374, -0.6808, -0.6146,  1.1049,  0.0208,  0.7497, -0.7880,\n",
      "         -0.4838, -1.2996],\n",
      "        [-0.4501, -1.6248, -0.8510, -0.6164, -0.6986,  0.3659,  0.1076,  0.6572,\n",
      "          0.4807,  0.6949],\n",
      "        [-1.8787, -1.4432,  2.4473, -1.3145,  1.4204,  0.1078, -0.6199, -0.6909,\n",
      "          0.1790,  0.6187]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2799,  0.2034,  1.3756,  0.9236,  1.3603, -0.0703,  1.7963, -2.7218,\n",
      "          0.4580, -0.8413],\n",
      "        [ 0.3469,  0.9378, -0.6809, -0.6146,  1.1049,  0.0206,  0.7497, -0.7880,\n",
      "         -0.4840, -1.2996],\n",
      "        [-0.4506, -1.6246, -0.8511, -0.6166, -0.6986,  0.3663,  0.1076,  0.6572,\n",
      "          0.4806,  0.6948],\n",
      "        [-1.8789, -1.4431,  2.4473, -1.3145,  1.4204,  0.1079, -0.6199, -0.6909,\n",
      "          0.1790,  0.6187]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2800,  0.2040,  1.3755,  0.9235,  1.3603, -0.0703,  1.7963, -2.7218,\n",
      "          0.4578, -0.8413],\n",
      "        [ 0.3473,  0.9383, -0.6810, -0.6147,  1.1049,  0.0204,  0.7497, -0.7880,\n",
      "         -0.4842, -1.2996],\n",
      "        [-0.4510, -1.6244, -0.8511, -0.6168, -0.6986,  0.3666,  0.1076,  0.6572,\n",
      "          0.4806,  0.6948],\n",
      "        [-1.8791, -1.4431,  2.4473, -1.3146,  1.4204,  0.1081, -0.6199, -0.6909,\n",
      "          0.1790,  0.6187]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2801,  0.2047,  1.3754,  0.9234,  1.3603, -0.0704,  1.7963, -2.7218,\n",
      "          0.4575, -0.8414],\n",
      "        [ 0.3476,  0.9387, -0.6811, -0.6147,  1.1049,  0.0203,  0.7497, -0.7880,\n",
      "         -0.4844, -1.2996],\n",
      "        [-0.4515, -1.6242, -0.8511, -0.6170, -0.6986,  0.3669,  0.1076,  0.6572,\n",
      "          0.4805,  0.6948],\n",
      "        [-1.8793, -1.4431,  2.4473, -1.3147,  1.4204,  0.1082, -0.6199, -0.6909,\n",
      "          0.1790,  0.6187]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2802,  0.2054,  1.3753,  0.9232,  1.3603, -0.0704,  1.7963, -2.7218,\n",
      "          0.4572, -0.8414],\n",
      "        [ 0.3479,  0.9392, -0.6811, -0.6147,  1.1049,  0.0201,  0.7497, -0.7880,\n",
      "         -0.4846, -1.2996],\n",
      "        [-0.4519, -1.6240, -0.8511, -0.6171, -0.6986,  0.3672,  0.1076,  0.6572,\n",
      "          0.4805,  0.6947],\n",
      "        [-1.8795, -1.4431,  2.4473, -1.3148,  1.4204,  0.1083, -0.6199, -0.6909,\n",
      "          0.1790,  0.6187]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2804,  0.2060,  1.3752,  0.9231,  1.3603, -0.0704,  1.7963, -2.7218,\n",
      "          0.4570, -0.8414],\n",
      "        [ 0.3482,  0.9396, -0.6812, -0.6147,  1.1049,  0.0199,  0.7497, -0.7880,\n",
      "         -0.4848, -1.2996],\n",
      "        [-0.4524, -1.6239, -0.8511, -0.6173, -0.6986,  0.3675,  0.1076,  0.6572,\n",
      "          0.4804,  0.6947],\n",
      "        [-1.8797, -1.4430,  2.4473, -1.3148,  1.4204,  0.1085, -0.6199, -0.6909,\n",
      "          0.1790,  0.6187]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2805,  0.2067,  1.3751,  0.9229,  1.3603, -0.0705,  1.7963, -2.7218,\n",
      "          0.4567, -0.8415],\n",
      "        [ 0.3485,  0.9401, -0.6813, -0.6147,  1.1049,  0.0198,  0.7497, -0.7880,\n",
      "         -0.4850, -1.2997],\n",
      "        [-0.4528, -1.6237, -0.8512, -0.6175, -0.6986,  0.3678,  0.1076,  0.6572,\n",
      "          0.4804,  0.6947],\n",
      "        [-1.8799, -1.4430,  2.4473, -1.3149,  1.4204,  0.1086, -0.6199, -0.6909,\n",
      "          0.1790,  0.6187]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2806,  0.2073,  1.3750,  0.9228,  1.3603, -0.0705,  1.7963, -2.7218,\n",
      "          0.4565, -0.8415],\n",
      "        [ 0.3489,  0.9405, -0.6814, -0.6147,  1.1049,  0.0196,  0.7497, -0.7880,\n",
      "         -0.4852, -1.2997],\n",
      "        [-0.4533, -1.6235, -0.8512, -0.6177, -0.6986,  0.3681,  0.1076,  0.6572,\n",
      "          0.4803,  0.6947],\n",
      "        [-1.8801, -1.4430,  2.4473, -1.3150,  1.4204,  0.1087, -0.6199, -0.6909,\n",
      "          0.1790,  0.6187]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2807,  0.2080,  1.3749,  0.9227,  1.3603, -0.0705,  1.7963, -2.7218,\n",
      "          0.4562, -0.8415],\n",
      "        [ 0.3492,  0.9410, -0.6815, -0.6148,  1.1049,  0.0194,  0.7497, -0.7880,\n",
      "         -0.4854, -1.2997],\n",
      "        [-0.4537, -1.6233, -0.8512, -0.6179, -0.6986,  0.3684,  0.1076,  0.6572,\n",
      "          0.4803,  0.6946],\n",
      "        [-1.8803, -1.4429,  2.4473, -1.3150,  1.4204,  0.1089, -0.6199, -0.6909,\n",
      "          0.1790,  0.6187]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2808,  0.2087,  1.3747,  0.9225,  1.3603, -0.0706,  1.7963, -2.7218,\n",
      "          0.4559, -0.8416],\n",
      "        [ 0.3495,  0.9414, -0.6815, -0.6148,  1.1049,  0.0192,  0.7497, -0.7880,\n",
      "         -0.4856, -1.2997],\n",
      "        [-0.4542, -1.6231, -0.8512, -0.6181, -0.6986,  0.3687,  0.1076,  0.6572,\n",
      "          0.4802,  0.6946],\n",
      "        [-1.8805, -1.4429,  2.4473, -1.3151,  1.4204,  0.1090, -0.6199, -0.6909,\n",
      "          0.1790,  0.6187]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2809,  0.2093,  1.3746,  0.9224,  1.3603, -0.0706,  1.7963, -2.7218,\n",
      "          0.4557, -0.8416],\n",
      "        [ 0.3498,  0.9419, -0.6816, -0.6148,  1.1049,  0.0191,  0.7497, -0.7880,\n",
      "         -0.4858, -1.2997],\n",
      "        [-0.4546, -1.6229, -0.8513, -0.6183, -0.6986,  0.3690,  0.1076,  0.6572,\n",
      "          0.4802,  0.6946],\n",
      "        [-1.8807, -1.4429,  2.4473, -1.3152,  1.4204,  0.1091, -0.6199, -0.6909,\n",
      "          0.1790,  0.6187]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2810,  0.2100,  1.3745,  0.9222,  1.3603, -0.0706,  1.7963, -2.7218,\n",
      "          0.4554, -0.8416],\n",
      "        [ 0.3502,  0.9423, -0.6817, -0.6148,  1.1049,  0.0189,  0.7497, -0.7880,\n",
      "         -0.4860, -1.2997],\n",
      "        [-0.4550, -1.6228, -0.8513, -0.6185, -0.6986,  0.3693,  0.1076,  0.6572,\n",
      "          0.4802,  0.6946],\n",
      "        [-1.8808, -1.4429,  2.4473, -1.3153,  1.4204,  0.1093, -0.6199, -0.6909,\n",
      "          0.1790,  0.6187]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2812,  0.2106,  1.3744,  0.9221,  1.3603, -0.0707,  1.7963, -2.7218,\n",
      "          0.4551, -0.8417],\n",
      "        [ 0.3505,  0.9428, -0.6818, -0.6148,  1.1049,  0.0187,  0.7497, -0.7880,\n",
      "         -0.4862, -1.2997],\n",
      "        [-0.4555, -1.6226, -0.8513, -0.6187, -0.6986,  0.3696,  0.1076,  0.6572,\n",
      "          0.4801,  0.6945],\n",
      "        [-1.8810, -1.4428,  2.4473, -1.3153,  1.4204,  0.1094, -0.6199, -0.6909,\n",
      "          0.1790,  0.6186]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2813,  0.2112,  1.3743,  0.9220,  1.3603, -0.0707,  1.7963, -2.7218,\n",
      "          0.4549, -0.8417],\n",
      "        [ 0.3508,  0.9432, -0.6819, -0.6149,  1.1049,  0.0185,  0.7497, -0.7880,\n",
      "         -0.4863, -1.2998],\n",
      "        [-0.4559, -1.6224, -0.8513, -0.6189, -0.6986,  0.3699,  0.1076,  0.6572,\n",
      "          0.4801,  0.6945],\n",
      "        [-1.8812, -1.4428,  2.4473, -1.3154,  1.4204,  0.1095, -0.6199, -0.6909,\n",
      "          0.1790,  0.6186]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2814,  0.2119,  1.3742,  0.9218,  1.3603, -0.0708,  1.7963, -2.7218,\n",
      "          0.4546, -0.8417],\n",
      "        [ 0.3511,  0.9437, -0.6820, -0.6149,  1.1049,  0.0184,  0.7497, -0.7880,\n",
      "         -0.4865, -1.2998],\n",
      "        [-0.4564, -1.6222, -0.8514, -0.6191, -0.6986,  0.3702,  0.1076,  0.6572,\n",
      "          0.4800,  0.6945],\n",
      "        [-1.8814, -1.4428,  2.4473, -1.3155,  1.4204,  0.1097, -0.6199, -0.6909,\n",
      "          0.1790,  0.6186]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2815,  0.2125,  1.3741,  0.9217,  1.3603, -0.0708,  1.7963, -2.7218,\n",
      "          0.4544, -0.8418],\n",
      "        [ 0.3514,  0.9441, -0.6820, -0.6149,  1.1049,  0.0182,  0.7497, -0.7880,\n",
      "         -0.4867, -1.2998],\n",
      "        [-0.4568, -1.6220, -0.8514, -0.6192, -0.6986,  0.3705,  0.1076,  0.6572,\n",
      "          0.4800,  0.6945],\n",
      "        [-1.8816, -1.4427,  2.4473, -1.3155,  1.4204,  0.1098, -0.6199, -0.6909,\n",
      "          0.1790,  0.6186]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2816,  0.2132,  1.3740,  0.9215,  1.3603, -0.0708,  1.7963, -2.7218,\n",
      "          0.4541, -0.8418],\n",
      "        [ 0.3517,  0.9445, -0.6821, -0.6149,  1.1049,  0.0180,  0.7497, -0.7880,\n",
      "         -0.4869, -1.2998],\n",
      "        [-0.4573, -1.6219, -0.8514, -0.6194, -0.6986,  0.3708,  0.1076,  0.6572,\n",
      "          0.4799,  0.6944],\n",
      "        [-1.8818, -1.4427,  2.4473, -1.3156,  1.4204,  0.1099, -0.6199, -0.6909,\n",
      "          0.1790,  0.6186]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2817,  0.2138,  1.3738,  0.9214,  1.3603, -0.0709,  1.7963, -2.7218,\n",
      "          0.4538, -0.8418],\n",
      "        [ 0.3521,  0.9450, -0.6822, -0.6149,  1.1049,  0.0178,  0.7497, -0.7880,\n",
      "         -0.4871, -1.2998],\n",
      "        [-0.4577, -1.6217, -0.8514, -0.6196, -0.6986,  0.3711,  0.1076,  0.6572,\n",
      "          0.4799,  0.6944],\n",
      "        [-1.8820, -1.4427,  2.4473, -1.3157,  1.4204,  0.1101, -0.6199, -0.6909,\n",
      "          0.1790,  0.6186]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2818,  0.2144,  1.3737,  0.9213,  1.3603, -0.0709,  1.7963, -2.7218,\n",
      "          0.4536, -0.8419],\n",
      "        [ 0.3524,  0.9454, -0.6823, -0.6149,  1.1049,  0.0177,  0.7497, -0.7880,\n",
      "         -0.4873, -1.2998],\n",
      "        [-0.4581, -1.6215, -0.8514, -0.6198, -0.6986,  0.3714,  0.1076,  0.6572,\n",
      "          0.4798,  0.6944],\n",
      "        [-1.8822, -1.4427,  2.4473, -1.3157,  1.4204,  0.1102, -0.6199, -0.6909,\n",
      "          0.1790,  0.6186]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2820,  0.2150,  1.3736,  0.9211,  1.3603, -0.0709,  1.7963, -2.7218,\n",
      "          0.4533, -0.8419],\n",
      "        [ 0.3527,  0.9458, -0.6824, -0.6150,  1.1049,  0.0175,  0.7497, -0.7880,\n",
      "         -0.4875, -1.2998],\n",
      "        [-0.4586, -1.6213, -0.8515, -0.6200, -0.6986,  0.3717,  0.1076,  0.6572,\n",
      "          0.4798,  0.6944],\n",
      "        [-1.8823, -1.4426,  2.4473, -1.3158,  1.4204,  0.1103, -0.6199, -0.6909,\n",
      "          0.1790,  0.6186]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2821,  0.2157,  1.3735,  0.9210,  1.3603, -0.0710,  1.7963, -2.7218,\n",
      "          0.4530, -0.8419],\n",
      "        [ 0.3530,  0.9463, -0.6824, -0.6150,  1.1049,  0.0173,  0.7497, -0.7880,\n",
      "         -0.4877, -1.2999],\n",
      "        [-0.4590, -1.6212, -0.8515, -0.6202, -0.6986,  0.3719,  0.1076,  0.6572,\n",
      "          0.4797,  0.6943],\n",
      "        [-1.8825, -1.4426,  2.4473, -1.3159,  1.4204,  0.1105, -0.6199, -0.6909,\n",
      "          0.1790,  0.6186]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2822,  0.2163,  1.3734,  0.9209,  1.3603, -0.0710,  1.7963, -2.7218,\n",
      "          0.4528, -0.8420],\n",
      "        [ 0.3533,  0.9467, -0.6825, -0.6150,  1.1049,  0.0172,  0.7497, -0.7880,\n",
      "         -0.4879, -1.2999],\n",
      "        [-0.4594, -1.6210, -0.8515, -0.6204, -0.6986,  0.3722,  0.1076,  0.6572,\n",
      "          0.4797,  0.6943],\n",
      "        [-1.8827, -1.4426,  2.4473, -1.3159,  1.4204,  0.1106, -0.6199, -0.6909,\n",
      "          0.1790,  0.6186]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2823,  0.2169,  1.3733,  0.9207,  1.3603, -0.0711,  1.7963, -2.7218,\n",
      "          0.4525, -0.8420],\n",
      "        [ 0.3536,  0.9471, -0.6826, -0.6150,  1.1049,  0.0170,  0.7497, -0.7880,\n",
      "         -0.4881, -1.2999],\n",
      "        [-0.4599, -1.6208, -0.8515, -0.6206, -0.6986,  0.3725,  0.1076,  0.6572,\n",
      "          0.4796,  0.6943],\n",
      "        [-1.8829, -1.4426,  2.4473, -1.3160,  1.4204,  0.1107, -0.6199, -0.6909,\n",
      "          0.1790,  0.6186]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2824,  0.2175,  1.3732,  0.9206,  1.3603, -0.0711,  1.7963, -2.7218,\n",
      "          0.4523, -0.8420],\n",
      "        [ 0.3540,  0.9475, -0.6827, -0.6150,  1.1049,  0.0168,  0.7497, -0.7880,\n",
      "         -0.4883, -1.2999],\n",
      "        [-0.4603, -1.6207, -0.8516, -0.6208, -0.6986,  0.3728,  0.1076,  0.6572,\n",
      "          0.4796,  0.6943],\n",
      "        [-1.8831, -1.4425,  2.4473, -1.3161,  1.4204,  0.1109, -0.6199, -0.6909,\n",
      "          0.1790,  0.6185]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2825,  0.2181,  1.3731,  0.9205,  1.3603, -0.0712,  1.7963, -2.7218,\n",
      "          0.4520, -0.8420],\n",
      "        [ 0.3543,  0.9480, -0.6828, -0.6150,  1.1049,  0.0166,  0.7497, -0.7880,\n",
      "         -0.4885, -1.2999],\n",
      "        [-0.4607, -1.6205, -0.8516, -0.6209, -0.6986,  0.3731,  0.1076,  0.6572,\n",
      "          0.4795,  0.6942],\n",
      "        [-1.8833, -1.4425,  2.4473, -1.3162,  1.4204,  0.1110, -0.6199, -0.6909,\n",
      "          0.1790,  0.6185]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2826,  0.2188,  1.3729,  0.9203,  1.3603, -0.0712,  1.7963, -2.7218,\n",
      "          0.4517, -0.8421],\n",
      "        [ 0.3546,  0.9484, -0.6829, -0.6151,  1.1049,  0.0165,  0.7497, -0.7880,\n",
      "         -0.4887, -1.2999],\n",
      "        [-0.4612, -1.6203, -0.8516, -0.6211, -0.6986,  0.3734,  0.1076,  0.6572,\n",
      "          0.4795,  0.6942],\n",
      "        [-1.8835, -1.4425,  2.4473, -1.3162,  1.4204,  0.1111, -0.6199, -0.6909,\n",
      "          0.1790,  0.6185]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2827,  0.2194,  1.3728,  0.9202,  1.3603, -0.0712,  1.7963, -2.7218,\n",
      "          0.4515, -0.8421],\n",
      "        [ 0.3549,  0.9488, -0.6829, -0.6151,  1.1049,  0.0163,  0.7497, -0.7880,\n",
      "         -0.4889, -1.2999],\n",
      "        [-0.4616, -1.6201, -0.8516, -0.6213, -0.6986,  0.3737,  0.1076,  0.6572,\n",
      "          0.4794,  0.6942],\n",
      "        [-1.8836, -1.4425,  2.4473, -1.3163,  1.4204,  0.1112, -0.6199, -0.6909,\n",
      "          0.1790,  0.6185]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2828,  0.2200,  1.3727,  0.9201,  1.3603, -0.0713,  1.7963, -2.7218,\n",
      "          0.4512, -0.8421],\n",
      "        [ 0.3552,  0.9492, -0.6830, -0.6151,  1.1049,  0.0161,  0.7497, -0.7880,\n",
      "         -0.4891, -1.2999],\n",
      "        [-0.4620, -1.6200, -0.8517, -0.6215, -0.6986,  0.3740,  0.1076,  0.6572,\n",
      "          0.4794,  0.6942],\n",
      "        [-1.8838, -1.4424,  2.4473, -1.3164,  1.4204,  0.1114, -0.6199, -0.6909,\n",
      "          0.1790,  0.6185]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2830,  0.2206,  1.3726,  0.9199,  1.3603, -0.0713,  1.7963, -2.7218,\n",
      "          0.4509, -0.8422],\n",
      "        [ 0.3555,  0.9496, -0.6831, -0.6151,  1.1049,  0.0159,  0.7497, -0.7880,\n",
      "         -0.4893, -1.3000],\n",
      "        [-0.4625, -1.6198, -0.8517, -0.6217, -0.6986,  0.3743,  0.1076,  0.6572,\n",
      "          0.4793,  0.6941],\n",
      "        [-1.8840, -1.4424,  2.4473, -1.3164,  1.4204,  0.1115, -0.6199, -0.6909,\n",
      "          0.1790,  0.6185]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2831,  0.2212,  1.3725,  0.9198,  1.3603, -0.0714,  1.7963, -2.7218,\n",
      "          0.4507, -0.8422],\n",
      "        [ 0.3558,  0.9500, -0.6832, -0.6151,  1.1049,  0.0158,  0.7497, -0.7880,\n",
      "         -0.4895, -1.3000],\n",
      "        [-0.4629, -1.6197, -0.8517, -0.6219, -0.6986,  0.3746,  0.1076,  0.6572,\n",
      "          0.4793,  0.6941],\n",
      "        [-1.8842, -1.4424,  2.4473, -1.3165,  1.4204,  0.1116, -0.6199, -0.6909,\n",
      "          0.1790,  0.6185]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2832,  0.2218,  1.3724,  0.9197,  1.3603, -0.0714,  1.7963, -2.7218,\n",
      "          0.4504, -0.8422],\n",
      "        [ 0.3561,  0.9505, -0.6833, -0.6151,  1.1049,  0.0156,  0.7497, -0.7880,\n",
      "         -0.4897, -1.3000],\n",
      "        [-0.4633, -1.6195, -0.8517, -0.6221, -0.6986,  0.3749,  0.1076,  0.6572,\n",
      "          0.4792,  0.6941],\n",
      "        [-1.8844, -1.4424,  2.4473, -1.3166,  1.4204,  0.1118, -0.6199, -0.6909,\n",
      "          0.1790,  0.6185]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2833,  0.2224,  1.3723,  0.9195,  1.3603, -0.0715,  1.7963, -2.7218,\n",
      "          0.4501, -0.8423],\n",
      "        [ 0.3565,  0.9509, -0.6833, -0.6151,  1.1049,  0.0154,  0.7497, -0.7880,\n",
      "         -0.4898, -1.3000],\n",
      "        [-0.4638, -1.6193, -0.8517, -0.6222, -0.6986,  0.3752,  0.1076,  0.6572,\n",
      "          0.4792,  0.6941],\n",
      "        [-1.8846, -1.4423,  2.4473, -1.3166,  1.4204,  0.1119, -0.6199, -0.6909,\n",
      "          0.1790,  0.6185]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2834,  0.2230,  1.3722,  0.9194,  1.3603, -0.0715,  1.7963, -2.7218,\n",
      "          0.4499, -0.8423],\n",
      "        [ 0.3568,  0.9513, -0.6834, -0.6152,  1.1049,  0.0152,  0.7497, -0.7880,\n",
      "         -0.4900, -1.3000],\n",
      "        [-0.4642, -1.6192, -0.8518, -0.6224, -0.6986,  0.3754,  0.1076,  0.6572,\n",
      "          0.4791,  0.6940],\n",
      "        [-1.8848, -1.4423,  2.4473, -1.3167,  1.4204,  0.1120, -0.6199, -0.6909,\n",
      "          0.1790,  0.6185]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2835,  0.2236,  1.3721,  0.9193,  1.3603, -0.0716,  1.7963, -2.7218,\n",
      "          0.4496, -0.8423],\n",
      "        [ 0.3571,  0.9517, -0.6835, -0.6152,  1.1049,  0.0150,  0.7497, -0.7880,\n",
      "         -0.4902, -1.3000],\n",
      "        [-0.4646, -1.6190, -0.8518, -0.6226, -0.6986,  0.3757,  0.1076,  0.6572,\n",
      "          0.4791,  0.6940],\n",
      "        [-1.8849, -1.4423,  2.4473, -1.3168,  1.4204,  0.1121, -0.6199, -0.6909,\n",
      "          0.1790,  0.6185]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2836,  0.2242,  1.3719,  0.9192,  1.3603, -0.0716,  1.7963, -2.7218,\n",
      "          0.4493, -0.8424],\n",
      "        [ 0.3574,  0.9521, -0.6836, -0.6152,  1.1049,  0.0149,  0.7497, -0.7880,\n",
      "         -0.4904, -1.3000],\n",
      "        [-0.4651, -1.6188, -0.8518, -0.6228, -0.6986,  0.3760,  0.1076,  0.6572,\n",
      "          0.4790,  0.6940],\n",
      "        [-1.8851, -1.4423,  2.4473, -1.3168,  1.4204,  0.1123, -0.6199, -0.6909,\n",
      "          0.1790,  0.6184]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2837,  0.2247,  1.3718,  0.9190,  1.3603, -0.0717,  1.7963, -2.7218,\n",
      "          0.4491, -0.8424],\n",
      "        [ 0.3577,  0.9525, -0.6837, -0.6152,  1.1049,  0.0147,  0.7497, -0.7880,\n",
      "         -0.4906, -1.3001],\n",
      "        [-0.4655, -1.6187, -0.8518, -0.6230, -0.6986,  0.3763,  0.1076,  0.6572,\n",
      "          0.4790,  0.6940],\n",
      "        [-1.8853, -1.4422,  2.4473, -1.3169,  1.4204,  0.1124, -0.6199, -0.6909,\n",
      "          0.1790,  0.6184]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2838,  0.2253,  1.3717,  0.9189,  1.3603, -0.0717,  1.7963, -2.7218,\n",
      "          0.4488, -0.8424],\n",
      "        [ 0.3580,  0.9529, -0.6838, -0.6152,  1.1049,  0.0145,  0.7497, -0.7880,\n",
      "         -0.4908, -1.3001],\n",
      "        [-0.4659, -1.6185, -0.8519, -0.6232, -0.6986,  0.3766,  0.1076,  0.6572,\n",
      "          0.4789,  0.6939],\n",
      "        [-1.8855, -1.4422,  2.4473, -1.3170,  1.4204,  0.1125, -0.6199, -0.6909,\n",
      "          0.1790,  0.6184]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2840,  0.2259,  1.3716,  0.9188,  1.3603, -0.0718,  1.7963, -2.7218,\n",
      "          0.4485, -0.8424],\n",
      "        [ 0.3583,  0.9533, -0.6838, -0.6152,  1.1049,  0.0143,  0.7497, -0.7880,\n",
      "         -0.4910, -1.3001],\n",
      "        [-0.4663, -1.6184, -0.8519, -0.6234, -0.6986,  0.3769,  0.1076,  0.6572,\n",
      "          0.4789,  0.6939],\n",
      "        [-1.8857, -1.4422,  2.4473, -1.3170,  1.4204,  0.1127, -0.6199, -0.6909,\n",
      "          0.1790,  0.6184]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2841,  0.2265,  1.3715,  0.9186,  1.3603, -0.0718,  1.7963, -2.7218,\n",
      "          0.4483, -0.8425],\n",
      "        [ 0.3586,  0.9537, -0.6839, -0.6152,  1.1049,  0.0142,  0.7497, -0.7880,\n",
      "         -0.4912, -1.3001],\n",
      "        [-0.4668, -1.6182, -0.8519, -0.6235, -0.6986,  0.3772,  0.1076,  0.6572,\n",
      "          0.4788,  0.6939],\n",
      "        [-1.8858, -1.4422,  2.4473, -1.3171,  1.4204,  0.1128, -0.6199, -0.6909,\n",
      "          0.1790,  0.6184]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2842,  0.2271,  1.3714,  0.9185,  1.3603, -0.0719,  1.7963, -2.7218,\n",
      "          0.4480, -0.8425],\n",
      "        [ 0.3589,  0.9541, -0.6840, -0.6152,  1.1049,  0.0140,  0.7497, -0.7880,\n",
      "         -0.4914, -1.3001],\n",
      "        [-0.4672, -1.6180, -0.8519, -0.6237, -0.6986,  0.3774,  0.1076,  0.6572,\n",
      "          0.4788,  0.6939],\n",
      "        [-1.8860, -1.4421,  2.4473, -1.3172,  1.4204,  0.1129, -0.6199, -0.6909,\n",
      "          0.1790,  0.6184]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2843,  0.2277,  1.3713,  0.9184,  1.3603, -0.0719,  1.7963, -2.7218,\n",
      "          0.4477, -0.8425],\n",
      "        [ 0.3592,  0.9545, -0.6841, -0.6153,  1.1049,  0.0138,  0.7497, -0.7880,\n",
      "         -0.4916, -1.3001],\n",
      "        [-0.4676, -1.6179, -0.8520, -0.6239, -0.6986,  0.3777,  0.1076,  0.6572,\n",
      "          0.4787,  0.6938],\n",
      "        [-1.8862, -1.4421,  2.4473, -1.3172,  1.4204,  0.1130, -0.6199, -0.6909,\n",
      "          0.1790,  0.6184]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2844,  0.2282,  1.3712,  0.9183,  1.3603, -0.0720,  1.7963, -2.7218,\n",
      "          0.4475, -0.8426],\n",
      "        [ 0.3595,  0.9549, -0.6842, -0.6153,  1.1049,  0.0136,  0.7497, -0.7880,\n",
      "         -0.4918, -1.3001],\n",
      "        [-0.4680, -1.6177, -0.8520, -0.6241, -0.6986,  0.3780,  0.1076,  0.6572,\n",
      "          0.4787,  0.6938],\n",
      "        [-1.8864, -1.4421,  2.4473, -1.3173,  1.4204,  0.1132, -0.6199, -0.6909,\n",
      "          0.1790,  0.6184]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2845,  0.2288,  1.3710,  0.9181,  1.3603, -0.0720,  1.7963, -2.7218,\n",
      "          0.4472, -0.8426],\n",
      "        [ 0.3599,  0.9553, -0.6842, -0.6153,  1.1049,  0.0135,  0.7497, -0.7880,\n",
      "         -0.4920, -1.3002],\n",
      "        [-0.4685, -1.6176, -0.8520, -0.6243, -0.6986,  0.3783,  0.1076,  0.6572,\n",
      "          0.4786,  0.6938],\n",
      "        [-1.8866, -1.4421,  2.4473, -1.3174,  1.4204,  0.1133, -0.6199, -0.6909,\n",
      "          0.1790,  0.6184]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2846,  0.2294,  1.3709,  0.9180,  1.3603, -0.0721,  1.7963, -2.7218,\n",
      "          0.4469, -0.8426],\n",
      "        [ 0.3602,  0.9557, -0.6843, -0.6153,  1.1049,  0.0133,  0.7497, -0.7880,\n",
      "         -0.4922, -1.3002],\n",
      "        [-0.4689, -1.6174, -0.8520, -0.6245, -0.6986,  0.3786,  0.1076,  0.6572,\n",
      "          0.4786,  0.6938],\n",
      "        [-1.8868, -1.4421,  2.4473, -1.3174,  1.4204,  0.1134, -0.6199, -0.6909,\n",
      "          0.1790,  0.6184]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2847,  0.2299,  1.3708,  0.9179,  1.3603, -0.0721,  1.7963, -2.7218,\n",
      "          0.4467, -0.8427],\n",
      "        [ 0.3605,  0.9561, -0.6844, -0.6153,  1.1049,  0.0131,  0.7497, -0.7880,\n",
      "         -0.4924, -1.3002],\n",
      "        [-0.4693, -1.6173, -0.8520, -0.6246, -0.6986,  0.3789,  0.1076,  0.6572,\n",
      "          0.4786,  0.6937],\n",
      "        [-1.8869, -1.4420,  2.4473, -1.3175,  1.4204,  0.1135, -0.6199, -0.6909,\n",
      "          0.1790,  0.6184]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2848,  0.2305,  1.3707,  0.9178,  1.3603, -0.0722,  1.7963, -2.7218,\n",
      "          0.4464, -0.8427],\n",
      "        [ 0.3608,  0.9565, -0.6845, -0.6153,  1.1049,  0.0129,  0.7497, -0.7880,\n",
      "         -0.4926, -1.3002],\n",
      "        [-0.4697, -1.6171, -0.8521, -0.6248, -0.6986,  0.3791,  0.1076,  0.6572,\n",
      "          0.4785,  0.6937],\n",
      "        [-1.8871, -1.4420,  2.4473, -1.3176,  1.4204,  0.1137, -0.6199, -0.6909,\n",
      "          0.1790,  0.6184]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2849,  0.2311,  1.3706,  0.9176,  1.3603, -0.0722,  1.7963, -2.7218,\n",
      "          0.4461, -0.8427],\n",
      "        [ 0.3611,  0.9569, -0.6846, -0.6153,  1.1049,  0.0128,  0.7497, -0.7880,\n",
      "         -0.4928, -1.3002],\n",
      "        [-0.4702, -1.6170, -0.8521, -0.6250, -0.6986,  0.3794,  0.1076,  0.6572,\n",
      "          0.4785,  0.6937],\n",
      "        [-1.8873, -1.4420,  2.4473, -1.3176,  1.4204,  0.1138, -0.6199, -0.6909,\n",
      "          0.1790,  0.6183]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2850,  0.2316,  1.3705,  0.9175,  1.3603, -0.0723,  1.7963, -2.7218,\n",
      "          0.4459, -0.8427],\n",
      "        [ 0.3614,  0.9572, -0.6847, -0.6153,  1.1049,  0.0126,  0.7497, -0.7880,\n",
      "         -0.4930, -1.3002],\n",
      "        [-0.4706, -1.6168, -0.8521, -0.6252, -0.6986,  0.3797,  0.1076,  0.6572,\n",
      "          0.4784,  0.6937],\n",
      "        [-1.8875, -1.4420,  2.4473, -1.3177,  1.4204,  0.1139, -0.6199, -0.6909,\n",
      "          0.1790,  0.6183]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2852,  0.2322,  1.3704,  0.9174,  1.3603, -0.0723,  1.7963, -2.7218,\n",
      "          0.4456, -0.8428],\n",
      "        [ 0.3617,  0.9576, -0.6847, -0.6154,  1.1049,  0.0124,  0.7497, -0.7880,\n",
      "         -0.4932, -1.3002],\n",
      "        [-0.4710, -1.6167, -0.8521, -0.6254, -0.6986,  0.3800,  0.1076,  0.6572,\n",
      "          0.4784,  0.6936],\n",
      "        [-1.8877, -1.4419,  2.4473, -1.3178,  1.4204,  0.1140, -0.6199, -0.6909,\n",
      "          0.1790,  0.6183]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2853,  0.2328,  1.3703,  0.9173,  1.3603, -0.0724,  1.7963, -2.7218,\n",
      "          0.4453, -0.8428],\n",
      "        [ 0.3620,  0.9580, -0.6848, -0.6154,  1.1049,  0.0122,  0.7497, -0.7880,\n",
      "         -0.4934, -1.3002],\n",
      "        [-0.4714, -1.6165, -0.8522, -0.6255, -0.6986,  0.3803,  0.1076,  0.6572,\n",
      "          0.4783,  0.6936],\n",
      "        [-1.8878, -1.4419,  2.4473, -1.3178,  1.4204,  0.1142, -0.6199, -0.6909,\n",
      "          0.1790,  0.6183]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2854,  0.2333,  1.3702,  0.9171,  1.3603, -0.0724,  1.7963, -2.7218,\n",
      "          0.4451, -0.8428],\n",
      "        [ 0.3623,  0.9584, -0.6849, -0.6154,  1.1049,  0.0120,  0.7497, -0.7880,\n",
      "         -0.4936, -1.3003],\n",
      "        [-0.4718, -1.6164, -0.8522, -0.6257, -0.6986,  0.3805,  0.1076,  0.6572,\n",
      "          0.4783,  0.6936],\n",
      "        [-1.8880, -1.4419,  2.4473, -1.3179,  1.4204,  0.1143, -0.6199, -0.6909,\n",
      "          0.1789,  0.6183]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2855,  0.2339,  1.3700,  0.9170,  1.3603, -0.0725,  1.7963, -2.7218,\n",
      "          0.4448, -0.8429],\n",
      "        [ 0.3626,  0.9588, -0.6850, -0.6154,  1.1049,  0.0119,  0.7497, -0.7880,\n",
      "         -0.4938, -1.3003],\n",
      "        [-0.4723, -1.6162, -0.8522, -0.6259, -0.6986,  0.3808,  0.1076,  0.6572,\n",
      "          0.4782,  0.6936],\n",
      "        [-1.8882, -1.4419,  2.4473, -1.3180,  1.4204,  0.1144, -0.6199, -0.6909,\n",
      "          0.1789,  0.6183]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2856,  0.2344,  1.3699,  0.9169,  1.3603, -0.0725,  1.7963, -2.7218,\n",
      "          0.4445, -0.8429],\n",
      "        [ 0.3629,  0.9592, -0.6851, -0.6154,  1.1049,  0.0117,  0.7497, -0.7880,\n",
      "         -0.4940, -1.3003],\n",
      "        [-0.4727, -1.6161, -0.8522, -0.6261, -0.6986,  0.3811,  0.1076,  0.6572,\n",
      "          0.4782,  0.6935],\n",
      "        [-1.8884, -1.4419,  2.4473, -1.3180,  1.4204,  0.1145, -0.6199, -0.6909,\n",
      "          0.1789,  0.6183]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2857,  0.2350,  1.3698,  0.9168,  1.3603, -0.0726,  1.7963, -2.7218,\n",
      "          0.4443, -0.8429],\n",
      "        [ 0.3632,  0.9595, -0.6851, -0.6154,  1.1049,  0.0115,  0.7497, -0.7880,\n",
      "         -0.4942, -1.3003],\n",
      "        [-0.4731, -1.6159, -0.8523, -0.6263, -0.6986,  0.3814,  0.1076,  0.6572,\n",
      "          0.4781,  0.6935],\n",
      "        [-1.8885, -1.4418,  2.4473, -1.3181,  1.4204,  0.1147, -0.6199, -0.6909,\n",
      "          0.1789,  0.6183]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2858,  0.2355,  1.3697,  0.9167,  1.3603, -0.0726,  1.7963, -2.7218,\n",
      "          0.4440, -0.8430],\n",
      "        [ 0.3635,  0.9599, -0.6852, -0.6154,  1.1049,  0.0113,  0.7497, -0.7880,\n",
      "         -0.4944, -1.3003],\n",
      "        [-0.4735, -1.6158, -0.8523, -0.6264, -0.6986,  0.3817,  0.1076,  0.6572,\n",
      "          0.4781,  0.6935],\n",
      "        [-1.8887, -1.4418,  2.4473, -1.3182,  1.4204,  0.1148, -0.6199, -0.6909,\n",
      "          0.1789,  0.6183]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2859,  0.2361,  1.3696,  0.9165,  1.3603, -0.0727,  1.7963, -2.7218,\n",
      "          0.4437, -0.8430],\n",
      "        [ 0.3638,  0.9603, -0.6853, -0.6154,  1.1049,  0.0112,  0.7497, -0.7880,\n",
      "         -0.4946, -1.3003],\n",
      "        [-0.4739, -1.6156, -0.8523, -0.6266, -0.6986,  0.3819,  0.1076,  0.6572,\n",
      "          0.4780,  0.6935],\n",
      "        [-1.8889, -1.4418,  2.4473, -1.3182,  1.4204,  0.1149, -0.6199, -0.6909,\n",
      "          0.1789,  0.6183]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2860,  0.2366,  1.3695,  0.9164,  1.3603, -0.0728,  1.7963, -2.7218,\n",
      "          0.4435, -0.8430],\n",
      "        [ 0.3641,  0.9607, -0.6854, -0.6154,  1.1049,  0.0110,  0.7497, -0.7880,\n",
      "         -0.4948, -1.3003],\n",
      "        [-0.4743, -1.6155, -0.8523, -0.6268, -0.6986,  0.3822,  0.1076,  0.6572,\n",
      "          0.4780,  0.6934],\n",
      "        [-1.8891, -1.4418,  2.4473, -1.3183,  1.4204,  0.1150, -0.6199, -0.6909,\n",
      "          0.1789,  0.6183]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2861,  0.2371,  1.3694,  0.9163,  1.3603, -0.0728,  1.7963, -2.7218,\n",
      "          0.4432, -0.8430],\n",
      "        [ 0.3644,  0.9610, -0.6855, -0.6154,  1.1049,  0.0108,  0.7497, -0.7880,\n",
      "         -0.4950, -1.3003],\n",
      "        [-0.4748, -1.6153, -0.8523, -0.6270, -0.6986,  0.3825,  0.1076,  0.6572,\n",
      "          0.4779,  0.6934],\n",
      "        [-1.8893, -1.4418,  2.4473, -1.3184,  1.4204,  0.1152, -0.6199, -0.6909,\n",
      "          0.1789,  0.6183]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2862,  0.2377,  1.3693,  0.9162,  1.3603, -0.0729,  1.7963, -2.7218,\n",
      "          0.4429, -0.8431],\n",
      "        [ 0.3647,  0.9614, -0.6856, -0.6155,  1.1049,  0.0106,  0.7497, -0.7880,\n",
      "         -0.4952, -1.3004],\n",
      "        [-0.4752, -1.6152, -0.8524, -0.6272, -0.6986,  0.3828,  0.1076,  0.6572,\n",
      "          0.4779,  0.6934],\n",
      "        [-1.8894, -1.4417,  2.4473, -1.3184,  1.4204,  0.1153, -0.6199, -0.6909,\n",
      "          0.1789,  0.6182]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2863,  0.2382,  1.3691,  0.9160,  1.3603, -0.0729,  1.7963, -2.7218,\n",
      "          0.4427, -0.8431],\n",
      "        [ 0.3650,  0.9618, -0.6856, -0.6155,  1.1049,  0.0104,  0.7497, -0.7880,\n",
      "         -0.4954, -1.3004],\n",
      "        [-0.4756, -1.6150, -0.8524, -0.6273, -0.6986,  0.3830,  0.1076,  0.6572,\n",
      "          0.4778,  0.6934],\n",
      "        [-1.8896, -1.4417,  2.4473, -1.3185,  1.4204,  0.1154, -0.6199, -0.6909,\n",
      "          0.1789,  0.6182]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2864,  0.2387,  1.3690,  0.9159,  1.3603, -0.0730,  1.7963, -2.7218,\n",
      "          0.4424, -0.8431],\n",
      "        [ 0.3653,  0.9621, -0.6857, -0.6155,  1.1049,  0.0103,  0.7497, -0.7880,\n",
      "         -0.4956, -1.3004],\n",
      "        [-0.4760, -1.6149, -0.8524, -0.6275, -0.6986,  0.3833,  0.1076,  0.6572,\n",
      "          0.4778,  0.6933],\n",
      "        [-1.8898, -1.4417,  2.4473, -1.3186,  1.4204,  0.1155, -0.6199, -0.6909,\n",
      "          0.1789,  0.6182]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2865,  0.2393,  1.3689,  0.9158,  1.3603, -0.0730,  1.7963, -2.7218,\n",
      "          0.4421, -0.8432],\n",
      "        [ 0.3656,  0.9625, -0.6858, -0.6155,  1.1049,  0.0101,  0.7497, -0.7880,\n",
      "         -0.4958, -1.3004],\n",
      "        [-0.4764, -1.6148, -0.8524, -0.6277, -0.6986,  0.3836,  0.1076,  0.6572,\n",
      "          0.4777,  0.6933],\n",
      "        [-1.8900, -1.4417,  2.4473, -1.3186,  1.4204,  0.1157, -0.6199, -0.6909,\n",
      "          0.1789,  0.6182]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2866,  0.2398,  1.3688,  0.9157,  1.3603, -0.0731,  1.7963, -2.7218,\n",
      "          0.4418, -0.8432],\n",
      "        [ 0.3659,  0.9629, -0.6859, -0.6155,  1.1049,  0.0099,  0.7497, -0.7880,\n",
      "         -0.4960, -1.3004],\n",
      "        [-0.4768, -1.6146, -0.8525, -0.6279, -0.6986,  0.3839,  0.1076,  0.6572,\n",
      "          0.4777,  0.6933],\n",
      "        [-1.8901, -1.4417,  2.4473, -1.3187,  1.4204,  0.1158, -0.6199, -0.6909,\n",
      "          0.1789,  0.6182]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2868,  0.2403,  1.3687,  0.9156,  1.3603, -0.0732,  1.7963, -2.7218,\n",
      "          0.4416, -0.8432],\n",
      "        [ 0.3662,  0.9632, -0.6860, -0.6155,  1.1049,  0.0097,  0.7497, -0.7880,\n",
      "         -0.4962, -1.3004],\n",
      "        [-0.4772, -1.6145, -0.8525, -0.6280, -0.6986,  0.3841,  0.1076,  0.6572,\n",
      "          0.4776,  0.6933],\n",
      "        [-1.8903, -1.4416,  2.4473, -1.3188,  1.4204,  0.1159, -0.6199, -0.6909,\n",
      "          0.1789,  0.6182]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2869,  0.2409,  1.3686,  0.9155,  1.3603, -0.0732,  1.7963, -2.7218,\n",
      "          0.4413, -0.8432],\n",
      "        [ 0.3665,  0.9636, -0.6860, -0.6155,  1.1049,  0.0095,  0.7497, -0.7880,\n",
      "         -0.4964, -1.3004],\n",
      "        [-0.4776, -1.6143, -0.8525, -0.6282, -0.6986,  0.3844,  0.1076,  0.6572,\n",
      "          0.4776,  0.6932],\n",
      "        [-1.8905, -1.4416,  2.4473, -1.3188,  1.4204,  0.1160, -0.6199, -0.6909,\n",
      "          0.1789,  0.6182]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2870,  0.2414,  1.3685,  0.9153,  1.3603, -0.0733,  1.7963, -2.7218,\n",
      "          0.4410, -0.8433],\n",
      "        [ 0.3668,  0.9640, -0.6861, -0.6155,  1.1049,  0.0094,  0.7497, -0.7880,\n",
      "         -0.4966, -1.3005],\n",
      "        [-0.4781, -1.6142, -0.8525, -0.6284, -0.6986,  0.3847,  0.1076,  0.6572,\n",
      "          0.4775,  0.6932],\n",
      "        [-1.8907, -1.4416,  2.4473, -1.3189,  1.4204,  0.1162, -0.6199, -0.6909,\n",
      "          0.1789,  0.6182]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2871,  0.2419,  1.3684,  0.9152,  1.3603, -0.0733,  1.7963, -2.7218,\n",
      "          0.4408, -0.8433],\n",
      "        [ 0.3671,  0.9643, -0.6862, -0.6155,  1.1049,  0.0092,  0.7497, -0.7880,\n",
      "         -0.4968, -1.3005],\n",
      "        [-0.4785, -1.6141, -0.8526, -0.6286, -0.6986,  0.3849,  0.1076,  0.6572,\n",
      "          0.4775,  0.6932],\n",
      "        [-1.8908, -1.4416,  2.4473, -1.3190,  1.4204,  0.1163, -0.6199, -0.6909,\n",
      "          0.1789,  0.6182]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2872,  0.2424,  1.3683,  0.9151,  1.3603, -0.0734,  1.7963, -2.7218,\n",
      "          0.4405, -0.8433],\n",
      "        [ 0.3674,  0.9647, -0.6863, -0.6155,  1.1049,  0.0090,  0.7497, -0.7880,\n",
      "         -0.4970, -1.3005],\n",
      "        [-0.4789, -1.6139, -0.8526, -0.6287, -0.6986,  0.3852,  0.1076,  0.6572,\n",
      "          0.4774,  0.6932],\n",
      "        [-1.8910, -1.4416,  2.4473, -1.3190,  1.4204,  0.1164, -0.6199, -0.6909,\n",
      "          0.1789,  0.6182]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2873,  0.2429,  1.3681,  0.9150,  1.3603, -0.0735,  1.7963, -2.7218,\n",
      "          0.4402, -0.8434],\n",
      "        [ 0.3677,  0.9650, -0.6864, -0.6155,  1.1049,  0.0088,  0.7497, -0.7880,\n",
      "         -0.4972, -1.3005],\n",
      "        [-0.4793, -1.6138, -0.8526, -0.6289, -0.6986,  0.3855,  0.1076,  0.6572,\n",
      "          0.4774,  0.6932],\n",
      "        [-1.8912, -1.4415,  2.4473, -1.3191,  1.4204,  0.1165, -0.6199, -0.6909,\n",
      "          0.1789,  0.6182]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2874,  0.2435,  1.3680,  0.9149,  1.3603, -0.0735,  1.7963, -2.7218,\n",
      "          0.4400, -0.8434],\n",
      "        [ 0.3680,  0.9654, -0.6865, -0.6155,  1.1049,  0.0086,  0.7497, -0.7880,\n",
      "         -0.4974, -1.3005],\n",
      "        [-0.4797, -1.6136, -0.8526, -0.6291, -0.6986,  0.3858,  0.1076,  0.6572,\n",
      "          0.4773,  0.6931],\n",
      "        [-1.8914, -1.4415,  2.4473, -1.3192,  1.4204,  0.1166, -0.6199, -0.6909,\n",
      "          0.1789,  0.6182]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2875,  0.2440,  1.3679,  0.9148,  1.3603, -0.0736,  1.7963, -2.7218,\n",
      "          0.4397, -0.8434],\n",
      "        [ 0.3683,  0.9658, -0.6865, -0.6155,  1.1049,  0.0085,  0.7497, -0.7880,\n",
      "         -0.4976, -1.3005],\n",
      "        [-0.4801, -1.6135, -0.8526, -0.6293, -0.6986,  0.3860,  0.1076,  0.6572,\n",
      "          0.4773,  0.6931],\n",
      "        [-1.8915, -1.4415,  2.4473, -1.3192,  1.4204,  0.1168, -0.6199, -0.6909,\n",
      "          0.1789,  0.6181]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2876,  0.2445,  1.3678,  0.9146,  1.3603, -0.0736,  1.7963, -2.7218,\n",
      "          0.4394, -0.8435],\n",
      "        [ 0.3686,  0.9661, -0.6866, -0.6156,  1.1049,  0.0083,  0.7497, -0.7880,\n",
      "         -0.4978, -1.3005],\n",
      "        [-0.4805, -1.6134, -0.8527, -0.6294, -0.6986,  0.3863,  0.1076,  0.6572,\n",
      "          0.4773,  0.6931],\n",
      "        [-1.8917, -1.4415,  2.4473, -1.3193,  1.4204,  0.1169, -0.6199, -0.6909,\n",
      "          0.1789,  0.6181]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2877,  0.2450,  1.3677,  0.9145,  1.3603, -0.0737,  1.7963, -2.7218,\n",
      "          0.4391, -0.8435],\n",
      "        [ 0.3688,  0.9665, -0.6867, -0.6156,  1.1049,  0.0081,  0.7497, -0.7880,\n",
      "         -0.4980, -1.3005],\n",
      "        [-0.4809, -1.6132, -0.8527, -0.6296, -0.6986,  0.3866,  0.1076,  0.6572,\n",
      "          0.4772,  0.6931],\n",
      "        [-1.8919, -1.4415,  2.4473, -1.3194,  1.4204,  0.1170, -0.6199, -0.6909,\n",
      "          0.1789,  0.6181]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2878,  0.2455,  1.3676,  0.9144,  1.3603, -0.0738,  1.7963, -2.7218,\n",
      "          0.4389, -0.8435],\n",
      "        [ 0.3691,  0.9668, -0.6868, -0.6156,  1.1049,  0.0079,  0.7497, -0.7880,\n",
      "         -0.4982, -1.3006],\n",
      "        [-0.4813, -1.6131, -0.8527, -0.6298, -0.6986,  0.3868,  0.1076,  0.6572,\n",
      "          0.4772,  0.6930],\n",
      "        [-1.8921, -1.4414,  2.4473, -1.3194,  1.4204,  0.1171, -0.6199, -0.6909,\n",
      "          0.1789,  0.6181]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2879,  0.2460,  1.3675,  0.9143,  1.3603, -0.0738,  1.7963, -2.7218,\n",
      "          0.4386, -0.8435],\n",
      "        [ 0.3694,  0.9672, -0.6869, -0.6156,  1.1049,  0.0077,  0.7497, -0.7880,\n",
      "         -0.4984, -1.3006],\n",
      "        [-0.4817, -1.6130, -0.8527, -0.6300, -0.6986,  0.3871,  0.1076,  0.6572,\n",
      "          0.4771,  0.6930],\n",
      "        [-1.8922, -1.4414,  2.4473, -1.3195,  1.4204,  0.1173, -0.6199, -0.6909,\n",
      "          0.1789,  0.6181]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2880,  0.2465,  1.3674,  0.9142,  1.3603, -0.0739,  1.7963, -2.7218,\n",
      "          0.4383, -0.8436],\n",
      "        [ 0.3697,  0.9675, -0.6869, -0.6156,  1.1049,  0.0076,  0.7497, -0.7880,\n",
      "         -0.4986, -1.3006],\n",
      "        [-0.4821, -1.6128, -0.8528, -0.6301, -0.6986,  0.3874,  0.1076,  0.6572,\n",
      "          0.4771,  0.6930],\n",
      "        [-1.8924, -1.4414,  2.4473, -1.3196,  1.4204,  0.1174, -0.6199, -0.6909,\n",
      "          0.1789,  0.6181]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2881,  0.2470,  1.3672,  0.9141,  1.3603, -0.0740,  1.7963, -2.7218,\n",
      "          0.4381, -0.8436],\n",
      "        [ 0.3700,  0.9679, -0.6870, -0.6156,  1.1049,  0.0074,  0.7497, -0.7880,\n",
      "         -0.4988, -1.3006],\n",
      "        [-0.4825, -1.6127, -0.8528, -0.6303, -0.6986,  0.3876,  0.1076,  0.6572,\n",
      "          0.4770,  0.6930],\n",
      "        [-1.8926, -1.4414,  2.4473, -1.3196,  1.4204,  0.1175, -0.6199, -0.6909,\n",
      "          0.1789,  0.6181]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2882,  0.2475,  1.3671,  0.9140,  1.3603, -0.0740,  1.7963, -2.7218,\n",
      "          0.4378, -0.8436],\n",
      "        [ 0.3703,  0.9682, -0.6871, -0.6156,  1.1049,  0.0072,  0.7497, -0.7880,\n",
      "         -0.4990, -1.3006],\n",
      "        [-0.4829, -1.6126, -0.8528, -0.6305, -0.6986,  0.3879,  0.1076,  0.6572,\n",
      "          0.4770,  0.6929],\n",
      "        [-1.8927, -1.4414,  2.4473, -1.3197,  1.4204,  0.1176, -0.6199, -0.6909,\n",
      "          0.1789,  0.6181]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2883,  0.2480,  1.3670,  0.9138,  1.3603, -0.0741,  1.7963, -2.7218,\n",
      "          0.4375, -0.8437],\n",
      "        [ 0.3706,  0.9686, -0.6872, -0.6156,  1.1049,  0.0070,  0.7497, -0.7880,\n",
      "         -0.4992, -1.3006],\n",
      "        [-0.4833, -1.6125, -0.8528, -0.6307, -0.6986,  0.3882,  0.1076,  0.6572,\n",
      "          0.4769,  0.6929],\n",
      "        [-1.8929, -1.4414,  2.4473, -1.3197,  1.4204,  0.1177, -0.6199, -0.6909,\n",
      "          0.1789,  0.6181]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2884,  0.2485,  1.3669,  0.9137,  1.3603, -0.0741,  1.7963, -2.7218,\n",
      "          0.4372, -0.8437],\n",
      "        [ 0.3709,  0.9689, -0.6873, -0.6156,  1.1049,  0.0068,  0.7497, -0.7880,\n",
      "         -0.4994, -1.3006],\n",
      "        [-0.4837, -1.6123, -0.8529, -0.6308, -0.6986,  0.3885,  0.1076,  0.6572,\n",
      "          0.4769,  0.6929],\n",
      "        [-1.8931, -1.4413,  2.4473, -1.3198,  1.4204,  0.1179, -0.6199, -0.6909,\n",
      "          0.1789,  0.6181]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2885,  0.2490,  1.3668,  0.9136,  1.3603, -0.0742,  1.7963, -2.7218,\n",
      "          0.4370, -0.8437],\n",
      "        [ 0.3712,  0.9692, -0.6874, -0.6156,  1.1049,  0.0067,  0.7497, -0.7880,\n",
      "         -0.4996, -1.3006],\n",
      "        [-0.4841, -1.6122, -0.8529, -0.6310, -0.6986,  0.3887,  0.1076,  0.6572,\n",
      "          0.4768,  0.6929],\n",
      "        [-1.8933, -1.4413,  2.4473, -1.3199,  1.4204,  0.1180, -0.6199, -0.6909,\n",
      "          0.1789,  0.6181]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2886,  0.2495,  1.3667,  0.9135,  1.3603, -0.0743,  1.7963, -2.7218,\n",
      "          0.4367, -0.8437],\n",
      "        [ 0.3715,  0.9696, -0.6874, -0.6156,  1.1049,  0.0065,  0.7497, -0.7880,\n",
      "         -0.4998, -1.3007],\n",
      "        [-0.4846, -1.6121, -0.8529, -0.6312, -0.6986,  0.3890,  0.1076,  0.6572,\n",
      "          0.4768,  0.6928],\n",
      "        [-1.8934, -1.4413,  2.4473, -1.3199,  1.4204,  0.1181, -0.6199, -0.6909,\n",
      "          0.1790,  0.6181]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2887,  0.2500,  1.3666,  0.9134,  1.3603, -0.0743,  1.7963, -2.7218,\n",
      "          0.4364, -0.8438],\n",
      "        [ 0.3718,  0.9699, -0.6875, -0.6156,  1.1049,  0.0063,  0.7497, -0.7880,\n",
      "         -0.5000, -1.3007],\n",
      "        [-0.4850, -1.6119, -0.8529, -0.6314, -0.6986,  0.3892,  0.1076,  0.6572,\n",
      "          0.4767,  0.6928],\n",
      "        [-1.8936, -1.4413,  2.4473, -1.3200,  1.4204,  0.1182, -0.6199, -0.6909,\n",
      "          0.1790,  0.6180]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2888,  0.2505,  1.3665,  0.9133,  1.3603, -0.0744,  1.7963, -2.7218,\n",
      "          0.4361, -0.8438],\n",
      "        [ 0.3721,  0.9703, -0.6876, -0.6156,  1.1049,  0.0061,  0.7497, -0.7880,\n",
      "         -0.5002, -1.3007],\n",
      "        [-0.4854, -1.6118, -0.8529, -0.6315, -0.6986,  0.3895,  0.1076,  0.6572,\n",
      "          0.4767,  0.6928],\n",
      "        [-1.8938, -1.4413,  2.4473, -1.3201,  1.4204,  0.1183, -0.6199, -0.6909,\n",
      "          0.1790,  0.6180]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2889,  0.2510,  1.3664,  0.9132,  1.3603, -0.0745,  1.7963, -2.7218,\n",
      "          0.4359, -0.8438],\n",
      "        [ 0.3723,  0.9706, -0.6877, -0.6156,  1.1049,  0.0059,  0.7497, -0.7880,\n",
      "         -0.5004, -1.3007],\n",
      "        [-0.4858, -1.6117, -0.8530, -0.6317, -0.6986,  0.3898,  0.1076,  0.6572,\n",
      "          0.4766,  0.6928],\n",
      "        [-1.8939, -1.4413,  2.4473, -1.3201,  1.4204,  0.1185, -0.6199, -0.6909,\n",
      "          0.1790,  0.6180]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2890,  0.2514,  1.3662,  0.9131,  1.3603, -0.0745,  1.7963, -2.7218,\n",
      "          0.4356, -0.8439],\n",
      "        [ 0.3726,  0.9709, -0.6878, -0.6156,  1.1049,  0.0058,  0.7497, -0.7880,\n",
      "         -0.5006, -1.3007],\n",
      "        [-0.4862, -1.6116, -0.8530, -0.6319, -0.6986,  0.3900,  0.1076,  0.6572,\n",
      "          0.4766,  0.6928],\n",
      "        [-1.8941, -1.4412,  2.4473, -1.3202,  1.4204,  0.1186, -0.6199, -0.6909,\n",
      "          0.1790,  0.6180]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2891,  0.2519,  1.3661,  0.9129,  1.3603, -0.0746,  1.7963, -2.7218,\n",
      "          0.4353, -0.8439],\n",
      "        [ 0.3729,  0.9713, -0.6878, -0.6156,  1.1049,  0.0056,  0.7497, -0.7880,\n",
      "         -0.5008, -1.3007],\n",
      "        [-0.4866, -1.6114, -0.8530, -0.6320, -0.6986,  0.3903,  0.1076,  0.6572,\n",
      "          0.4765,  0.6927],\n",
      "        [-1.8943, -1.4412,  2.4473, -1.3203,  1.4204,  0.1187, -0.6199, -0.6909,\n",
      "          0.1790,  0.6180]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2892,  0.2524,  1.3660,  0.9128,  1.3603, -0.0747,  1.7963, -2.7218,\n",
      "          0.4351, -0.8439],\n",
      "        [ 0.3732,  0.9716, -0.6879, -0.6156,  1.1049,  0.0054,  0.7497, -0.7880,\n",
      "         -0.5010, -1.3007],\n",
      "        [-0.4870, -1.6113, -0.8530, -0.6322, -0.6986,  0.3906,  0.1076,  0.6572,\n",
      "          0.4765,  0.6927],\n",
      "        [-1.8945, -1.4412,  2.4473, -1.3203,  1.4204,  0.1188, -0.6199, -0.6909,\n",
      "          0.1790,  0.6180]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2893,  0.2529,  1.3659,  0.9127,  1.3603, -0.0747,  1.7963, -2.7218,\n",
      "          0.4348, -0.8439],\n",
      "        [ 0.3735,  0.9719, -0.6880, -0.6156,  1.1049,  0.0052,  0.7497, -0.7880,\n",
      "         -0.5012, -1.3007],\n",
      "        [-0.4874, -1.6112, -0.8531, -0.6324, -0.6986,  0.3908,  0.1076,  0.6572,\n",
      "          0.4764,  0.6927],\n",
      "        [-1.8946, -1.4412,  2.4473, -1.3204,  1.4204,  0.1189, -0.6199, -0.6909,\n",
      "          0.1790,  0.6180]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2894,  0.2534,  1.3658,  0.9126,  1.3603, -0.0748,  1.7963, -2.7218,\n",
      "          0.4345, -0.8440],\n",
      "        [ 0.3738,  0.9723, -0.6881, -0.6156,  1.1049,  0.0050,  0.7497, -0.7880,\n",
      "         -0.5014, -1.3008],\n",
      "        [-0.4877, -1.6111, -0.8531, -0.6326, -0.6986,  0.3911,  0.1076,  0.6572,\n",
      "          0.4764,  0.6927],\n",
      "        [-1.8948, -1.4412,  2.4473, -1.3205,  1.4204,  0.1191, -0.6199, -0.6909,\n",
      "          0.1790,  0.6180]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2895,  0.2538,  1.3657,  0.9125,  1.3603, -0.0749,  1.7963, -2.7218,\n",
      "          0.4342, -0.8440],\n",
      "        [ 0.3741,  0.9726, -0.6882, -0.6156,  1.1049,  0.0049,  0.7497, -0.7880,\n",
      "         -0.5016, -1.3008],\n",
      "        [-0.4881, -1.6109, -0.8531, -0.6327, -0.6986,  0.3914,  0.1076,  0.6572,\n",
      "          0.4763,  0.6926],\n",
      "        [-1.8950, -1.4412,  2.4473, -1.3205,  1.4204,  0.1192, -0.6199, -0.6909,\n",
      "          0.1790,  0.6180]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2896,  0.2543,  1.3656,  0.9124,  1.3603, -0.0749,  1.7963, -2.7218,\n",
      "          0.4340, -0.8440],\n",
      "        [ 0.3744,  0.9729, -0.6883, -0.6156,  1.1049,  0.0047,  0.7497, -0.7880,\n",
      "         -0.5018, -1.3008],\n",
      "        [-0.4885, -1.6108, -0.8531, -0.6329, -0.6986,  0.3916,  0.1076,  0.6572,\n",
      "          0.4763,  0.6926],\n",
      "        [-1.8951, -1.4411,  2.4473, -1.3206,  1.4204,  0.1193, -0.6199, -0.6909,\n",
      "          0.1790,  0.6180]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2897,  0.2548,  1.3655,  0.9123,  1.3603, -0.0750,  1.7963, -2.7218,\n",
      "          0.4337, -0.8440],\n",
      "        [ 0.3746,  0.9733, -0.6883, -0.6156,  1.1049,  0.0045,  0.7497, -0.7880,\n",
      "         -0.5020, -1.3008],\n",
      "        [-0.4889, -1.6107, -0.8531, -0.6331, -0.6986,  0.3919,  0.1076,  0.6572,\n",
      "          0.4762,  0.6926],\n",
      "        [-1.8953, -1.4411,  2.4473, -1.3206,  1.4204,  0.1194, -0.6199, -0.6909,\n",
      "          0.1790,  0.6180]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2898,  0.2553,  1.3653,  0.9122,  1.3603, -0.0751,  1.7963, -2.7218,\n",
      "          0.4334, -0.8441],\n",
      "        [ 0.3749,  0.9736, -0.6884, -0.6156,  1.1049,  0.0043,  0.7497, -0.7880,\n",
      "         -0.5022, -1.3008],\n",
      "        [-0.4893, -1.6106, -0.8532, -0.6332, -0.6986,  0.3921,  0.1076,  0.6572,\n",
      "          0.4762,  0.6926],\n",
      "        [-1.8955, -1.4411,  2.4473, -1.3207,  1.4204,  0.1195, -0.6199, -0.6909,\n",
      "          0.1790,  0.6180]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2899,  0.2557,  1.3652,  0.9121,  1.3603, -0.0751,  1.7963, -2.7218,\n",
      "          0.4331, -0.8441],\n",
      "        [ 0.3752,  0.9739, -0.6885, -0.6157,  1.1049,  0.0041,  0.7497, -0.7880,\n",
      "         -0.5024, -1.3008],\n",
      "        [-0.4897, -1.6105, -0.8532, -0.6334, -0.6986,  0.3924,  0.1076,  0.6572,\n",
      "          0.4762,  0.6925],\n",
      "        [-1.8956, -1.4411,  2.4473, -1.3208,  1.4204,  0.1197, -0.6199, -0.6909,\n",
      "          0.1790,  0.6180]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2900,  0.2562,  1.3651,  0.9120,  1.3603, -0.0752,  1.7963, -2.7218,\n",
      "          0.4329, -0.8441],\n",
      "        [ 0.3755,  0.9742, -0.6886, -0.6157,  1.1049,  0.0040,  0.7497, -0.7880,\n",
      "         -0.5026, -1.3008],\n",
      "        [-0.4901, -1.6103, -0.8532, -0.6336, -0.6986,  0.3927,  0.1076,  0.6572,\n",
      "          0.4761,  0.6925],\n",
      "        [-1.8958, -1.4411,  2.4473, -1.3208,  1.4204,  0.1198, -0.6199, -0.6909,\n",
      "          0.1790,  0.6179]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2901,  0.2567,  1.3650,  0.9119,  1.3603, -0.0753,  1.7963, -2.7218,\n",
      "          0.4326, -0.8442],\n",
      "        [ 0.3758,  0.9746, -0.6887, -0.6157,  1.1049,  0.0038,  0.7497, -0.7880,\n",
      "         -0.5028, -1.3008],\n",
      "        [-0.4905, -1.6102, -0.8532, -0.6338, -0.6986,  0.3929,  0.1076,  0.6572,\n",
      "          0.4761,  0.6925],\n",
      "        [-1.8960, -1.4411,  2.4473, -1.3209,  1.4204,  0.1199, -0.6199, -0.6909,\n",
      "          0.1790,  0.6179]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2902,  0.2571,  1.3649,  0.9118,  1.3603, -0.0754,  1.7963, -2.7218,\n",
      "          0.4323, -0.8442],\n",
      "        [ 0.3761,  0.9749, -0.6887, -0.6157,  1.1049,  0.0036,  0.7497, -0.7880,\n",
      "         -0.5030, -1.3009],\n",
      "        [-0.4909, -1.6101, -0.8533, -0.6339, -0.6986,  0.3932,  0.1076,  0.6572,\n",
      "          0.4760,  0.6925],\n",
      "        [-1.8961, -1.4410,  2.4473, -1.3210,  1.4204,  0.1200, -0.6199, -0.6909,\n",
      "          0.1790,  0.6179]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2903,  0.2576,  1.3648,  0.9116,  1.3603, -0.0754,  1.7963, -2.7218,\n",
      "          0.4320, -0.8442],\n",
      "        [ 0.3763,  0.9752, -0.6888, -0.6157,  1.1049,  0.0034,  0.7497, -0.7880,\n",
      "         -0.5032, -1.3009],\n",
      "        [-0.4913, -1.6100, -0.8533, -0.6341, -0.6986,  0.3934,  0.1076,  0.6572,\n",
      "          0.4760,  0.6925],\n",
      "        [-1.8963, -1.4410,  2.4473, -1.3210,  1.4204,  0.1201, -0.6199, -0.6909,\n",
      "          0.1790,  0.6179]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2904,  0.2580,  1.3647,  0.9115,  1.3603, -0.0755,  1.7963, -2.7218,\n",
      "          0.4318, -0.8442],\n",
      "        [ 0.3766,  0.9755, -0.6889, -0.6157,  1.1049,  0.0032,  0.7497, -0.7880,\n",
      "         -0.5034, -1.3009],\n",
      "        [-0.4917, -1.6099, -0.8533, -0.6343, -0.6986,  0.3937,  0.1076,  0.6572,\n",
      "          0.4759,  0.6924],\n",
      "        [-1.8965, -1.4410,  2.4473, -1.3211,  1.4204,  0.1202, -0.6199, -0.6909,\n",
      "          0.1790,  0.6179]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2905,  0.2585,  1.3646,  0.9114,  1.3603, -0.0756,  1.7963, -2.7218,\n",
      "          0.4315, -0.8443],\n",
      "        [ 0.3769,  0.9759, -0.6890, -0.6157,  1.1049,  0.0030,  0.7497, -0.7880,\n",
      "         -0.5036, -1.3009],\n",
      "        [-0.4921, -1.6097, -0.8533, -0.6344, -0.6986,  0.3940,  0.1076,  0.6572,\n",
      "          0.4759,  0.6924],\n",
      "        [-1.8966, -1.4410,  2.4473, -1.3211,  1.4204,  0.1204, -0.6199, -0.6909,\n",
      "          0.1790,  0.6179]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2906,  0.2590,  1.3645,  0.9113,  1.3603, -0.0756,  1.7963, -2.7218,\n",
      "          0.4312, -0.8443],\n",
      "        [ 0.3772,  0.9762, -0.6891, -0.6157,  1.1049,  0.0029,  0.7497, -0.7880,\n",
      "         -0.5038, -1.3009],\n",
      "        [-0.4925, -1.6096, -0.8534, -0.6346, -0.6986,  0.3942,  0.1076,  0.6572,\n",
      "          0.4758,  0.6924],\n",
      "        [-1.8968, -1.4410,  2.4473, -1.3212,  1.4204,  0.1205, -0.6199, -0.6909,\n",
      "          0.1790,  0.6179]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9075e-01,  2.5942e-01,  1.3643e+00,  9.1123e-01,  1.3603e+00,\n",
      "         -7.5702e-02,  1.7963e+00, -2.7218e+00,  4.3094e-01, -8.4433e-01],\n",
      "        [ 3.7748e-01,  9.7649e-01, -6.8915e-01, -6.1567e-01,  1.1049e+00,\n",
      "          2.6843e-03,  7.4967e-01, -7.8798e-01, -5.0404e-01, -1.3009e+00],\n",
      "        [-4.9288e-01, -1.6095e+00, -8.5338e-01, -6.3476e-01, -6.9855e-01,\n",
      "          3.9448e-01,  1.0762e-01,  6.5721e-01,  4.7577e-01,  6.9237e-01],\n",
      "        [-1.8970e+00, -1.4410e+00,  2.4473e+00, -1.3213e+00,  1.4204e+00,\n",
      "          1.2060e-01, -6.1993e-01, -6.9090e-01,  1.7896e-01,  6.1789e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9085e-01,  2.5987e-01,  1.3642e+00,  9.1112e-01,  1.3603e+00,\n",
      "         -7.5773e-02,  1.7963e+00, -2.7218e+00,  4.3067e-01, -8.4435e-01],\n",
      "        [ 3.7776e-01,  9.7681e-01, -6.8923e-01, -6.1567e-01,  1.1049e+00,\n",
      "          2.5027e-03,  7.4967e-01, -7.8798e-01, -5.0425e-01, -1.3009e+00],\n",
      "        [-4.9327e-01, -1.6094e+00, -8.5340e-01, -6.3493e-01, -6.9855e-01,\n",
      "          3.9474e-01,  1.0762e-01,  6.5721e-01,  4.7572e-01,  6.9235e-01],\n",
      "        [-1.8971e+00, -1.4410e+00,  2.4473e+00, -1.3213e+00,  1.4204e+00,\n",
      "          1.2072e-01, -6.1993e-01, -6.9090e-01,  1.7896e-01,  6.1788e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9094e-01,  2.6033e-01,  1.3641e+00,  9.1102e-01,  1.3603e+00,\n",
      "         -7.5844e-02,  1.7963e+00, -2.7218e+00,  4.3039e-01, -8.4438e-01],\n",
      "        [ 3.7804e-01,  9.7713e-01, -6.8931e-01, -6.1567e-01,  1.1049e+00,\n",
      "          2.3210e-03,  7.4967e-01, -7.8798e-01, -5.0445e-01, -1.3009e+00],\n",
      "        [-4.9366e-01, -1.6093e+00, -8.5342e-01, -6.3510e-01, -6.9855e-01,\n",
      "          3.9500e-01,  1.0762e-01,  6.5721e-01,  4.7568e-01,  6.9232e-01],\n",
      "        [-1.8973e+00, -1.4409e+00,  2.4473e+00, -1.3214e+00,  1.4204e+00,\n",
      "          1.2083e-01, -6.1993e-01, -6.9090e-01,  1.7896e-01,  6.1788e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9104e-01,  2.6078e-01,  1.3640e+00,  9.1091e-01,  1.3603e+00,\n",
      "         -7.5915e-02,  1.7963e+00, -2.7218e+00,  4.3012e-01, -8.4441e-01],\n",
      "        [ 3.7832e-01,  9.7744e-01, -6.8939e-01, -6.1567e-01,  1.1049e+00,\n",
      "          2.1392e-03,  7.4967e-01, -7.8798e-01, -5.0466e-01, -1.3010e+00],\n",
      "        [-4.9405e-01, -1.6092e+00, -8.5345e-01, -6.3526e-01, -6.9855e-01,\n",
      "          3.9526e-01,  1.0762e-01,  6.5721e-01,  4.7563e-01,  6.9230e-01],\n",
      "        [-1.8975e+00, -1.4409e+00,  2.4473e+00, -1.3215e+00,  1.4204e+00,\n",
      "          1.2095e-01, -6.1993e-01, -6.9090e-01,  1.7896e-01,  6.1787e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9114e-01,  2.6123e-01,  1.3639e+00,  9.1081e-01,  1.3603e+00,\n",
      "         -7.5987e-02,  1.7963e+00, -2.7218e+00,  4.2984e-01, -8.4444e-01],\n",
      "        [ 3.7860e-01,  9.7775e-01, -6.8947e-01, -6.1567e-01,  1.1049e+00,\n",
      "          1.9574e-03,  7.4967e-01, -7.8798e-01, -5.0486e-01, -1.3010e+00],\n",
      "        [-4.9444e-01, -1.6091e+00, -8.5347e-01, -6.3543e-01, -6.9855e-01,\n",
      "          3.9551e-01,  1.0762e-01,  6.5721e-01,  4.7558e-01,  6.9228e-01],\n",
      "        [-1.8976e+00, -1.4409e+00,  2.4473e+00, -1.3215e+00,  1.4204e+00,\n",
      "          1.2107e-01, -6.1993e-01, -6.9090e-01,  1.7896e-01,  6.1786e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9124e-01,  2.6167e-01,  1.3638e+00,  9.1070e-01,  1.3603e+00,\n",
      "         -7.6059e-02,  1.7963e+00, -2.7218e+00,  4.2956e-01, -8.4446e-01],\n",
      "        [ 3.7888e-01,  9.7807e-01, -6.8956e-01, -6.1567e-01,  1.1049e+00,\n",
      "          1.7755e-03,  7.4967e-01, -7.8798e-01, -5.0507e-01, -1.3010e+00],\n",
      "        [-4.9483e-01, -1.6089e+00, -8.5349e-01, -6.3560e-01, -6.9855e-01,\n",
      "          3.9577e-01,  1.0762e-01,  6.5721e-01,  4.7553e-01,  6.9226e-01],\n",
      "        [-1.8978e+00, -1.4409e+00,  2.4473e+00, -1.3216e+00,  1.4204e+00,\n",
      "          1.2118e-01, -6.1993e-01, -6.9090e-01,  1.7896e-01,  6.1785e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9134e-01,  2.6212e-01,  1.3637e+00,  9.1060e-01,  1.3603e+00,\n",
      "         -7.6131e-02,  1.7963e+00, -2.7218e+00,  4.2929e-01, -8.4449e-01],\n",
      "        [ 3.7916e-01,  9.7838e-01, -6.8964e-01, -6.1567e-01,  1.1049e+00,\n",
      "          1.5936e-03,  7.4967e-01, -7.8798e-01, -5.0527e-01, -1.3010e+00],\n",
      "        [-4.9522e-01, -1.6088e+00, -8.5352e-01, -6.3576e-01, -6.9855e-01,\n",
      "          3.9603e-01,  1.0762e-01,  6.5721e-01,  4.7549e-01,  6.9223e-01],\n",
      "        [-1.8980e+00, -1.4409e+00,  2.4473e+00, -1.3216e+00,  1.4204e+00,\n",
      "          1.2130e-01, -6.1993e-01, -6.9090e-01,  1.7896e-01,  6.1784e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9144e-01,  2.6256e-01,  1.3636e+00,  9.1050e-01,  1.3603e+00,\n",
      "         -7.6203e-02,  1.7963e+00, -2.7218e+00,  4.2901e-01, -8.4452e-01],\n",
      "        [ 3.7944e-01,  9.7869e-01, -6.8972e-01, -6.1567e-01,  1.1049e+00,\n",
      "          1.4117e-03,  7.4967e-01, -7.8798e-01, -5.0548e-01, -1.3010e+00],\n",
      "        [-4.9561e-01, -1.6087e+00, -8.5354e-01, -6.3593e-01, -6.9855e-01,\n",
      "          3.9628e-01,  1.0762e-01,  6.5721e-01,  4.7544e-01,  6.9221e-01],\n",
      "        [-1.8981e+00, -1.4409e+00,  2.4473e+00, -1.3217e+00,  1.4204e+00,\n",
      "          1.2142e-01, -6.1993e-01, -6.9090e-01,  1.7896e-01,  6.1784e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9153e-01,  2.6300e-01,  1.3635e+00,  9.1040e-01,  1.3603e+00,\n",
      "         -7.6276e-02,  1.7963e+00, -2.7218e+00,  4.2874e-01, -8.4455e-01],\n",
      "        [ 3.7972e-01,  9.7900e-01, -6.8980e-01, -6.1567e-01,  1.1049e+00,\n",
      "          1.2297e-03,  7.4967e-01, -7.8798e-01, -5.0568e-01, -1.3010e+00],\n",
      "        [-4.9599e-01, -1.6086e+00, -8.5356e-01, -6.3610e-01, -6.9855e-01,\n",
      "          3.9654e-01,  1.0762e-01,  6.5721e-01,  4.7539e-01,  6.9219e-01],\n",
      "        [-1.8983e+00, -1.4409e+00,  2.4473e+00, -1.3218e+00,  1.4204e+00,\n",
      "          1.2153e-01, -6.1993e-01, -6.9090e-01,  1.7897e-01,  6.1783e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9163e-01,  2.6344e-01,  1.3633e+00,  9.1029e-01,  1.3603e+00,\n",
      "         -7.6348e-02,  1.7963e+00, -2.7218e+00,  4.2846e-01, -8.4457e-01],\n",
      "        [ 3.8000e-01,  9.7930e-01, -6.8988e-01, -6.1567e-01,  1.1049e+00,\n",
      "          1.0477e-03,  7.4967e-01, -7.8798e-01, -5.0589e-01, -1.3010e+00],\n",
      "        [-4.9638e-01, -1.6085e+00, -8.5358e-01, -6.3626e-01, -6.9855e-01,\n",
      "          3.9679e-01,  1.0762e-01,  6.5721e-01,  4.7534e-01,  6.9217e-01],\n",
      "        [-1.8985e+00, -1.4408e+00,  2.4473e+00, -1.3218e+00,  1.4204e+00,\n",
      "          1.2165e-01, -6.1993e-01, -6.9090e-01,  1.7897e-01,  6.1782e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9173e-01,  2.6388e-01,  1.3632e+00,  9.1019e-01,  1.3603e+00,\n",
      "         -7.6421e-02,  1.7963e+00, -2.7218e+00,  4.2818e-01, -8.4460e-01],\n",
      "        [ 3.8028e-01,  9.7961e-01, -6.8996e-01, -6.1567e-01,  1.1049e+00,\n",
      "          8.6559e-04,  7.4967e-01, -7.8798e-01, -5.0609e-01, -1.3010e+00],\n",
      "        [-4.9677e-01, -1.6084e+00, -8.5361e-01, -6.3643e-01, -6.9855e-01,\n",
      "          3.9705e-01,  1.0762e-01,  6.5721e-01,  4.7530e-01,  6.9214e-01],\n",
      "        [-1.8986e+00, -1.4408e+00,  2.4473e+00, -1.3219e+00,  1.4204e+00,\n",
      "          1.2177e-01, -6.1993e-01, -6.9090e-01,  1.7897e-01,  6.1781e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9183e-01,  2.6432e-01,  1.3631e+00,  9.1009e-01,  1.3603e+00,\n",
      "         -7.6495e-02,  1.7963e+00, -2.7218e+00,  4.2791e-01, -8.4463e-01],\n",
      "        [ 3.8056e-01,  9.7992e-01, -6.9005e-01, -6.1567e-01,  1.1049e+00,\n",
      "          6.8348e-04,  7.4967e-01, -7.8798e-01, -5.0630e-01, -1.3011e+00],\n",
      "        [-4.9716e-01, -1.6083e+00, -8.5363e-01, -6.3659e-01, -6.9855e-01,\n",
      "          3.9730e-01,  1.0762e-01,  6.5721e-01,  4.7525e-01,  6.9212e-01],\n",
      "        [-1.8988e+00, -1.4408e+00,  2.4473e+00, -1.3220e+00,  1.4204e+00,\n",
      "          1.2188e-01, -6.1993e-01, -6.9090e-01,  1.7897e-01,  6.1781e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9192e-01,  2.6476e-01,  1.3630e+00,  9.0999e-01,  1.3603e+00,\n",
      "         -7.6568e-02,  1.7963e+00, -2.7218e+00,  4.2763e-01, -8.4466e-01],\n",
      "        [ 3.8083e-01,  9.8022e-01, -6.9013e-01, -6.1567e-01,  1.1049e+00,\n",
      "          5.0133e-04,  7.4967e-01, -7.8798e-01, -5.0650e-01, -1.3011e+00],\n",
      "        [-4.9754e-01, -1.6082e+00, -8.5365e-01, -6.3676e-01, -6.9855e-01,\n",
      "          3.9756e-01,  1.0762e-01,  6.5721e-01,  4.7520e-01,  6.9210e-01],\n",
      "        [-1.8990e+00, -1.4408e+00,  2.4473e+00, -1.3220e+00,  1.4204e+00,\n",
      "          1.2200e-01, -6.1993e-01, -6.9090e-01,  1.7897e-01,  6.1780e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9202e-01,  2.6519e-01,  1.3629e+00,  9.0989e-01,  1.3603e+00,\n",
      "         -7.6642e-02,  1.7963e+00, -2.7218e+00,  4.2735e-01, -8.4468e-01],\n",
      "        [ 3.8111e-01,  9.8052e-01, -6.9021e-01, -6.1567e-01,  1.1049e+00,\n",
      "          3.1914e-04,  7.4967e-01, -7.8798e-01, -5.0671e-01, -1.3011e+00],\n",
      "        [-4.9793e-01, -1.6081e+00, -8.5368e-01, -6.3693e-01, -6.9855e-01,\n",
      "          3.9781e-01,  1.0762e-01,  6.5721e-01,  4.7516e-01,  6.9208e-01],\n",
      "        [-1.8991e+00, -1.4408e+00,  2.4473e+00, -1.3221e+00,  1.4204e+00,\n",
      "          1.2211e-01, -6.1993e-01, -6.9090e-01,  1.7897e-01,  6.1779e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9212e-01,  2.6562e-01,  1.3628e+00,  9.0979e-01,  1.3603e+00,\n",
      "         -7.6716e-02,  1.7963e+00, -2.7218e+00,  4.2708e-01, -8.4471e-01],\n",
      "        [ 3.8139e-01,  9.8083e-01, -6.9029e-01, -6.1567e-01,  1.1049e+00,\n",
      "          1.3692e-04,  7.4967e-01, -7.8798e-01, -5.0691e-01, -1.3011e+00],\n",
      "        [-4.9831e-01, -1.6080e+00, -8.5370e-01, -6.3709e-01, -6.9855e-01,\n",
      "          3.9806e-01,  1.0762e-01,  6.5721e-01,  4.7511e-01,  6.9206e-01],\n",
      "        [-1.8993e+00, -1.4408e+00,  2.4473e+00, -1.3221e+00,  1.4204e+00,\n",
      "          1.2223e-01, -6.1993e-01, -6.9090e-01,  1.7897e-01,  6.1778e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9221e-01,  2.6605e-01,  1.3627e+00,  9.0969e-01,  1.3603e+00,\n",
      "         -7.6790e-02,  1.7963e+00, -2.7218e+00,  4.2680e-01, -8.4474e-01],\n",
      "        [ 3.8167e-01,  9.8113e-01, -6.9037e-01, -6.1567e-01,  1.1049e+00,\n",
      "         -4.5346e-05,  7.4967e-01, -7.8798e-01, -5.0712e-01, -1.3011e+00],\n",
      "        [-4.9870e-01, -1.6078e+00, -8.5372e-01, -6.3725e-01, -6.9855e-01,\n",
      "          3.9832e-01,  1.0762e-01,  6.5721e-01,  4.7506e-01,  6.9203e-01],\n",
      "        [-1.8995e+00, -1.4408e+00,  2.4473e+00, -1.3222e+00,  1.4204e+00,\n",
      "          1.2235e-01, -6.1993e-01, -6.9090e-01,  1.7897e-01,  6.1778e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9231e-01,  2.6648e-01,  1.3626e+00,  9.0959e-01,  1.3603e+00,\n",
      "         -7.6864e-02,  1.7963e+00, -2.7218e+00,  4.2652e-01, -8.4476e-01],\n",
      "        [ 3.8194e-01,  9.8143e-01, -6.9045e-01, -6.1566e-01,  1.1049e+00,\n",
      "         -2.2764e-04,  7.4967e-01, -7.8798e-01, -5.0733e-01, -1.3011e+00],\n",
      "        [-4.9908e-01, -1.6077e+00, -8.5374e-01, -6.3742e-01, -6.9855e-01,\n",
      "          3.9857e-01,  1.0762e-01,  6.5721e-01,  4.7501e-01,  6.9201e-01],\n",
      "        [-1.8996e+00, -1.4408e+00,  2.4473e+00, -1.3223e+00,  1.4204e+00,\n",
      "          1.2246e-01, -6.1993e-01, -6.9090e-01,  1.7897e-01,  6.1777e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9241e-01,  2.6691e-01,  1.3624e+00,  9.0949e-01,  1.3603e+00,\n",
      "         -7.6939e-02,  1.7963e+00, -2.7218e+00,  4.2624e-01, -8.4479e-01],\n",
      "        [ 3.8222e-01,  9.8173e-01, -6.9054e-01, -6.1566e-01,  1.1049e+00,\n",
      "         -4.0998e-04,  7.4967e-01, -7.8798e-01, -5.0753e-01, -1.3011e+00],\n",
      "        [-4.9946e-01, -1.6076e+00, -8.5377e-01, -6.3758e-01, -6.9855e-01,\n",
      "          3.9882e-01,  1.0762e-01,  6.5721e-01,  4.7497e-01,  6.9199e-01],\n",
      "        [-1.8998e+00, -1.4407e+00,  2.4473e+00, -1.3223e+00,  1.4204e+00,\n",
      "          1.2258e-01, -6.1993e-01, -6.9090e-01,  1.7897e-01,  6.1776e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9250e-01,  2.6734e-01,  1.3623e+00,  9.0939e-01,  1.3603e+00,\n",
      "         -7.7014e-02,  1.7963e+00, -2.7218e+00,  4.2597e-01, -8.4482e-01],\n",
      "        [ 3.8249e-01,  9.8203e-01, -6.9062e-01, -6.1566e-01,  1.1049e+00,\n",
      "         -5.9235e-04,  7.4967e-01, -7.8798e-01, -5.0774e-01, -1.3011e+00],\n",
      "        [-4.9985e-01, -1.6075e+00, -8.5379e-01, -6.3775e-01, -6.9855e-01,\n",
      "          3.9908e-01,  1.0762e-01,  6.5721e-01,  4.7492e-01,  6.9197e-01],\n",
      "        [-1.9000e+00, -1.4407e+00,  2.4473e+00, -1.3224e+00,  1.4204e+00,\n",
      "          1.2269e-01, -6.1993e-01, -6.9090e-01,  1.7898e-01,  6.1775e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9260e-01,  2.6776e-01,  1.3622e+00,  9.0929e-01,  1.3603e+00,\n",
      "         -7.7089e-02,  1.7963e+00, -2.7218e+00,  4.2569e-01, -8.4484e-01],\n",
      "        [ 3.8277e-01,  9.8232e-01, -6.9070e-01, -6.1566e-01,  1.1049e+00,\n",
      "         -7.7475e-04,  7.4967e-01, -7.8798e-01, -5.0794e-01, -1.3011e+00],\n",
      "        [-5.0023e-01, -1.6074e+00, -8.5381e-01, -6.3791e-01, -6.9855e-01,\n",
      "          3.9933e-01,  1.0762e-01,  6.5721e-01,  4.7487e-01,  6.9195e-01],\n",
      "        [-1.9001e+00, -1.4407e+00,  2.4473e+00, -1.3224e+00,  1.4204e+00,\n",
      "          1.2281e-01, -6.1993e-01, -6.9090e-01,  1.7898e-01,  6.1775e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9270e-01,  2.6818e-01,  1.3621e+00,  9.0919e-01,  1.3603e+00,\n",
      "         -7.7164e-02,  1.7963e+00, -2.7218e+00,  4.2541e-01, -8.4487e-01],\n",
      "        [ 3.8304e-01,  9.8262e-01, -6.9078e-01, -6.1566e-01,  1.1049e+00,\n",
      "         -9.5718e-04,  7.4967e-01, -7.8798e-01, -5.0815e-01, -1.3012e+00],\n",
      "        [-5.0061e-01, -1.6073e+00, -8.5384e-01, -6.3808e-01, -6.9855e-01,\n",
      "          3.9958e-01,  1.0762e-01,  6.5721e-01,  4.7483e-01,  6.9192e-01],\n",
      "        [-1.9003e+00, -1.4407e+00,  2.4473e+00, -1.3225e+00,  1.4204e+00,\n",
      "          1.2292e-01, -6.1993e-01, -6.9090e-01,  1.7898e-01,  6.1774e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9279e-01,  2.6861e-01,  1.3620e+00,  9.0909e-01,  1.3603e+00,\n",
      "         -7.7240e-02,  1.7963e+00, -2.7218e+00,  4.2513e-01, -8.4490e-01],\n",
      "        [ 3.8332e-01,  9.8292e-01, -6.9086e-01, -6.1566e-01,  1.1049e+00,\n",
      "         -1.1396e-03,  7.4967e-01, -7.8798e-01, -5.0836e-01, -1.3012e+00],\n",
      "        [-5.0099e-01, -1.6072e+00, -8.5386e-01, -6.3824e-01, -6.9855e-01,\n",
      "          3.9983e-01,  1.0762e-01,  6.5721e-01,  4.7478e-01,  6.9190e-01],\n",
      "        [-1.9004e+00, -1.4407e+00,  2.4473e+00, -1.3226e+00,  1.4204e+00,\n",
      "          1.2304e-01, -6.1993e-01, -6.9090e-01,  1.7898e-01,  6.1773e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9289e-01,  2.6903e-01,  1.3619e+00,  9.0899e-01,  1.3603e+00,\n",
      "         -7.7316e-02,  1.7963e+00, -2.7218e+00,  4.2486e-01, -8.4492e-01],\n",
      "        [ 3.8359e-01,  9.8321e-01, -6.9094e-01, -6.1565e-01,  1.1049e+00,\n",
      "         -1.3221e-03,  7.4967e-01, -7.8798e-01, -5.0856e-01, -1.3012e+00],\n",
      "        [-5.0137e-01, -1.6071e+00, -8.5388e-01, -6.3840e-01, -6.9855e-01,\n",
      "          4.0008e-01,  1.0762e-01,  6.5721e-01,  4.7473e-01,  6.9188e-01],\n",
      "        [-1.9006e+00, -1.4407e+00,  2.4473e+00, -1.3226e+00,  1.4204e+00,\n",
      "          1.2315e-01, -6.1993e-01, -6.9090e-01,  1.7898e-01,  6.1772e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9298e-01,  2.6944e-01,  1.3618e+00,  9.0890e-01,  1.3603e+00,\n",
      "         -7.7392e-02,  1.7963e+00, -2.7218e+00,  4.2458e-01, -8.4495e-01],\n",
      "        [ 3.8386e-01,  9.8351e-01, -6.9102e-01, -6.1565e-01,  1.1049e+00,\n",
      "         -1.5047e-03,  7.4967e-01, -7.8798e-01, -5.0877e-01, -1.3012e+00],\n",
      "        [-5.0175e-01, -1.6070e+00, -8.5390e-01, -6.3857e-01, -6.9855e-01,\n",
      "          4.0033e-01,  1.0762e-01,  6.5721e-01,  4.7469e-01,  6.9186e-01],\n",
      "        [-1.9008e+00, -1.4407e+00,  2.4473e+00, -1.3227e+00,  1.4204e+00,\n",
      "          1.2327e-01, -6.1993e-01, -6.9090e-01,  1.7898e-01,  6.1772e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9308e-01,  2.6986e-01,  1.3617e+00,  9.0880e-01,  1.3603e+00,\n",
      "         -7.7468e-02,  1.7963e+00, -2.7218e+00,  4.2430e-01, -8.4498e-01],\n",
      "        [ 3.8414e-01,  9.8380e-01, -6.9111e-01, -6.1565e-01,  1.1049e+00,\n",
      "         -1.6872e-03,  7.4967e-01, -7.8798e-01, -5.0898e-01, -1.3012e+00],\n",
      "        [-5.0214e-01, -1.6069e+00, -8.5393e-01, -6.3873e-01, -6.9855e-01,\n",
      "          4.0058e-01,  1.0762e-01,  6.5721e-01,  4.7464e-01,  6.9184e-01],\n",
      "        [-1.9009e+00, -1.4407e+00,  2.4473e+00, -1.3228e+00,  1.4204e+00,\n",
      "          1.2338e-01, -6.1993e-01, -6.9090e-01,  1.7898e-01,  6.1771e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9317e-01,  2.7028e-01,  1.3616e+00,  9.0870e-01,  1.3603e+00,\n",
      "         -7.7544e-02,  1.7963e+00, -2.7218e+00,  4.2402e-01, -8.4500e-01],\n",
      "        [ 3.8441e-01,  9.8409e-01, -6.9119e-01, -6.1565e-01,  1.1049e+00,\n",
      "         -1.8698e-03,  7.4967e-01, -7.8798e-01, -5.0918e-01, -1.3012e+00],\n",
      "        [-5.0252e-01, -1.6068e+00, -8.5395e-01, -6.3889e-01, -6.9855e-01,\n",
      "          4.0083e-01,  1.0762e-01,  6.5721e-01,  4.7459e-01,  6.9182e-01],\n",
      "        [-1.9011e+00, -1.4406e+00,  2.4473e+00, -1.3228e+00,  1.4204e+00,\n",
      "          1.2349e-01, -6.1993e-01, -6.9090e-01,  1.7898e-01,  6.1770e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9327e-01,  2.7069e-01,  1.3614e+00,  9.0860e-01,  1.3603e+00,\n",
      "         -7.7621e-02,  1.7963e+00, -2.7218e+00,  4.2374e-01, -8.4503e-01],\n",
      "        [ 3.8468e-01,  9.8438e-01, -6.9127e-01, -6.1564e-01,  1.1049e+00,\n",
      "         -2.0524e-03,  7.4967e-01, -7.8798e-01, -5.0939e-01, -1.3012e+00],\n",
      "        [-5.0289e-01, -1.6067e+00, -8.5397e-01, -6.3905e-01, -6.9855e-01,\n",
      "          4.0108e-01,  1.0762e-01,  6.5721e-01,  4.7455e-01,  6.9179e-01],\n",
      "        [-1.9012e+00, -1.4406e+00,  2.4473e+00, -1.3229e+00,  1.4204e+00,\n",
      "          1.2361e-01, -6.1993e-01, -6.9090e-01,  1.7898e-01,  6.1769e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9336e-01,  2.7110e-01,  1.3613e+00,  9.0851e-01,  1.3603e+00,\n",
      "         -7.7697e-02,  1.7963e+00, -2.7218e+00,  4.2346e-01, -8.4506e-01],\n",
      "        [ 3.8496e-01,  9.8467e-01, -6.9135e-01, -6.1564e-01,  1.1049e+00,\n",
      "         -2.2351e-03,  7.4967e-01, -7.8798e-01, -5.0960e-01, -1.3012e+00],\n",
      "        [-5.0327e-01, -1.6066e+00, -8.5400e-01, -6.3922e-01, -6.9855e-01,\n",
      "          4.0133e-01,  1.0762e-01,  6.5721e-01,  4.7450e-01,  6.9177e-01],\n",
      "        [-1.9014e+00, -1.4406e+00,  2.4472e+00, -1.3229e+00,  1.4204e+00,\n",
      "          1.2372e-01, -6.1993e-01, -6.9090e-01,  1.7899e-01,  6.1769e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9346e-01,  2.7151e-01,  1.3612e+00,  9.0841e-01,  1.3603e+00,\n",
      "         -7.7774e-02,  1.7963e+00, -2.7218e+00,  4.2319e-01, -8.4508e-01],\n",
      "        [ 3.8523e-01,  9.8496e-01, -6.9143e-01, -6.1564e-01,  1.1049e+00,\n",
      "         -2.4177e-03,  7.4967e-01, -7.8798e-01, -5.0981e-01, -1.3013e+00],\n",
      "        [-5.0365e-01, -1.6065e+00, -8.5402e-01, -6.3938e-01, -6.9855e-01,\n",
      "          4.0158e-01,  1.0762e-01,  6.5721e-01,  4.7445e-01,  6.9175e-01],\n",
      "        [-1.9016e+00, -1.4406e+00,  2.4472e+00, -1.3230e+00,  1.4204e+00,\n",
      "          1.2384e-01, -6.1993e-01, -6.9090e-01,  1.7899e-01,  6.1768e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.9355e-01,  2.7192e-01,  1.3611e+00,  9.0831e-01,  1.3603e+00,\n",
      "         -7.7852e-02,  1.7963e+00, -2.7218e+00,  4.2291e-01, -8.4511e-01],\n",
      "        [ 3.8550e-01,  9.8525e-01, -6.9151e-01, -6.1563e-01,  1.1049e+00,\n",
      "         -2.6004e-03,  7.4967e-01, -7.8798e-01, -5.1001e-01, -1.3013e+00],\n",
      "        [-5.0403e-01, -1.6064e+00, -8.5404e-01, -6.3954e-01, -6.9855e-01,\n",
      "          4.0183e-01,  1.0762e-01,  6.5721e-01,  4.7441e-01,  6.9173e-01],\n",
      "        [-1.9017e+00, -1.4406e+00,  2.4472e+00, -1.3231e+00,  1.4204e+00,\n",
      "          1.2395e-01, -6.1993e-01, -6.9090e-01,  1.7899e-01,  6.1767e-01]],\n",
      "       dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2936,  0.2723,  1.3610,  0.9082,  1.3603, -0.0779,  1.7963, -2.7218,\n",
      "          0.4226, -0.8451],\n",
      "        [ 0.3858,  0.9855, -0.6916, -0.6156,  1.1049, -0.0028,  0.7497, -0.7880,\n",
      "         -0.5102, -1.3013],\n",
      "        [-0.5044, -1.6063, -0.8541, -0.6397, -0.6986,  0.4021,  0.1076,  0.6572,\n",
      "          0.4744,  0.6917],\n",
      "        [-1.9019, -1.4406,  2.4472, -1.3231,  1.4204,  0.1241, -0.6199, -0.6909,\n",
      "          0.1790,  0.6177]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2937,  0.2727,  1.3609,  0.9081,  1.3603, -0.0780,  1.7963, -2.7218,\n",
      "          0.4223, -0.8452],\n",
      "        [ 0.3860,  0.9858, -0.6917, -0.6156,  1.1049, -0.0030,  0.7497, -0.7880,\n",
      "         -0.5104, -1.3013],\n",
      "        [-0.5048, -1.6062, -0.8541, -0.6399, -0.6986,  0.4023,  0.1076,  0.6572,\n",
      "          0.4743,  0.6917],\n",
      "        [-1.9021, -1.4406,  2.4472, -1.3232,  1.4204,  0.1242, -0.6199, -0.6909,\n",
      "          0.1790,  0.6177]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2938,  0.2731,  1.3608,  0.9080,  1.3603, -0.0781,  1.7963, -2.7218,\n",
      "          0.4221, -0.8452],\n",
      "        [ 0.3863,  0.9861, -0.6918, -0.6156,  1.1049, -0.0031,  0.7497, -0.7880,\n",
      "         -0.5106, -1.3013],\n",
      "        [-0.5052, -1.6061, -0.8541, -0.6400, -0.6986,  0.4026,  0.1076,  0.6572,\n",
      "          0.4743,  0.6917],\n",
      "        [-1.9022, -1.4406,  2.4472, -1.3232,  1.4204,  0.1243, -0.6199, -0.6909,\n",
      "          0.1790,  0.6176]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2939,  0.2735,  1.3607,  0.9079,  1.3603, -0.0782,  1.7963, -2.7218,\n",
      "          0.4218, -0.8452],\n",
      "        [ 0.3866,  0.9864, -0.6918, -0.6156,  1.1049, -0.0033,  0.7497, -0.7880,\n",
      "         -0.5108, -1.3013],\n",
      "        [-0.5055, -1.6060, -0.8541, -0.6402, -0.6986,  0.4028,  0.1076,  0.6572,\n",
      "          0.4742,  0.6916],\n",
      "        [-1.9024, -1.4406,  2.4472, -1.3233,  1.4204,  0.1244, -0.6199, -0.6909,\n",
      "          0.1790,  0.6176]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2940,  0.2739,  1.3606,  0.9078,  1.3603, -0.0782,  1.7963, -2.7218,\n",
      "          0.4215, -0.8452],\n",
      "        [ 0.3869,  0.9867, -0.6919, -0.6156,  1.1049, -0.0035,  0.7497, -0.7880,\n",
      "         -0.5111, -1.3013],\n",
      "        [-0.5059, -1.6059, -0.8542, -0.6403, -0.6986,  0.4031,  0.1076,  0.6572,\n",
      "          0.4742,  0.6916],\n",
      "        [-1.9025, -1.4405,  2.4472, -1.3234,  1.4204,  0.1245, -0.6199, -0.6909,\n",
      "          0.1790,  0.6176]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2941,  0.2744,  1.3604,  0.9077,  1.3603, -0.0783,  1.7963, -2.7218,\n",
      "          0.4212, -0.8453],\n",
      "        [ 0.3871,  0.9870, -0.6920, -0.6156,  1.1049, -0.0037,  0.7497, -0.7880,\n",
      "         -0.5113, -1.3013],\n",
      "        [-0.5063, -1.6058, -0.8542, -0.6405, -0.6986,  0.4033,  0.1076,  0.6572,\n",
      "          0.4741,  0.6916],\n",
      "        [-1.9027, -1.4405,  2.4472, -1.3234,  1.4204,  0.1246, -0.6199, -0.6909,\n",
      "          0.1790,  0.6176]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2942,  0.2747,  1.3603,  0.9077,  1.3603, -0.0784,  1.7963, -2.7218,\n",
      "          0.4210, -0.8453],\n",
      "        [ 0.3874,  0.9872, -0.6921, -0.6156,  1.1049, -0.0039,  0.7497, -0.7880,\n",
      "         -0.5115, -1.3013],\n",
      "        [-0.5067, -1.6057, -0.8542, -0.6407, -0.6986,  0.4036,  0.1076,  0.6572,\n",
      "          0.4741,  0.6916],\n",
      "        [-1.9029, -1.4405,  2.4472, -1.3235,  1.4204,  0.1247, -0.6199, -0.6909,\n",
      "          0.1790,  0.6176]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2943,  0.2751,  1.3602,  0.9076,  1.3603, -0.0785,  1.7963, -2.7218,\n",
      "          0.4207, -0.8453],\n",
      "        [ 0.3877,  0.9875, -0.6922, -0.6156,  1.1049, -0.0041,  0.7497, -0.7880,\n",
      "         -0.5117, -1.3014],\n",
      "        [-0.5070, -1.6056, -0.8542, -0.6408, -0.6986,  0.4038,  0.1076,  0.6572,\n",
      "          0.4740,  0.6916],\n",
      "        [-1.9030, -1.4405,  2.4472, -1.3235,  1.4204,  0.1249, -0.6199, -0.6909,\n",
      "          0.1790,  0.6176]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2944,  0.2755,  1.3601,  0.9075,  1.3603, -0.0786,  1.7963, -2.7218,\n",
      "          0.4204, -0.8453],\n",
      "        [ 0.3879,  0.9878, -0.6922, -0.6156,  1.1049, -0.0042,  0.7497, -0.7880,\n",
      "         -0.5119, -1.3014],\n",
      "        [-0.5074, -1.6055, -0.8542, -0.6410, -0.6986,  0.4041,  0.1076,  0.6572,\n",
      "          0.4740,  0.6915],\n",
      "        [-1.9032, -1.4405,  2.4472, -1.3236,  1.4204,  0.1250, -0.6199, -0.6909,\n",
      "          0.1790,  0.6176]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2945,  0.2759,  1.3600,  0.9074,  1.3603, -0.0786,  1.7963, -2.7218,\n",
      "          0.4201, -0.8454],\n",
      "        [ 0.3882,  0.9881, -0.6923, -0.6156,  1.1049, -0.0044,  0.7497, -0.7880,\n",
      "         -0.5121, -1.3014],\n",
      "        [-0.5078, -1.6054, -0.8543, -0.6411, -0.6986,  0.4043,  0.1076,  0.6572,\n",
      "          0.4739,  0.6915],\n",
      "        [-1.9033, -1.4405,  2.4472, -1.3237,  1.4204,  0.1251, -0.6199, -0.6909,\n",
      "          0.1790,  0.6176]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2946,  0.2763,  1.3599,  0.9073,  1.3603, -0.0787,  1.7963, -2.7218,\n",
      "          0.4198, -0.8454],\n",
      "        [ 0.3885,  0.9883, -0.6924, -0.6156,  1.1049, -0.0046,  0.7497, -0.7880,\n",
      "         -0.5123, -1.3014],\n",
      "        [-0.5082, -1.6053, -0.8543, -0.6413, -0.6986,  0.4045,  0.1076,  0.6572,\n",
      "          0.4739,  0.6915],\n",
      "        [-1.9035, -1.4405,  2.4472, -1.3237,  1.4204,  0.1252, -0.6199, -0.6909,\n",
      "          0.1790,  0.6176]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2947,  0.2767,  1.3598,  0.9072,  1.3603, -0.0788,  1.7963, -2.7218,\n",
      "          0.4196, -0.8454],\n",
      "        [ 0.3887,  0.9886, -0.6925, -0.6156,  1.1049, -0.0048,  0.7497, -0.7880,\n",
      "         -0.5125, -1.3014],\n",
      "        [-0.5085, -1.6053, -0.8543, -0.6415, -0.6986,  0.4048,  0.1076,  0.6572,\n",
      "          0.4738,  0.6915],\n",
      "        [-1.9036, -1.4405,  2.4472, -1.3238,  1.4204,  0.1253, -0.6199, -0.6909,\n",
      "          0.1790,  0.6176]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2948,  0.2771,  1.3597,  0.9071,  1.3603, -0.0789,  1.7963, -2.7218,\n",
      "          0.4193, -0.8455],\n",
      "        [ 0.3890,  0.9889, -0.6926, -0.6156,  1.1049, -0.0050,  0.7497, -0.7880,\n",
      "         -0.5127, -1.3014],\n",
      "        [-0.5089, -1.6052, -0.8543, -0.6416, -0.6986,  0.4050,  0.1076,  0.6572,\n",
      "          0.4738,  0.6915],\n",
      "        [-1.9038, -1.4405,  2.4472, -1.3238,  1.4204,  0.1254, -0.6199, -0.6909,\n",
      "          0.1790,  0.6176]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2949,  0.2775,  1.3596,  0.9070,  1.3603, -0.0790,  1.7963, -2.7218,\n",
      "          0.4190, -0.8455],\n",
      "        [ 0.3893,  0.9892, -0.6927, -0.6156,  1.1049, -0.0052,  0.7497, -0.7880,\n",
      "         -0.5129, -1.3014],\n",
      "        [-0.5093, -1.6051, -0.8544, -0.6418, -0.6986,  0.4053,  0.1076,  0.6572,\n",
      "          0.4738,  0.6914],\n",
      "        [-1.9040, -1.4404,  2.4472, -1.3239,  1.4204,  0.1255, -0.6199, -0.6909,\n",
      "          0.1790,  0.6176]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2949,  0.2779,  1.3594,  0.9069,  1.3603, -0.0790,  1.7963, -2.7218,\n",
      "          0.4187, -0.8455],\n",
      "        [ 0.3895,  0.9894, -0.6927, -0.6156,  1.1049, -0.0053,  0.7497, -0.7880,\n",
      "         -0.5131, -1.3014],\n",
      "        [-0.5096, -1.6050, -0.8544, -0.6419, -0.6986,  0.4055,  0.1076,  0.6572,\n",
      "          0.4737,  0.6914],\n",
      "        [-1.9041, -1.4404,  2.4472, -1.3240,  1.4204,  0.1256, -0.6199, -0.6909,\n",
      "          0.1790,  0.6176]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2950,  0.2783,  1.3593,  0.9068,  1.3603, -0.0791,  1.7963, -2.7218,\n",
      "          0.4184, -0.8455],\n",
      "        [ 0.3898,  0.9897, -0.6928, -0.6156,  1.1049, -0.0055,  0.7497, -0.7880,\n",
      "         -0.5133, -1.3015],\n",
      "        [-0.5100, -1.6049, -0.8544, -0.6421, -0.6986,  0.4058,  0.1076,  0.6572,\n",
      "          0.4737,  0.6914],\n",
      "        [-1.9043, -1.4404,  2.4472, -1.3240,  1.4204,  0.1258, -0.6199, -0.6909,\n",
      "          0.1790,  0.6176]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2951,  0.2787,  1.3592,  0.9067,  1.3603, -0.0792,  1.7963, -2.7218,\n",
      "          0.4182, -0.8456],\n",
      "        [ 0.3901,  0.9900, -0.6929, -0.6156,  1.1049, -0.0057,  0.7497, -0.7880,\n",
      "         -0.5136, -1.3015],\n",
      "        [-0.5104, -1.6048, -0.8544, -0.6423, -0.6986,  0.4060,  0.1076,  0.6572,\n",
      "          0.4736,  0.6914],\n",
      "        [-1.9044, -1.4404,  2.4472, -1.3241,  1.4204,  0.1259, -0.6199, -0.6909,\n",
      "          0.1790,  0.6175]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2952,  0.2790,  1.3591,  0.9066,  1.3603, -0.0793,  1.7963, -2.7218,\n",
      "          0.4179, -0.8456],\n",
      "        [ 0.3903,  0.9903, -0.6930, -0.6156,  1.1049, -0.0059,  0.7497, -0.7880,\n",
      "         -0.5138, -1.3015],\n",
      "        [-0.5108, -1.6047, -0.8545, -0.6424, -0.6986,  0.4063,  0.1076,  0.6572,\n",
      "          0.4736,  0.6913],\n",
      "        [-1.9046, -1.4404,  2.4472, -1.3241,  1.4204,  0.1260, -0.6199, -0.6909,\n",
      "          0.1790,  0.6175]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2953,  0.2794,  1.3590,  0.9065,  1.3603, -0.0794,  1.7963, -2.7218,\n",
      "          0.4176, -0.8456],\n",
      "        [ 0.3906,  0.9905, -0.6931, -0.6155,  1.1049, -0.0061,  0.7497, -0.7880,\n",
      "         -0.5140, -1.3015],\n",
      "        [-0.5111, -1.6046, -0.8545, -0.6426, -0.6986,  0.4065,  0.1076,  0.6572,\n",
      "          0.4735,  0.6913],\n",
      "        [-1.9048, -1.4404,  2.4472, -1.3242,  1.4204,  0.1261, -0.6199, -0.6909,\n",
      "          0.1790,  0.6175]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2954,  0.2798,  1.3589,  0.9065,  1.3603, -0.0794,  1.7963, -2.7218,\n",
      "          0.4173, -0.8456],\n",
      "        [ 0.3909,  0.9908, -0.6931, -0.6155,  1.1049, -0.0063,  0.7497, -0.7880,\n",
      "         -0.5142, -1.3015],\n",
      "        [-0.5115, -1.6045, -0.8545, -0.6427, -0.6986,  0.4067,  0.1076,  0.6572,\n",
      "          0.4735,  0.6913],\n",
      "        [-1.9049, -1.4404,  2.4472, -1.3243,  1.4204,  0.1262, -0.6199, -0.6909,\n",
      "          0.1790,  0.6175]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2955,  0.2802,  1.3588,  0.9064,  1.3603, -0.0795,  1.7963, -2.7218,\n",
      "          0.4170, -0.8457],\n",
      "        [ 0.3911,  0.9911, -0.6932, -0.6155,  1.1049, -0.0064,  0.7497, -0.7880,\n",
      "         -0.5144, -1.3015],\n",
      "        [-0.5119, -1.6044, -0.8545, -0.6429, -0.6986,  0.4070,  0.1076,  0.6572,\n",
      "          0.4734,  0.6913],\n",
      "        [-1.9051, -1.4404,  2.4472, -1.3243,  1.4204,  0.1263, -0.6199, -0.6909,\n",
      "          0.1790,  0.6175]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2956,  0.2806,  1.3587,  0.9063,  1.3603, -0.0796,  1.7963, -2.7218,\n",
      "          0.4167, -0.8457],\n",
      "        [ 0.3914,  0.9913, -0.6933, -0.6155,  1.1049, -0.0066,  0.7497, -0.7880,\n",
      "         -0.5146, -1.3015],\n",
      "        [-0.5122, -1.6043, -0.8545, -0.6430, -0.6986,  0.4072,  0.1076,  0.6572,\n",
      "          0.4734,  0.6913],\n",
      "        [-1.9052, -1.4404,  2.4472, -1.3244,  1.4204,  0.1264, -0.6199, -0.6909,\n",
      "          0.1790,  0.6175]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2957,  0.2809,  1.3585,  0.9062,  1.3603, -0.0797,  1.7963, -2.7218,\n",
      "          0.4165, -0.8457],\n",
      "        [ 0.3916,  0.9916, -0.6934, -0.6155,  1.1049, -0.0068,  0.7497, -0.7880,\n",
      "         -0.5148, -1.3015],\n",
      "        [-0.5126, -1.6043, -0.8546, -0.6432, -0.6986,  0.4075,  0.1076,  0.6572,\n",
      "          0.4733,  0.6912],\n",
      "        [-1.9054, -1.4404,  2.4472, -1.3244,  1.4204,  0.1265, -0.6199, -0.6909,\n",
      "          0.1790,  0.6175]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2958,  0.2813,  1.3584,  0.9061,  1.3603, -0.0798,  1.7963, -2.7218,\n",
      "          0.4162, -0.8457],\n",
      "        [ 0.3919,  0.9919, -0.6935, -0.6155,  1.1049, -0.0070,  0.7497, -0.7880,\n",
      "         -0.5150, -1.3015],\n",
      "        [-0.5130, -1.6042, -0.8546, -0.6434, -0.6986,  0.4077,  0.1076,  0.6572,\n",
      "          0.4733,  0.6912],\n",
      "        [-1.9055, -1.4404,  2.4472, -1.3245,  1.4204,  0.1266, -0.6199, -0.6909,\n",
      "          0.1790,  0.6175]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2959,  0.2817,  1.3583,  0.9060,  1.3603, -0.0798,  1.7963, -2.7218,\n",
      "          0.4159, -0.8458],\n",
      "        [ 0.3922,  0.9921, -0.6936, -0.6155,  1.1049, -0.0072,  0.7497, -0.7880,\n",
      "         -0.5152, -1.3016],\n",
      "        [-0.5133, -1.6041, -0.8546, -0.6435, -0.6986,  0.4080,  0.1076,  0.6572,\n",
      "          0.4733,  0.6912],\n",
      "        [-1.9057, -1.4403,  2.4472, -1.3246,  1.4204,  0.1268, -0.6199, -0.6909,\n",
      "          0.1790,  0.6175]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2960,  0.2821,  1.3582,  0.9059,  1.3603, -0.0799,  1.7963, -2.7218,\n",
      "          0.4156, -0.8458],\n",
      "        [ 0.3924,  0.9924, -0.6936, -0.6155,  1.1049, -0.0074,  0.7497, -0.7880,\n",
      "         -0.5154, -1.3016],\n",
      "        [-0.5137, -1.6040, -0.8546, -0.6437, -0.6986,  0.4082,  0.1076,  0.6572,\n",
      "          0.4732,  0.6912],\n",
      "        [-1.9059, -1.4403,  2.4472, -1.3246,  1.4204,  0.1269, -0.6199, -0.6909,\n",
      "          0.1790,  0.6175]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2960,  0.2824,  1.3581,  0.9058,  1.3603, -0.0800,  1.7963, -2.7218,\n",
      "          0.4153, -0.8458],\n",
      "        [ 0.3927,  0.9927, -0.6937, -0.6155,  1.1049, -0.0075,  0.7497, -0.7880,\n",
      "         -0.5157, -1.3016],\n",
      "        [-0.5141, -1.6039, -0.8547, -0.6438, -0.6986,  0.4084,  0.1076,  0.6572,\n",
      "          0.4732,  0.6912],\n",
      "        [-1.9060, -1.4403,  2.4472, -1.3247,  1.4204,  0.1270, -0.6199, -0.6909,\n",
      "          0.1790,  0.6175]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2961,  0.2828,  1.3580,  0.9057,  1.3603, -0.0801,  1.7963, -2.7218,\n",
      "          0.4151, -0.8458],\n",
      "        [ 0.3930,  0.9929, -0.6938, -0.6155,  1.1049, -0.0077,  0.7497, -0.7880,\n",
      "         -0.5159, -1.3016],\n",
      "        [-0.5144, -1.6038, -0.8547, -0.6440, -0.6986,  0.4087,  0.1076,  0.6572,\n",
      "          0.4731,  0.6911],\n",
      "        [-1.9062, -1.4403,  2.4472, -1.3247,  1.4204,  0.1271, -0.6199, -0.6909,\n",
      "          0.1790,  0.6175]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2962,  0.2832,  1.3579,  0.9057,  1.3603, -0.0802,  1.7963, -2.7218,\n",
      "          0.4148, -0.8459],\n",
      "        [ 0.3932,  0.9932, -0.6939, -0.6155,  1.1049, -0.0079,  0.7497, -0.7880,\n",
      "         -0.5161, -1.3016],\n",
      "        [-0.5148, -1.6037, -0.8547, -0.6441, -0.6986,  0.4089,  0.1076,  0.6572,\n",
      "          0.4731,  0.6911],\n",
      "        [-1.9063, -1.4403,  2.4472, -1.3248,  1.4204,  0.1272, -0.6199, -0.6909,\n",
      "          0.1790,  0.6175]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2963,  0.2836,  1.3578,  0.9056,  1.3603, -0.0803,  1.7963, -2.7218,\n",
      "          0.4145, -0.8459],\n",
      "        [ 0.3935,  0.9935, -0.6940, -0.6155,  1.1049, -0.0081,  0.7497, -0.7880,\n",
      "         -0.5163, -1.3016],\n",
      "        [-0.5152, -1.6037, -0.8547, -0.6443, -0.6986,  0.4092,  0.1076,  0.6572,\n",
      "          0.4730,  0.6911],\n",
      "        [-1.9065, -1.4403,  2.4472, -1.3248,  1.4204,  0.1273, -0.6199, -0.6909,\n",
      "          0.1790,  0.6175]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2964,  0.2839,  1.3577,  0.9055,  1.3603, -0.0803,  1.7963, -2.7218,\n",
      "          0.4142, -0.8459],\n",
      "        [ 0.3937,  0.9937, -0.6940, -0.6155,  1.1049, -0.0083,  0.7497, -0.7880,\n",
      "         -0.5165, -1.3016],\n",
      "        [-0.5155, -1.6036, -0.8548, -0.6445, -0.6986,  0.4094,  0.1076,  0.6572,\n",
      "          0.4730,  0.6911],\n",
      "        [-1.9066, -1.4403,  2.4472, -1.3249,  1.4204,  0.1274, -0.6199, -0.6909,\n",
      "          0.1790,  0.6174]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2965,  0.2843,  1.3575,  0.9054,  1.3603, -0.0804,  1.7963, -2.7218,\n",
      "          0.4139, -0.8459],\n",
      "        [ 0.3940,  0.9940, -0.6941, -0.6155,  1.1049, -0.0085,  0.7497, -0.7880,\n",
      "         -0.5167, -1.3016],\n",
      "        [-0.5159, -1.6035, -0.8548, -0.6446, -0.6986,  0.4096,  0.1076,  0.6572,\n",
      "          0.4729,  0.6911],\n",
      "        [-1.9068, -1.4403,  2.4472, -1.3250,  1.4204,  0.1275, -0.6199, -0.6909,\n",
      "          0.1790,  0.6174]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2966,  0.2846,  1.3574,  0.9053,  1.3603, -0.0805,  1.7963, -2.7218,\n",
      "          0.4136, -0.8460],\n",
      "        [ 0.3943,  0.9942, -0.6942, -0.6154,  1.1049, -0.0086,  0.7497, -0.7880,\n",
      "         -0.5169, -1.3016],\n",
      "        [-0.5163, -1.6034, -0.8548, -0.6448, -0.6986,  0.4099,  0.1076,  0.6572,\n",
      "          0.4729,  0.6910],\n",
      "        [-1.9069, -1.4403,  2.4472, -1.3250,  1.4204,  0.1276, -0.6199, -0.6909,\n",
      "          0.1790,  0.6174]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2967,  0.2850,  1.3573,  0.9052,  1.3603, -0.0806,  1.7963, -2.7218,\n",
      "          0.4134, -0.8460],\n",
      "        [ 0.3945,  0.9945, -0.6943, -0.6154,  1.1049, -0.0088,  0.7497, -0.7880,\n",
      "         -0.5171, -1.3017],\n",
      "        [-0.5166, -1.6033, -0.8548, -0.6449, -0.6986,  0.4101,  0.1076,  0.6572,\n",
      "          0.4728,  0.6910],\n",
      "        [-1.9071, -1.4403,  2.4472, -1.3251,  1.4204,  0.1278, -0.6199, -0.6909,\n",
      "          0.1790,  0.6174]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2968,  0.2854,  1.3572,  0.9051,  1.3603, -0.0807,  1.7963, -2.7218,\n",
      "          0.4131, -0.8460],\n",
      "        [ 0.3948,  0.9947, -0.6944, -0.6154,  1.1049, -0.0090,  0.7497, -0.7880,\n",
      "         -0.5173, -1.3017],\n",
      "        [-0.5170, -1.6032, -0.8548, -0.6451, -0.6986,  0.4104,  0.1076,  0.6572,\n",
      "          0.4728,  0.6910],\n",
      "        [-1.9072, -1.4403,  2.4472, -1.3251,  1.4204,  0.1279, -0.6199, -0.6909,\n",
      "          0.1790,  0.6174]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2968,  0.2857,  1.3571,  0.9050,  1.3603, -0.0807,  1.7963, -2.7218,\n",
      "          0.4128, -0.8460],\n",
      "        [ 0.3950,  0.9950, -0.6945, -0.6154,  1.1049, -0.0092,  0.7497, -0.7880,\n",
      "         -0.5176, -1.3017],\n",
      "        [-0.5174, -1.6032, -0.8549, -0.6452, -0.6986,  0.4106,  0.1076,  0.6572,\n",
      "          0.4727,  0.6910],\n",
      "        [-1.9074, -1.4403,  2.4472, -1.3252,  1.4204,  0.1280, -0.6199, -0.6909,\n",
      "          0.1790,  0.6174]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2969,  0.2861,  1.3570,  0.9050,  1.3603, -0.0808,  1.7963, -2.7218,\n",
      "          0.4125, -0.8461],\n",
      "        [ 0.3953,  0.9953, -0.6945, -0.6154,  1.1049, -0.0094,  0.7497, -0.7880,\n",
      "         -0.5178, -1.3017],\n",
      "        [-0.5177, -1.6031, -0.8549, -0.6454, -0.6986,  0.4108,  0.1076,  0.6572,\n",
      "          0.4727,  0.6909],\n",
      "        [-1.9076, -1.4402,  2.4472, -1.3253,  1.4204,  0.1281, -0.6199, -0.6909,\n",
      "          0.1791,  0.6174]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2970,  0.2865,  1.3569,  0.9049,  1.3603, -0.0809,  1.7963, -2.7218,\n",
      "          0.4122, -0.8461],\n",
      "        [ 0.3956,  0.9955, -0.6946, -0.6154,  1.1049, -0.0096,  0.7497, -0.7880,\n",
      "         -0.5180, -1.3017],\n",
      "        [-0.5181, -1.6030, -0.8549, -0.6455, -0.6986,  0.4111,  0.1076,  0.6572,\n",
      "          0.4727,  0.6909],\n",
      "        [-1.9077, -1.4402,  2.4472, -1.3253,  1.4204,  0.1282, -0.6199, -0.6909,\n",
      "          0.1791,  0.6174]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2971,  0.2868,  1.3568,  0.9048,  1.3603, -0.0810,  1.7963, -2.7218,\n",
      "          0.4120, -0.8461],\n",
      "        [ 0.3958,  0.9958, -0.6947, -0.6154,  1.1049, -0.0097,  0.7497, -0.7880,\n",
      "         -0.5182, -1.3017],\n",
      "        [-0.5184, -1.6029, -0.8549, -0.6457, -0.6986,  0.4113,  0.1076,  0.6572,\n",
      "          0.4726,  0.6909],\n",
      "        [-1.9079, -1.4402,  2.4472, -1.3254,  1.4204,  0.1283, -0.6199, -0.6909,\n",
      "          0.1791,  0.6174]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2972,  0.2872,  1.3567,  0.9047,  1.3603, -0.0811,  1.7963, -2.7218,\n",
      "          0.4117, -0.8461],\n",
      "        [ 0.3961,  0.9960, -0.6948, -0.6154,  1.1049, -0.0099,  0.7497, -0.7880,\n",
      "         -0.5184, -1.3017],\n",
      "        [-0.5188, -1.6028, -0.8550, -0.6459, -0.6986,  0.4116,  0.1076,  0.6572,\n",
      "          0.4726,  0.6909],\n",
      "        [-1.9080, -1.4402,  2.4472, -1.3254,  1.4204,  0.1284, -0.6199, -0.6909,\n",
      "          0.1791,  0.6174]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2973,  0.2875,  1.3565,  0.9046,  1.3603, -0.0812,  1.7963, -2.7218,\n",
      "          0.4114, -0.8462],\n",
      "        [ 0.3963,  0.9963, -0.6949, -0.6154,  1.1049, -0.0101,  0.7497, -0.7880,\n",
      "         -0.5186, -1.3017],\n",
      "        [-0.5192, -1.6028, -0.8550, -0.6460, -0.6986,  0.4118,  0.1076,  0.6572,\n",
      "          0.4725,  0.6909],\n",
      "        [-1.9082, -1.4402,  2.4472, -1.3255,  1.4204,  0.1285, -0.6199, -0.6909,\n",
      "          0.1791,  0.6174]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2974,  0.2879,  1.3564,  0.9045,  1.3603, -0.0813,  1.7963, -2.7218,\n",
      "          0.4111, -0.8462],\n",
      "        [ 0.3966,  0.9965, -0.6949, -0.6154,  1.1049, -0.0103,  0.7497, -0.7880,\n",
      "         -0.5188, -1.3017],\n",
      "        [-0.5195, -1.6027, -0.8550, -0.6462, -0.6986,  0.4120,  0.1076,  0.6572,\n",
      "          0.4725,  0.6908],\n",
      "        [-1.9083, -1.4402,  2.4472, -1.3256,  1.4204,  0.1286, -0.6199, -0.6909,\n",
      "          0.1791,  0.6174]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2975,  0.2882,  1.3563,  0.9045,  1.3603, -0.0813,  1.7963, -2.7218,\n",
      "          0.4108, -0.8462],\n",
      "        [ 0.3968,  0.9968, -0.6950, -0.6154,  1.1049, -0.0105,  0.7497, -0.7880,\n",
      "         -0.5190, -1.3018],\n",
      "        [-0.5199, -1.6026, -0.8550, -0.6463, -0.6986,  0.4123,  0.1076,  0.6572,\n",
      "          0.4724,  0.6908],\n",
      "        [-1.9085, -1.4402,  2.4472, -1.3256,  1.4204,  0.1287, -0.6199, -0.6909,\n",
      "          0.1791,  0.6174]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2976,  0.2886,  1.3562,  0.9044,  1.3603, -0.0814,  1.7963, -2.7218,\n",
      "          0.4105, -0.8462],\n",
      "        [ 0.3971,  0.9970, -0.6951, -0.6154,  1.1049, -0.0107,  0.7497, -0.7880,\n",
      "         -0.5192, -1.3018],\n",
      "        [-0.5202, -1.6025, -0.8550, -0.6465, -0.6986,  0.4125,  0.1076,  0.6572,\n",
      "          0.4724,  0.6908],\n",
      "        [-1.9086, -1.4402,  2.4472, -1.3257,  1.4204,  0.1289, -0.6199, -0.6909,\n",
      "          0.1791,  0.6174]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2976,  0.2889,  1.3561,  0.9043,  1.3603, -0.0815,  1.7963, -2.7218,\n",
      "          0.4103, -0.8463],\n",
      "        [ 0.3974,  0.9973, -0.6952, -0.6153,  1.1049, -0.0108,  0.7497, -0.7880,\n",
      "         -0.5195, -1.3018],\n",
      "        [-0.5206, -1.6024, -0.8551, -0.6466, -0.6986,  0.4127,  0.1076,  0.6572,\n",
      "          0.4723,  0.6908],\n",
      "        [-1.9088, -1.4402,  2.4472, -1.3257,  1.4204,  0.1290, -0.6199, -0.6909,\n",
      "          0.1791,  0.6173]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2977,  0.2893,  1.3560,  0.9042,  1.3603, -0.0816,  1.7963, -2.7218,\n",
      "          0.4100, -0.8463],\n",
      "        [ 0.3976,  0.9975, -0.6953, -0.6153,  1.1049, -0.0110,  0.7497, -0.7880,\n",
      "         -0.5197, -1.3018],\n",
      "        [-0.5210, -1.6024, -0.8551, -0.6468, -0.6986,  0.4130,  0.1076,  0.6572,\n",
      "          0.4723,  0.6908],\n",
      "        [-1.9089, -1.4402,  2.4472, -1.3258,  1.4204,  0.1291, -0.6199, -0.6909,\n",
      "          0.1791,  0.6173]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2978,  0.2896,  1.3559,  0.9041,  1.3603, -0.0817,  1.7963, -2.7218,\n",
      "          0.4097, -0.8463],\n",
      "        [ 0.3979,  0.9978, -0.6953, -0.6153,  1.1049, -0.0112,  0.7497, -0.7880,\n",
      "         -0.5199, -1.3018],\n",
      "        [-0.5213, -1.6023, -0.8551, -0.6469, -0.6986,  0.4132,  0.1076,  0.6572,\n",
      "          0.4723,  0.6907],\n",
      "        [-1.9091, -1.4402,  2.4472, -1.3258,  1.4204,  0.1292, -0.6199, -0.6909,\n",
      "          0.1791,  0.6173]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2979,  0.2900,  1.3558,  0.9040,  1.3603, -0.0818,  1.7963, -2.7218,\n",
      "          0.4094, -0.8463],\n",
      "        [ 0.3981,  0.9980, -0.6954, -0.6153,  1.1049, -0.0114,  0.7497, -0.7880,\n",
      "         -0.5201, -1.3018],\n",
      "        [-0.5217, -1.6022, -0.8551, -0.6471, -0.6986,  0.4135,  0.1076,  0.6572,\n",
      "          0.4722,  0.6907],\n",
      "        [-1.9092, -1.4402,  2.4472, -1.3259,  1.4204,  0.1293, -0.6199, -0.6909,\n",
      "          0.1791,  0.6173]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2980,  0.2903,  1.3557,  0.9040,  1.3603, -0.0818,  1.7963, -2.7218,\n",
      "          0.4091, -0.8464],\n",
      "        [ 0.3984,  0.9983, -0.6955, -0.6153,  1.1049, -0.0116,  0.7497, -0.7880,\n",
      "         -0.5203, -1.3018],\n",
      "        [-0.5220, -1.6021, -0.8552, -0.6472, -0.6986,  0.4137,  0.1076,  0.6572,\n",
      "          0.4722,  0.6907],\n",
      "        [-1.9094, -1.4402,  2.4472, -1.3260,  1.4204,  0.1294, -0.6199, -0.6909,\n",
      "          0.1791,  0.6173]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2981,  0.2906,  1.3555,  0.9039,  1.3603, -0.0819,  1.7963, -2.7218,\n",
      "          0.4088, -0.8464],\n",
      "        [ 0.3986,  0.9985, -0.6956, -0.6153,  1.1049, -0.0118,  0.7497, -0.7880,\n",
      "         -0.5205, -1.3018],\n",
      "        [-0.5224, -1.6021, -0.8552, -0.6474, -0.6986,  0.4139,  0.1076,  0.6572,\n",
      "          0.4721,  0.6907],\n",
      "        [-1.9095, -1.4402,  2.4472, -1.3260,  1.4204,  0.1295, -0.6199, -0.6909,\n",
      "          0.1791,  0.6173]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2982,  0.2910,  1.3554,  0.9038,  1.3603, -0.0820,  1.7963, -2.7218,\n",
      "          0.4086, -0.8464],\n",
      "        [ 0.3989,  0.9987, -0.6957, -0.6153,  1.1049, -0.0119,  0.7497, -0.7880,\n",
      "         -0.5207, -1.3018],\n",
      "        [-0.5227, -1.6020, -0.8552, -0.6475, -0.6986,  0.4142,  0.1076,  0.6572,\n",
      "          0.4721,  0.6907],\n",
      "        [-1.9097, -1.4402,  2.4472, -1.3261,  1.4204,  0.1296, -0.6199, -0.6909,\n",
      "          0.1791,  0.6173]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2982,  0.2913,  1.3553,  0.9037,  1.3603, -0.0821,  1.7963, -2.7218,\n",
      "          0.4083, -0.8464],\n",
      "        [ 0.3991,  0.9990, -0.6958, -0.6153,  1.1049, -0.0121,  0.7497, -0.7880,\n",
      "         -0.5209, -1.3019],\n",
      "        [-0.5231, -1.6019, -0.8552, -0.6477, -0.6986,  0.4144,  0.1076,  0.6572,\n",
      "          0.4720,  0.6906],\n",
      "        [-1.9098, -1.4401,  2.4472, -1.3261,  1.4204,  0.1297, -0.6199, -0.6909,\n",
      "          0.1791,  0.6173]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2983,  0.2917,  1.3552,  0.9036,  1.3603, -0.0822,  1.7963, -2.7218,\n",
      "          0.4080, -0.8465],\n",
      "        [ 0.3994,  0.9992, -0.6958, -0.6153,  1.1049, -0.0123,  0.7497, -0.7880,\n",
      "         -0.5212, -1.3019],\n",
      "        [-0.5235, -1.6018, -0.8553, -0.6478, -0.6986,  0.4146,  0.1076,  0.6572,\n",
      "          0.4720,  0.6906],\n",
      "        [-1.9100, -1.4401,  2.4472, -1.3262,  1.4204,  0.1298, -0.6199, -0.6909,\n",
      "          0.1791,  0.6173]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2984,  0.2920,  1.3551,  0.9035,  1.3603, -0.0823,  1.7963, -2.7218,\n",
      "          0.4077, -0.8465],\n",
      "        [ 0.3996,  0.9995, -0.6959, -0.6153,  1.1049, -0.0125,  0.7497, -0.7880,\n",
      "         -0.5214, -1.3019],\n",
      "        [-0.5238, -1.6018, -0.8553, -0.6480, -0.6986,  0.4149,  0.1076,  0.6572,\n",
      "          0.4719,  0.6906],\n",
      "        [-1.9101, -1.4401,  2.4472, -1.3262,  1.4204,  0.1299, -0.6199, -0.6909,\n",
      "          0.1791,  0.6173]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2985,  0.2923,  1.3550,  0.9035,  1.3603, -0.0824,  1.7963, -2.7218,\n",
      "          0.4074, -0.8465],\n",
      "        [ 0.3999,  0.9997, -0.6960, -0.6152,  1.1049, -0.0127,  0.7497, -0.7880,\n",
      "         -0.5216, -1.3019],\n",
      "        [-0.5242, -1.6017, -0.8553, -0.6481, -0.6986,  0.4151,  0.1076,  0.6572,\n",
      "          0.4719,  0.6906],\n",
      "        [-1.9103, -1.4401,  2.4472, -1.3263,  1.4204,  0.1300, -0.6199, -0.6909,\n",
      "          0.1791,  0.6173]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2986,  0.2927,  1.3549,  0.9034,  1.3603, -0.0824,  1.7963, -2.7218,\n",
      "          0.4071, -0.8465],\n",
      "        [ 0.4002,  1.0000, -0.6961, -0.6152,  1.1049, -0.0128,  0.7497, -0.7880,\n",
      "         -0.5218, -1.3019],\n",
      "        [-0.5245, -1.6016, -0.8553, -0.6483, -0.6986,  0.4153,  0.1076,  0.6572,\n",
      "          0.4719,  0.6906],\n",
      "        [-1.9105, -1.4401,  2.4472, -1.3264,  1.4204,  0.1302, -0.6199, -0.6909,\n",
      "          0.1791,  0.6173]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2987,  0.2930,  1.3548,  0.9033,  1.3603, -0.0825,  1.7963, -2.7218,\n",
      "          0.4068, -0.8466],\n",
      "        [ 0.4004,  1.0002, -0.6962, -0.6152,  1.1049, -0.0130,  0.7497, -0.7880,\n",
      "         -0.5220, -1.3019],\n",
      "        [-0.5249, -1.6015, -0.8553, -0.6484, -0.6986,  0.4156,  0.1076,  0.6572,\n",
      "          0.4718,  0.6905],\n",
      "        [-1.9106, -1.4401,  2.4472, -1.3264,  1.4204,  0.1303, -0.6199, -0.6909,\n",
      "          0.1791,  0.6173]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2988,  0.2934,  1.3546,  0.9032,  1.3603, -0.0826,  1.7963, -2.7218,\n",
      "          0.4066, -0.8466],\n",
      "        [ 0.4007,  1.0004, -0.6962, -0.6152,  1.1049, -0.0132,  0.7497, -0.7880,\n",
      "         -0.5222, -1.3019],\n",
      "        [-0.5252, -1.6015, -0.8554, -0.6486, -0.6986,  0.4158,  0.1076,  0.6572,\n",
      "          0.4718,  0.6905],\n",
      "        [-1.9108, -1.4401,  2.4472, -1.3265,  1.4204,  0.1304, -0.6199, -0.6909,\n",
      "          0.1791,  0.6173]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2988,  0.2937,  1.3545,  0.9031,  1.3603, -0.0827,  1.7963, -2.7218,\n",
      "          0.4063, -0.8466],\n",
      "        [ 0.4009,  1.0007, -0.6963, -0.6152,  1.1049, -0.0134,  0.7497, -0.7880,\n",
      "         -0.5224, -1.3019],\n",
      "        [-0.5256, -1.6014, -0.8554, -0.6487, -0.6986,  0.4160,  0.1076,  0.6572,\n",
      "          0.4717,  0.6905],\n",
      "        [-1.9109, -1.4401,  2.4472, -1.3265,  1.4204,  0.1305, -0.6199, -0.6909,\n",
      "          0.1791,  0.6172]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2989,  0.2940,  1.3544,  0.9031,  1.3603, -0.0828,  1.7963, -2.7218,\n",
      "          0.4060, -0.8466],\n",
      "        [ 0.4012,  1.0009, -0.6964, -0.6152,  1.1049, -0.0136,  0.7497, -0.7880,\n",
      "         -0.5226, -1.3019],\n",
      "        [-0.5259, -1.6013, -0.8554, -0.6489, -0.6986,  0.4163,  0.1076,  0.6572,\n",
      "          0.4717,  0.6905],\n",
      "        [-1.9111, -1.4401,  2.4472, -1.3266,  1.4204,  0.1306, -0.6199, -0.6909,\n",
      "          0.1791,  0.6172]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2990,  0.2943,  1.3543,  0.9030,  1.3603, -0.0829,  1.7963, -2.7218,\n",
      "          0.4057, -0.8467],\n",
      "        [ 0.4014,  1.0011, -0.6965, -0.6152,  1.1049, -0.0138,  0.7497, -0.7880,\n",
      "         -0.5229, -1.3020],\n",
      "        [-0.5263, -1.6013, -0.8554, -0.6490, -0.6986,  0.4165,  0.1076,  0.6572,\n",
      "          0.4716,  0.6905],\n",
      "        [-1.9112, -1.4401,  2.4472, -1.3266,  1.4204,  0.1307, -0.6199, -0.6909,\n",
      "          0.1791,  0.6172]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2991,  0.2947,  1.3542,  0.9029,  1.3603, -0.0830,  1.7963, -2.7218,\n",
      "          0.4054, -0.8467],\n",
      "        [ 0.4017,  1.0014, -0.6966, -0.6152,  1.1049, -0.0139,  0.7497, -0.7880,\n",
      "         -0.5231, -1.3020],\n",
      "        [-0.5266, -1.6012, -0.8555, -0.6492, -0.6986,  0.4167,  0.1076,  0.6572,\n",
      "          0.4716,  0.6904],\n",
      "        [-1.9114, -1.4401,  2.4472, -1.3267,  1.4204,  0.1308, -0.6199, -0.6909,\n",
      "          0.1791,  0.6172]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2992,  0.2950,  1.3541,  0.9028,  1.3603, -0.0830,  1.7963, -2.7218,\n",
      "          0.4051, -0.8467],\n",
      "        [ 0.4019,  1.0016, -0.6967, -0.6152,  1.1049, -0.0141,  0.7497, -0.7880,\n",
      "         -0.5233, -1.3020],\n",
      "        [-0.5270, -1.6011, -0.8555, -0.6493, -0.6986,  0.4170,  0.1076,  0.6572,\n",
      "          0.4715,  0.6904],\n",
      "        [-1.9115, -1.4401,  2.4472, -1.3268,  1.4204,  0.1309, -0.6199, -0.6909,\n",
      "          0.1791,  0.6172]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2993,  0.2953,  1.3540,  0.9027,  1.3603, -0.0831,  1.7963, -2.7218,\n",
      "          0.4049, -0.8467],\n",
      "        [ 0.4022,  1.0018, -0.6967, -0.6151,  1.1049, -0.0143,  0.7497, -0.7880,\n",
      "         -0.5235, -1.3020],\n",
      "        [-0.5273, -1.6010, -0.8555, -0.6495, -0.6986,  0.4172,  0.1076,  0.6572,\n",
      "          0.4715,  0.6904],\n",
      "        [-1.9117, -1.4401,  2.4472, -1.3268,  1.4204,  0.1310, -0.6199, -0.6909,\n",
      "          0.1791,  0.6172]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2994,  0.2957,  1.3539,  0.9027,  1.3603, -0.0832,  1.7963, -2.7218,\n",
      "          0.4046, -0.8468],\n",
      "        [ 0.4024,  1.0021, -0.6968, -0.6151,  1.1049, -0.0145,  0.7497, -0.7880,\n",
      "         -0.5237, -1.3020],\n",
      "        [-0.5277, -1.6010, -0.8555, -0.6496, -0.6986,  0.4174,  0.1076,  0.6572,\n",
      "          0.4715,  0.6904],\n",
      "        [-1.9118, -1.4401,  2.4472, -1.3269,  1.4204,  0.1311, -0.6199, -0.6909,\n",
      "          0.1791,  0.6172]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2994,  0.2960,  1.3538,  0.9026,  1.3603, -0.0833,  1.7963, -2.7218,\n",
      "          0.4043, -0.8468],\n",
      "        [ 0.4027,  1.0023, -0.6969, -0.6151,  1.1049, -0.0147,  0.7497, -0.7880,\n",
      "         -0.5239, -1.3020],\n",
      "        [-0.5280, -1.6009, -0.8555, -0.6498, -0.6986,  0.4177,  0.1076,  0.6572,\n",
      "          0.4714,  0.6904],\n",
      "        [-1.9119, -1.4401,  2.4472, -1.3269,  1.4204,  0.1312, -0.6199, -0.6909,\n",
      "          0.1791,  0.6172]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2995,  0.2963,  1.3536,  0.9025,  1.3603, -0.0834,  1.7963, -2.7218,\n",
      "          0.4040, -0.8468],\n",
      "        [ 0.4029,  1.0025, -0.6970, -0.6151,  1.1049, -0.0149,  0.7497, -0.7880,\n",
      "         -0.5241, -1.3020],\n",
      "        [-0.5284, -1.6008, -0.8556, -0.6499, -0.6986,  0.4179,  0.1076,  0.6572,\n",
      "          0.4714,  0.6903],\n",
      "        [-1.9121, -1.4401,  2.4472, -1.3270,  1.4204,  0.1313, -0.6199, -0.6909,\n",
      "          0.1791,  0.6172]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2996,  0.2966,  1.3535,  0.9024,  1.3603, -0.0835,  1.7963, -2.7218,\n",
      "          0.4037, -0.8468],\n",
      "        [ 0.4032,  1.0028, -0.6971, -0.6151,  1.1049, -0.0150,  0.7497, -0.7880,\n",
      "         -0.5244, -1.3020],\n",
      "        [-0.5287, -1.6008, -0.8556, -0.6501, -0.6986,  0.4181,  0.1076,  0.6572,\n",
      "          0.4713,  0.6903],\n",
      "        [-1.9122, -1.4401,  2.4472, -1.3270,  1.4204,  0.1314, -0.6199, -0.6909,\n",
      "          0.1791,  0.6172]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2997,  0.2969,  1.3534,  0.9023,  1.3603, -0.0836,  1.7963, -2.7218,\n",
      "          0.4034, -0.8469],\n",
      "        [ 0.4034,  1.0030, -0.6971, -0.6151,  1.1049, -0.0152,  0.7497, -0.7880,\n",
      "         -0.5246, -1.3020],\n",
      "        [-0.5291, -1.6007, -0.8556, -0.6502, -0.6986,  0.4184,  0.1076,  0.6572,\n",
      "          0.4713,  0.6903],\n",
      "        [-1.9124, -1.4401,  2.4472, -1.3271,  1.4204,  0.1316, -0.6199, -0.6909,\n",
      "          0.1791,  0.6172]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2998,  0.2973,  1.3533,  0.9023,  1.3603, -0.0837,  1.7963, -2.7218,\n",
      "          0.4031, -0.8469],\n",
      "        [ 0.4037,  1.0032, -0.6972, -0.6151,  1.1049, -0.0154,  0.7497, -0.7880,\n",
      "         -0.5248, -1.3020],\n",
      "        [-0.5294, -1.6006, -0.8556, -0.6504, -0.6986,  0.4186,  0.1076,  0.6572,\n",
      "          0.4712,  0.6903],\n",
      "        [-1.9125, -1.4401,  2.4472, -1.3272,  1.4204,  0.1317, -0.6199, -0.6909,\n",
      "          0.1791,  0.6172]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2999,  0.2976,  1.3532,  0.9022,  1.3603, -0.0837,  1.7963, -2.7218,\n",
      "          0.4029, -0.8469],\n",
      "        [ 0.4039,  1.0035, -0.6973, -0.6151,  1.1049, -0.0156,  0.7497, -0.7880,\n",
      "         -0.5250, -1.3021],\n",
      "        [-0.5298, -1.6006, -0.8557, -0.6505, -0.6986,  0.4188,  0.1076,  0.6572,\n",
      "          0.4712,  0.6903],\n",
      "        [-1.9127, -1.4400,  2.4472, -1.3272,  1.4204,  0.1318, -0.6199, -0.6909,\n",
      "          0.1791,  0.6172]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.2999,  0.2979,  1.3531,  0.9021,  1.3603, -0.0838,  1.7963, -2.7218,\n",
      "          0.4026, -0.8469],\n",
      "        [ 0.4041,  1.0037, -0.6974, -0.6150,  1.1049, -0.0158,  0.7497, -0.7880,\n",
      "         -0.5252, -1.3021],\n",
      "        [-0.5301, -1.6005, -0.8557, -0.6507, -0.6986,  0.4191,  0.1076,  0.6572,\n",
      "          0.4712,  0.6902],\n",
      "        [-1.9128, -1.4400,  2.4472, -1.3273,  1.4204,  0.1319, -0.6199, -0.6909,\n",
      "          0.1791,  0.6172]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3000,  0.2982,  1.3530,  0.9020,  1.3603, -0.0839,  1.7963, -2.7218,\n",
      "          0.4023, -0.8470],\n",
      "        [ 0.4044,  1.0039, -0.6975, -0.6150,  1.1049, -0.0160,  0.7497, -0.7880,\n",
      "         -0.5254, -1.3021],\n",
      "        [-0.5305, -1.6004, -0.8557, -0.6508, -0.6986,  0.4193,  0.1076,  0.6572,\n",
      "          0.4711,  0.6902],\n",
      "        [-1.9130, -1.4400,  2.4472, -1.3273,  1.4204,  0.1320, -0.6199, -0.6909,\n",
      "          0.1791,  0.6172]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3001,  0.2985,  1.3529,  0.9020,  1.3603, -0.0840,  1.7963, -2.7218,\n",
      "          0.4020, -0.8470],\n",
      "        [ 0.4046,  1.0042, -0.6976, -0.6150,  1.1049, -0.0161,  0.7497, -0.7880,\n",
      "         -0.5256, -1.3021],\n",
      "        [-0.5308, -1.6004, -0.8557, -0.6510, -0.6986,  0.4195,  0.1076,  0.6572,\n",
      "          0.4711,  0.6902],\n",
      "        [-1.9131, -1.4400,  2.4472, -1.3274,  1.4204,  0.1321, -0.6199, -0.6909,\n",
      "          0.1792,  0.6171]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3002,  0.2989,  1.3528,  0.9019,  1.3603, -0.0841,  1.7963, -2.7218,\n",
      "          0.4017, -0.8470],\n",
      "        [ 0.4049,  1.0044, -0.6976, -0.6150,  1.1049, -0.0163,  0.7497, -0.7880,\n",
      "         -0.5259, -1.3021],\n",
      "        [-0.5312, -1.6003, -0.8558, -0.6511, -0.6986,  0.4197,  0.1076,  0.6572,\n",
      "          0.4710,  0.6902],\n",
      "        [-1.9133, -1.4400,  2.4472, -1.3274,  1.4204,  0.1322, -0.6199, -0.6909,\n",
      "          0.1792,  0.6171]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3003,  0.2992,  1.3526,  0.9018,  1.3603, -0.0842,  1.7963, -2.7218,\n",
      "          0.4014, -0.8470],\n",
      "        [ 0.4051,  1.0046, -0.6977, -0.6150,  1.1049, -0.0165,  0.7497, -0.7880,\n",
      "         -0.5261, -1.3021],\n",
      "        [-0.5315, -1.6002, -0.8558, -0.6513, -0.6986,  0.4200,  0.1076,  0.6572,\n",
      "          0.4710,  0.6902],\n",
      "        [-1.9134, -1.4400,  2.4472, -1.3275,  1.4204,  0.1323, -0.6199, -0.6909,\n",
      "          0.1792,  0.6171]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3004,  0.2995,  1.3525,  0.9017,  1.3603, -0.0843,  1.7963, -2.7218,\n",
      "          0.4012, -0.8470],\n",
      "        [ 0.4054,  1.0048, -0.6978, -0.6150,  1.1049, -0.0167,  0.7497, -0.7880,\n",
      "         -0.5263, -1.3021],\n",
      "        [-0.5319, -1.6002, -0.8558, -0.6514, -0.6986,  0.4202,  0.1076,  0.6572,\n",
      "          0.4709,  0.6901],\n",
      "        [-1.9136, -1.4400,  2.4472, -1.3275,  1.4204,  0.1324, -0.6199, -0.6909,\n",
      "          0.1792,  0.6171]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3004,  0.2998,  1.3524,  0.9017,  1.3603, -0.0844,  1.7963, -2.7218,\n",
      "          0.4009, -0.8471],\n",
      "        [ 0.4056,  1.0051, -0.6979, -0.6150,  1.1049, -0.0169,  0.7497, -0.7880,\n",
      "         -0.5265, -1.3021],\n",
      "        [-0.5322, -1.6001, -0.8558, -0.6516, -0.6986,  0.4204,  0.1076,  0.6572,\n",
      "          0.4709,  0.6901],\n",
      "        [-1.9137, -1.4400,  2.4472, -1.3276,  1.4204,  0.1325, -0.6199, -0.6909,\n",
      "          0.1792,  0.6171]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3005,  0.3001,  1.3523,  0.9016,  1.3603, -0.0844,  1.7963, -2.7218,\n",
      "          0.4006, -0.8471],\n",
      "        [ 0.4059,  1.0053, -0.6980, -0.6150,  1.1049, -0.0171,  0.7497, -0.7880,\n",
      "         -0.5267, -1.3021],\n",
      "        [-0.5326, -1.6000, -0.8558, -0.6517, -0.6986,  0.4207,  0.1076,  0.6572,\n",
      "          0.4709,  0.6901],\n",
      "        [-1.9139, -1.4400,  2.4472, -1.3277,  1.4204,  0.1326, -0.6199, -0.6909,\n",
      "          0.1792,  0.6171]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3006,  0.3004,  1.3522,  0.9015,  1.3603, -0.0845,  1.7963, -2.7218,\n",
      "          0.4003, -0.8471],\n",
      "        [ 0.4061,  1.0055, -0.6980, -0.6149,  1.1049, -0.0172,  0.7497, -0.7880,\n",
      "         -0.5269, -1.3022],\n",
      "        [-0.5329, -1.6000, -0.8559, -0.6519, -0.6986,  0.4209,  0.1076,  0.6572,\n",
      "          0.4708,  0.6901],\n",
      "        [-1.9140, -1.4400,  2.4472, -1.3277,  1.4204,  0.1327, -0.6199, -0.6909,\n",
      "          0.1792,  0.6171]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3007,  0.3007,  1.3521,  0.9014,  1.3603, -0.0846,  1.7963, -2.7218,\n",
      "          0.4000, -0.8471],\n",
      "        [ 0.4064,  1.0057, -0.6981, -0.6149,  1.1049, -0.0174,  0.7497, -0.7880,\n",
      "         -0.5271, -1.3022],\n",
      "        [-0.5333, -1.5999, -0.8559, -0.6520, -0.6986,  0.4211,  0.1076,  0.6572,\n",
      "          0.4708,  0.6901],\n",
      "        [-1.9142, -1.4400,  2.4472, -1.3278,  1.4204,  0.1328, -0.6199, -0.6909,\n",
      "          0.1792,  0.6171]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3008,  0.3010,  1.3520,  0.9014,  1.3603, -0.0847,  1.7963, -2.7218,\n",
      "          0.3997, -0.8472],\n",
      "        [ 0.4066,  1.0059, -0.6982, -0.6149,  1.1049, -0.0176,  0.7497, -0.7880,\n",
      "         -0.5274, -1.3022],\n",
      "        [-0.5336, -1.5999, -0.8559, -0.6522, -0.6986,  0.4214,  0.1076,  0.6572,\n",
      "          0.4707,  0.6901],\n",
      "        [-1.9143, -1.4400,  2.4472, -1.3278,  1.4204,  0.1329, -0.6199, -0.6909,\n",
      "          0.1792,  0.6171]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3008,  0.3013,  1.3519,  0.9013,  1.3603, -0.0848,  1.7963, -2.7218,\n",
      "          0.3994, -0.8472],\n",
      "        [ 0.4068,  1.0062, -0.6983, -0.6149,  1.1049, -0.0178,  0.7497, -0.7880,\n",
      "         -0.5276, -1.3022],\n",
      "        [-0.5339, -1.5998, -0.8559, -0.6523, -0.6986,  0.4216,  0.1076,  0.6572,\n",
      "          0.4707,  0.6900],\n",
      "        [-1.9145, -1.4400,  2.4472, -1.3279,  1.4204,  0.1330, -0.6199, -0.6909,\n",
      "          0.1792,  0.6171]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3009,  0.3016,  1.3518,  0.9012,  1.3603, -0.0849,  1.7963, -2.7218,\n",
      "          0.3992, -0.8472],\n",
      "        [ 0.4071,  1.0064, -0.6984, -0.6149,  1.1049, -0.0180,  0.7497, -0.7880,\n",
      "         -0.5278, -1.3022],\n",
      "        [-0.5343, -1.5997, -0.8560, -0.6525, -0.6986,  0.4218,  0.1076,  0.6572,\n",
      "          0.4706,  0.6900],\n",
      "        [-1.9146, -1.4400,  2.4472, -1.3279,  1.4204,  0.1331, -0.6199, -0.6909,\n",
      "          0.1792,  0.6171]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3010,  0.3019,  1.3516,  0.9011,  1.3603, -0.0850,  1.7963, -2.7218,\n",
      "          0.3989, -0.8472],\n",
      "        [ 0.4073,  1.0066, -0.6984, -0.6149,  1.1049, -0.0181,  0.7497, -0.7880,\n",
      "         -0.5280, -1.3022],\n",
      "        [-0.5346, -1.5997, -0.8560, -0.6526, -0.6986,  0.4220,  0.1076,  0.6572,\n",
      "          0.4706,  0.6900],\n",
      "        [-1.9147, -1.4400,  2.4472, -1.3280,  1.4204,  0.1333, -0.6199, -0.6909,\n",
      "          0.1792,  0.6171]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3011,  0.3023,  1.3515,  0.9011,  1.3603, -0.0851,  1.7963, -2.7218,\n",
      "          0.3986, -0.8473],\n",
      "        [ 0.4076,  1.0068, -0.6985, -0.6149,  1.1049, -0.0183,  0.7497, -0.7880,\n",
      "         -0.5282, -1.3022],\n",
      "        [-0.5350, -1.5996, -0.8560, -0.6527, -0.6986,  0.4223,  0.1076,  0.6572,\n",
      "          0.4706,  0.6900],\n",
      "        [-1.9149, -1.4400,  2.4472, -1.3280,  1.4204,  0.1334, -0.6199, -0.6909,\n",
      "          0.1792,  0.6171]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3012,  0.3026,  1.3514,  0.9010,  1.3603, -0.0852,  1.7963, -2.7218,\n",
      "          0.3983, -0.8473],\n",
      "        [ 0.4078,  1.0070, -0.6986, -0.6148,  1.1049, -0.0185,  0.7497, -0.7880,\n",
      "         -0.5284, -1.3022],\n",
      "        [-0.5353, -1.5995, -0.8560, -0.6529, -0.6986,  0.4225,  0.1076,  0.6572,\n",
      "          0.4705,  0.6900],\n",
      "        [-1.9150, -1.4400,  2.4472, -1.3281,  1.4204,  0.1335, -0.6199, -0.6909,\n",
      "          0.1792,  0.6171]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3013,  0.3029,  1.3513,  0.9009,  1.3603, -0.0852,  1.7963, -2.7218,\n",
      "          0.3980, -0.8473],\n",
      "        [ 0.4081,  1.0073, -0.6987, -0.6148,  1.1049, -0.0187,  0.7497, -0.7880,\n",
      "         -0.5286, -1.3022],\n",
      "        [-0.5357, -1.5995, -0.8560, -0.6530, -0.6986,  0.4227,  0.1076,  0.6572,\n",
      "          0.4705,  0.6899],\n",
      "        [-1.9152, -1.4400,  2.4472, -1.3282,  1.4204,  0.1336, -0.6199, -0.6909,\n",
      "          0.1792,  0.6171]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3013,  0.3032,  1.3512,  0.9008,  1.3603, -0.0853,  1.7963, -2.7218,\n",
      "          0.3977, -0.8473],\n",
      "        [ 0.4083,  1.0075, -0.6988, -0.6148,  1.1049, -0.0189,  0.7497, -0.7880,\n",
      "         -0.5289, -1.3022],\n",
      "        [-0.5360, -1.5994, -0.8561, -0.6532, -0.6986,  0.4229,  0.1076,  0.6572,\n",
      "          0.4704,  0.6899],\n",
      "        [-1.9153, -1.4400,  2.4472, -1.3282,  1.4204,  0.1337, -0.6199, -0.6909,\n",
      "          0.1792,  0.6170]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3014,  0.3035,  1.3511,  0.9008,  1.3603, -0.0854,  1.7963, -2.7218,\n",
      "          0.3974, -0.8474],\n",
      "        [ 0.4085,  1.0077, -0.6989, -0.6148,  1.1049, -0.0191,  0.7497, -0.7880,\n",
      "         -0.5291, -1.3023],\n",
      "        [-0.5364, -1.5994, -0.8561, -0.6533, -0.6986,  0.4232,  0.1076,  0.6572,\n",
      "          0.4704,  0.6899],\n",
      "        [-1.9155, -1.4400,  2.4472, -1.3283,  1.4204,  0.1338, -0.6199, -0.6909,\n",
      "          0.1792,  0.6170]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3015,  0.3038,  1.3510,  0.9007,  1.3603, -0.0855,  1.7963, -2.7218,\n",
      "          0.3972, -0.8474],\n",
      "        [ 0.4088,  1.0079, -0.6989, -0.6148,  1.1049, -0.0192,  0.7497, -0.7880,\n",
      "         -0.5293, -1.3023],\n",
      "        [-0.5367, -1.5993, -0.8561, -0.6535, -0.6986,  0.4234,  0.1076,  0.6572,\n",
      "          0.4703,  0.6899],\n",
      "        [-1.9156, -1.4400,  2.4472, -1.3283,  1.4204,  0.1339, -0.6199, -0.6909,\n",
      "          0.1792,  0.6170]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3016,  0.3041,  1.3509,  0.9006,  1.3603, -0.0856,  1.7963, -2.7218,\n",
      "          0.3969, -0.8474],\n",
      "        [ 0.4090,  1.0081, -0.6990, -0.6148,  1.1049, -0.0194,  0.7497, -0.7880,\n",
      "         -0.5295, -1.3023],\n",
      "        [-0.5370, -1.5992, -0.8561, -0.6536, -0.6986,  0.4236,  0.1076,  0.6572,\n",
      "          0.4703,  0.6899],\n",
      "        [-1.9158, -1.4400,  2.4472, -1.3284,  1.4204,  0.1340, -0.6199, -0.6909,\n",
      "          0.1792,  0.6170]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3017,  0.3043,  1.3507,  0.9006,  1.3603, -0.0857,  1.7963, -2.7218,\n",
      "          0.3966, -0.8474],\n",
      "        [ 0.4093,  1.0083, -0.6991, -0.6148,  1.1049, -0.0196,  0.7497, -0.7880,\n",
      "         -0.5297, -1.3023],\n",
      "        [-0.5374, -1.5992, -0.8562, -0.6538, -0.6986,  0.4239,  0.1076,  0.6572,\n",
      "          0.4703,  0.6898],\n",
      "        [-1.9159, -1.4400,  2.4472, -1.3284,  1.4204,  0.1341, -0.6199, -0.6909,\n",
      "          0.1792,  0.6170]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3017,  0.3046,  1.3506,  0.9005,  1.3603, -0.0858,  1.7963, -2.7218,\n",
      "          0.3963, -0.8474],\n",
      "        [ 0.4095,  1.0086, -0.6992, -0.6147,  1.1049, -0.0198,  0.7497, -0.7880,\n",
      "         -0.5299, -1.3023],\n",
      "        [-0.5377, -1.5991, -0.8562, -0.6539, -0.6986,  0.4241,  0.1076,  0.6572,\n",
      "          0.4702,  0.6898],\n",
      "        [-1.9161, -1.4400,  2.4472, -1.3285,  1.4204,  0.1342, -0.6199, -0.6909,\n",
      "          0.1792,  0.6170]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3018,  0.3049,  1.3505,  0.9004,  1.3603, -0.0859,  1.7963, -2.7218,\n",
      "          0.3960, -0.8475],\n",
      "        [ 0.4098,  1.0088, -0.6993, -0.6147,  1.1049, -0.0200,  0.7497, -0.7880,\n",
      "         -0.5302, -1.3023],\n",
      "        [-0.5381, -1.5991, -0.8562, -0.6541, -0.6986,  0.4243,  0.1076,  0.6572,\n",
      "          0.4702,  0.6898],\n",
      "        [-1.9162, -1.4400,  2.4472, -1.3285,  1.4204,  0.1343, -0.6199, -0.6909,\n",
      "          0.1792,  0.6170]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3019,  0.3052,  1.3504,  0.9003,  1.3603, -0.0860,  1.7963, -2.7218,\n",
      "          0.3957, -0.8475],\n",
      "        [ 0.4100,  1.0090, -0.6993, -0.6147,  1.1049, -0.0202,  0.7497, -0.7880,\n",
      "         -0.5304, -1.3023],\n",
      "        [-0.5384, -1.5990, -0.8562, -0.6542, -0.6986,  0.4245,  0.1076,  0.6572,\n",
      "          0.4701,  0.6898],\n",
      "        [-1.9163, -1.4400,  2.4472, -1.3286,  1.4204,  0.1344, -0.6199, -0.6909,\n",
      "          0.1792,  0.6170]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3020,  0.3055,  1.3503,  0.9003,  1.3603, -0.0860,  1.7963, -2.7218,\n",
      "          0.3954, -0.8475],\n",
      "        [ 0.4102,  1.0092, -0.6994, -0.6147,  1.1049, -0.0203,  0.7497, -0.7880,\n",
      "         -0.5306, -1.3023],\n",
      "        [-0.5387, -1.5990, -0.8563, -0.6543, -0.6986,  0.4248,  0.1076,  0.6572,\n",
      "          0.4701,  0.6898],\n",
      "        [-1.9165, -1.4400,  2.4472, -1.3287,  1.4204,  0.1345, -0.6199, -0.6909,\n",
      "          0.1792,  0.6170]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3021,  0.3058,  1.3502,  0.9002,  1.3603, -0.0861,  1.7963, -2.7218,\n",
      "          0.3951, -0.8475],\n",
      "        [ 0.4105,  1.0094, -0.6995, -0.6147,  1.1049, -0.0205,  0.7497, -0.7880,\n",
      "         -0.5308, -1.3023],\n",
      "        [-0.5391, -1.5989, -0.8563, -0.6545, -0.6986,  0.4250,  0.1076,  0.6572,\n",
      "          0.4700,  0.6897],\n",
      "        [-1.9166, -1.4400,  2.4472, -1.3287,  1.4204,  0.1346, -0.6199, -0.6909,\n",
      "          0.1792,  0.6170]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3021,  0.3061,  1.3501,  0.9001,  1.3603, -0.0862,  1.7963, -2.7218,\n",
      "          0.3949, -0.8476],\n",
      "        [ 0.4107,  1.0096, -0.6996, -0.6147,  1.1049, -0.0207,  0.7497, -0.7880,\n",
      "         -0.5310, -1.3024],\n",
      "        [-0.5394, -1.5988, -0.8563, -0.6546, -0.6986,  0.4252,  0.1076,  0.6572,\n",
      "          0.4700,  0.6897],\n",
      "        [-1.9168, -1.4400,  2.4472, -1.3288,  1.4204,  0.1347, -0.6199, -0.6909,\n",
      "          0.1792,  0.6170]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3022,  0.3064,  1.3500,  0.9001,  1.3603, -0.0863,  1.7963, -2.7218,\n",
      "          0.3946, -0.8476],\n",
      "        [ 0.4110,  1.0098, -0.6997, -0.6146,  1.1049, -0.0209,  0.7497, -0.7880,\n",
      "         -0.5312, -1.3024],\n",
      "        [-0.5397, -1.5988, -0.8563, -0.6548, -0.6986,  0.4254,  0.1076,  0.6572,\n",
      "          0.4700,  0.6897],\n",
      "        [-1.9169, -1.4400,  2.4472, -1.3288,  1.4204,  0.1348, -0.6199, -0.6909,\n",
      "          0.1792,  0.6170]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3023,  0.3067,  1.3499,  0.9000,  1.3603, -0.0864,  1.7963, -2.7218,\n",
      "          0.3943, -0.8476],\n",
      "        [ 0.4112,  1.0100, -0.6998, -0.6146,  1.1049, -0.0211,  0.7497, -0.7880,\n",
      "         -0.5315, -1.3024],\n",
      "        [-0.5401, -1.5987, -0.8563, -0.6549, -0.6986,  0.4257,  0.1076,  0.6572,\n",
      "          0.4699,  0.6897],\n",
      "        [-1.9171, -1.4400,  2.4472, -1.3289,  1.4204,  0.1349, -0.6199, -0.6909,\n",
      "          0.1793,  0.6170]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3024,  0.3070,  1.3497,  0.8999,  1.3603, -0.0865,  1.7963, -2.7218,\n",
      "          0.3940, -0.8476],\n",
      "        [ 0.4114,  1.0103, -0.6998, -0.6146,  1.1049, -0.0212,  0.7497, -0.7880,\n",
      "         -0.5317, -1.3024],\n",
      "        [-0.5404, -1.5987, -0.8564, -0.6551, -0.6986,  0.4259,  0.1076,  0.6572,\n",
      "          0.4699,  0.6897],\n",
      "        [-1.9172, -1.4400,  2.4472, -1.3289,  1.4204,  0.1350, -0.6199, -0.6909,\n",
      "          0.1793,  0.6170]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3025,  0.3073,  1.3496,  0.8998,  1.3603, -0.0866,  1.7963, -2.7218,\n",
      "          0.3937, -0.8477],\n",
      "        [ 0.4117,  1.0105, -0.6999, -0.6146,  1.1049, -0.0214,  0.7497, -0.7880,\n",
      "         -0.5319, -1.3024],\n",
      "        [-0.5408, -1.5986, -0.8564, -0.6552, -0.6986,  0.4261,  0.1076,  0.6572,\n",
      "          0.4698,  0.6897],\n",
      "        [-1.9173, -1.4400,  2.4472, -1.3290,  1.4204,  0.1351, -0.6199, -0.6909,\n",
      "          0.1793,  0.6170]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3025,  0.3075,  1.3495,  0.8998,  1.3603, -0.0867,  1.7963, -2.7218,\n",
      "          0.3934, -0.8477],\n",
      "        [ 0.4119,  1.0107, -0.7000, -0.6146,  1.1049, -0.0216,  0.7497, -0.7880,\n",
      "         -0.5321, -1.3024],\n",
      "        [-0.5411, -1.5986, -0.8564, -0.6554, -0.6986,  0.4263,  0.1076,  0.6572,\n",
      "          0.4698,  0.6896],\n",
      "        [-1.9175, -1.4399,  2.4472, -1.3290,  1.4204,  0.1352, -0.6199, -0.6909,\n",
      "          0.1793,  0.6169]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3026,  0.3078,  1.3494,  0.8997,  1.3603, -0.0868,  1.7963, -2.7218,\n",
      "          0.3931, -0.8477],\n",
      "        [ 0.4121,  1.0109, -0.7001, -0.6146,  1.1049, -0.0218,  0.7497, -0.7880,\n",
      "         -0.5323, -1.3024],\n",
      "        [-0.5414, -1.5985, -0.8564, -0.6555, -0.6986,  0.4266,  0.1076,  0.6572,\n",
      "          0.4698,  0.6896],\n",
      "        [-1.9176, -1.4399,  2.4472, -1.3291,  1.4204,  0.1354, -0.6199, -0.6909,\n",
      "          0.1793,  0.6169]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3027,  0.3081,  1.3493,  0.8996,  1.3603, -0.0869,  1.7963, -2.7218,\n",
      "          0.3929, -0.8477],\n",
      "        [ 0.4124,  1.0111, -0.7002, -0.6145,  1.1049, -0.0220,  0.7497, -0.7880,\n",
      "         -0.5325, -1.3024],\n",
      "        [-0.5418, -1.5985, -0.8565, -0.6556, -0.6986,  0.4268,  0.1076,  0.6572,\n",
      "          0.4697,  0.6896],\n",
      "        [-1.9178, -1.4399,  2.4472, -1.3292,  1.4204,  0.1355, -0.6199, -0.6909,\n",
      "          0.1793,  0.6169]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3028,  0.3084,  1.3492,  0.8996,  1.3603, -0.0869,  1.7963, -2.7218,\n",
      "          0.3926, -0.8477],\n",
      "        [ 0.4126,  1.0113, -0.7002, -0.6145,  1.1049, -0.0221,  0.7497, -0.7880,\n",
      "         -0.5328, -1.3024],\n",
      "        [-0.5421, -1.5984, -0.8565, -0.6558, -0.6986,  0.4270,  0.1076,  0.6572,\n",
      "          0.4697,  0.6896],\n",
      "        [-1.9179, -1.4399,  2.4472, -1.3292,  1.4204,  0.1356, -0.6199, -0.6909,\n",
      "          0.1793,  0.6169]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3028,  0.3087,  1.3491,  0.8995,  1.3603, -0.0870,  1.7963, -2.7218,\n",
      "          0.3923, -0.8478],\n",
      "        [ 0.4129,  1.0115, -0.7003, -0.6145,  1.1049, -0.0223,  0.7497, -0.7880,\n",
      "         -0.5330, -1.3024],\n",
      "        [-0.5424, -1.5983, -0.8565, -0.6559, -0.6986,  0.4272,  0.1076,  0.6572,\n",
      "          0.4696,  0.6896],\n",
      "        [-1.9181, -1.4399,  2.4472, -1.3293,  1.4204,  0.1357, -0.6199, -0.6909,\n",
      "          0.1793,  0.6169]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3029,  0.3090,  1.3490,  0.8994,  1.3603, -0.0871,  1.7963, -2.7218,\n",
      "          0.3920, -0.8478],\n",
      "        [ 0.4131,  1.0117, -0.7004, -0.6145,  1.1049, -0.0225,  0.7497, -0.7880,\n",
      "         -0.5332, -1.3025],\n",
      "        [-0.5428, -1.5983, -0.8565, -0.6561, -0.6986,  0.4275,  0.1076,  0.6572,\n",
      "          0.4696,  0.6895],\n",
      "        [-1.9182, -1.4399,  2.4472, -1.3293,  1.4204,  0.1358, -0.6199, -0.6909,\n",
      "          0.1793,  0.6169]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3030,  0.3092,  1.3489,  0.8994,  1.3603, -0.0872,  1.7963, -2.7218,\n",
      "          0.3917, -0.8478],\n",
      "        [ 0.4133,  1.0119, -0.7005, -0.6145,  1.1049, -0.0227,  0.7497, -0.7880,\n",
      "         -0.5334, -1.3025],\n",
      "        [-0.5431, -1.5982, -0.8565, -0.6562, -0.6986,  0.4277,  0.1076,  0.6572,\n",
      "          0.4696,  0.6895],\n",
      "        [-1.9183, -1.4399,  2.4472, -1.3294,  1.4204,  0.1359, -0.6199, -0.6909,\n",
      "          0.1793,  0.6169]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3031,  0.3095,  1.3487,  0.8993,  1.3603, -0.0873,  1.7963, -2.7218,\n",
      "          0.3914, -0.8478],\n",
      "        [ 0.4136,  1.0121, -0.7006, -0.6145,  1.1049, -0.0229,  0.7497, -0.7880,\n",
      "         -0.5336, -1.3025],\n",
      "        [-0.5434, -1.5982, -0.8566, -0.6563, -0.6986,  0.4279,  0.1076,  0.6572,\n",
      "          0.4695,  0.6895],\n",
      "        [-1.9185, -1.4399,  2.4472, -1.3294,  1.4204,  0.1360, -0.6199, -0.6909,\n",
      "          0.1793,  0.6169]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3032,  0.3098,  1.3486,  0.8992,  1.3603, -0.0874,  1.7963, -2.7218,\n",
      "          0.3911, -0.8479],\n",
      "        [ 0.4138,  1.0123, -0.7007, -0.6144,  1.1049, -0.0231,  0.7497, -0.7880,\n",
      "         -0.5338, -1.3025],\n",
      "        [-0.5438, -1.5981, -0.8566, -0.6565, -0.6986,  0.4281,  0.1076,  0.6572,\n",
      "          0.4695,  0.6895],\n",
      "        [-1.9186, -1.4399,  2.4472, -1.3295,  1.4204,  0.1361, -0.6199, -0.6909,\n",
      "          0.1793,  0.6169]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3032,  0.3101,  1.3485,  0.8992,  1.3603, -0.0875,  1.7963, -2.7218,\n",
      "          0.3908, -0.8479],\n",
      "        [ 0.4140,  1.0125, -0.7007, -0.6144,  1.1049, -0.0232,  0.7497, -0.7880,\n",
      "         -0.5341, -1.3025],\n",
      "        [-0.5441, -1.5981, -0.8566, -0.6566, -0.6986,  0.4283,  0.1076,  0.6572,\n",
      "          0.4694,  0.6895],\n",
      "        [-1.9188, -1.4399,  2.4472, -1.3295,  1.4204,  0.1362, -0.6199, -0.6909,\n",
      "          0.1793,  0.6169]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3033,  0.3103,  1.3484,  0.8991,  1.3603, -0.0876,  1.7963, -2.7218,\n",
      "          0.3906, -0.8479],\n",
      "        [ 0.4143,  1.0127, -0.7008, -0.6144,  1.1049, -0.0234,  0.7497, -0.7880,\n",
      "         -0.5343, -1.3025],\n",
      "        [-0.5444, -1.5980, -0.8566, -0.6568, -0.6986,  0.4286,  0.1076,  0.6572,\n",
      "          0.4694,  0.6894],\n",
      "        [-1.9189, -1.4399,  2.4472, -1.3296,  1.4204,  0.1363, -0.6199, -0.6909,\n",
      "          0.1793,  0.6169]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3034,  0.3106,  1.3483,  0.8990,  1.3603, -0.0877,  1.7963, -2.7218,\n",
      "          0.3903, -0.8479],\n",
      "        [ 0.4145,  1.0129, -0.7009, -0.6144,  1.1049, -0.0236,  0.7497, -0.7880,\n",
      "         -0.5345, -1.3025],\n",
      "        [-0.5448, -1.5980, -0.8567, -0.6569, -0.6986,  0.4288,  0.1076,  0.6572,\n",
      "          0.4693,  0.6894],\n",
      "        [-1.9191, -1.4399,  2.4472, -1.3296,  1.4204,  0.1364, -0.6199, -0.6909,\n",
      "          0.1793,  0.6169]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3035,  0.3109,  1.3482,  0.8990,  1.3603, -0.0878,  1.7963, -2.7218,\n",
      "          0.3900, -0.8480],\n",
      "        [ 0.4147,  1.0131, -0.7010, -0.6144,  1.1049, -0.0238,  0.7497, -0.7880,\n",
      "         -0.5347, -1.3025],\n",
      "        [-0.5451, -1.5979, -0.8567, -0.6571, -0.6986,  0.4290,  0.1076,  0.6572,\n",
      "          0.4693,  0.6894],\n",
      "        [-1.9192, -1.4399,  2.4472, -1.3297,  1.4204,  0.1365, -0.6199, -0.6909,\n",
      "          0.1793,  0.6169]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3035,  0.3112,  1.3481,  0.8989,  1.3603, -0.0878,  1.7963, -2.7218,\n",
      "          0.3897, -0.8480],\n",
      "        [ 0.4150,  1.0133, -0.7011, -0.6144,  1.1049, -0.0240,  0.7497, -0.7880,\n",
      "         -0.5349, -1.3025],\n",
      "        [-0.5454, -1.5979, -0.8567, -0.6572, -0.6986,  0.4292,  0.1076,  0.6572,\n",
      "          0.4693,  0.6894],\n",
      "        [-1.9193, -1.4399,  2.4472, -1.3297,  1.4204,  0.1366, -0.6199, -0.6909,\n",
      "          0.1793,  0.6169]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3036,  0.3114,  1.3480,  0.8988,  1.3603, -0.0879,  1.7963, -2.7218,\n",
      "          0.3894, -0.8480],\n",
      "        [ 0.4152,  1.0135, -0.7011, -0.6143,  1.1049, -0.0241,  0.7497, -0.7880,\n",
      "         -0.5351, -1.3025],\n",
      "        [-0.5458, -1.5978, -0.8567, -0.6573, -0.6986,  0.4295,  0.1076,  0.6572,\n",
      "          0.4692,  0.6894],\n",
      "        [-1.9195, -1.4399,  2.4472, -1.3298,  1.4204,  0.1367, -0.6199, -0.6909,\n",
      "          0.1793,  0.6169]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3037,  0.3117,  1.3479,  0.8988,  1.3603, -0.0880,  1.7963, -2.7218,\n",
      "          0.3891, -0.8480],\n",
      "        [ 0.4154,  1.0137, -0.7012, -0.6143,  1.1049, -0.0243,  0.7497, -0.7880,\n",
      "         -0.5354, -1.3026],\n",
      "        [-0.5461, -1.5978, -0.8568, -0.6575, -0.6986,  0.4297,  0.1076,  0.6572,\n",
      "          0.4692,  0.6894],\n",
      "        [-1.9196, -1.4399,  2.4472, -1.3299,  1.4204,  0.1368, -0.6199, -0.6909,\n",
      "          0.1793,  0.6169]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3038,  0.3120,  1.3477,  0.8987,  1.3603, -0.0881,  1.7963, -2.7218,\n",
      "          0.3888, -0.8480],\n",
      "        [ 0.4157,  1.0139, -0.7013, -0.6143,  1.1049, -0.0245,  0.7497, -0.7880,\n",
      "         -0.5356, -1.3026],\n",
      "        [-0.5464, -1.5977, -0.8568, -0.6576, -0.6986,  0.4299,  0.1076,  0.6572,\n",
      "          0.4691,  0.6893],\n",
      "        [-1.9198, -1.4399,  2.4472, -1.3299,  1.4204,  0.1369, -0.6199, -0.6909,\n",
      "          0.1793,  0.6168]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3038,  0.3123,  1.3476,  0.8986,  1.3603, -0.0882,  1.7963, -2.7218,\n",
      "          0.3886, -0.8481],\n",
      "        [ 0.4159,  1.0141, -0.7014, -0.6143,  1.1049, -0.0247,  0.7497, -0.7880,\n",
      "         -0.5358, -1.3026],\n",
      "        [-0.5468, -1.5977, -0.8568, -0.6578, -0.6986,  0.4301,  0.1076,  0.6572,\n",
      "          0.4691,  0.6893],\n",
      "        [-1.9199, -1.4399,  2.4472, -1.3300,  1.4204,  0.1370, -0.6199, -0.6909,\n",
      "          0.1793,  0.6168]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3039,  0.3125,  1.3475,  0.8986,  1.3603, -0.0883,  1.7963, -2.7218,\n",
      "          0.3883, -0.8481],\n",
      "        [ 0.4161,  1.0143, -0.7015, -0.6143,  1.1049, -0.0249,  0.7497, -0.7880,\n",
      "         -0.5360, -1.3026],\n",
      "        [-0.5471, -1.5976, -0.8568, -0.6579, -0.6986,  0.4303,  0.1076,  0.6572,\n",
      "          0.4691,  0.6893],\n",
      "        [-1.9200, -1.4399,  2.4472, -1.3300,  1.4204,  0.1371, -0.6199, -0.6909,\n",
      "          0.1793,  0.6168]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3040,  0.3128,  1.3474,  0.8985,  1.3603, -0.0884,  1.7963, -2.7218,\n",
      "          0.3880, -0.8481],\n",
      "        [ 0.4164,  1.0145, -0.7016, -0.6143,  1.1049, -0.0250,  0.7497, -0.7880,\n",
      "         -0.5362, -1.3026],\n",
      "        [-0.5474, -1.5976, -0.8568, -0.6580, -0.6986,  0.4306,  0.1076,  0.6572,\n",
      "          0.4690,  0.6893],\n",
      "        [-1.9202, -1.4399,  2.4472, -1.3301,  1.4204,  0.1372, -0.6199, -0.6909,\n",
      "          0.1793,  0.6168]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3041,  0.3131,  1.3473,  0.8984,  1.3603, -0.0885,  1.7963, -2.7218,\n",
      "          0.3877, -0.8481],\n",
      "        [ 0.4166,  1.0147, -0.7016, -0.6142,  1.1049, -0.0252,  0.7497, -0.7880,\n",
      "         -0.5364, -1.3026],\n",
      "        [-0.5478, -1.5975, -0.8569, -0.6582, -0.6986,  0.4308,  0.1076,  0.6572,\n",
      "          0.4690,  0.6893],\n",
      "        [-1.9203, -1.4399,  2.4472, -1.3301,  1.4204,  0.1373, -0.6199, -0.6909,\n",
      "          0.1794,  0.6168]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3042,  0.3133,  1.3472,  0.8984,  1.3603, -0.0886,  1.7963, -2.7218,\n",
      "          0.3874, -0.8482],\n",
      "        [ 0.4168,  1.0149, -0.7017, -0.6142,  1.1049, -0.0254,  0.7497, -0.7880,\n",
      "         -0.5367, -1.3026],\n",
      "        [-0.5481, -1.5975, -0.8569, -0.6583, -0.6986,  0.4310,  0.1076,  0.6572,\n",
      "          0.4689,  0.6892],\n",
      "        [-1.9205, -1.4399,  2.4472, -1.3302,  1.4204,  0.1374, -0.6199, -0.6909,\n",
      "          0.1794,  0.6168]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3042,  0.3136,  1.3471,  0.8983,  1.3603, -0.0887,  1.7963, -2.7218,\n",
      "          0.3871, -0.8482],\n",
      "        [ 0.4171,  1.0151, -0.7018, -0.6142,  1.1049, -0.0256,  0.7497, -0.7880,\n",
      "         -0.5369, -1.3026],\n",
      "        [-0.5484, -1.5974, -0.8569, -0.6585, -0.6986,  0.4312,  0.1076,  0.6572,\n",
      "          0.4689,  0.6892],\n",
      "        [-1.9206, -1.4399,  2.4472, -1.3302,  1.4204,  0.1375, -0.6199, -0.6909,\n",
      "          0.1794,  0.6168]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3043,  0.3139,  1.3470,  0.8982,  1.3603, -0.0888,  1.7963, -2.7218,\n",
      "          0.3868, -0.8482],\n",
      "        [ 0.4173,  1.0153, -0.7019, -0.6142,  1.1049, -0.0258,  0.7497, -0.7880,\n",
      "         -0.5371, -1.3026],\n",
      "        [-0.5487, -1.5974, -0.8569, -0.6586, -0.6986,  0.4314,  0.1076,  0.6572,\n",
      "          0.4689,  0.6892],\n",
      "        [-1.9207, -1.4399,  2.4472, -1.3303,  1.4204,  0.1376, -0.6199, -0.6909,\n",
      "          0.1794,  0.6168]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3044,  0.3141,  1.3468,  0.8982,  1.3603, -0.0888,  1.7963, -2.7218,\n",
      "          0.3865, -0.8482],\n",
      "        [ 0.4175,  1.0155, -0.7020, -0.6142,  1.1049, -0.0260,  0.7497, -0.7880,\n",
      "         -0.5373, -1.3026],\n",
      "        [-0.5491, -1.5973, -0.8570, -0.6587, -0.6986,  0.4317,  0.1076,  0.6572,\n",
      "          0.4688,  0.6892],\n",
      "        [-1.9209, -1.4399,  2.4472, -1.3303,  1.4204,  0.1377, -0.6199, -0.6909,\n",
      "          0.1794,  0.6168]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3045,  0.3144,  1.3467,  0.8981,  1.3603, -0.0889,  1.7963, -2.7218,\n",
      "          0.3863, -0.8482],\n",
      "        [ 0.4178,  1.0157, -0.7020, -0.6141,  1.1049, -0.0261,  0.7497, -0.7880,\n",
      "         -0.5375, -1.3027],\n",
      "        [-0.5494, -1.5973, -0.8570, -0.6589, -0.6986,  0.4319,  0.1076,  0.6572,\n",
      "          0.4688,  0.6892],\n",
      "        [-1.9210, -1.4399,  2.4472, -1.3304,  1.4204,  0.1378, -0.6199, -0.6909,\n",
      "          0.1794,  0.6168]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3045,  0.3146,  1.3466,  0.8980,  1.3603, -0.0890,  1.7963, -2.7218,\n",
      "          0.3860, -0.8483],\n",
      "        [ 0.4180,  1.0159, -0.7021, -0.6141,  1.1049, -0.0263,  0.7497, -0.7880,\n",
      "         -0.5377, -1.3027],\n",
      "        [-0.5497, -1.5973, -0.8570, -0.6590, -0.6986,  0.4321,  0.1076,  0.6572,\n",
      "          0.4688,  0.6892],\n",
      "        [-1.9212, -1.4399,  2.4472, -1.3304,  1.4204,  0.1379, -0.6199, -0.6909,\n",
      "          0.1794,  0.6168]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3046,  0.3149,  1.3465,  0.8980,  1.3603, -0.0891,  1.7963, -2.7218,\n",
      "          0.3857, -0.8483],\n",
      "        [ 0.4182,  1.0161, -0.7022, -0.6141,  1.1049, -0.0265,  0.7497, -0.7880,\n",
      "         -0.5380, -1.3027],\n",
      "        [-0.5501, -1.5972, -0.8570, -0.6592, -0.6986,  0.4323,  0.1076,  0.6572,\n",
      "          0.4687,  0.6891],\n",
      "        [-1.9213, -1.4399,  2.4472, -1.3305,  1.4204,  0.1380, -0.6199, -0.6909,\n",
      "          0.1794,  0.6168]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3047,  0.3152,  1.3464,  0.8979,  1.3603, -0.0892,  1.7963, -2.7218,\n",
      "          0.3854, -0.8483],\n",
      "        [ 0.4184,  1.0163, -0.7023, -0.6141,  1.1049, -0.0267,  0.7497, -0.7880,\n",
      "         -0.5382, -1.3027],\n",
      "        [-0.5504, -1.5972, -0.8570, -0.6593, -0.6985,  0.4325,  0.1076,  0.6572,\n",
      "          0.4687,  0.6891],\n",
      "        [-1.9214, -1.4399,  2.4472, -1.3306,  1.4204,  0.1381, -0.6199, -0.6909,\n",
      "          0.1794,  0.6168]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3048,  0.3154,  1.3463,  0.8978,  1.3603, -0.0893,  1.7963, -2.7218,\n",
      "          0.3851, -0.8483],\n",
      "        [ 0.4187,  1.0164, -0.7024, -0.6141,  1.1049, -0.0269,  0.7497, -0.7880,\n",
      "         -0.5384, -1.3027],\n",
      "        [-0.5507, -1.5971, -0.8571, -0.6594, -0.6985,  0.4328,  0.1076,  0.6572,\n",
      "          0.4686,  0.6891],\n",
      "        [-1.9216, -1.4399,  2.4472, -1.3306,  1.4204,  0.1382, -0.6199, -0.6909,\n",
      "          0.1794,  0.6168]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3048,  0.3157,  1.3462,  0.8978,  1.3603, -0.0894,  1.7963, -2.7218,\n",
      "          0.3848, -0.8484],\n",
      "        [ 0.4189,  1.0166, -0.7025, -0.6140,  1.1049, -0.0270,  0.7497, -0.7880,\n",
      "         -0.5386, -1.3027],\n",
      "        [-0.5510, -1.5971, -0.8571, -0.6596, -0.6985,  0.4330,  0.1076,  0.6572,\n",
      "          0.4686,  0.6891],\n",
      "        [-1.9217, -1.4399,  2.4472, -1.3307,  1.4204,  0.1383, -0.6199, -0.6909,\n",
      "          0.1794,  0.6168]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3049,  0.3159,  1.3461,  0.8977,  1.3603, -0.0895,  1.7963, -2.7218,\n",
      "          0.3845, -0.8484],\n",
      "        [ 0.4191,  1.0168, -0.7025, -0.6140,  1.1049, -0.0272,  0.7497, -0.7880,\n",
      "         -0.5388, -1.3027],\n",
      "        [-0.5514, -1.5970, -0.8571, -0.6597, -0.6985,  0.4332,  0.1076,  0.6572,\n",
      "          0.4686,  0.6891],\n",
      "        [-1.9218, -1.4399,  2.4472, -1.3307,  1.4204,  0.1384, -0.6199, -0.6909,\n",
      "          0.1794,  0.6167]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3050,  0.3162,  1.3460,  0.8976,  1.3603, -0.0896,  1.7963, -2.7218,\n",
      "          0.3843, -0.8484],\n",
      "        [ 0.4194,  1.0170, -0.7026, -0.6140,  1.1049, -0.0274,  0.7497, -0.7880,\n",
      "         -0.5391, -1.3027],\n",
      "        [-0.5517, -1.5970, -0.8571, -0.6599, -0.6985,  0.4334,  0.1076,  0.6572,\n",
      "          0.4685,  0.6890],\n",
      "        [-1.9220, -1.4399,  2.4472, -1.3308,  1.4204,  0.1385, -0.6199, -0.6909,\n",
      "          0.1794,  0.6167]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3051,  0.3165,  1.3458,  0.8976,  1.3603, -0.0897,  1.7963, -2.7218,\n",
      "          0.3840, -0.8484],\n",
      "        [ 0.4196,  1.0172, -0.7027, -0.6140,  1.1049, -0.0276,  0.7497, -0.7880,\n",
      "         -0.5393, -1.3027],\n",
      "        [-0.5520, -1.5969, -0.8572, -0.6600, -0.6985,  0.4336,  0.1076,  0.6572,\n",
      "          0.4685,  0.6890],\n",
      "        [-1.9221, -1.4399,  2.4472, -1.3308,  1.4204,  0.1386, -0.6199, -0.6909,\n",
      "          0.1794,  0.6167]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3051,  0.3167,  1.3457,  0.8975,  1.3603, -0.0898,  1.7963, -2.7218,\n",
      "          0.3837, -0.8485],\n",
      "        [ 0.4198,  1.0174, -0.7028, -0.6140,  1.1049, -0.0278,  0.7497, -0.7880,\n",
      "         -0.5395, -1.3027],\n",
      "        [-0.5523, -1.5969, -0.8572, -0.6601, -0.6985,  0.4339,  0.1076,  0.6572,\n",
      "          0.4684,  0.6890],\n",
      "        [-1.9223, -1.4399,  2.4472, -1.3309,  1.4204,  0.1387, -0.6199, -0.6909,\n",
      "          0.1794,  0.6167]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3052,  0.3170,  1.3456,  0.8975,  1.3603, -0.0898,  1.7963, -2.7218,\n",
      "          0.3834, -0.8485],\n",
      "        [ 0.4200,  1.0176, -0.7029, -0.6140,  1.1049, -0.0279,  0.7497, -0.7880,\n",
      "         -0.5397, -1.3028],\n",
      "        [-0.5527, -1.5969, -0.8572, -0.6603, -0.6985,  0.4341,  0.1076,  0.6572,\n",
      "          0.4684,  0.6890],\n",
      "        [-1.9224, -1.4399,  2.4472, -1.3309,  1.4204,  0.1388, -0.6199, -0.6909,\n",
      "          0.1794,  0.6167]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3053,  0.3172,  1.3455,  0.8974,  1.3603, -0.0899,  1.7963, -2.7218,\n",
      "          0.3831, -0.8485],\n",
      "        [ 0.4203,  1.0178, -0.7029, -0.6139,  1.1049, -0.0281,  0.7497, -0.7880,\n",
      "         -0.5399, -1.3028],\n",
      "        [-0.5530, -1.5968, -0.8572, -0.6604, -0.6985,  0.4343,  0.1076,  0.6572,\n",
      "          0.4684,  0.6890],\n",
      "        [-1.9225, -1.4399,  2.4472, -1.3310,  1.4204,  0.1389, -0.6199, -0.6909,\n",
      "          0.1794,  0.6167]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3053,  0.3175,  1.3454,  0.8973,  1.3603, -0.0900,  1.7963, -2.7218,\n",
      "          0.3828, -0.8485],\n",
      "        [ 0.4205,  1.0180, -0.7030, -0.6139,  1.1049, -0.0283,  0.7497, -0.7880,\n",
      "         -0.5401, -1.3028],\n",
      "        [-0.5533, -1.5968, -0.8572, -0.6605, -0.6985,  0.4345,  0.1076,  0.6572,\n",
      "          0.4683,  0.6890],\n",
      "        [-1.9227, -1.4399,  2.4472, -1.3310,  1.4204,  0.1390, -0.6199, -0.6909,\n",
      "          0.1794,  0.6167]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3054,  0.3177,  1.3453,  0.8973,  1.3603, -0.0901,  1.7963, -2.7218,\n",
      "          0.3825, -0.8485],\n",
      "        [ 0.4207,  1.0181, -0.7031, -0.6139,  1.1049, -0.0285,  0.7497, -0.7880,\n",
      "         -0.5404, -1.3028],\n",
      "        [-0.5536, -1.5967, -0.8573, -0.6607, -0.6985,  0.4347,  0.1076,  0.6572,\n",
      "          0.4683,  0.6889],\n",
      "        [-1.9228, -1.4399,  2.4472, -1.3311,  1.4204,  0.1391, -0.6199, -0.6909,\n",
      "          0.1794,  0.6167]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3055,  0.3180,  1.3452,  0.8972,  1.3603, -0.0902,  1.7963, -2.7218,\n",
      "          0.3822, -0.8486],\n",
      "        [ 0.4210,  1.0183, -0.7032, -0.6139,  1.1049, -0.0287,  0.7497, -0.7880,\n",
      "         -0.5406, -1.3028],\n",
      "        [-0.5540, -1.5967, -0.8573, -0.6608, -0.6985,  0.4349,  0.1076,  0.6572,\n",
      "          0.4683,  0.6889],\n",
      "        [-1.9229, -1.4399,  2.4472, -1.3311,  1.4204,  0.1392, -0.6199, -0.6909,\n",
      "          0.1795,  0.6167]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3056,  0.3182,  1.3451,  0.8971,  1.3603, -0.0903,  1.7963, -2.7218,\n",
      "          0.3820, -0.8486],\n",
      "        [ 0.4212,  1.0185, -0.7033, -0.6139,  1.1049, -0.0288,  0.7497, -0.7880,\n",
      "         -0.5408, -1.3028],\n",
      "        [-0.5543, -1.5966, -0.8573, -0.6610, -0.6985,  0.4352,  0.1076,  0.6572,\n",
      "          0.4682,  0.6889],\n",
      "        [-1.9231, -1.4399,  2.4472, -1.3312,  1.4204,  0.1394, -0.6199, -0.6909,\n",
      "          0.1795,  0.6167]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3056,  0.3185,  1.3450,  0.8971,  1.3603, -0.0904,  1.7963, -2.7218,\n",
      "          0.3817, -0.8486],\n",
      "        [ 0.4214,  1.0187, -0.7033, -0.6138,  1.1049, -0.0290,  0.7497, -0.7880,\n",
      "         -0.5410, -1.3028],\n",
      "        [-0.5546, -1.5966, -0.8573, -0.6611, -0.6985,  0.4354,  0.1076,  0.6572,\n",
      "          0.4682,  0.6889],\n",
      "        [-1.9232, -1.4399,  2.4472, -1.3312,  1.4204,  0.1395, -0.6199, -0.6909,\n",
      "          0.1795,  0.6167]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3057,  0.3187,  1.3448,  0.8970,  1.3603, -0.0905,  1.7963, -2.7218,\n",
      "          0.3814, -0.8486],\n",
      "        [ 0.4216,  1.0189, -0.7034, -0.6138,  1.1049, -0.0292,  0.7497, -0.7880,\n",
      "         -0.5412, -1.3028],\n",
      "        [-0.5549, -1.5966, -0.8574, -0.6612, -0.6985,  0.4356,  0.1076,  0.6572,\n",
      "          0.4681,  0.6889],\n",
      "        [-1.9234, -1.4399,  2.4472, -1.3313,  1.4204,  0.1396, -0.6199, -0.6909,\n",
      "          0.1795,  0.6167]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3058,  0.3190,  1.3447,  0.8970,  1.3603, -0.0906,  1.7963, -2.7218,\n",
      "          0.3811, -0.8486],\n",
      "        [ 0.4219,  1.0191, -0.7035, -0.6138,  1.1049, -0.0294,  0.7497, -0.7880,\n",
      "         -0.5414, -1.3028],\n",
      "        [-0.5552, -1.5965, -0.8574, -0.6614, -0.6985,  0.4358,  0.1076,  0.6572,\n",
      "          0.4681,  0.6888],\n",
      "        [-1.9235, -1.4399,  2.4472, -1.3313,  1.4204,  0.1397, -0.6199, -0.6909,\n",
      "          0.1795,  0.6167]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3059,  0.3192,  1.3446,  0.8969,  1.3603, -0.0907,  1.7963, -2.7218,\n",
      "          0.3808, -0.8487],\n",
      "        [ 0.4221,  1.0193, -0.7036, -0.6138,  1.1049, -0.0296,  0.7497, -0.7880,\n",
      "         -0.5417, -1.3028],\n",
      "        [-0.5556, -1.5965, -0.8574, -0.6615, -0.6985,  0.4360,  0.1076,  0.6572,\n",
      "          0.4681,  0.6888],\n",
      "        [-1.9236, -1.4399,  2.4472, -1.3314,  1.4204,  0.1398, -0.6199, -0.6909,\n",
      "          0.1795,  0.6167]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3059,  0.3195,  1.3445,  0.8968,  1.3603, -0.0908,  1.7963, -2.7218,\n",
      "          0.3805, -0.8487],\n",
      "        [ 0.4223,  1.0194, -0.7037, -0.6138,  1.1049, -0.0297,  0.7497, -0.7880,\n",
      "         -0.5419, -1.3029],\n",
      "        [-0.5559, -1.5964, -0.8574, -0.6616, -0.6985,  0.4363,  0.1076,  0.6572,\n",
      "          0.4680,  0.6888],\n",
      "        [-1.9238, -1.4399,  2.4472, -1.3315,  1.4204,  0.1399, -0.6199, -0.6909,\n",
      "          0.1795,  0.6167]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3060,  0.3197,  1.3444,  0.8968,  1.3603, -0.0908,  1.7963, -2.7218,\n",
      "          0.3802, -0.8487],\n",
      "        [ 0.4225,  1.0196, -0.7038, -0.6137,  1.1049, -0.0299,  0.7497, -0.7880,\n",
      "         -0.5421, -1.3029],\n",
      "        [-0.5562, -1.5964, -0.8575, -0.6618, -0.6985,  0.4365,  0.1076,  0.6572,\n",
      "          0.4680,  0.6888],\n",
      "        [-1.9239, -1.4399,  2.4472, -1.3315,  1.4204,  0.1400, -0.6199, -0.6909,\n",
      "          0.1795,  0.6167]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3061,  0.3200,  1.3443,  0.8967,  1.3603, -0.0909,  1.7963, -2.7218,\n",
      "          0.3800, -0.8487],\n",
      "        [ 0.4228,  1.0198, -0.7038, -0.6137,  1.1049, -0.0301,  0.7497, -0.7880,\n",
      "         -0.5423, -1.3029],\n",
      "        [-0.5565, -1.5964, -0.8575, -0.6619, -0.6985,  0.4367,  0.1076,  0.6572,\n",
      "          0.4679,  0.6888],\n",
      "        [-1.9240, -1.4399,  2.4472, -1.3316,  1.4204,  0.1401, -0.6199, -0.6909,\n",
      "          0.1795,  0.6166]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3061,  0.3202,  1.3442,  0.8967,  1.3603, -0.0910,  1.7963, -2.7218,\n",
      "          0.3797, -0.8488],\n",
      "        [ 0.4230,  1.0200, -0.7039, -0.6137,  1.1049, -0.0303,  0.7497, -0.7880,\n",
      "         -0.5425, -1.3029],\n",
      "        [-0.5569, -1.5963, -0.8575, -0.6621, -0.6985,  0.4369,  0.1076,  0.6572,\n",
      "          0.4679,  0.6888],\n",
      "        [-1.9242, -1.4399,  2.4472, -1.3316,  1.4204,  0.1402, -0.6199, -0.6909,\n",
      "          0.1795,  0.6166]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3062,  0.3205,  1.3441,  0.8966,  1.3603, -0.0911,  1.7963, -2.7218,\n",
      "          0.3794, -0.8488],\n",
      "        [ 0.4232,  1.0202, -0.7040, -0.6137,  1.1049, -0.0304,  0.7497, -0.7880,\n",
      "         -0.5428, -1.3029],\n",
      "        [-0.5572, -1.5963, -0.8575, -0.6622, -0.6985,  0.4371,  0.1076,  0.6572,\n",
      "          0.4679,  0.6887],\n",
      "        [-1.9243, -1.4400,  2.4472, -1.3317,  1.4204,  0.1403, -0.6199, -0.6909,\n",
      "          0.1795,  0.6166]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3063,  0.3207,  1.3440,  0.8965,  1.3603, -0.0912,  1.7963, -2.7218,\n",
      "          0.3791, -0.8488],\n",
      "        [ 0.4234,  1.0203, -0.7041, -0.6137,  1.1049, -0.0306,  0.7497, -0.7880,\n",
      "         -0.5430, -1.3029],\n",
      "        [-0.5575, -1.5962, -0.8575, -0.6623, -0.6985,  0.4373,  0.1076,  0.6572,\n",
      "          0.4678,  0.6887],\n",
      "        [-1.9244, -1.4400,  2.4472, -1.3317,  1.4204,  0.1404, -0.6199, -0.6909,\n",
      "          0.1795,  0.6166]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3064,  0.3209,  1.3438,  0.8965,  1.3603, -0.0913,  1.7963, -2.7218,\n",
      "          0.3788, -0.8488],\n",
      "        [ 0.4237,  1.0205, -0.7042, -0.6136,  1.1049, -0.0308,  0.7497, -0.7880,\n",
      "         -0.5432, -1.3029],\n",
      "        [-0.5578, -1.5962, -0.8576, -0.6625, -0.6985,  0.4375,  0.1076,  0.6572,\n",
      "          0.4678,  0.6887],\n",
      "        [-1.9246, -1.4400,  2.4472, -1.3318,  1.4204,  0.1405, -0.6199, -0.6909,\n",
      "          0.1795,  0.6166]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3064,  0.3212,  1.3437,  0.8964,  1.3603, -0.0914,  1.7963, -2.7218,\n",
      "          0.3785, -0.8488],\n",
      "        [ 0.4239,  1.0207, -0.7042, -0.6136,  1.1049, -0.0310,  0.7497, -0.7880,\n",
      "         -0.5434, -1.3029],\n",
      "        [-0.5581, -1.5962, -0.8576, -0.6626, -0.6985,  0.4378,  0.1076,  0.6572,\n",
      "          0.4678,  0.6887],\n",
      "        [-1.9247, -1.4400,  2.4472, -1.3318,  1.4204,  0.1406, -0.6199, -0.6909,\n",
      "          0.1795,  0.6166]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3065,  0.3214,  1.3436,  0.8964,  1.3603, -0.0915,  1.7963, -2.7218,\n",
      "          0.3782, -0.8489],\n",
      "        [ 0.4241,  1.0209, -0.7043, -0.6136,  1.1049, -0.0312,  0.7497, -0.7880,\n",
      "         -0.5436, -1.3029],\n",
      "        [-0.5585, -1.5961, -0.8576, -0.6627, -0.6985,  0.4380,  0.1076,  0.6572,\n",
      "          0.4677,  0.6887],\n",
      "        [-1.9248, -1.4400,  2.4472, -1.3319,  1.4204,  0.1407, -0.6199, -0.6909,\n",
      "          0.1795,  0.6166]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3066,  0.3217,  1.3435,  0.8963,  1.3603, -0.0916,  1.7963, -2.7218,\n",
      "          0.3779, -0.8489],\n",
      "        [ 0.4243,  1.0211, -0.7044, -0.6136,  1.1049, -0.0313,  0.7497, -0.7880,\n",
      "         -0.5438, -1.3029],\n",
      "        [-0.5588, -1.5961, -0.8576, -0.6629, -0.6985,  0.4382,  0.1076,  0.6572,\n",
      "          0.4677,  0.6886],\n",
      "        [-1.9250, -1.4400,  2.4472, -1.3319,  1.4204,  0.1408, -0.6199, -0.6909,\n",
      "          0.1795,  0.6166]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3067,  0.3219,  1.3434,  0.8962,  1.3603, -0.0917,  1.7963, -2.7218,\n",
      "          0.3777, -0.8489],\n",
      "        [ 0.4245,  1.0212, -0.7045, -0.6135,  1.1049, -0.0315,  0.7497, -0.7880,\n",
      "         -0.5441, -1.3029],\n",
      "        [-0.5591, -1.5961, -0.8577, -0.6630, -0.6985,  0.4384,  0.1076,  0.6572,\n",
      "          0.4677,  0.6886],\n",
      "        [-1.9251, -1.4400,  2.4472, -1.3320,  1.4204,  0.1409, -0.6199, -0.6909,\n",
      "          0.1795,  0.6166]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3067,  0.3221,  1.3433,  0.8962,  1.3603, -0.0918,  1.7963, -2.7218,\n",
      "          0.3774, -0.8489],\n",
      "        [ 0.4248,  1.0214, -0.7046, -0.6135,  1.1049, -0.0317,  0.7497, -0.7880,\n",
      "         -0.5443, -1.3030],\n",
      "        [-0.5594, -1.5960, -0.8577, -0.6631, -0.6985,  0.4386,  0.1076,  0.6572,\n",
      "          0.4676,  0.6886],\n",
      "        [-1.9253, -1.4400,  2.4472, -1.3320,  1.4204,  0.1410, -0.6199, -0.6909,\n",
      "          0.1796,  0.6166]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3068,  0.3224,  1.3432,  0.8961,  1.3603, -0.0919,  1.7963, -2.7218,\n",
      "          0.3771, -0.8490],\n",
      "        [ 0.4250,  1.0216, -0.7047, -0.6135,  1.1049, -0.0319,  0.7497, -0.7880,\n",
      "         -0.5445, -1.3030],\n",
      "        [-0.5597, -1.5960, -0.8577, -0.6633, -0.6985,  0.4388,  0.1076,  0.6572,\n",
      "          0.4676,  0.6886],\n",
      "        [-1.9254, -1.4400,  2.4472, -1.3321,  1.4204,  0.1411, -0.6199, -0.6909,\n",
      "          0.1796,  0.6166]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3069,  0.3226,  1.3431,  0.8961,  1.3603, -0.0919,  1.7963, -2.7218,\n",
      "          0.3768, -0.8490],\n",
      "        [ 0.4252,  1.0218, -0.7047, -0.6135,  1.1049, -0.0321,  0.7497, -0.7880,\n",
      "         -0.5447, -1.3030],\n",
      "        [-0.5600, -1.5959, -0.8577, -0.6634, -0.6985,  0.4391,  0.1076,  0.6572,\n",
      "          0.4675,  0.6886],\n",
      "        [-1.9255, -1.4400,  2.4472, -1.3321,  1.4204,  0.1412, -0.6199, -0.6909,\n",
      "          0.1796,  0.6166]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3069,  0.3228,  1.3429,  0.8960,  1.3603, -0.0920,  1.7963, -2.7218,\n",
      "          0.3765, -0.8490],\n",
      "        [ 0.4254,  1.0219, -0.7048, -0.6135,  1.1049, -0.0322,  0.7497, -0.7880,\n",
      "         -0.5449, -1.3030],\n",
      "        [-0.5604, -1.5959, -0.8577, -0.6635, -0.6985,  0.4393,  0.1076,  0.6572,\n",
      "          0.4675,  0.6886],\n",
      "        [-1.9257, -1.4400,  2.4472, -1.3322,  1.4204,  0.1413, -0.6199, -0.6909,\n",
      "          0.1796,  0.6166]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3070,  0.3231,  1.3428,  0.8960,  1.3603, -0.0921,  1.7963, -2.7218,\n",
      "          0.3762, -0.8490],\n",
      "        [ 0.4257,  1.0221, -0.7049, -0.6134,  1.1049, -0.0324,  0.7497, -0.7880,\n",
      "         -0.5452, -1.3030],\n",
      "        [-0.5607, -1.5959, -0.8578, -0.6637, -0.6985,  0.4395,  0.1076,  0.6572,\n",
      "          0.4675,  0.6885],\n",
      "        [-1.9258, -1.4400,  2.4472, -1.3322,  1.4204,  0.1414, -0.6199, -0.6909,\n",
      "          0.1796,  0.6166]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3071,  0.3233,  1.3427,  0.8959,  1.3603, -0.0922,  1.7963, -2.7218,\n",
      "          0.3759, -0.8490],\n",
      "        [ 0.4259,  1.0223, -0.7050, -0.6134,  1.1049, -0.0326,  0.7497, -0.7880,\n",
      "         -0.5454, -1.3030],\n",
      "        [-0.5610, -1.5958, -0.8578, -0.6638, -0.6985,  0.4397,  0.1076,  0.6572,\n",
      "          0.4674,  0.6885],\n",
      "        [-1.9259, -1.4400,  2.4472, -1.3323,  1.4204,  0.1415, -0.6199, -0.6909,\n",
      "          0.1796,  0.6166]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3071,  0.3235,  1.3426,  0.8958,  1.3603, -0.0923,  1.7963, -2.7218,\n",
      "          0.3757, -0.8491],\n",
      "        [ 0.4261,  1.0225, -0.7051, -0.6134,  1.1049, -0.0328,  0.7497, -0.7880,\n",
      "         -0.5456, -1.3030],\n",
      "        [-0.5613, -1.5958, -0.8578, -0.6639, -0.6985,  0.4399,  0.1076,  0.6572,\n",
      "          0.4674,  0.6885],\n",
      "        [-1.9261, -1.4400,  2.4472, -1.3323,  1.4204,  0.1416, -0.6199, -0.6909,\n",
      "          0.1796,  0.6166]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3072,  0.3238,  1.3425,  0.8958,  1.3603, -0.0924,  1.7963, -2.7218,\n",
      "          0.3754, -0.8491],\n",
      "        [ 0.4263,  1.0226, -0.7051, -0.6134,  1.1049, -0.0330,  0.7497, -0.7880,\n",
      "         -0.5458, -1.3030],\n",
      "        [-0.5616, -1.5958, -0.8578, -0.6641, -0.6985,  0.4401,  0.1076,  0.6572,\n",
      "          0.4674,  0.6885],\n",
      "        [-1.9262, -1.4400,  2.4472, -1.3324,  1.4204,  0.1417, -0.6199, -0.6909,\n",
      "          0.1796,  0.6166]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3073,  0.3240,  1.3424,  0.8957,  1.3603, -0.0925,  1.7963, -2.7218,\n",
      "          0.3751, -0.8491],\n",
      "        [ 0.4265,  1.0228, -0.7052, -0.6134,  1.1049, -0.0331,  0.7497, -0.7880,\n",
      "         -0.5460, -1.3030],\n",
      "        [-0.5619, -1.5957, -0.8579, -0.6642, -0.6985,  0.4403,  0.1076,  0.6572,\n",
      "          0.4673,  0.6885],\n",
      "        [-1.9263, -1.4400,  2.4472, -1.3324,  1.4204,  0.1418, -0.6199, -0.6909,\n",
      "          0.1796,  0.6165]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3074,  0.3242,  1.3423,  0.8957,  1.3603, -0.0926,  1.7963, -2.7218,\n",
      "          0.3748, -0.8491],\n",
      "        [ 0.4268,  1.0230, -0.7053, -0.6133,  1.1049, -0.0333,  0.7497, -0.7880,\n",
      "         -0.5463, -1.3030],\n",
      "        [-0.5623, -1.5957, -0.8579, -0.6643, -0.6985,  0.4406,  0.1076,  0.6572,\n",
      "          0.4673,  0.6885],\n",
      "        [-1.9265, -1.4400,  2.4472, -1.3325,  1.4204,  0.1419, -0.6199, -0.6909,\n",
      "          0.1796,  0.6165]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3074,  0.3245,  1.3422,  0.8956,  1.3603, -0.0927,  1.7963, -2.7218,\n",
      "          0.3745, -0.8491],\n",
      "        [ 0.4270,  1.0232, -0.7054, -0.6133,  1.1049, -0.0335,  0.7497, -0.7880,\n",
      "         -0.5465, -1.3031],\n",
      "        [-0.5626, -1.5957, -0.8579, -0.6645, -0.6985,  0.4408,  0.1076,  0.6572,\n",
      "          0.4673,  0.6884],\n",
      "        [-1.9266, -1.4400,  2.4472, -1.3325,  1.4204,  0.1420, -0.6199, -0.6909,\n",
      "          0.1796,  0.6165]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3075,  0.3247,  1.3421,  0.8956,  1.3603, -0.0928,  1.7963, -2.7218,\n",
      "          0.3742, -0.8492],\n",
      "        [ 0.4272,  1.0233, -0.7055, -0.6133,  1.1049, -0.0337,  0.7497, -0.7880,\n",
      "         -0.5467, -1.3031],\n",
      "        [-0.5629, -1.5956, -0.8579, -0.6646, -0.6985,  0.4410,  0.1076,  0.6572,\n",
      "          0.4672,  0.6884],\n",
      "        [-1.9267, -1.4400,  2.4471, -1.3326,  1.4204,  0.1421, -0.6199, -0.6909,\n",
      "          0.1796,  0.6165]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3076,  0.3249,  1.3419,  0.8955,  1.3603, -0.0929,  1.7963, -2.7218,\n",
      "          0.3739, -0.8492],\n",
      "        [ 0.4274,  1.0235, -0.7056, -0.6133,  1.1049, -0.0338,  0.7497, -0.7880,\n",
      "         -0.5469, -1.3031],\n",
      "        [-0.5632, -1.5956, -0.8579, -0.6647, -0.6985,  0.4412,  0.1076,  0.6572,\n",
      "          0.4672,  0.6884],\n",
      "        [-1.9269, -1.4400,  2.4471, -1.3326,  1.4204,  0.1422, -0.6199, -0.6909,\n",
      "          0.1796,  0.6165]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3076,  0.3252,  1.3418,  0.8954,  1.3603, -0.0930,  1.7963, -2.7218,\n",
      "          0.3737, -0.8492],\n",
      "        [ 0.4276,  1.0237, -0.7056, -0.6132,  1.1049, -0.0340,  0.7497, -0.7880,\n",
      "         -0.5471, -1.3031],\n",
      "        [-0.5635, -1.5956, -0.8580, -0.6649, -0.6985,  0.4414,  0.1076,  0.6572,\n",
      "          0.4672,  0.6884],\n",
      "        [-1.9270, -1.4400,  2.4471, -1.3327,  1.4204,  0.1423, -0.6199, -0.6909,\n",
      "          0.1796,  0.6165]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3077,  0.3254,  1.3417,  0.8954,  1.3603, -0.0930,  1.7963, -2.7218,\n",
      "          0.3734, -0.8492],\n",
      "        [ 0.4278,  1.0238, -0.7057, -0.6132,  1.1049, -0.0342,  0.7497, -0.7880,\n",
      "         -0.5473, -1.3031],\n",
      "        [-0.5638, -1.5955, -0.8580, -0.6650, -0.6985,  0.4416,  0.1076,  0.6572,\n",
      "          0.4671,  0.6884],\n",
      "        [-1.9271, -1.4400,  2.4471, -1.3327,  1.4204,  0.1424, -0.6199, -0.6909,\n",
      "          0.1796,  0.6165]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3078,  0.3256,  1.3416,  0.8953,  1.3603, -0.0931,  1.7963, -2.7218,\n",
      "          0.3731, -0.8493],\n",
      "        [ 0.4281,  1.0240, -0.7058, -0.6132,  1.1049, -0.0344,  0.7497, -0.7880,\n",
      "         -0.5476, -1.3031],\n",
      "        [-0.5641, -1.5955, -0.8580, -0.6651, -0.6985,  0.4418,  0.1076,  0.6572,\n",
      "          0.4671,  0.6884],\n",
      "        [-1.9273, -1.4400,  2.4471, -1.3328,  1.4204,  0.1425, -0.6199, -0.6909,\n",
      "          0.1797,  0.6165]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3078,  0.3258,  1.3415,  0.8953,  1.3603, -0.0932,  1.7963, -2.7218,\n",
      "          0.3728, -0.8493],\n",
      "        [ 0.4283,  1.0242, -0.7059, -0.6132,  1.1049, -0.0346,  0.7497, -0.7880,\n",
      "         -0.5478, -1.3031],\n",
      "        [-0.5644, -1.5955, -0.8580, -0.6653, -0.6985,  0.4420,  0.1076,  0.6572,\n",
      "          0.4671,  0.6883],\n",
      "        [-1.9274, -1.4400,  2.4471, -1.3329,  1.4204,  0.1426, -0.6199, -0.6909,\n",
      "          0.1797,  0.6165]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3079,  0.3261,  1.3414,  0.8952,  1.3603, -0.0933,  1.7963, -2.7218,\n",
      "          0.3725, -0.8493],\n",
      "        [ 0.4285,  1.0244, -0.7060, -0.6131,  1.1049, -0.0347,  0.7497, -0.7880,\n",
      "         -0.5480, -1.3031],\n",
      "        [-0.5648, -1.5954, -0.8581, -0.6654, -0.6985,  0.4423,  0.1076,  0.6572,\n",
      "          0.4670,  0.6883],\n",
      "        [-1.9275, -1.4400,  2.4471, -1.3329,  1.4204,  0.1427, -0.6199, -0.6909,\n",
      "          0.1797,  0.6165]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3080,  0.3263,  1.3413,  0.8952,  1.3603, -0.0934,  1.7963, -2.7218,\n",
      "          0.3722, -0.8493],\n",
      "        [ 0.4287,  1.0245, -0.7060, -0.6131,  1.1049, -0.0349,  0.7497, -0.7880,\n",
      "         -0.5482, -1.3031],\n",
      "        [-0.5651, -1.5954, -0.8581, -0.6655, -0.6985,  0.4425,  0.1076,  0.6572,\n",
      "          0.4670,  0.6883],\n",
      "        [-1.9277, -1.4400,  2.4471, -1.3330,  1.4204,  0.1428, -0.6199, -0.6909,\n",
      "          0.1797,  0.6165]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3081,  0.3265,  1.3412,  0.8951,  1.3603, -0.0935,  1.7963, -2.7218,\n",
      "          0.3719, -0.8493],\n",
      "        [ 0.4289,  1.0247, -0.7061, -0.6131,  1.1049, -0.0351,  0.7497, -0.7880,\n",
      "         -0.5484, -1.3031],\n",
      "        [-0.5654, -1.5954, -0.8581, -0.6657, -0.6985,  0.4427,  0.1076,  0.6572,\n",
      "          0.4669,  0.6883],\n",
      "        [-1.9278, -1.4400,  2.4471, -1.3330,  1.4204,  0.1429, -0.6199, -0.6909,\n",
      "          0.1797,  0.6165]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3081,  0.3267,  1.3411,  0.8950,  1.3603, -0.0936,  1.7963, -2.7218,\n",
      "          0.3717, -0.8494],\n",
      "        [ 0.4292,  1.0249, -0.7062, -0.6131,  1.1049, -0.0353,  0.7497, -0.7880,\n",
      "         -0.5487, -1.3031],\n",
      "        [-0.5657, -1.5953, -0.8581, -0.6658, -0.6985,  0.4429,  0.1076,  0.6572,\n",
      "          0.4669,  0.6883],\n",
      "        [-1.9279, -1.4400,  2.4471, -1.3331,  1.4204,  0.1430, -0.6199, -0.6909,\n",
      "          0.1797,  0.6165]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3082,  0.3270,  1.3409,  0.8950,  1.3603, -0.0937,  1.7963, -2.7218,\n",
      "          0.3714, -0.8494],\n",
      "        [ 0.4294,  1.0250, -0.7063, -0.6131,  1.1049, -0.0354,  0.7497, -0.7880,\n",
      "         -0.5489, -1.3032],\n",
      "        [-0.5660, -1.5953, -0.8582, -0.6659, -0.6985,  0.4431,  0.1076,  0.6572,\n",
      "          0.4669,  0.6882],\n",
      "        [-1.9280, -1.4400,  2.4471, -1.3331,  1.4204,  0.1431, -0.6199, -0.6909,\n",
      "          0.1797,  0.6165]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3083,  0.3272,  1.3408,  0.8949,  1.3603, -0.0938,  1.7963, -2.7218,\n",
      "          0.3711, -0.8494],\n",
      "        [ 0.4296,  1.0252, -0.7064, -0.6130,  1.1049, -0.0356,  0.7497, -0.7880,\n",
      "         -0.5491, -1.3032],\n",
      "        [-0.5663, -1.5953, -0.8582, -0.6661, -0.6985,  0.4433,  0.1076,  0.6572,\n",
      "          0.4668,  0.6882],\n",
      "        [-1.9282, -1.4400,  2.4471, -1.3332,  1.4204,  0.1432, -0.6199, -0.6909,\n",
      "          0.1797,  0.6165]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3083,  0.3274,  1.3407,  0.8949,  1.3603, -0.0939,  1.7963, -2.7218,\n",
      "          0.3708, -0.8494],\n",
      "        [ 0.4298,  1.0254, -0.7065, -0.6130,  1.1049, -0.0358,  0.7497, -0.7880,\n",
      "         -0.5493, -1.3032],\n",
      "        [-0.5666, -1.5952, -0.8582, -0.6662, -0.6985,  0.4435,  0.1076,  0.6572,\n",
      "          0.4668,  0.6882],\n",
      "        [-1.9283, -1.4400,  2.4471, -1.3332,  1.4204,  0.1432, -0.6199, -0.6909,\n",
      "          0.1797,  0.6165]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3084,  0.3276,  1.3406,  0.8948,  1.3603, -0.0940,  1.7963, -2.7218,\n",
      "          0.3705, -0.8494],\n",
      "        [ 0.4300,  1.0255, -0.7065, -0.6130,  1.1049, -0.0360,  0.7497, -0.7880,\n",
      "         -0.5495, -1.3032],\n",
      "        [-0.5669, -1.5952, -0.8582, -0.6663, -0.6985,  0.4437,  0.1076,  0.6572,\n",
      "          0.4668,  0.6882],\n",
      "        [-1.9284, -1.4400,  2.4471, -1.3333,  1.4204,  0.1433, -0.6199, -0.6909,\n",
      "          0.1797,  0.6165]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3085,  0.3278,  1.3405,  0.8948,  1.3603, -0.0941,  1.7963, -2.7218,\n",
      "          0.3702, -0.8495],\n",
      "        [ 0.4302,  1.0257, -0.7066, -0.6130,  1.1049, -0.0362,  0.7497, -0.7880,\n",
      "         -0.5498, -1.3032],\n",
      "        [-0.5672, -1.5952, -0.8582, -0.6665, -0.6985,  0.4440,  0.1076,  0.6572,\n",
      "          0.4667,  0.6882],\n",
      "        [-1.9286, -1.4400,  2.4471, -1.3333,  1.4204,  0.1434, -0.6199, -0.6909,\n",
      "          0.1797,  0.6164]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3085,  0.3281,  1.3404,  0.8947,  1.3603, -0.0942,  1.7963, -2.7218,\n",
      "          0.3699, -0.8495],\n",
      "        [ 0.4305,  1.0259, -0.7067, -0.6129,  1.1049, -0.0363,  0.7497, -0.7880,\n",
      "         -0.5500, -1.3032],\n",
      "        [-0.5676, -1.5951, -0.8583, -0.6666, -0.6985,  0.4442,  0.1076,  0.6572,\n",
      "          0.4667,  0.6882],\n",
      "        [-1.9287, -1.4400,  2.4471, -1.3334,  1.4204,  0.1435, -0.6199, -0.6909,\n",
      "          0.1797,  0.6164]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3086,  0.3283,  1.3403,  0.8947,  1.3603, -0.0942,  1.7963, -2.7218,\n",
      "          0.3697, -0.8495],\n",
      "        [ 0.4307,  1.0260, -0.7068, -0.6129,  1.1049, -0.0365,  0.7497, -0.7880,\n",
      "         -0.5502, -1.3032],\n",
      "        [-0.5679, -1.5951, -0.8583, -0.6667, -0.6985,  0.4444,  0.1076,  0.6572,\n",
      "          0.4667,  0.6881],\n",
      "        [-1.9288, -1.4400,  2.4471, -1.3334,  1.4204,  0.1436, -0.6199, -0.6909,\n",
      "          0.1797,  0.6164]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3087,  0.3285,  1.3402,  0.8946,  1.3603, -0.0943,  1.7963, -2.7218,\n",
      "          0.3694, -0.8495],\n",
      "        [ 0.4309,  1.0262, -0.7069, -0.6129,  1.1049, -0.0367,  0.7497, -0.7880,\n",
      "         -0.5504, -1.3032],\n",
      "        [-0.5682, -1.5951, -0.8583, -0.6669, -0.6985,  0.4446,  0.1076,  0.6572,\n",
      "          0.4666,  0.6881],\n",
      "        [-1.9290, -1.4400,  2.4471, -1.3335,  1.4204,  0.1437, -0.6199, -0.6909,\n",
      "          0.1797,  0.6164]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3087,  0.3287,  1.3401,  0.8946,  1.3603, -0.0944,  1.7963, -2.7218,\n",
      "          0.3691, -0.8495],\n",
      "        [ 0.4311,  1.0264, -0.7069, -0.6129,  1.1049, -0.0369,  0.7497, -0.7880,\n",
      "         -0.5506, -1.3032],\n",
      "        [-0.5685, -1.5951, -0.8583, -0.6670, -0.6985,  0.4448,  0.1076,  0.6572,\n",
      "          0.4666,  0.6881],\n",
      "        [-1.9291, -1.4401,  2.4471, -1.3335,  1.4204,  0.1438, -0.6199, -0.6909,\n",
      "          0.1798,  0.6164]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3088,  0.3289,  1.3399,  0.8945,  1.3603, -0.0945,  1.7963, -2.7218,\n",
      "          0.3688, -0.8496],\n",
      "        [ 0.4313,  1.0265, -0.7070, -0.6128,  1.1049, -0.0370,  0.7497, -0.7880,\n",
      "         -0.5508, -1.3032],\n",
      "        [-0.5688, -1.5950, -0.8584, -0.6671, -0.6985,  0.4450,  0.1076,  0.6572,\n",
      "          0.4666,  0.6881],\n",
      "        [-1.9292, -1.4401,  2.4471, -1.3336,  1.4204,  0.1439, -0.6199, -0.6909,\n",
      "          0.1798,  0.6164]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3089,  0.3291,  1.3398,  0.8945,  1.3603, -0.0946,  1.7963, -2.7218,\n",
      "          0.3685, -0.8496],\n",
      "        [ 0.4315,  1.0267, -0.7071, -0.6128,  1.1049, -0.0372,  0.7497, -0.7880,\n",
      "         -0.5511, -1.3033],\n",
      "        [-0.5691, -1.5950, -0.8584, -0.6673, -0.6985,  0.4452,  0.1076,  0.6572,\n",
      "          0.4665,  0.6881],\n",
      "        [-1.9294, -1.4401,  2.4471, -1.3336,  1.4204,  0.1440, -0.6199, -0.6909,\n",
      "          0.1798,  0.6164]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3089,  0.3294,  1.3397,  0.8944,  1.3603, -0.0947,  1.7963, -2.7218,\n",
      "          0.3682, -0.8496],\n",
      "        [ 0.4317,  1.0268, -0.7072, -0.6128,  1.1049, -0.0374,  0.7497, -0.7880,\n",
      "         -0.5513, -1.3033],\n",
      "        [-0.5694, -1.5950, -0.8584, -0.6674, -0.6985,  0.4454,  0.1076,  0.6572,\n",
      "          0.4665,  0.6881],\n",
      "        [-1.9295, -1.4401,  2.4471, -1.3337,  1.4204,  0.1441, -0.6199, -0.6909,\n",
      "          0.1798,  0.6164]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3090,  0.3296,  1.3396,  0.8943,  1.3603, -0.0948,  1.7963, -2.7218,\n",
      "          0.3679, -0.8496],\n",
      "        [ 0.4320,  1.0270, -0.7073, -0.6128,  1.1049, -0.0376,  0.7497, -0.7880,\n",
      "         -0.5515, -1.3033],\n",
      "        [-0.5697, -1.5949, -0.8584, -0.6675, -0.6985,  0.4456,  0.1076,  0.6572,\n",
      "          0.4665,  0.6880],\n",
      "        [-1.9296, -1.4401,  2.4471, -1.3337,  1.4204,  0.1442, -0.6199, -0.6909,\n",
      "          0.1798,  0.6164]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3091,  0.3298,  1.3395,  0.8943,  1.3603, -0.0949,  1.7963, -2.7218,\n",
      "          0.3677, -0.8497],\n",
      "        [ 0.4322,  1.0272, -0.7074, -0.6128,  1.1049, -0.0377,  0.7497, -0.7880,\n",
      "         -0.5517, -1.3033],\n",
      "        [-0.5700, -1.5949, -0.8584, -0.6677, -0.6985,  0.4459,  0.1076,  0.6572,\n",
      "          0.4664,  0.6880],\n",
      "        [-1.9297, -1.4401,  2.4471, -1.3338,  1.4204,  0.1443, -0.6199, -0.6909,\n",
      "          0.1798,  0.6164]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3091,  0.3300,  1.3394,  0.8942,  1.3603, -0.0950,  1.7963, -2.7218,\n",
      "          0.3674, -0.8497],\n",
      "        [ 0.4324,  1.0273, -0.7074, -0.6127,  1.1049, -0.0379,  0.7497, -0.7880,\n",
      "         -0.5519, -1.3033],\n",
      "        [-0.5703, -1.5949, -0.8585, -0.6678, -0.6985,  0.4461,  0.1076,  0.6572,\n",
      "          0.4664,  0.6880],\n",
      "        [-1.9299, -1.4401,  2.4471, -1.3338,  1.4204,  0.1444, -0.6199, -0.6909,\n",
      "          0.1798,  0.6164]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3092,  0.3302,  1.3393,  0.8942,  1.3603, -0.0951,  1.7963, -2.7218,\n",
      "          0.3671, -0.8497],\n",
      "        [ 0.4326,  1.0275, -0.7075, -0.6127,  1.1049, -0.0381,  0.7497, -0.7880,\n",
      "         -0.5522, -1.3033],\n",
      "        [-0.5706, -1.5949, -0.8585, -0.6679, -0.6985,  0.4463,  0.1076,  0.6572,\n",
      "          0.4664,  0.6880],\n",
      "        [-1.9300, -1.4401,  2.4471, -1.3339,  1.4204,  0.1445, -0.6199, -0.6909,\n",
      "          0.1798,  0.6164]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3093,  0.3304,  1.3392,  0.8941,  1.3603, -0.0952,  1.7963, -2.7218,\n",
      "          0.3668, -0.8497],\n",
      "        [ 0.4328,  1.0277, -0.7076, -0.6127,  1.1049, -0.0383,  0.7497, -0.7880,\n",
      "         -0.5524, -1.3033],\n",
      "        [-0.5709, -1.5948, -0.8585, -0.6680, -0.6985,  0.4465,  0.1076,  0.6572,\n",
      "          0.4663,  0.6880],\n",
      "        [-1.9301, -1.4401,  2.4471, -1.3339,  1.4204,  0.1446, -0.6199, -0.6909,\n",
      "          0.1798,  0.6164]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3093,  0.3306,  1.3390,  0.8941,  1.3603, -0.0953,  1.7963, -2.7218,\n",
      "          0.3665, -0.8497],\n",
      "        [ 0.4330,  1.0278, -0.7077, -0.6127,  1.1049, -0.0385,  0.7497, -0.7880,\n",
      "         -0.5526, -1.3033],\n",
      "        [-0.5712, -1.5948, -0.8585, -0.6682, -0.6985,  0.4467,  0.1076,  0.6572,\n",
      "          0.4663,  0.6880],\n",
      "        [-1.9303, -1.4401,  2.4471, -1.3340,  1.4204,  0.1447, -0.6199, -0.6909,\n",
      "          0.1798,  0.6164]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3094,  0.3308,  1.3389,  0.8940,  1.3603, -0.0953,  1.7963, -2.7218,\n",
      "          0.3662, -0.8498],\n",
      "        [ 0.4332,  1.0280, -0.7078, -0.6126,  1.1049, -0.0386,  0.7497, -0.7880,\n",
      "         -0.5528, -1.3033],\n",
      "        [-0.5716, -1.5948, -0.8586, -0.6683, -0.6985,  0.4469,  0.1076,  0.6572,\n",
      "          0.4663,  0.6879],\n",
      "        [-1.9304, -1.4401,  2.4471, -1.3340,  1.4204,  0.1448, -0.6199, -0.6909,\n",
      "          0.1798,  0.6164]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3095,  0.3311,  1.3388,  0.8940,  1.3603, -0.0954,  1.7963, -2.7218,\n",
      "          0.3660, -0.8498],\n",
      "        [ 0.4334,  1.0281, -0.7078, -0.6126,  1.1049, -0.0388,  0.7497, -0.7880,\n",
      "         -0.5530, -1.3033],\n",
      "        [-0.5719, -1.5948, -0.8586, -0.6684, -0.6985,  0.4471,  0.1076,  0.6572,\n",
      "          0.4662,  0.6879],\n",
      "        [-1.9305, -1.4401,  2.4471, -1.3341,  1.4204,  0.1449, -0.6199, -0.6909,\n",
      "          0.1798,  0.6164]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3095,  0.3313,  1.3387,  0.8939,  1.3603, -0.0955,  1.7963, -2.7218,\n",
      "          0.3657, -0.8498],\n",
      "        [ 0.4337,  1.0283, -0.7079, -0.6126,  1.1049, -0.0390,  0.7497, -0.7880,\n",
      "         -0.5532, -1.3033],\n",
      "        [-0.5722, -1.5947, -0.8586, -0.6686, -0.6985,  0.4473,  0.1076,  0.6572,\n",
      "          0.4662,  0.6879],\n",
      "        [-1.9307, -1.4401,  2.4471, -1.3341,  1.4204,  0.1450, -0.6199, -0.6909,\n",
      "          0.1799,  0.6164]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3096,  0.3315,  1.3386,  0.8939,  1.3603, -0.0956,  1.7963, -2.7218,\n",
      "          0.3654, -0.8498],\n",
      "        [ 0.4339,  1.0285, -0.7080, -0.6126,  1.1049, -0.0392,  0.7497, -0.7880,\n",
      "         -0.5535, -1.3034],\n",
      "        [-0.5725, -1.5947, -0.8586, -0.6687, -0.6985,  0.4475,  0.1076,  0.6572,\n",
      "          0.4662,  0.6879],\n",
      "        [-1.9308, -1.4401,  2.4471, -1.3342,  1.4204,  0.1451, -0.6199, -0.6909,\n",
      "          0.1799,  0.6163]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3097,  0.3317,  1.3385,  0.8938,  1.3603, -0.0957,  1.7963, -2.7218,\n",
      "          0.3651, -0.8498],\n",
      "        [ 0.4341,  1.0286, -0.7081, -0.6125,  1.1049, -0.0393,  0.7497, -0.7880,\n",
      "         -0.5537, -1.3034],\n",
      "        [-0.5728, -1.5947, -0.8586, -0.6688, -0.6985,  0.4477,  0.1076,  0.6572,\n",
      "          0.4662,  0.6879],\n",
      "        [-1.9309, -1.4401,  2.4471, -1.3342,  1.4204,  0.1452, -0.6199, -0.6909,\n",
      "          0.1799,  0.6163]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3097,  0.3319,  1.3384,  0.8938,  1.3603, -0.0958,  1.7963, -2.7218,\n",
      "          0.3648, -0.8499],\n",
      "        [ 0.4343,  1.0288, -0.7082, -0.6125,  1.1049, -0.0395,  0.7497, -0.7880,\n",
      "         -0.5539, -1.3034],\n",
      "        [-0.5731, -1.5947, -0.8587, -0.6689, -0.6985,  0.4480,  0.1076,  0.6572,\n",
      "          0.4661,  0.6879],\n",
      "        [-1.9310, -1.4401,  2.4471, -1.3343,  1.4204,  0.1453, -0.6199, -0.6909,\n",
      "          0.1799,  0.6163]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3098,  0.3321,  1.3383,  0.8937,  1.3603, -0.0959,  1.7963, -2.7218,\n",
      "          0.3645, -0.8499],\n",
      "        [ 0.4345,  1.0289, -0.7083, -0.6125,  1.1049, -0.0397,  0.7497, -0.7880,\n",
      "         -0.5541, -1.3034],\n",
      "        [-0.5734, -1.5946, -0.8587, -0.6691, -0.6985,  0.4482,  0.1076,  0.6572,\n",
      "          0.4661,  0.6878],\n",
      "        [-1.9312, -1.4401,  2.4471, -1.3343,  1.4204,  0.1454, -0.6199, -0.6909,\n",
      "          0.1799,  0.6163]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3099,  0.3323,  1.3382,  0.8937,  1.3603, -0.0960,  1.7963, -2.7218,\n",
      "          0.3643, -0.8499],\n",
      "        [ 0.4347,  1.0291, -0.7083, -0.6125,  1.1049, -0.0399,  0.7497, -0.7880,\n",
      "         -0.5543, -1.3034],\n",
      "        [-0.5737, -1.5946, -0.8587, -0.6692, -0.6985,  0.4484,  0.1076,  0.6572,\n",
      "          0.4661,  0.6878],\n",
      "        [-1.9313, -1.4401,  2.4471, -1.3344,  1.4204,  0.1455, -0.6199, -0.6909,\n",
      "          0.1799,  0.6163]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3099,  0.3325,  1.3380,  0.8936,  1.3603, -0.0961,  1.7963, -2.7218,\n",
      "          0.3640, -0.8499],\n",
      "        [ 0.4349,  1.0292, -0.7084, -0.6124,  1.1049, -0.0400,  0.7497, -0.7880,\n",
      "         -0.5546, -1.3034],\n",
      "        [-0.5740, -1.5946, -0.8587, -0.6693, -0.6985,  0.4486,  0.1076,  0.6572,\n",
      "          0.4660,  0.6878],\n",
      "        [-1.9314, -1.4401,  2.4471, -1.3344,  1.4204,  0.1456, -0.6199, -0.6909,\n",
      "          0.1799,  0.6163]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3100,  0.3327,  1.3379,  0.8936,  1.3603, -0.0962,  1.7963, -2.7218,\n",
      "          0.3637, -0.8499],\n",
      "        [ 0.4351,  1.0294, -0.7085, -0.6124,  1.1049, -0.0402,  0.7497, -0.7880,\n",
      "         -0.5548, -1.3034],\n",
      "        [-0.5743, -1.5946, -0.8588, -0.6695, -0.6985,  0.4488,  0.1076,  0.6572,\n",
      "          0.4660,  0.6878],\n",
      "        [-1.9316, -1.4401,  2.4471, -1.3345,  1.4204,  0.1457, -0.6199, -0.6909,\n",
      "          0.1799,  0.6163]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3101,  0.3329,  1.3378,  0.8935,  1.3603, -0.0963,  1.7963, -2.7218,\n",
      "          0.3634, -0.8500],\n",
      "        [ 0.4353,  1.0296, -0.7086, -0.6124,  1.1049, -0.0404,  0.7497, -0.7880,\n",
      "         -0.5550, -1.3034],\n",
      "        [-0.5746, -1.5945, -0.8588, -0.6696, -0.6985,  0.4490,  0.1076,  0.6572,\n",
      "          0.4660,  0.6878],\n",
      "        [-1.9317, -1.4401,  2.4471, -1.3345,  1.4204,  0.1458, -0.6199, -0.6909,\n",
      "          0.1799,  0.6163]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3101,  0.3331,  1.3377,  0.8935,  1.3603, -0.0963,  1.7963, -2.7218,\n",
      "          0.3631, -0.8500],\n",
      "        [ 0.4355,  1.0297, -0.7087, -0.6124,  1.1049, -0.0406,  0.7497, -0.7880,\n",
      "         -0.5552, -1.3034],\n",
      "        [-0.5749, -1.5945, -0.8588, -0.6697, -0.6985,  0.4492,  0.1076,  0.6572,\n",
      "          0.4659,  0.6878],\n",
      "        [-1.9318, -1.4401,  2.4471, -1.3346,  1.4204,  0.1459, -0.6199, -0.6909,\n",
      "          0.1799,  0.6163]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3102,  0.3333,  1.3376,  0.8934,  1.3603, -0.0964,  1.7963, -2.7218,\n",
      "          0.3628, -0.8500],\n",
      "        [ 0.4358,  1.0299, -0.7087, -0.6123,  1.1049, -0.0407,  0.7497, -0.7880,\n",
      "         -0.5554, -1.3034],\n",
      "        [-0.5752, -1.5945, -0.8588, -0.6699, -0.6985,  0.4494,  0.1076,  0.6572,\n",
      "          0.4659,  0.6877],\n",
      "        [-1.9319, -1.4402,  2.4471, -1.3346,  1.4204,  0.1460, -0.6199, -0.6909,\n",
      "          0.1799,  0.6163]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3103,  0.3335,  1.3375,  0.8934,  1.3603, -0.0965,  1.7963, -2.7218,\n",
      "          0.3626, -0.8500],\n",
      "        [ 0.4360,  1.0300, -0.7088, -0.6123,  1.1049, -0.0409,  0.7497, -0.7880,\n",
      "         -0.5557, -1.3034],\n",
      "        [-0.5755, -1.5945, -0.8588, -0.6700, -0.6985,  0.4496,  0.1076,  0.6572,\n",
      "          0.4659,  0.6877],\n",
      "        [-1.9321, -1.4402,  2.4471, -1.3347,  1.4204,  0.1461, -0.6199, -0.6909,\n",
      "          0.1799,  0.6163]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3103,  0.3337,  1.3374,  0.8933,  1.3603, -0.0966,  1.7963, -2.7218,\n",
      "          0.3623, -0.8500],\n",
      "        [ 0.4362,  1.0302, -0.7089, -0.6123,  1.1049, -0.0411,  0.7497, -0.7880,\n",
      "         -0.5559, -1.3035],\n",
      "        [-0.5758, -1.5944, -0.8589, -0.6701, -0.6985,  0.4498,  0.1076,  0.6572,\n",
      "          0.4658,  0.6877],\n",
      "        [-1.9322, -1.4402,  2.4471, -1.3347,  1.4204,  0.1462, -0.6199, -0.6909,\n",
      "          0.1800,  0.6163]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3104,  0.3339,  1.3373,  0.8933,  1.3603, -0.0967,  1.7963, -2.7218,\n",
      "          0.3620, -0.8501],\n",
      "        [ 0.4364,  1.0303, -0.7090, -0.6123,  1.1049, -0.0413,  0.7497, -0.7880,\n",
      "         -0.5561, -1.3035],\n",
      "        [-0.5761, -1.5944, -0.8589, -0.6702, -0.6985,  0.4500,  0.1076,  0.6572,\n",
      "          0.4658,  0.6877],\n",
      "        [-1.9323, -1.4402,  2.4471, -1.3348,  1.4204,  0.1463, -0.6199, -0.6909,\n",
      "          0.1800,  0.6163]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3105,  0.3341,  1.3372,  0.8932,  1.3603, -0.0968,  1.7963, -2.7218,\n",
      "          0.3617, -0.8501],\n",
      "        [ 0.4366,  1.0305, -0.7091, -0.6122,  1.1049, -0.0414,  0.7497, -0.7880,\n",
      "         -0.5563, -1.3035],\n",
      "        [-0.5764, -1.5944, -0.8589, -0.6704, -0.6985,  0.4502,  0.1076,  0.6572,\n",
      "          0.4658,  0.6877],\n",
      "        [-1.9324, -1.4402,  2.4471, -1.3348,  1.4204,  0.1464, -0.6199, -0.6909,\n",
      "          0.1800,  0.6163]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3105,  0.3343,  1.3370,  0.8932,  1.3603, -0.0969,  1.7963, -2.7218,\n",
      "          0.3614, -0.8501],\n",
      "        [ 0.4368,  1.0306, -0.7092, -0.6122,  1.1049, -0.0416,  0.7497, -0.7880,\n",
      "         -0.5565, -1.3035],\n",
      "        [-0.5767, -1.5944, -0.8589, -0.6705, -0.6985,  0.4504,  0.1076,  0.6572,\n",
      "          0.4658,  0.6877],\n",
      "        [-1.9326, -1.4402,  2.4471, -1.3349,  1.4204,  0.1465, -0.6199, -0.6909,\n",
      "          0.1800,  0.6163]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3106,  0.3345,  1.3369,  0.8931,  1.3603, -0.0970,  1.7963, -2.7218,\n",
      "          0.3611, -0.8501],\n",
      "        [ 0.4370,  1.0308, -0.7092, -0.6122,  1.1049, -0.0418,  0.7497, -0.7880,\n",
      "         -0.5567, -1.3035],\n",
      "        [-0.5770, -1.5943, -0.8590, -0.6706, -0.6985,  0.4507,  0.1076,  0.6572,\n",
      "          0.4657,  0.6876],\n",
      "        [-1.9327, -1.4402,  2.4471, -1.3349,  1.4204,  0.1466, -0.6199, -0.6909,\n",
      "          0.1800,  0.6163]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3107,  0.3347,  1.3368,  0.8931,  1.3603, -0.0971,  1.7963, -2.7218,\n",
      "          0.3609, -0.8501],\n",
      "        [ 0.4372,  1.0309, -0.7093, -0.6122,  1.1049, -0.0420,  0.7497, -0.7880,\n",
      "         -0.5570, -1.3035],\n",
      "        [-0.5773, -1.5943, -0.8590, -0.6707, -0.6985,  0.4509,  0.1076,  0.6572,\n",
      "          0.4657,  0.6876],\n",
      "        [-1.9328, -1.4402,  2.4471, -1.3350,  1.4204,  0.1467, -0.6199, -0.6909,\n",
      "          0.1800,  0.6163]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3107,  0.3349,  1.3367,  0.8930,  1.3603, -0.0972,  1.7963, -2.7218,\n",
      "          0.3606, -0.8502],\n",
      "        [ 0.4374,  1.0311, -0.7094, -0.6121,  1.1049, -0.0421,  0.7497, -0.7880,\n",
      "         -0.5572, -1.3035],\n",
      "        [-0.5776, -1.5943, -0.8590, -0.6709, -0.6985,  0.4511,  0.1076,  0.6572,\n",
      "          0.4657,  0.6876],\n",
      "        [-1.9330, -1.4402,  2.4471, -1.3350,  1.4204,  0.1468, -0.6199, -0.6909,\n",
      "          0.1800,  0.6162]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3108,  0.3351,  1.3366,  0.8930,  1.3603, -0.0973,  1.7963, -2.7218,\n",
      "          0.3603, -0.8502],\n",
      "        [ 0.4376,  1.0312, -0.7095, -0.6121,  1.1049, -0.0423,  0.7497, -0.7880,\n",
      "         -0.5574, -1.3035],\n",
      "        [-0.5779, -1.5943, -0.8590, -0.6710, -0.6985,  0.4513,  0.1076,  0.6572,\n",
      "          0.4656,  0.6876],\n",
      "        [-1.9331, -1.4402,  2.4471, -1.3351,  1.4204,  0.1469, -0.6199, -0.6909,\n",
      "          0.1800,  0.6162]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3109,  0.3353,  1.3365,  0.8929,  1.3603, -0.0974,  1.7963, -2.7218,\n",
      "          0.3600, -0.8502],\n",
      "        [ 0.4378,  1.0314, -0.7096, -0.6121,  1.1049, -0.0425,  0.7497, -0.7880,\n",
      "         -0.5576, -1.3035],\n",
      "        [-0.5782, -1.5943, -0.8590, -0.6711, -0.6985,  0.4515,  0.1076,  0.6572,\n",
      "          0.4656,  0.6876],\n",
      "        [-1.9332, -1.4402,  2.4471, -1.3351,  1.4204,  0.1470, -0.6199, -0.6909,\n",
      "          0.1800,  0.6162]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3109,  0.3355,  1.3364,  0.8929,  1.3603, -0.0974,  1.7963, -2.7218,\n",
      "          0.3597, -0.8502],\n",
      "        [ 0.4380,  1.0315, -0.7096, -0.6121,  1.1049, -0.0427,  0.7497, -0.7880,\n",
      "         -0.5578, -1.3035],\n",
      "        [-0.5785, -1.5942, -0.8591, -0.6713, -0.6985,  0.4517,  0.1076,  0.6572,\n",
      "          0.4656,  0.6876],\n",
      "        [-1.9333, -1.4402,  2.4471, -1.3352,  1.4204,  0.1471, -0.6199, -0.6909,\n",
      "          0.1800,  0.6162]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3110,  0.3357,  1.3363,  0.8928,  1.3603, -0.0975,  1.7963, -2.7218,\n",
      "          0.3594, -0.8502],\n",
      "        [ 0.4383,  1.0317, -0.7097, -0.6120,  1.1049, -0.0428,  0.7497, -0.7880,\n",
      "         -0.5581, -1.3035],\n",
      "        [-0.5788, -1.5942, -0.8591, -0.6714, -0.6985,  0.4519,  0.1076,  0.6572,\n",
      "          0.4655,  0.6875],\n",
      "        [-1.9335, -1.4402,  2.4471, -1.3352,  1.4204,  0.1472, -0.6199, -0.6909,\n",
      "          0.1800,  0.6162]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3110,  0.3359,  1.3361,  0.8928,  1.3603, -0.0976,  1.7963, -2.7218,\n",
      "          0.3592, -0.8503],\n",
      "        [ 0.4385,  1.0318, -0.7098, -0.6120,  1.1049, -0.0430,  0.7497, -0.7880,\n",
      "         -0.5583, -1.3035],\n",
      "        [-0.5791, -1.5942, -0.8591, -0.6715, -0.6985,  0.4521,  0.1076,  0.6572,\n",
      "          0.4655,  0.6875],\n",
      "        [-1.9336, -1.4402,  2.4471, -1.3353,  1.4204,  0.1472, -0.6199, -0.6909,\n",
      "          0.1800,  0.6162]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3111,  0.3361,  1.3360,  0.8927,  1.3603, -0.0977,  1.7963, -2.7218,\n",
      "          0.3589, -0.8503],\n",
      "        [ 0.4387,  1.0320, -0.7099, -0.6120,  1.1049, -0.0432,  0.7497, -0.7880,\n",
      "         -0.5585, -1.3036],\n",
      "        [-0.5794, -1.5942, -0.8591, -0.6716, -0.6985,  0.4523,  0.1076,  0.6572,\n",
      "          0.4655,  0.6875],\n",
      "        [-1.9337, -1.4402,  2.4471, -1.3353,  1.4204,  0.1473, -0.6199, -0.6909,\n",
      "          0.1801,  0.6162]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3112,  0.3363,  1.3359,  0.8927,  1.3603, -0.0978,  1.7963, -2.7218,\n",
      "          0.3586, -0.8503],\n",
      "        [ 0.4389,  1.0321, -0.7100, -0.6120,  1.1049, -0.0434,  0.7497, -0.7880,\n",
      "         -0.5587, -1.3036],\n",
      "        [-0.5797, -1.5942, -0.8592, -0.6718, -0.6985,  0.4525,  0.1076,  0.6572,\n",
      "          0.4655,  0.6875],\n",
      "        [-1.9338, -1.4402,  2.4471, -1.3354,  1.4204,  0.1474, -0.6199, -0.6909,\n",
      "          0.1801,  0.6162]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3112,  0.3365,  1.3358,  0.8926,  1.3603, -0.0979,  1.7963, -2.7218,\n",
      "          0.3583, -0.8503],\n",
      "        [ 0.4391,  1.0323, -0.7101, -0.6119,  1.1049, -0.0435,  0.7497, -0.7880,\n",
      "         -0.5589, -1.3036],\n",
      "        [-0.5800, -1.5941, -0.8592, -0.6719, -0.6985,  0.4527,  0.1076,  0.6572,\n",
      "          0.4654,  0.6875],\n",
      "        [-1.9340, -1.4402,  2.4471, -1.3354,  1.4204,  0.1475, -0.6199, -0.6909,\n",
      "          0.1801,  0.6162]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3113,  0.3367,  1.3357,  0.8926,  1.3603, -0.0980,  1.7963, -2.7218,\n",
      "          0.3580, -0.8503],\n",
      "        [ 0.4393,  1.0324, -0.7101, -0.6119,  1.1049, -0.0437,  0.7497, -0.7880,\n",
      "         -0.5591, -1.3036],\n",
      "        [-0.5803, -1.5941, -0.8592, -0.6720, -0.6985,  0.4529,  0.1076,  0.6572,\n",
      "          0.4654,  0.6875],\n",
      "        [-1.9341, -1.4402,  2.4471, -1.3355,  1.4204,  0.1476, -0.6199, -0.6909,\n",
      "          0.1801,  0.6162]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3114,  0.3368,  1.3356,  0.8925,  1.3603, -0.0981,  1.7963, -2.7218,\n",
      "          0.3578, -0.8504],\n",
      "        [ 0.4395,  1.0326, -0.7102, -0.6119,  1.1049, -0.0439,  0.7497, -0.7880,\n",
      "         -0.5594, -1.3036],\n",
      "        [-0.5806, -1.5941, -0.8592, -0.6721, -0.6985,  0.4531,  0.1076,  0.6572,\n",
      "          0.4654,  0.6874],\n",
      "        [-1.9342, -1.4403,  2.4471, -1.3355,  1.4204,  0.1477, -0.6199, -0.6909,\n",
      "          0.1801,  0.6162]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3114,  0.3370,  1.3355,  0.8925,  1.3603, -0.0982,  1.7963, -2.7218,\n",
      "          0.3575, -0.8504],\n",
      "        [ 0.4397,  1.0327, -0.7103, -0.6118,  1.1049, -0.0441,  0.7497, -0.7880,\n",
      "         -0.5596, -1.3036],\n",
      "        [-0.5809, -1.5941, -0.8592, -0.6723, -0.6985,  0.4533,  0.1076,  0.6572,\n",
      "          0.4653,  0.6874],\n",
      "        [-1.9343, -1.4403,  2.4471, -1.3356,  1.4204,  0.1478, -0.6199, -0.6909,\n",
      "          0.1801,  0.6162]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3115,  0.3372,  1.3354,  0.8924,  1.3603, -0.0983,  1.7963, -2.7218,\n",
      "          0.3572, -0.8504],\n",
      "        [ 0.4399,  1.0329, -0.7104, -0.6118,  1.1049, -0.0442,  0.7497, -0.7880,\n",
      "         -0.5598, -1.3036],\n",
      "        [-0.5812, -1.5941, -0.8593, -0.6724, -0.6985,  0.4535,  0.1076,  0.6572,\n",
      "          0.4653,  0.6874],\n",
      "        [-1.9345, -1.4403,  2.4471, -1.3356,  1.4204,  0.1479, -0.6199, -0.6909,\n",
      "          0.1801,  0.6162]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3116,  0.3374,  1.3353,  0.8924,  1.3603, -0.0984,  1.7963, -2.7218,\n",
      "          0.3569, -0.8504],\n",
      "        [ 0.4401,  1.0330, -0.7105, -0.6118,  1.1049, -0.0444,  0.7497, -0.7880,\n",
      "         -0.5600, -1.3036],\n",
      "        [-0.5815, -1.5940, -0.8593, -0.6725, -0.6985,  0.4538,  0.1076,  0.6572,\n",
      "          0.4653,  0.6874],\n",
      "        [-1.9346, -1.4403,  2.4471, -1.3357,  1.4204,  0.1480, -0.6199, -0.6909,\n",
      "          0.1801,  0.6162]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3116,  0.3376,  1.3351,  0.8923,  1.3603, -0.0984,  1.7963, -2.7218,\n",
      "          0.3566, -0.8504],\n",
      "        [ 0.4403,  1.0332, -0.7105, -0.6118,  1.1049, -0.0446,  0.7497, -0.7880,\n",
      "         -0.5602, -1.3036],\n",
      "        [-0.5818, -1.5940, -0.8593, -0.6726, -0.6985,  0.4540,  0.1076,  0.6572,\n",
      "          0.4653,  0.6874],\n",
      "        [-1.9347, -1.4403,  2.4471, -1.3357,  1.4204,  0.1481, -0.6199, -0.6909,\n",
      "          0.1801,  0.6162]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3117,  0.3378,  1.3350,  0.8923,  1.3603, -0.0985,  1.7963, -2.7218,\n",
      "          0.3564, -0.8505],\n",
      "        [ 0.4405,  1.0333, -0.7106, -0.6117,  1.1049, -0.0447,  0.7497, -0.7880,\n",
      "         -0.5605, -1.3036],\n",
      "        [-0.5821, -1.5940, -0.8593, -0.6728, -0.6985,  0.4542,  0.1076,  0.6572,\n",
      "          0.4652,  0.6874],\n",
      "        [-1.9348, -1.4403,  2.4471, -1.3358,  1.4204,  0.1482, -0.6199, -0.6909,\n",
      "          0.1801,  0.6162]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3117,  0.3380,  1.3349,  0.8923,  1.3603, -0.0986,  1.7963, -2.7218,\n",
      "          0.3561, -0.8505],\n",
      "        [ 0.4407,  1.0335, -0.7107, -0.6117,  1.1049, -0.0449,  0.7497, -0.7880,\n",
      "         -0.5607, -1.3036],\n",
      "        [-0.5824, -1.5940, -0.8594, -0.6729, -0.6985,  0.4544,  0.1076,  0.6572,\n",
      "          0.4652,  0.6873],\n",
      "        [-1.9350, -1.4403,  2.4471, -1.3358,  1.4204,  0.1483, -0.6199, -0.6909,\n",
      "          0.1802,  0.6162]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3118,  0.3382,  1.3348,  0.8922,  1.3603, -0.0987,  1.7963, -2.7218,\n",
      "          0.3558, -0.8505],\n",
      "        [ 0.4409,  1.0336, -0.7108, -0.6117,  1.1049, -0.0451,  0.7497, -0.7880,\n",
      "         -0.5609, -1.3037],\n",
      "        [-0.5827, -1.5940, -0.8594, -0.6730, -0.6985,  0.4546,  0.1076,  0.6572,\n",
      "          0.4652,  0.6873],\n",
      "        [-1.9351, -1.4403,  2.4471, -1.3359,  1.4204,  0.1484, -0.6199, -0.6909,\n",
      "          0.1802,  0.6162]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3119,  0.3384,  1.3347,  0.8922,  1.3603, -0.0988,  1.7963, -2.7218,\n",
      "          0.3555, -0.8505],\n",
      "        [ 0.4411,  1.0338, -0.7109, -0.6117,  1.1049, -0.0453,  0.7497, -0.7880,\n",
      "         -0.5611, -1.3037],\n",
      "        [-0.5829, -1.5939, -0.8594, -0.6731, -0.6985,  0.4548,  0.1076,  0.6572,\n",
      "          0.4652,  0.6873],\n",
      "        [-1.9352, -1.4403,  2.4471, -1.3359,  1.4204,  0.1485, -0.6199, -0.6909,\n",
      "          0.1802,  0.6161]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3119,  0.3385,  1.3346,  0.8921,  1.3603, -0.0989,  1.7963, -2.7218,\n",
      "          0.3552, -0.8505],\n",
      "        [ 0.4413,  1.0339, -0.7110, -0.6116,  1.1049, -0.0454,  0.7497, -0.7880,\n",
      "         -0.5613, -1.3037],\n",
      "        [-0.5832, -1.5939, -0.8594, -0.6733, -0.6985,  0.4550,  0.1076,  0.6572,\n",
      "          0.4651,  0.6873],\n",
      "        [-1.9353, -1.4403,  2.4471, -1.3360,  1.4204,  0.1486, -0.6199, -0.6909,\n",
      "          0.1802,  0.6161]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3120,  0.3387,  1.3345,  0.8921,  1.3603, -0.0990,  1.7963, -2.7218,\n",
      "          0.3549, -0.8506],\n",
      "        [ 0.4415,  1.0340, -0.7110, -0.6116,  1.1049, -0.0456,  0.7497, -0.7880,\n",
      "         -0.5615, -1.3037],\n",
      "        [-0.5835, -1.5939, -0.8595, -0.6734, -0.6985,  0.4552,  0.1076,  0.6572,\n",
      "          0.4651,  0.6873],\n",
      "        [-1.9355, -1.4403,  2.4471, -1.3360,  1.4204,  0.1487, -0.6199, -0.6909,\n",
      "          0.1802,  0.6161]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3121,  0.3389,  1.3344,  0.8920,  1.3603, -0.0991,  1.7963, -2.7218,\n",
      "          0.3547, -0.8506],\n",
      "        [ 0.4417,  1.0342, -0.7111, -0.6116,  1.1049, -0.0458,  0.7497, -0.7880,\n",
      "         -0.5618, -1.3037],\n",
      "        [-0.5838, -1.5939, -0.8595, -0.6735, -0.6985,  0.4554,  0.1076,  0.6572,\n",
      "          0.4651,  0.6873],\n",
      "        [-1.9356, -1.4403,  2.4471, -1.3360,  1.4204,  0.1488, -0.6199, -0.6909,\n",
      "          0.1802,  0.6161]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3121,  0.3391,  1.3343,  0.8920,  1.3603, -0.0992,  1.7963, -2.7218,\n",
      "          0.3544, -0.8506],\n",
      "        [ 0.4419,  1.0343, -0.7112, -0.6116,  1.1049, -0.0460,  0.7497, -0.7880,\n",
      "         -0.5620, -1.3037],\n",
      "        [-0.5841, -1.5939, -0.8595, -0.6737, -0.6985,  0.4556,  0.1076,  0.6572,\n",
      "          0.4650,  0.6873],\n",
      "        [-1.9357, -1.4403,  2.4471, -1.3361,  1.4204,  0.1489, -0.6199, -0.6909,\n",
      "          0.1802,  0.6161]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3122,  0.3393,  1.3341,  0.8919,  1.3603, -0.0993,  1.7963, -2.7218,\n",
      "          0.3541, -0.8506],\n",
      "        [ 0.4421,  1.0345, -0.7113, -0.6115,  1.1049, -0.0461,  0.7497, -0.7880,\n",
      "         -0.5622, -1.3037],\n",
      "        [-0.5844, -1.5939, -0.8595, -0.6738, -0.6985,  0.4558,  0.1076,  0.6572,\n",
      "          0.4650,  0.6872],\n",
      "        [-1.9358, -1.4403,  2.4471, -1.3361,  1.4204,  0.1490, -0.6199, -0.6909,\n",
      "          0.1802,  0.6161]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3122,  0.3395,  1.3340,  0.8919,  1.3603, -0.0994,  1.7963, -2.7218,\n",
      "          0.3538, -0.8506],\n",
      "        [ 0.4423,  1.0346, -0.7114, -0.6115,  1.1049, -0.0463,  0.7497, -0.7880,\n",
      "         -0.5624, -1.3037],\n",
      "        [-0.5847, -1.5938, -0.8595, -0.6739, -0.6985,  0.4560,  0.1076,  0.6572,\n",
      "          0.4650,  0.6872],\n",
      "        [-1.9360, -1.4403,  2.4471, -1.3362,  1.4204,  0.1491, -0.6199, -0.6909,\n",
      "          0.1802,  0.6161]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3123,  0.3396,  1.3339,  0.8918,  1.3603, -0.0994,  1.7963, -2.7218,\n",
      "          0.3536, -0.8507],\n",
      "        [ 0.4425,  1.0348, -0.7114, -0.6115,  1.1049, -0.0465,  0.7497, -0.7880,\n",
      "         -0.5626, -1.3037],\n",
      "        [-0.5850, -1.5938, -0.8596, -0.6740, -0.6985,  0.4562,  0.1076,  0.6572,\n",
      "          0.4650,  0.6872],\n",
      "        [-1.9361, -1.4403,  2.4471, -1.3362,  1.4204,  0.1492, -0.6199, -0.6909,\n",
      "          0.1802,  0.6161]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3124,  0.3398,  1.3338,  0.8918,  1.3603, -0.0995,  1.7963, -2.7218,\n",
      "          0.3533, -0.8507],\n",
      "        [ 0.4427,  1.0349, -0.7115, -0.6114,  1.1049, -0.0467,  0.7497, -0.7880,\n",
      "         -0.5628, -1.3037],\n",
      "        [-0.5853, -1.5938, -0.8596, -0.6741, -0.6985,  0.4564,  0.1076,  0.6572,\n",
      "          0.4649,  0.6872],\n",
      "        [-1.9362, -1.4404,  2.4471, -1.3363,  1.4204,  0.1493, -0.6199, -0.6909,\n",
      "          0.1803,  0.6161]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3124,  0.3400,  1.3337,  0.8917,  1.3603, -0.0996,  1.7963, -2.7218,\n",
      "          0.3530, -0.8507],\n",
      "        [ 0.4429,  1.0350, -0.7116, -0.6114,  1.1049, -0.0468,  0.7497, -0.7880,\n",
      "         -0.5631, -1.3037],\n",
      "        [-0.5856, -1.5938, -0.8596, -0.6743, -0.6985,  0.4566,  0.1076,  0.6572,\n",
      "          0.4649,  0.6872],\n",
      "        [-1.9363, -1.4404,  2.4471, -1.3363,  1.4204,  0.1494, -0.6199, -0.6909,\n",
      "          0.1803,  0.6161]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3125,  0.3402,  1.3336,  0.8917,  1.3603, -0.0997,  1.7963, -2.7218,\n",
      "          0.3527, -0.8507],\n",
      "        [ 0.4431,  1.0352, -0.7117, -0.6114,  1.1049, -0.0470,  0.7497, -0.7880,\n",
      "         -0.5633, -1.3038],\n",
      "        [-0.5859, -1.5938, -0.8596, -0.6744, -0.6985,  0.4568,  0.1076,  0.6572,\n",
      "          0.4649,  0.6872],\n",
      "        [-1.9365, -1.4404,  2.4471, -1.3364,  1.4204,  0.1494, -0.6199, -0.6909,\n",
      "          0.1803,  0.6161]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3126,  0.3404,  1.3335,  0.8917,  1.3603, -0.0998,  1.7963, -2.7218,\n",
      "          0.3524, -0.8507],\n",
      "        [ 0.4433,  1.0353, -0.7118, -0.6114,  1.1049, -0.0472,  0.7497, -0.7880,\n",
      "         -0.5635, -1.3038],\n",
      "        [-0.5862, -1.5938, -0.8597, -0.6745, -0.6985,  0.4570,  0.1076,  0.6572,\n",
      "          0.4649,  0.6871],\n",
      "        [-1.9366, -1.4404,  2.4471, -1.3364,  1.4204,  0.1495, -0.6199, -0.6909,\n",
      "          0.1803,  0.6161]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3126,  0.3406,  1.3334,  0.8916,  1.3603, -0.0999,  1.7963, -2.7218,\n",
      "          0.3522, -0.8508],\n",
      "        [ 0.4435,  1.0355, -0.7119, -0.6113,  1.1049, -0.0473,  0.7497, -0.7880,\n",
      "         -0.5637, -1.3038],\n",
      "        [-0.5865, -1.5937, -0.8597, -0.6746, -0.6985,  0.4572,  0.1076,  0.6572,\n",
      "          0.4648,  0.6871],\n",
      "        [-1.9367, -1.4404,  2.4471, -1.3365,  1.4204,  0.1496, -0.6199, -0.6909,\n",
      "          0.1803,  0.6161]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3127,  0.3407,  1.3332,  0.8916,  1.3603, -0.1000,  1.7963, -2.7218,\n",
      "          0.3519, -0.8508],\n",
      "        [ 0.4437,  1.0356, -0.7119, -0.6113,  1.1049, -0.0475,  0.7497, -0.7880,\n",
      "         -0.5639, -1.3038],\n",
      "        [-0.5868, -1.5937, -0.8597, -0.6748, -0.6985,  0.4574,  0.1076,  0.6572,\n",
      "          0.4648,  0.6871],\n",
      "        [-1.9368, -1.4404,  2.4471, -1.3365,  1.4204,  0.1497, -0.6199, -0.6909,\n",
      "          0.1803,  0.6161]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3127,  0.3409,  1.3331,  0.8915,  1.3603, -0.1001,  1.7963, -2.7218,\n",
      "          0.3516, -0.8508],\n",
      "        [ 0.4439,  1.0357, -0.7120, -0.6113,  1.1049, -0.0477,  0.7497, -0.7880,\n",
      "         -0.5641, -1.3038],\n",
      "        [-0.5870, -1.5937, -0.8597, -0.6749, -0.6985,  0.4576,  0.1076,  0.6572,\n",
      "          0.4648,  0.6871],\n",
      "        [-1.9369, -1.4404,  2.4471, -1.3366,  1.4204,  0.1498, -0.6199, -0.6909,\n",
      "          0.1803,  0.6161]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3128,  0.3411,  1.3330,  0.8915,  1.3603, -0.1002,  1.7963, -2.7218,\n",
      "          0.3513, -0.8508],\n",
      "        [ 0.4441,  1.0359, -0.7121, -0.6113,  1.1049, -0.0479,  0.7497, -0.7880,\n",
      "         -0.5644, -1.3038],\n",
      "        [-0.5873, -1.5937, -0.8597, -0.6750, -0.6985,  0.4578,  0.1076,  0.6572,\n",
      "          0.4648,  0.6871],\n",
      "        [-1.9371, -1.4404,  2.4471, -1.3366,  1.4204,  0.1499, -0.6199, -0.6909,\n",
      "          0.1803,  0.6161]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3129,  0.3413,  1.3329,  0.8914,  1.3603, -0.1003,  1.7963, -2.7218,\n",
      "          0.3510, -0.8508],\n",
      "        [ 0.4443,  1.0360, -0.7122, -0.6112,  1.1049, -0.0480,  0.7497, -0.7880,\n",
      "         -0.5646, -1.3038],\n",
      "        [-0.5876, -1.5937, -0.8598, -0.6751, -0.6985,  0.4580,  0.1076,  0.6572,\n",
      "          0.4647,  0.6871],\n",
      "        [-1.9372, -1.4404,  2.4471, -1.3367,  1.4204,  0.1500, -0.6199, -0.6909,\n",
      "          0.1803,  0.6161]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3129,  0.3414,  1.3328,  0.8914,  1.3603, -0.1003,  1.7963, -2.7218,\n",
      "          0.3508, -0.8509],\n",
      "        [ 0.4445,  1.0362, -0.7123, -0.6112,  1.1049, -0.0482,  0.7497, -0.7880,\n",
      "         -0.5648, -1.3038],\n",
      "        [-0.5879, -1.5937, -0.8598, -0.6753, -0.6985,  0.4582,  0.1076,  0.6572,\n",
      "          0.4647,  0.6870],\n",
      "        [-1.9373, -1.4404,  2.4471, -1.3367,  1.4204,  0.1501, -0.6199, -0.6909,\n",
      "          0.1803,  0.6161]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3130,  0.3416,  1.3327,  0.8913,  1.3603, -0.1004,  1.7963, -2.7218,\n",
      "          0.3505, -0.8509],\n",
      "        [ 0.4447,  1.0363, -0.7123, -0.6112,  1.1049, -0.0484,  0.7497, -0.7880,\n",
      "         -0.5650, -1.3038],\n",
      "        [-0.5882, -1.5937, -0.8598, -0.6754, -0.6985,  0.4584,  0.1076,  0.6572,\n",
      "          0.4647,  0.6870],\n",
      "        [-1.9374, -1.4404,  2.4471, -1.3368,  1.4204,  0.1502, -0.6199, -0.6909,\n",
      "          0.1804,  0.6160]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3130,  0.3418,  1.3326,  0.8913,  1.3603, -0.1005,  1.7963, -2.7218,\n",
      "          0.3502, -0.8509],\n",
      "        [ 0.4449,  1.0364, -0.7124, -0.6111,  1.1049, -0.0485,  0.7497, -0.7880,\n",
      "         -0.5652, -1.3038],\n",
      "        [-0.5885, -1.5936, -0.8598, -0.6755, -0.6985,  0.4586,  0.1076,  0.6572,\n",
      "          0.4647,  0.6870],\n",
      "        [-1.9376, -1.4404,  2.4471, -1.3368,  1.4204,  0.1503, -0.6199, -0.6909,\n",
      "          0.1804,  0.6160]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3131,  0.3420,  1.3325,  0.8913,  1.3603, -0.1006,  1.7963, -2.7218,\n",
      "          0.3499, -0.8509],\n",
      "        [ 0.4451,  1.0366, -0.7125, -0.6111,  1.1049, -0.0487,  0.7497, -0.7880,\n",
      "         -0.5655, -1.3038],\n",
      "        [-0.5888, -1.5936, -0.8599, -0.6756, -0.6985,  0.4588,  0.1076,  0.6572,\n",
      "          0.4646,  0.6870],\n",
      "        [-1.9377, -1.4404,  2.4471, -1.3369,  1.4204,  0.1504, -0.6199, -0.6909,\n",
      "          0.1804,  0.6160]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3132,  0.3421,  1.3324,  0.8912,  1.3603, -0.1007,  1.7963, -2.7218,\n",
      "          0.3497, -0.8509],\n",
      "        [ 0.4453,  1.0367, -0.7126, -0.6111,  1.1049, -0.0489,  0.7497, -0.7880,\n",
      "         -0.5657, -1.3038],\n",
      "        [-0.5891, -1.5936, -0.8599, -0.6758, -0.6985,  0.4591,  0.1076,  0.6572,\n",
      "          0.4646,  0.6870],\n",
      "        [-1.9378, -1.4404,  2.4471, -1.3369,  1.4204,  0.1505, -0.6199, -0.6909,\n",
      "          0.1804,  0.6160]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3132,  0.3423,  1.3322,  0.8912,  1.3603, -0.1008,  1.7963, -2.7218,\n",
      "          0.3494, -0.8510],\n",
      "        [ 0.4455,  1.0369, -0.7127, -0.6111,  1.1049, -0.0491,  0.7497, -0.7880,\n",
      "         -0.5659, -1.3039],\n",
      "        [-0.5894, -1.5936, -0.8599, -0.6759, -0.6985,  0.4593,  0.1076,  0.6572,\n",
      "          0.4646,  0.6870],\n",
      "        [-1.9379, -1.4405,  2.4471, -1.3370,  1.4204,  0.1506, -0.6199, -0.6909,\n",
      "          0.1804,  0.6160]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3133,  0.3425,  1.3321,  0.8911,  1.3603, -0.1009,  1.7963, -2.7218,\n",
      "          0.3491, -0.8510],\n",
      "        [ 0.4457,  1.0370, -0.7128, -0.6110,  1.1049, -0.0492,  0.7497, -0.7880,\n",
      "         -0.5661, -1.3039],\n",
      "        [-0.5896, -1.5936, -0.8599, -0.6760, -0.6985,  0.4595,  0.1076,  0.6572,\n",
      "          0.4646,  0.6869],\n",
      "        [-1.9380, -1.4405,  2.4471, -1.3370,  1.4204,  0.1507, -0.6199, -0.6909,\n",
      "          0.1804,  0.6160]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3133,  0.3427,  1.3320,  0.8911,  1.3603, -0.1010,  1.7963, -2.7218,\n",
      "          0.3488, -0.8510],\n",
      "        [ 0.4459,  1.0371, -0.7128, -0.6110,  1.1049, -0.0494,  0.7497, -0.7880,\n",
      "         -0.5663, -1.3039],\n",
      "        [-0.5899, -1.5936, -0.8599, -0.6761, -0.6985,  0.4597,  0.1076,  0.6572,\n",
      "          0.4645,  0.6869],\n",
      "        [-1.9382, -1.4405,  2.4471, -1.3371,  1.4204,  0.1508, -0.6199, -0.6909,\n",
      "          0.1804,  0.6160]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3134,  0.3428,  1.3319,  0.8910,  1.3603, -0.1011,  1.7963, -2.7218,\n",
      "          0.3485, -0.8510],\n",
      "        [ 0.4461,  1.0373, -0.7129, -0.6110,  1.1049, -0.0496,  0.7497, -0.7880,\n",
      "         -0.5665, -1.3039],\n",
      "        [-0.5902, -1.5936, -0.8600, -0.6762, -0.6985,  0.4599,  0.1076,  0.6572,\n",
      "          0.4645,  0.6869],\n",
      "        [-1.9383, -1.4405,  2.4471, -1.3371,  1.4204,  0.1509, -0.6199, -0.6909,\n",
      "          0.1804,  0.6160]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3135,  0.3430,  1.3318,  0.8910,  1.3603, -0.1012,  1.7963, -2.7218,\n",
      "          0.3483, -0.8510],\n",
      "        [ 0.4463,  1.0374, -0.7130, -0.6109,  1.1049, -0.0497,  0.7497, -0.7880,\n",
      "         -0.5667, -1.3039],\n",
      "        [-0.5905, -1.5936, -0.8600, -0.6764, -0.6985,  0.4601,  0.1076,  0.6572,\n",
      "          0.4645,  0.6869],\n",
      "        [-1.9384, -1.4405,  2.4471, -1.3372,  1.4204,  0.1510, -0.6199, -0.6909,\n",
      "          0.1804,  0.6160]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3135,  0.3432,  1.3317,  0.8910,  1.3603, -0.1012,  1.7963, -2.7218,\n",
      "          0.3480, -0.8511],\n",
      "        [ 0.4465,  1.0375, -0.7131, -0.6109,  1.1049, -0.0499,  0.7497, -0.7880,\n",
      "         -0.5670, -1.3039],\n",
      "        [-0.5908, -1.5935, -0.8600, -0.6765, -0.6985,  0.4603,  0.1076,  0.6572,\n",
      "          0.4645,  0.6869],\n",
      "        [-1.9385, -1.4405,  2.4471, -1.3372,  1.4204,  0.1511, -0.6199, -0.6909,\n",
      "          0.1805,  0.6160]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3136,  0.3434,  1.3316,  0.8909,  1.3603, -0.1013,  1.7963, -2.7218,\n",
      "          0.3477, -0.8511],\n",
      "        [ 0.4467,  1.0377, -0.7132, -0.6109,  1.1049, -0.0501,  0.7497, -0.7880,\n",
      "         -0.5672, -1.3039],\n",
      "        [-0.5911, -1.5935, -0.8600, -0.6766, -0.6985,  0.4605,  0.1076,  0.6572,\n",
      "          0.4644,  0.6869],\n",
      "        [-1.9386, -1.4405,  2.4471, -1.3373,  1.4204,  0.1512, -0.6199, -0.6909,\n",
      "          0.1805,  0.6160]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3136,  0.3435,  1.3315,  0.8909,  1.3603, -0.1014,  1.7963, -2.7218,\n",
      "          0.3474, -0.8511],\n",
      "        [ 0.4469,  1.0378, -0.7132, -0.6109,  1.1049, -0.0503,  0.7497, -0.7880,\n",
      "         -0.5674, -1.3039],\n",
      "        [-0.5914, -1.5935, -0.8601, -0.6767, -0.6985,  0.4607,  0.1076,  0.6572,\n",
      "          0.4644,  0.6869],\n",
      "        [-1.9388, -1.4405,  2.4471, -1.3373,  1.4204,  0.1512, -0.6199, -0.6909,\n",
      "          0.1805,  0.6160]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3137,  0.3437,  1.3314,  0.8908,  1.3603, -0.1015,  1.7963, -2.7218,\n",
      "          0.3472, -0.8511],\n",
      "        [ 0.4471,  1.0379, -0.7133, -0.6108,  1.1049, -0.0504,  0.7497, -0.7880,\n",
      "         -0.5676, -1.3039],\n",
      "        [-0.5917, -1.5935, -0.8601, -0.6769, -0.6985,  0.4609,  0.1076,  0.6572,\n",
      "          0.4644,  0.6868],\n",
      "        [-1.9389, -1.4405,  2.4471, -1.3373,  1.4204,  0.1513, -0.6199, -0.6909,\n",
      "          0.1805,  0.6160]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3138,  0.3439,  1.3312,  0.8908,  1.3603, -0.1016,  1.7963, -2.7218,\n",
      "          0.3469, -0.8511],\n",
      "        [ 0.4473,  1.0381, -0.7134, -0.6108,  1.1049, -0.0506,  0.7497, -0.7880,\n",
      "         -0.5678, -1.3039],\n",
      "        [-0.5919, -1.5935, -0.8601, -0.6770, -0.6985,  0.4611,  0.1076,  0.6572,\n",
      "          0.4644,  0.6868],\n",
      "        [-1.9390, -1.4405,  2.4471, -1.3374,  1.4204,  0.1514, -0.6199, -0.6909,\n",
      "          0.1805,  0.6160]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3138,  0.3440,  1.3311,  0.8907,  1.3603, -0.1017,  1.7963, -2.7218,\n",
      "          0.3466, -0.8511],\n",
      "        [ 0.4475,  1.0382, -0.7135, -0.6108,  1.1049, -0.0508,  0.7497, -0.7880,\n",
      "         -0.5680, -1.3039],\n",
      "        [-0.5922, -1.5935, -0.8601, -0.6771, -0.6985,  0.4613,  0.1076,  0.6572,\n",
      "          0.4644,  0.6868],\n",
      "        [-1.9391, -1.4405,  2.4471, -1.3374,  1.4204,  0.1515, -0.6199, -0.6909,\n",
      "          0.1805,  0.6160]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3139,  0.3442,  1.3310,  0.8907,  1.3603, -0.1018,  1.7963, -2.7218,\n",
      "          0.3463, -0.8512],\n",
      "        [ 0.4477,  1.0383, -0.7136, -0.6107,  1.1049, -0.0509,  0.7497, -0.7880,\n",
      "         -0.5683, -1.3039],\n",
      "        [-0.5925, -1.5935, -0.8601, -0.6772, -0.6985,  0.4615,  0.1076,  0.6572,\n",
      "          0.4643,  0.6868],\n",
      "        [-1.9393, -1.4405,  2.4471, -1.3375,  1.4204,  0.1516, -0.6199, -0.6909,\n",
      "          0.1805,  0.6160]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3139,  0.3444,  1.3309,  0.8907,  1.3603, -0.1019,  1.7963, -2.7218,\n",
      "          0.3461, -0.8512],\n",
      "        [ 0.4479,  1.0385, -0.7137, -0.6107,  1.1049, -0.0511,  0.7497, -0.7880,\n",
      "         -0.5685, -1.3040],\n",
      "        [-0.5928, -1.5935, -0.8602, -0.6773, -0.6985,  0.4617,  0.1076,  0.6572,\n",
      "          0.4643,  0.6868],\n",
      "        [-1.9394, -1.4405,  2.4471, -1.3375,  1.4204,  0.1517, -0.6199, -0.6909,\n",
      "          0.1805,  0.6160]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3140,  0.3445,  1.3308,  0.8906,  1.3603, -0.1020,  1.7963, -2.7218,\n",
      "          0.3458, -0.8512],\n",
      "        [ 0.4481,  1.0386, -0.7137, -0.6107,  1.1049, -0.0513,  0.7497, -0.7880,\n",
      "         -0.5687, -1.3040],\n",
      "        [-0.5931, -1.5935, -0.8602, -0.6775, -0.6985,  0.4619,  0.1076,  0.6572,\n",
      "          0.4643,  0.6868],\n",
      "        [-1.9395, -1.4406,  2.4471, -1.3376,  1.4204,  0.1518, -0.6199, -0.6909,\n",
      "          0.1805,  0.6160]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3141,  0.3447,  1.3307,  0.8906,  1.3603, -0.1021,  1.7963, -2.7218,\n",
      "          0.3455, -0.8512],\n",
      "        [ 0.4483,  1.0387, -0.7138, -0.6107,  1.1049, -0.0515,  0.7497, -0.7880,\n",
      "         -0.5689, -1.3040],\n",
      "        [-0.5934, -1.5934, -0.8602, -0.6776, -0.6985,  0.4621,  0.1076,  0.6572,\n",
      "          0.4643,  0.6867],\n",
      "        [-1.9396, -1.4406,  2.4471, -1.3376,  1.4204,  0.1519, -0.6199, -0.6909,\n",
      "          0.1806,  0.6160]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3141,  0.3449,  1.3306,  0.8905,  1.3603, -0.1021,  1.7963, -2.7218,\n",
      "          0.3452, -0.8512],\n",
      "        [ 0.4485,  1.0389, -0.7139, -0.6106,  1.1049, -0.0516,  0.7497, -0.7880,\n",
      "         -0.5691, -1.3040],\n",
      "        [-0.5936, -1.5934, -0.8602, -0.6777, -0.6985,  0.4623,  0.1076,  0.6572,\n",
      "          0.4642,  0.6867],\n",
      "        [-1.9397, -1.4406,  2.4471, -1.3377,  1.4204,  0.1520, -0.6199, -0.6909,\n",
      "          0.1806,  0.6159]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3142,  0.3450,  1.3305,  0.8905,  1.3603, -0.1022,  1.7963, -2.7218,\n",
      "          0.3450, -0.8513],\n",
      "        [ 0.4487,  1.0390, -0.7140, -0.6106,  1.1049, -0.0518,  0.7497, -0.7880,\n",
      "         -0.5693, -1.3040],\n",
      "        [-0.5939, -1.5934, -0.8603, -0.6778, -0.6985,  0.4625,  0.1076,  0.6572,\n",
      "          0.4642,  0.6867],\n",
      "        [-1.9399, -1.4406,  2.4471, -1.3377,  1.4204,  0.1521, -0.6199, -0.6909,\n",
      "          0.1806,  0.6159]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3142,  0.3452,  1.3303,  0.8905,  1.3603, -0.1023,  1.7963, -2.7218,\n",
      "          0.3447, -0.8513],\n",
      "        [ 0.4489,  1.0391, -0.7141, -0.6106,  1.1049, -0.0520,  0.7497, -0.7880,\n",
      "         -0.5696, -1.3040],\n",
      "        [-0.5942, -1.5934, -0.8603, -0.6780, -0.6985,  0.4627,  0.1076,  0.6572,\n",
      "          0.4642,  0.6867],\n",
      "        [-1.9400, -1.4406,  2.4471, -1.3378,  1.4204,  0.1522, -0.6199, -0.6909,\n",
      "          0.1806,  0.6159]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3143,  0.3454,  1.3302,  0.8904,  1.3603, -0.1024,  1.7963, -2.7218,\n",
      "          0.3444, -0.8513],\n",
      "        [ 0.4491,  1.0393, -0.7141, -0.6105,  1.1049, -0.0521,  0.7497, -0.7880,\n",
      "         -0.5698, -1.3040],\n",
      "        [-0.5945, -1.5934, -0.8603, -0.6781, -0.6985,  0.4629,  0.1076,  0.6572,\n",
      "          0.4642,  0.6867],\n",
      "        [-1.9401, -1.4406,  2.4471, -1.3378,  1.4204,  0.1523, -0.6199, -0.6909,\n",
      "          0.1806,  0.6159]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3144,  0.3455,  1.3301,  0.8904,  1.3603, -0.1025,  1.7963, -2.7218,\n",
      "          0.3441, -0.8513],\n",
      "        [ 0.4493,  1.0394, -0.7142, -0.6105,  1.1049, -0.0523,  0.7497, -0.7880,\n",
      "         -0.5700, -1.3040],\n",
      "        [-0.5948, -1.5934, -0.8603, -0.6782, -0.6985,  0.4631,  0.1076,  0.6572,\n",
      "          0.4642,  0.6867],\n",
      "        [-1.9402, -1.4406,  2.4471, -1.3379,  1.4204,  0.1524, -0.6199, -0.6909,\n",
      "          0.1806,  0.6159]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3144,  0.3457,  1.3300,  0.8903,  1.3603, -0.1026,  1.7963, -2.7218,\n",
      "          0.3439, -0.8513],\n",
      "        [ 0.4495,  1.0395, -0.7143, -0.6105,  1.1049, -0.0525,  0.7497, -0.7880,\n",
      "         -0.5702, -1.3040],\n",
      "        [-0.5951, -1.5934, -0.8603, -0.6783, -0.6985,  0.4633,  0.1076,  0.6572,\n",
      "          0.4641,  0.6867],\n",
      "        [-1.9403, -1.4406,  2.4471, -1.3379,  1.4204,  0.1525, -0.6199, -0.6909,\n",
      "          0.1806,  0.6159]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3145,  0.3459,  1.3299,  0.8903,  1.3603, -0.1027,  1.7963, -2.7218,\n",
      "          0.3436, -0.8514],\n",
      "        [ 0.4496,  1.0397, -0.7144, -0.6105,  1.1049, -0.0526,  0.7497, -0.7880,\n",
      "         -0.5704, -1.3040],\n",
      "        [-0.5953, -1.5934, -0.8604, -0.6784, -0.6985,  0.4635,  0.1076,  0.6572,\n",
      "          0.4641,  0.6866],\n",
      "        [-1.9405, -1.4406,  2.4471, -1.3380,  1.4204,  0.1526, -0.6199, -0.6909,\n",
      "          0.1806,  0.6159]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3145,  0.3460,  1.3298,  0.8902,  1.3603, -0.1028,  1.7963, -2.7218,\n",
      "          0.3433, -0.8514],\n",
      "        [ 0.4498,  1.0398, -0.7145, -0.6104,  1.1049, -0.0528,  0.7497, -0.7880,\n",
      "         -0.5706, -1.3040],\n",
      "        [-0.5956, -1.5934, -0.8604, -0.6786, -0.6985,  0.4637,  0.1076,  0.6572,\n",
      "          0.4641,  0.6866],\n",
      "        [-1.9406, -1.4406,  2.4471, -1.3380,  1.4204,  0.1526, -0.6199, -0.6909,\n",
      "          0.1807,  0.6159]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3146,  0.3462,  1.3297,  0.8902,  1.3603, -0.1029,  1.7963, -2.7218,\n",
      "          0.3430, -0.8514],\n",
      "        [ 0.4500,  1.0399, -0.7146, -0.6104,  1.1049, -0.0530,  0.7497, -0.7880,\n",
      "         -0.5708, -1.3041],\n",
      "        [-0.5959, -1.5934, -0.8604, -0.6787, -0.6985,  0.4639,  0.1076,  0.6572,\n",
      "          0.4641,  0.6866],\n",
      "        [-1.9407, -1.4406,  2.4471, -1.3381,  1.4204,  0.1527, -0.6199, -0.6909,\n",
      "          0.1807,  0.6159]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3147,  0.3464,  1.3296,  0.8902,  1.3603, -0.1029,  1.7963, -2.7218,\n",
      "          0.3428, -0.8514],\n",
      "        [ 0.4502,  1.0400, -0.7146, -0.6104,  1.1049, -0.0532,  0.7497, -0.7880,\n",
      "         -0.5711, -1.3041],\n",
      "        [-0.5962, -1.5933, -0.8604, -0.6788, -0.6985,  0.4641,  0.1076,  0.6572,\n",
      "          0.4640,  0.6866],\n",
      "        [-1.9408, -1.4406,  2.4471, -1.3381,  1.4204,  0.1528, -0.6199, -0.6909,\n",
      "          0.1807,  0.6159]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3147,  0.3465,  1.3295,  0.8901,  1.3603, -0.1030,  1.7963, -2.7218,\n",
      "          0.3425, -0.8514],\n",
      "        [ 0.4504,  1.0402, -0.7147, -0.6103,  1.1049, -0.0533,  0.7497, -0.7880,\n",
      "         -0.5713, -1.3041],\n",
      "        [-0.5965, -1.5933, -0.8605, -0.6789, -0.6985,  0.4643,  0.1076,  0.6572,\n",
      "          0.4640,  0.6866],\n",
      "        [-1.9409, -1.4407,  2.4471, -1.3382,  1.4204,  0.1529, -0.6199, -0.6909,\n",
      "          0.1807,  0.6159]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3148,  0.3467,  1.3293,  0.8901,  1.3603, -0.1031,  1.7963, -2.7218,\n",
      "          0.3422, -0.8515],\n",
      "        [ 0.4506,  1.0403, -0.7148, -0.6103,  1.1049, -0.0535,  0.7497, -0.7880,\n",
      "         -0.5715, -1.3041],\n",
      "        [-0.5968, -1.5933, -0.8605, -0.6790, -0.6985,  0.4645,  0.1076,  0.6572,\n",
      "          0.4640,  0.6866],\n",
      "        [-1.9410, -1.4407,  2.4471, -1.3382,  1.4204,  0.1530, -0.6199, -0.6909,\n",
      "          0.1807,  0.6159]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3148,  0.3468,  1.3292,  0.8900,  1.3603, -0.1032,  1.7963, -2.7218,\n",
      "          0.3419, -0.8515],\n",
      "        [ 0.4508,  1.0404, -0.7149, -0.6103,  1.1049, -0.0537,  0.7497, -0.7880,\n",
      "         -0.5717, -1.3041],\n",
      "        [-0.5970, -1.5933, -0.8605, -0.6792, -0.6985,  0.4647,  0.1076,  0.6572,\n",
      "          0.4640,  0.6865],\n",
      "        [-1.9412, -1.4407,  2.4471, -1.3382,  1.4204,  0.1531, -0.6199, -0.6909,\n",
      "          0.1807,  0.6159]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3149,  0.3470,  1.3291,  0.8900,  1.3603, -0.1033,  1.7963, -2.7218,\n",
      "          0.3417, -0.8515],\n",
      "        [ 0.4510,  1.0406, -0.7150, -0.6102,  1.1049, -0.0538,  0.7497, -0.7880,\n",
      "         -0.5719, -1.3041],\n",
      "        [-0.5973, -1.5933, -0.8605, -0.6793, -0.6985,  0.4649,  0.1076,  0.6572,\n",
      "          0.4640,  0.6865],\n",
      "        [-1.9413, -1.4407,  2.4471, -1.3383,  1.4204,  0.1532, -0.6199, -0.6909,\n",
      "          0.1807,  0.6159]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3149,  0.3472,  1.3290,  0.8900,  1.3603, -0.1034,  1.7963, -2.7218,\n",
      "          0.3414, -0.8515],\n",
      "        [ 0.4512,  1.0407, -0.7151, -0.6102,  1.1049, -0.0540,  0.7497, -0.7880,\n",
      "         -0.5721, -1.3041],\n",
      "        [-0.5976, -1.5933, -0.8605, -0.6794, -0.6985,  0.4651,  0.1076,  0.6572,\n",
      "          0.4639,  0.6865],\n",
      "        [-1.9414, -1.4407,  2.4471, -1.3383,  1.4204,  0.1533, -0.6199, -0.6909,\n",
      "          0.1807,  0.6159]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3150,  0.3473,  1.3289,  0.8899,  1.3603, -0.1035,  1.7963, -2.7218,\n",
      "          0.3411, -0.8515],\n",
      "        [ 0.4514,  1.0408, -0.7151, -0.6102,  1.1049, -0.0542,  0.7497, -0.7880,\n",
      "         -0.5724, -1.3041],\n",
      "        [-0.5979, -1.5933, -0.8606, -0.6795, -0.6985,  0.4653,  0.1076,  0.6572,\n",
      "          0.4639,  0.6865],\n",
      "        [-1.9415, -1.4407,  2.4471, -1.3384,  1.4204,  0.1534, -0.6199, -0.6909,\n",
      "          0.1808,  0.6159]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3151,  0.3475,  1.3288,  0.8899,  1.3603, -0.1036,  1.7963, -2.7218,\n",
      "          0.3409, -0.8515],\n",
      "        [ 0.4516,  1.0409, -0.7152, -0.6102,  1.1049, -0.0543,  0.7497, -0.7880,\n",
      "         -0.5726, -1.3041],\n",
      "        [-0.5982, -1.5933, -0.8606, -0.6796, -0.6985,  0.4655,  0.1076,  0.6572,\n",
      "          0.4639,  0.6865],\n",
      "        [-1.9416, -1.4407,  2.4471, -1.3384,  1.4204,  0.1535, -0.6199, -0.6909,\n",
      "          0.1808,  0.6159]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3151,  0.3476,  1.3287,  0.8899,  1.3603, -0.1037,  1.7963, -2.7218,\n",
      "          0.3406, -0.8516],\n",
      "        [ 0.4518,  1.0411, -0.7153, -0.6101,  1.1049, -0.0545,  0.7497, -0.7880,\n",
      "         -0.5728, -1.3041],\n",
      "        [-0.5984, -1.5933, -0.8606, -0.6798, -0.6985,  0.4657,  0.1076,  0.6572,\n",
      "          0.4639,  0.6865],\n",
      "        [-1.9418, -1.4407,  2.4471, -1.3385,  1.4204,  0.1536, -0.6199, -0.6909,\n",
      "          0.1808,  0.6159]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3152,  0.3478,  1.3286,  0.8898,  1.3603, -0.1037,  1.7963, -2.7218,\n",
      "          0.3403, -0.8516],\n",
      "        [ 0.4520,  1.0412, -0.7154, -0.6101,  1.1049, -0.0547,  0.7497, -0.7880,\n",
      "         -0.5730, -1.3041],\n",
      "        [-0.5987, -1.5933, -0.8606, -0.6799, -0.6985,  0.4659,  0.1076,  0.6572,\n",
      "          0.4639,  0.6865],\n",
      "        [-1.9419, -1.4407,  2.4471, -1.3385,  1.4204,  0.1537, -0.6199, -0.6909,\n",
      "          0.1808,  0.6159]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3152,  0.3479,  1.3285,  0.8898,  1.3603, -0.1038,  1.7963, -2.7218,\n",
      "          0.3400, -0.8516],\n",
      "        [ 0.4521,  1.0413, -0.7155, -0.6101,  1.1049, -0.0548,  0.7497, -0.7880,\n",
      "         -0.5732, -1.3041],\n",
      "        [-0.5990, -1.5933, -0.8607, -0.6800, -0.6985,  0.4661,  0.1076,  0.6572,\n",
      "          0.4639,  0.6864],\n",
      "        [-1.9420, -1.4407,  2.4471, -1.3386,  1.4204,  0.1538, -0.6199, -0.6909,\n",
      "          0.1808,  0.6158]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3153,  0.3481,  1.3283,  0.8897,  1.3603, -0.1039,  1.7963, -2.7218,\n",
      "          0.3398, -0.8516],\n",
      "        [ 0.4523,  1.0414, -0.7155, -0.6100,  1.1049, -0.0550,  0.7497, -0.7880,\n",
      "         -0.5734, -1.3042],\n",
      "        [-0.5993, -1.5933, -0.8607, -0.6801, -0.6985,  0.4663,  0.1076,  0.6572,\n",
      "          0.4638,  0.6864],\n",
      "        [-1.9421, -1.4407,  2.4471, -1.3386,  1.4204,  0.1539, -0.6199, -0.6909,\n",
      "          0.1808,  0.6158]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3153,  0.3483,  1.3282,  0.8897,  1.3603, -0.1040,  1.7963, -2.7218,\n",
      "          0.3395, -0.8516],\n",
      "        [ 0.4525,  1.0416, -0.7156, -0.6100,  1.1049, -0.0552,  0.7497, -0.7880,\n",
      "         -0.5736, -1.3042],\n",
      "        [-0.5996, -1.5933, -0.8607, -0.6802, -0.6985,  0.4665,  0.1076,  0.6572,\n",
      "          0.4638,  0.6864],\n",
      "        [-1.9422, -1.4408,  2.4471, -1.3387,  1.4204,  0.1540, -0.6199, -0.6909,\n",
      "          0.1808,  0.6158]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3154,  0.3484,  1.3281,  0.8897,  1.3603, -0.1041,  1.7963, -2.7218,\n",
      "          0.3392, -0.8517],\n",
      "        [ 0.4527,  1.0417, -0.7157, -0.6100,  1.1049, -0.0553,  0.7497, -0.7880,\n",
      "         -0.5739, -1.3042],\n",
      "        [-0.5998, -1.5932, -0.8607, -0.6804, -0.6985,  0.4667,  0.1076,  0.6572,\n",
      "          0.4638,  0.6864],\n",
      "        [-1.9423, -1.4408,  2.4471, -1.3387,  1.4204,  0.1540, -0.6199, -0.6909,\n",
      "          0.1808,  0.6158]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3155,  0.3486,  1.3280,  0.8896,  1.3603, -0.1042,  1.7963, -2.7218,\n",
      "          0.3390, -0.8517],\n",
      "        [ 0.4529,  1.0418, -0.7158, -0.6099,  1.1049, -0.0555,  0.7497, -0.7880,\n",
      "         -0.5741, -1.3042],\n",
      "        [-0.6001, -1.5932, -0.8607, -0.6805, -0.6985,  0.4669,  0.1076,  0.6572,\n",
      "          0.4638,  0.6864],\n",
      "        [-1.9425, -1.4408,  2.4471, -1.3388,  1.4204,  0.1541, -0.6199, -0.6909,\n",
      "          0.1809,  0.6158]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3155,  0.3487,  1.3279,  0.8896,  1.3603, -0.1043,  1.7963, -2.7218,\n",
      "          0.3387, -0.8517],\n",
      "        [ 0.4531,  1.0419, -0.7159, -0.6099,  1.1049, -0.0557,  0.7497, -0.7880,\n",
      "         -0.5743, -1.3042],\n",
      "        [-0.6004, -1.5932, -0.8608, -0.6806, -0.6985,  0.4671,  0.1076,  0.6572,\n",
      "          0.4638,  0.6864],\n",
      "        [-1.9426, -1.4408,  2.4471, -1.3388,  1.4204,  0.1542, -0.6199, -0.6909,\n",
      "          0.1809,  0.6158]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3156,  0.3489,  1.3278,  0.8895,  1.3603, -0.1044,  1.7963, -2.7218,\n",
      "          0.3384, -0.8517],\n",
      "        [ 0.4533,  1.0421, -0.7160, -0.6099,  1.1049, -0.0559,  0.7497, -0.7880,\n",
      "         -0.5745, -1.3042],\n",
      "        [-0.6007, -1.5932, -0.8608, -0.6807, -0.6985,  0.4673,  0.1076,  0.6572,\n",
      "          0.4637,  0.6863],\n",
      "        [-1.9427, -1.4408,  2.4471, -1.3389,  1.4204,  0.1543, -0.6199, -0.6909,\n",
      "          0.1809,  0.6158]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3156,  0.3490,  1.3277,  0.8895,  1.3603, -0.1045,  1.7963, -2.7218,\n",
      "          0.3381, -0.8517],\n",
      "        [ 0.4535,  1.0422, -0.7160, -0.6099,  1.1049, -0.0560,  0.7497, -0.7880,\n",
      "         -0.5747, -1.3042],\n",
      "        [-0.6009, -1.5932, -0.8608, -0.6808, -0.6985,  0.4675,  0.1076,  0.6572,\n",
      "          0.4637,  0.6863],\n",
      "        [-1.9428, -1.4408,  2.4471, -1.3389,  1.4204,  0.1544, -0.6199, -0.6909,\n",
      "          0.1809,  0.6158]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3157,  0.3492,  1.3276,  0.8895,  1.3603, -0.1045,  1.7963, -2.7218,\n",
      "          0.3379, -0.8518],\n",
      "        [ 0.4537,  1.0423, -0.7161, -0.6098,  1.1049, -0.0562,  0.7497, -0.7880,\n",
      "         -0.5749, -1.3042],\n",
      "        [-0.6012, -1.5932, -0.8608, -0.6809, -0.6985,  0.4677,  0.1076,  0.6572,\n",
      "          0.4637,  0.6863],\n",
      "        [-1.9429, -1.4408,  2.4471, -1.3389,  1.4204,  0.1545, -0.6199, -0.6909,\n",
      "          0.1809,  0.6158]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3157,  0.3493,  1.3274,  0.8894,  1.3603, -0.1046,  1.7963, -2.7218,\n",
      "          0.3376, -0.8518],\n",
      "        [ 0.4539,  1.0424, -0.7162, -0.6098,  1.1049, -0.0564,  0.7497, -0.7880,\n",
      "         -0.5751, -1.3042],\n",
      "        [-0.6015, -1.5932, -0.8609, -0.6811, -0.6985,  0.4678,  0.1076,  0.6572,\n",
      "          0.4637,  0.6863],\n",
      "        [-1.9430, -1.4408,  2.4471, -1.3390,  1.4204,  0.1546, -0.6199, -0.6909,\n",
      "          0.1809,  0.6158]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3158,  0.3495,  1.3273,  0.8894,  1.3603, -0.1047,  1.7963, -2.7218,\n",
      "          0.3373, -0.8518],\n",
      "        [ 0.4540,  1.0426, -0.7163, -0.6098,  1.1049, -0.0565,  0.7497, -0.7880,\n",
      "         -0.5754, -1.3042],\n",
      "        [-0.6018, -1.5932, -0.8609, -0.6812, -0.6985,  0.4680,  0.1076,  0.6572,\n",
      "          0.4637,  0.6863],\n",
      "        [-1.9432, -1.4408,  2.4471, -1.3390,  1.4204,  0.1547, -0.6199, -0.6909,\n",
      "          0.1809,  0.6158]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3159,  0.3496,  1.3272,  0.8893,  1.3603, -0.1048,  1.7963, -2.7218,\n",
      "          0.3371, -0.8518],\n",
      "        [ 0.4542,  1.0427, -0.7164, -0.6097,  1.1049, -0.0567,  0.7497, -0.7880,\n",
      "         -0.5756, -1.3042],\n",
      "        [-0.6021, -1.5932, -0.8609, -0.6813, -0.6985,  0.4682,  0.1076,  0.6572,\n",
      "          0.4637,  0.6863],\n",
      "        [-1.9433, -1.4408,  2.4471, -1.3391,  1.4204,  0.1548, -0.6199, -0.6909,\n",
      "          0.1809,  0.6158]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3159,  0.3498,  1.3271,  0.8893,  1.3603, -0.1049,  1.7963, -2.7218,\n",
      "          0.3368, -0.8518],\n",
      "        [ 0.4544,  1.0428, -0.7164, -0.6097,  1.1049, -0.0569,  0.7497, -0.7880,\n",
      "         -0.5758, -1.3042],\n",
      "        [-0.6023, -1.5932, -0.8609, -0.6814, -0.6985,  0.4684,  0.1076,  0.6572,\n",
      "          0.4636,  0.6863],\n",
      "        [-1.9434, -1.4408,  2.4471, -1.3391,  1.4204,  0.1549, -0.6199, -0.6909,\n",
      "          0.1810,  0.6158]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3160,  0.3500,  1.3270,  0.8893,  1.3603, -0.1050,  1.7963, -2.7218,\n",
      "          0.3365, -0.8518],\n",
      "        [ 0.4546,  1.0429, -0.7165, -0.6097,  1.1049, -0.0570,  0.7497, -0.7880,\n",
      "         -0.5760, -1.3042],\n",
      "        [-0.6026, -1.5932, -0.8609, -0.6815, -0.6985,  0.4686,  0.1076,  0.6572,\n",
      "          0.4636,  0.6862],\n",
      "        [-1.9435, -1.4409,  2.4471, -1.3392,  1.4204,  0.1550, -0.6199, -0.6909,\n",
      "          0.1810,  0.6158]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3160,  0.3501,  1.3269,  0.8892,  1.3603, -0.1051,  1.7963, -2.7218,\n",
      "          0.3363, -0.8519],\n",
      "        [ 0.4548,  1.0431, -0.7166, -0.6096,  1.1049, -0.0572,  0.7497, -0.7880,\n",
      "         -0.5762, -1.3043],\n",
      "        [-0.6029, -1.5932, -0.8610, -0.6817, -0.6985,  0.4688,  0.1076,  0.6572,\n",
      "          0.4636,  0.6862],\n",
      "        [-1.9436, -1.4409,  2.4471, -1.3392,  1.4204,  0.1551, -0.6199, -0.6909,\n",
      "          0.1810,  0.6158]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3161,  0.3503,  1.3268,  0.8892,  1.3603, -0.1052,  1.7963, -2.7218,\n",
      "          0.3360, -0.8519],\n",
      "        [ 0.4550,  1.0432, -0.7167, -0.6096,  1.1049, -0.0574,  0.7497, -0.7880,\n",
      "         -0.5764, -1.3043],\n",
      "        [-0.6032, -1.5932, -0.8610, -0.6818, -0.6985,  0.4690,  0.1076,  0.6572,\n",
      "          0.4636,  0.6862],\n",
      "        [-1.9437, -1.4409,  2.4471, -1.3393,  1.4204,  0.1552, -0.6199, -0.6909,\n",
      "          0.1810,  0.6158]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3161,  0.3504,  1.3267,  0.8892,  1.3603, -0.1052,  1.7963, -2.7218,\n",
      "          0.3357, -0.8519],\n",
      "        [ 0.4552,  1.0433, -0.7168, -0.6096,  1.1049, -0.0575,  0.7497, -0.7880,\n",
      "         -0.5766, -1.3043],\n",
      "        [-0.6034, -1.5932, -0.8610, -0.6819, -0.6985,  0.4692,  0.1076,  0.6572,\n",
      "          0.4636,  0.6862],\n",
      "        [-1.9439, -1.4409,  2.4471, -1.3393,  1.4204,  0.1552, -0.6199, -0.6909,\n",
      "          0.1810,  0.6158]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3162,  0.3506,  1.3266,  0.8891,  1.3603, -0.1053,  1.7963, -2.7218,\n",
      "          0.3354, -0.8519],\n",
      "        [ 0.4554,  1.0434, -0.7169, -0.6096,  1.1049, -0.0577,  0.7497, -0.7880,\n",
      "         -0.5768, -1.3043],\n",
      "        [-0.6037, -1.5932, -0.8610, -0.6820, -0.6985,  0.4694,  0.1076,  0.6572,\n",
      "          0.4636,  0.6862],\n",
      "        [-1.9440, -1.4409,  2.4471, -1.3394,  1.4204,  0.1553, -0.6199, -0.6909,\n",
      "          0.1810,  0.6158]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3163,  0.3507,  1.3264,  0.8891,  1.3603, -0.1054,  1.7963, -2.7218,\n",
      "          0.3352, -0.8519],\n",
      "        [ 0.4556,  1.0435, -0.7169, -0.6095,  1.1049, -0.0579,  0.7497, -0.7880,\n",
      "         -0.5771, -1.3043],\n",
      "        [-0.6040, -1.5932, -0.8611, -0.6821, -0.6985,  0.4696,  0.1076,  0.6572,\n",
      "          0.4635,  0.6862],\n",
      "        [-1.9441, -1.4409,  2.4471, -1.3394,  1.4204,  0.1554, -0.6199, -0.6909,\n",
      "          0.1810,  0.6158]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3163,  0.3509,  1.3263,  0.8891,  1.3603, -0.1055,  1.7963, -2.7218,\n",
      "          0.3349, -0.8520],\n",
      "        [ 0.4557,  1.0437, -0.7170, -0.6095,  1.1049, -0.0580,  0.7497, -0.7880,\n",
      "         -0.5773, -1.3043],\n",
      "        [-0.6043, -1.5932, -0.8611, -0.6822, -0.6985,  0.4698,  0.1076,  0.6572,\n",
      "          0.4635,  0.6862],\n",
      "        [-1.9442, -1.4409,  2.4471, -1.3395,  1.4204,  0.1555, -0.6199, -0.6909,\n",
      "          0.1811,  0.6157]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3164,  0.3510,  1.3262,  0.8890,  1.3603, -0.1056,  1.7963, -2.7218,\n",
      "          0.3346, -0.8520],\n",
      "        [ 0.4559,  1.0438, -0.7171, -0.6095,  1.1049, -0.0582,  0.7497, -0.7880,\n",
      "         -0.5775, -1.3043],\n",
      "        [-0.6045, -1.5932, -0.8611, -0.6824, -0.6985,  0.4700,  0.1076,  0.6572,\n",
      "          0.4635,  0.6861],\n",
      "        [-1.9443, -1.4409,  2.4471, -1.3395,  1.4204,  0.1556, -0.6199, -0.6909,\n",
      "          0.1811,  0.6157]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3164,  0.3511,  1.3261,  0.8890,  1.3603, -0.1057,  1.7963, -2.7218,\n",
      "          0.3344, -0.8520],\n",
      "        [ 0.4561,  1.0439, -0.7172, -0.6094,  1.1049, -0.0584,  0.7497, -0.7880,\n",
      "         -0.5777, -1.3043],\n",
      "        [-0.6048, -1.5932, -0.8611, -0.6825, -0.6985,  0.4702,  0.1076,  0.6572,\n",
      "          0.4635,  0.6861],\n",
      "        [-1.9444, -1.4409,  2.4471, -1.3395,  1.4204,  0.1557, -0.6199, -0.6909,\n",
      "          0.1811,  0.6157]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3165,  0.3513,  1.3260,  0.8889,  1.3603, -0.1058,  1.7963, -2.7218,\n",
      "          0.3341, -0.8520],\n",
      "        [ 0.4563,  1.0440, -0.7173, -0.6094,  1.1049, -0.0585,  0.7497, -0.7880,\n",
      "         -0.5779, -1.3043],\n",
      "        [-0.6051, -1.5932, -0.8611, -0.6826, -0.6985,  0.4704,  0.1076,  0.6572,\n",
      "          0.4635,  0.6861],\n",
      "        [-1.9446, -1.4409,  2.4471, -1.3396,  1.4204,  0.1558, -0.6199, -0.6909,\n",
      "          0.1811,  0.6157]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3165,  0.3514,  1.3259,  0.8889,  1.3603, -0.1059,  1.7963, -2.7218,\n",
      "          0.3338, -0.8520],\n",
      "        [ 0.4565,  1.0441, -0.7173, -0.6094,  1.1049, -0.0587,  0.7497, -0.7880,\n",
      "         -0.5781, -1.3043],\n",
      "        [-0.6053, -1.5932, -0.8612, -0.6827, -0.6985,  0.4706,  0.1076,  0.6572,\n",
      "          0.4635,  0.6861],\n",
      "        [-1.9447, -1.4409,  2.4471, -1.3396,  1.4204,  0.1559, -0.6199, -0.6909,\n",
      "          0.1811,  0.6157]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3166,  0.3516,  1.3258,  0.8889,  1.3603, -0.1059,  1.7963, -2.7218,\n",
      "          0.3336, -0.8520],\n",
      "        [ 0.4567,  1.0443, -0.7174, -0.6093,  1.1049, -0.0589,  0.7497, -0.7880,\n",
      "         -0.5783, -1.3043],\n",
      "        [-0.6056, -1.5932, -0.8612, -0.6828, -0.6985,  0.4708,  0.1076,  0.6572,\n",
      "          0.4634,  0.6861],\n",
      "        [-1.9448, -1.4410,  2.4471, -1.3397,  1.4204,  0.1560, -0.6199, -0.6909,\n",
      "          0.1811,  0.6157]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3166,  0.3517,  1.3257,  0.8888,  1.3603, -0.1060,  1.7963, -2.7218,\n",
      "          0.3333, -0.8521],\n",
      "        [ 0.4569,  1.0444, -0.7175, -0.6093,  1.1049, -0.0590,  0.7497, -0.7880,\n",
      "         -0.5785, -1.3043],\n",
      "        [-0.6059, -1.5932, -0.8612, -0.6829, -0.6985,  0.4710,  0.1076,  0.6572,\n",
      "          0.4634,  0.6861],\n",
      "        [-1.9449, -1.4410,  2.4471, -1.3397,  1.4204,  0.1561, -0.6199, -0.6909,\n",
      "          0.1811,  0.6157]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3167,  0.3519,  1.3255,  0.8888,  1.3603, -0.1061,  1.7963, -2.7218,\n",
      "          0.3330, -0.8521],\n",
      "        [ 0.4570,  1.0445, -0.7176, -0.6093,  1.1049, -0.0592,  0.7497, -0.7880,\n",
      "         -0.5788, -1.3044],\n",
      "        [-0.6062, -1.5932, -0.8612, -0.6831, -0.6985,  0.4712,  0.1076,  0.6572,\n",
      "          0.4634,  0.6860],\n",
      "        [-1.9450, -1.4410,  2.4471, -1.3398,  1.4204,  0.1562, -0.6199, -0.6909,\n",
      "          0.1812,  0.6157]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3168,  0.3520,  1.3254,  0.8888,  1.3603, -0.1062,  1.7963, -2.7218,\n",
      "          0.3328, -0.8521],\n",
      "        [ 0.4572,  1.0446, -0.7177, -0.6092,  1.1049, -0.0594,  0.7497, -0.7880,\n",
      "         -0.5790, -1.3044],\n",
      "        [-0.6064, -1.5931, -0.8613, -0.6832, -0.6985,  0.4714,  0.1076,  0.6572,\n",
      "          0.4634,  0.6860],\n",
      "        [-1.9451, -1.4410,  2.4471, -1.3398,  1.4204,  0.1563, -0.6199, -0.6909,\n",
      "          0.1812,  0.6157]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3168,  0.3522,  1.3253,  0.8887,  1.3603, -0.1063,  1.7963, -2.7218,\n",
      "          0.3325, -0.8521],\n",
      "        [ 0.4574,  1.0447, -0.7178, -0.6092,  1.1049, -0.0595,  0.7497, -0.7880,\n",
      "         -0.5792, -1.3044],\n",
      "        [-0.6067, -1.5931, -0.8613, -0.6833, -0.6985,  0.4716,  0.1076,  0.6572,\n",
      "          0.4634,  0.6860],\n",
      "        [-1.9452, -1.4410,  2.4471, -1.3399,  1.4204,  0.1563, -0.6199, -0.6909,\n",
      "          0.1812,  0.6157]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3169,  0.3523,  1.3252,  0.8887,  1.3603, -0.1064,  1.7963, -2.7218,\n",
      "          0.3322, -0.8521],\n",
      "        [ 0.4576,  1.0449, -0.7178, -0.6092,  1.1049, -0.0597,  0.7497, -0.7880,\n",
      "         -0.5794, -1.3044],\n",
      "        [-0.6070, -1.5931, -0.8613, -0.6834, -0.6985,  0.4718,  0.1076,  0.6572,\n",
      "          0.4634,  0.6860],\n",
      "        [-1.9454, -1.4410,  2.4471, -1.3399,  1.4204,  0.1564, -0.6199, -0.6909,\n",
      "          0.1812,  0.6157]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3169,  0.3525,  1.3251,  0.8887,  1.3603, -0.1065,  1.7963, -2.7218,\n",
      "          0.3320, -0.8522],\n",
      "        [ 0.4578,  1.0450, -0.7179, -0.6092,  1.1049, -0.0599,  0.7497, -0.7880,\n",
      "         -0.5796, -1.3044],\n",
      "        [-0.6073, -1.5931, -0.8613, -0.6835, -0.6985,  0.4720,  0.1076,  0.6572,\n",
      "          0.4634,  0.6860],\n",
      "        [-1.9455, -1.4410,  2.4471, -1.3400,  1.4204,  0.1565, -0.6199, -0.6909,\n",
      "          0.1812,  0.6157]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3170,  0.3526,  1.3250,  0.8886,  1.3603, -0.1066,  1.7963, -2.7218,\n",
      "          0.3317, -0.8522],\n",
      "        [ 0.4580,  1.0451, -0.7180, -0.6091,  1.1049, -0.0600,  0.7497, -0.7880,\n",
      "         -0.5798, -1.3044],\n",
      "        [-0.6075, -1.5931, -0.8613, -0.6836, -0.6985,  0.4722,  0.1076,  0.6572,\n",
      "          0.4633,  0.6860],\n",
      "        [-1.9456, -1.4410,  2.4471, -1.3400,  1.4204,  0.1566, -0.6199, -0.6909,\n",
      "          0.1812,  0.6157]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3170,  0.3527,  1.3249,  0.8886,  1.3603, -0.1066,  1.7963, -2.7218,\n",
      "          0.3314, -0.8522],\n",
      "        [ 0.4582,  1.0452, -0.7181, -0.6091,  1.1049, -0.0602,  0.7497, -0.7880,\n",
      "         -0.5800, -1.3044],\n",
      "        [-0.6078, -1.5931, -0.8614, -0.6838, -0.6985,  0.4724,  0.1076,  0.6572,\n",
      "          0.4633,  0.6860],\n",
      "        [-1.9457, -1.4410,  2.4471, -1.3401,  1.4204,  0.1567, -0.6199, -0.6909,\n",
      "          0.1812,  0.6157]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3171,  0.3529,  1.3248,  0.8885,  1.3603, -0.1067,  1.7963, -2.7218,\n",
      "          0.3312, -0.8522],\n",
      "        [ 0.4583,  1.0453, -0.7182, -0.6091,  1.1049, -0.0604,  0.7497, -0.7880,\n",
      "         -0.5802, -1.3044],\n",
      "        [-0.6081, -1.5931, -0.8614, -0.6839, -0.6985,  0.4726,  0.1076,  0.6572,\n",
      "          0.4633,  0.6859],\n",
      "        [-1.9458, -1.4410,  2.4471, -1.3401,  1.4204,  0.1568, -0.6199, -0.6909,\n",
      "          0.1813,  0.6157]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3171,  0.3530,  1.3247,  0.8885,  1.3603, -0.1068,  1.7963, -2.7218,\n",
      "          0.3309, -0.8522],\n",
      "        [ 0.4585,  1.0454, -0.7183, -0.6090,  1.1049, -0.0605,  0.7497, -0.7880,\n",
      "         -0.5804, -1.3044],\n",
      "        [-0.6083, -1.5931, -0.8614, -0.6840, -0.6985,  0.4728,  0.1076,  0.6572,\n",
      "          0.4633,  0.6859],\n",
      "        [-1.9459, -1.4411,  2.4471, -1.3401,  1.4204,  0.1569, -0.6199, -0.6909,\n",
      "          0.1813,  0.6157]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3172,  0.3532,  1.3245,  0.8885,  1.3603, -0.1069,  1.7963, -2.7218,\n",
      "          0.3307, -0.8522],\n",
      "        [ 0.4587,  1.0456, -0.7183, -0.6090,  1.1049, -0.0607,  0.7497, -0.7880,\n",
      "         -0.5807, -1.3044],\n",
      "        [-0.6086, -1.5931, -0.8614, -0.6841, -0.6985,  0.4730,  0.1076,  0.6572,\n",
      "          0.4633,  0.6859],\n",
      "        [-1.9460, -1.4411,  2.4471, -1.3402,  1.4204,  0.1570, -0.6199, -0.6909,\n",
      "          0.1813,  0.6157]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3172,  0.3533,  1.3244,  0.8884,  1.3603, -0.1070,  1.7963, -2.7218,\n",
      "          0.3304, -0.8523],\n",
      "        [ 0.4589,  1.0457, -0.7184, -0.6090,  1.1049, -0.0609,  0.7497, -0.7880,\n",
      "         -0.5809, -1.3044],\n",
      "        [-0.6089, -1.5931, -0.8615, -0.6842, -0.6985,  0.4731,  0.1076,  0.6572,\n",
      "          0.4633,  0.6859],\n",
      "        [-1.9462, -1.4411,  2.4471, -1.3402,  1.4204,  0.1571, -0.6199, -0.6909,\n",
      "          0.1813,  0.6157]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3173,  0.3535,  1.3243,  0.8884,  1.3603, -0.1071,  1.7963, -2.7218,\n",
      "          0.3301, -0.8523],\n",
      "        [ 0.4591,  1.0458, -0.7185, -0.6089,  1.1049, -0.0610,  0.7497, -0.7880,\n",
      "         -0.5811, -1.3044],\n",
      "        [-0.6091, -1.5931, -0.8615, -0.6843, -0.6985,  0.4733,  0.1076,  0.6572,\n",
      "          0.4633,  0.6859],\n",
      "        [-1.9463, -1.4411,  2.4471, -1.3403,  1.4204,  0.1572, -0.6199, -0.6909,\n",
      "          0.1813,  0.6157]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3174,  0.3536,  1.3242,  0.8884,  1.3603, -0.1072,  1.7963, -2.7218,\n",
      "          0.3299, -0.8523],\n",
      "        [ 0.4593,  1.0459, -0.7186, -0.6089,  1.1049, -0.0612,  0.7497, -0.7880,\n",
      "         -0.5813, -1.3045],\n",
      "        [-0.6094, -1.5931, -0.8615, -0.6844, -0.6985,  0.4735,  0.1076,  0.6572,\n",
      "          0.4632,  0.6859],\n",
      "        [-1.9464, -1.4411,  2.4471, -1.3403,  1.4204,  0.1573, -0.6199, -0.6909,\n",
      "          0.1813,  0.6157]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3174,  0.3537,  1.3241,  0.8883,  1.3603, -0.1073,  1.7963, -2.7218,\n",
      "          0.3296, -0.8523],\n",
      "        [ 0.4594,  1.0460, -0.7187, -0.6089,  1.1049, -0.0613,  0.7497, -0.7880,\n",
      "         -0.5815, -1.3045],\n",
      "        [-0.6097, -1.5931, -0.8615, -0.6846, -0.6985,  0.4737,  0.1076,  0.6572,\n",
      "          0.4632,  0.6859],\n",
      "        [-1.9465, -1.4411,  2.4471, -1.3404,  1.4204,  0.1573, -0.6199, -0.6909,\n",
      "          0.1813,  0.6156]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3175,  0.3539,  1.3240,  0.8883,  1.3603, -0.1073,  1.7963, -2.7218,\n",
      "          0.3293, -0.8523],\n",
      "        [ 0.4596,  1.0461, -0.7187, -0.6088,  1.1049, -0.0615,  0.7497, -0.7880,\n",
      "         -0.5817, -1.3045],\n",
      "        [-0.6100, -1.5931, -0.8615, -0.6847, -0.6985,  0.4739,  0.1076,  0.6572,\n",
      "          0.4632,  0.6858],\n",
      "        [-1.9466, -1.4411,  2.4471, -1.3404,  1.4204,  0.1574, -0.6199, -0.6909,\n",
      "          0.1814,  0.6156]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3175,  0.3540,  1.3239,  0.8883,  1.3603, -0.1074,  1.7963, -2.7218,\n",
      "          0.3291, -0.8524],\n",
      "        [ 0.4598,  1.0463, -0.7188, -0.6088,  1.1049, -0.0617,  0.7497, -0.7880,\n",
      "         -0.5819, -1.3045],\n",
      "        [-0.6102, -1.5931, -0.8616, -0.6848, -0.6985,  0.4741,  0.1076,  0.6572,\n",
      "          0.4632,  0.6858],\n",
      "        [-1.9467, -1.4411,  2.4471, -1.3405,  1.4204,  0.1575, -0.6199, -0.6909,\n",
      "          0.1814,  0.6156]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3176,  0.3542,  1.3238,  0.8882,  1.3603, -0.1075,  1.7963, -2.7218,\n",
      "          0.3288, -0.8524],\n",
      "        [ 0.4600,  1.0464, -0.7189, -0.6088,  1.1049, -0.0618,  0.7497, -0.7880,\n",
      "         -0.5821, -1.3045],\n",
      "        [-0.6105, -1.5931, -0.8616, -0.6849, -0.6985,  0.4743,  0.1076,  0.6572,\n",
      "          0.4632,  0.6858],\n",
      "        [-1.9468, -1.4411,  2.4471, -1.3405,  1.4204,  0.1576, -0.6199, -0.6909,\n",
      "          0.1814,  0.6156]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3176,  0.3543,  1.3237,  0.8882,  1.3603, -0.1076,  1.7963, -2.7218,\n",
      "          0.3285, -0.8524],\n",
      "        [ 0.4602,  1.0465, -0.7190, -0.6087,  1.1049, -0.0620,  0.7497, -0.7880,\n",
      "         -0.5823, -1.3045],\n",
      "        [-0.6108, -1.5931, -0.8616, -0.6850, -0.6985,  0.4745,  0.1076,  0.6572,\n",
      "          0.4632,  0.6858],\n",
      "        [-1.9470, -1.4411,  2.4471, -1.3406,  1.4204,  0.1577, -0.6199, -0.6909,\n",
      "          0.1814,  0.6156]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3177,  0.3544,  1.3235,  0.8882,  1.3603, -0.1077,  1.7963, -2.7218,\n",
      "          0.3283, -0.8524],\n",
      "        [ 0.4604,  1.0466, -0.7191, -0.6087,  1.1049, -0.0622,  0.7497, -0.7880,\n",
      "         -0.5826, -1.3045],\n",
      "        [-0.6110, -1.5931, -0.8616, -0.6851, -0.6985,  0.4747,  0.1076,  0.6572,\n",
      "          0.4632,  0.6858],\n",
      "        [-1.9471, -1.4412,  2.4471, -1.3406,  1.4204,  0.1578, -0.6199, -0.6909,\n",
      "          0.1814,  0.6156]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3177,  0.3546,  1.3234,  0.8881,  1.3603, -0.1078,  1.7963, -2.7218,\n",
      "          0.3280, -0.8524],\n",
      "        [ 0.4605,  1.0467, -0.7192, -0.6087,  1.1049, -0.0623,  0.7497, -0.7880,\n",
      "         -0.5828, -1.3045],\n",
      "        [-0.6113, -1.5931, -0.8616, -0.6853, -0.6985,  0.4749,  0.1076,  0.6572,\n",
      "          0.4632,  0.6858],\n",
      "        [-1.9472, -1.4412,  2.4471, -1.3406,  1.4204,  0.1579, -0.6199, -0.6909,\n",
      "          0.1814,  0.6156]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3178,  0.3547,  1.3233,  0.8881,  1.3603, -0.1079,  1.7963, -2.7218,\n",
      "          0.3278, -0.8524],\n",
      "        [ 0.4607,  1.0468, -0.7192, -0.6086,  1.1049, -0.0625,  0.7497, -0.7880,\n",
      "         -0.5830, -1.3045],\n",
      "        [-0.6116, -1.5931, -0.8617, -0.6854, -0.6985,  0.4751,  0.1076,  0.6572,\n",
      "          0.4631,  0.6858],\n",
      "        [-1.9473, -1.4412,  2.4471, -1.3407,  1.4204,  0.1580, -0.6199, -0.6909,\n",
      "          0.1814,  0.6156]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3178,  0.3548,  1.3232,  0.8881,  1.3603, -0.1079,  1.7963, -2.7218,\n",
      "          0.3275, -0.8525],\n",
      "        [ 0.4609,  1.0469, -0.7193, -0.6086,  1.1049, -0.0627,  0.7497, -0.7880,\n",
      "         -0.5832, -1.3045],\n",
      "        [-0.6118, -1.5931, -0.8617, -0.6855, -0.6985,  0.4753,  0.1076,  0.6572,\n",
      "          0.4631,  0.6857],\n",
      "        [-1.9474, -1.4412,  2.4471, -1.3407,  1.4204,  0.1581, -0.6199, -0.6909,\n",
      "          0.1815,  0.6156]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3179,  0.3550,  1.3231,  0.8880,  1.3603, -0.1080,  1.7963, -2.7218,\n",
      "          0.3272, -0.8525],\n",
      "        [ 0.4611,  1.0471, -0.7194, -0.6086,  1.1049, -0.0628,  0.7497, -0.7880,\n",
      "         -0.5834, -1.3045],\n",
      "        [-0.6121, -1.5931, -0.8617, -0.6856, -0.6985,  0.4755,  0.1076,  0.6572,\n",
      "          0.4631,  0.6857],\n",
      "        [-1.9475, -1.4412,  2.4471, -1.3408,  1.4204,  0.1582, -0.6199, -0.6909,\n",
      "          0.1815,  0.6156]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3179,  0.3551,  1.3230,  0.8880,  1.3603, -0.1081,  1.7963, -2.7218,\n",
      "          0.3270, -0.8525],\n",
      "        [ 0.4613,  1.0472, -0.7195, -0.6085,  1.1049, -0.0630,  0.7497, -0.7880,\n",
      "         -0.5836, -1.3045],\n",
      "        [-0.6124, -1.5931, -0.8617, -0.6857, -0.6985,  0.4757,  0.1076,  0.6572,\n",
      "          0.4631,  0.6857],\n",
      "        [-1.9476, -1.4412,  2.4471, -1.3408,  1.4204,  0.1582, -0.6199, -0.6909,\n",
      "          0.1815,  0.6156]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3180,  0.3552,  1.3229,  0.8880,  1.3603, -0.1082,  1.7963, -2.7218,\n",
      "          0.3267, -0.8525],\n",
      "        [ 0.4615,  1.0473, -0.7196, -0.6085,  1.1049, -0.0632,  0.7497, -0.7880,\n",
      "         -0.5838, -1.3045],\n",
      "        [-0.6126, -1.5931, -0.8618, -0.6858, -0.6985,  0.4759,  0.1076,  0.6572,\n",
      "          0.4631,  0.6857],\n",
      "        [-1.9477, -1.4412,  2.4471, -1.3409,  1.4204,  0.1583, -0.6199, -0.6909,\n",
      "          0.1815,  0.6156]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3181,  0.3554,  1.3228,  0.8879,  1.3603, -0.1083,  1.7963, -2.7218,\n",
      "          0.3264, -0.8525],\n",
      "        [ 0.4616,  1.0474, -0.7196, -0.6085,  1.1049, -0.0633,  0.7497, -0.7880,\n",
      "         -0.5840, -1.3046],\n",
      "        [-0.6129, -1.5931, -0.8618, -0.6859, -0.6985,  0.4761,  0.1076,  0.6572,\n",
      "          0.4631,  0.6857],\n",
      "        [-1.9479, -1.4412,  2.4471, -1.3409,  1.4204,  0.1584, -0.6199, -0.6909,\n",
      "          0.1815,  0.6156]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3181,  0.3555,  1.3226,  0.8879,  1.3603, -0.1084,  1.7963, -2.7218,\n",
      "          0.3262, -0.8525],\n",
      "        [ 0.4618,  1.0475, -0.7197, -0.6085,  1.1049, -0.0635,  0.7497, -0.7880,\n",
      "         -0.5842, -1.3046],\n",
      "        [-0.6132, -1.5931, -0.8618, -0.6861, -0.6985,  0.4763,  0.1076,  0.6572,\n",
      "          0.4631,  0.6857],\n",
      "        [-1.9480, -1.4412,  2.4471, -1.3410,  1.4204,  0.1585, -0.6199, -0.6909,\n",
      "          0.1815,  0.6156]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3182,  0.3557,  1.3225,  0.8879,  1.3603, -0.1085,  1.7963, -2.7218,\n",
      "          0.3259, -0.8526],\n",
      "        [ 0.4620,  1.0476, -0.7198, -0.6084,  1.1049, -0.0637,  0.7497, -0.7880,\n",
      "         -0.5844, -1.3046],\n",
      "        [-0.6134, -1.5931, -0.8618, -0.6862, -0.6985,  0.4764,  0.1076,  0.6572,\n",
      "          0.4631,  0.6857],\n",
      "        [-1.9481, -1.4413,  2.4471, -1.3410,  1.4204,  0.1586, -0.6199, -0.6909,\n",
      "          0.1816,  0.6156]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3182,  0.3558,  1.3224,  0.8878,  1.3603, -0.1086,  1.7963, -2.7218,\n",
      "          0.3257, -0.8526],\n",
      "        [ 0.4622,  1.0477, -0.7199, -0.6084,  1.1049, -0.0638,  0.7497, -0.7880,\n",
      "         -0.5847, -1.3046],\n",
      "        [-0.6137, -1.5931, -0.8618, -0.6863, -0.6985,  0.4766,  0.1076,  0.6572,\n",
      "          0.4631,  0.6856],\n",
      "        [-1.9482, -1.4413,  2.4471, -1.3410,  1.4204,  0.1587, -0.6199, -0.6909,\n",
      "          0.1816,  0.6156]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3183,  0.3559,  1.3223,  0.8878,  1.3603, -0.1086,  1.7963, -2.7218,\n",
      "          0.3254, -0.8526],\n",
      "        [ 0.4624,  1.0478, -0.7200, -0.6084,  1.1049, -0.0640,  0.7497, -0.7880,\n",
      "         -0.5849, -1.3046],\n",
      "        [-0.6140, -1.5931, -0.8619, -0.6864, -0.6985,  0.4768,  0.1076,  0.6572,\n",
      "          0.4631,  0.6856],\n",
      "        [-1.9483, -1.4413,  2.4471, -1.3411,  1.4204,  0.1588, -0.6199, -0.6909,\n",
      "          0.1816,  0.6156]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3183,  0.3561,  1.3222,  0.8878,  1.3603, -0.1087,  1.7963, -2.7218,\n",
      "          0.3251, -0.8526],\n",
      "        [ 0.4625,  1.0479, -0.7201, -0.6083,  1.1049, -0.0641,  0.7497, -0.7880,\n",
      "         -0.5851, -1.3046],\n",
      "        [-0.6142, -1.5932, -0.8619, -0.6865, -0.6985,  0.4770,  0.1076,  0.6572,\n",
      "          0.4630,  0.6856],\n",
      "        [-1.9484, -1.4413,  2.4471, -1.3411,  1.4204,  0.1589, -0.6199, -0.6909,\n",
      "          0.1816,  0.6156]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3184,  0.3562,  1.3221,  0.8877,  1.3603, -0.1088,  1.7963, -2.7218,\n",
      "          0.3249, -0.8526],\n",
      "        [ 0.4627,  1.0481, -0.7201, -0.6083,  1.1049, -0.0643,  0.7497, -0.7880,\n",
      "         -0.5853, -1.3046],\n",
      "        [-0.6145, -1.5932, -0.8619, -0.6866, -0.6985,  0.4772,  0.1076,  0.6572,\n",
      "          0.4630,  0.6856],\n",
      "        [-1.9485, -1.4413,  2.4471, -1.3412,  1.4204,  0.1590, -0.6199, -0.6909,\n",
      "          0.1816,  0.6156]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3184,  0.3563,  1.3220,  0.8877,  1.3603, -0.1089,  1.7963, -2.7218,\n",
      "          0.3246, -0.8527],\n",
      "        [ 0.4629,  1.0482, -0.7202, -0.6083,  1.1049, -0.0645,  0.7497, -0.7880,\n",
      "         -0.5855, -1.3046],\n",
      "        [-0.6148, -1.5932, -0.8619, -0.6867, -0.6985,  0.4774,  0.1076,  0.6572,\n",
      "          0.4630,  0.6856],\n",
      "        [-1.9486, -1.4413,  2.4471, -1.3412,  1.4204,  0.1591, -0.6199, -0.6909,\n",
      "          0.1816,  0.6156]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3185,  0.3565,  1.3219,  0.8877,  1.3603, -0.1090,  1.7963, -2.7218,\n",
      "          0.3244, -0.8527],\n",
      "        [ 0.4631,  1.0483, -0.7203, -0.6082,  1.1049, -0.0646,  0.7497, -0.7880,\n",
      "         -0.5857, -1.3046],\n",
      "        [-0.6150, -1.5932, -0.8620, -0.6869, -0.6985,  0.4776,  0.1076,  0.6572,\n",
      "          0.4630,  0.6856],\n",
      "        [-1.9487, -1.4413,  2.4471, -1.3413,  1.4204,  0.1592, -0.6199, -0.6909,\n",
      "          0.1816,  0.6155]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3185,  0.3566,  1.3218,  0.8876,  1.3603, -0.1091,  1.7963, -2.7218,\n",
      "          0.3241, -0.8527],\n",
      "        [ 0.4633,  1.0484, -0.7204, -0.6082,  1.1049, -0.0648,  0.7497, -0.7880,\n",
      "         -0.5859, -1.3046],\n",
      "        [-0.6153, -1.5932, -0.8620, -0.6870, -0.6985,  0.4778,  0.1076,  0.6572,\n",
      "          0.4630,  0.6856],\n",
      "        [-1.9489, -1.4413,  2.4471, -1.3413,  1.4204,  0.1592, -0.6199, -0.6909,\n",
      "          0.1817,  0.6155]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3186,  0.3567,  1.3216,  0.8876,  1.3603, -0.1092,  1.7963, -2.7218,\n",
      "          0.3239, -0.8527],\n",
      "        [ 0.4634,  1.0485, -0.7205, -0.6082,  1.1049, -0.0650,  0.7497, -0.7880,\n",
      "         -0.5861, -1.3046],\n",
      "        [-0.6155, -1.5932, -0.8620, -0.6871, -0.6985,  0.4780,  0.1076,  0.6572,\n",
      "          0.4630,  0.6855],\n",
      "        [-1.9490, -1.4413,  2.4471, -1.3414,  1.4204,  0.1593, -0.6199, -0.6909,\n",
      "          0.1817,  0.6155]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3186,  0.3568,  1.3215,  0.8876,  1.3603, -0.1092,  1.7963, -2.7218,\n",
      "          0.3236, -0.8527],\n",
      "        [ 0.4636,  1.0486, -0.7206, -0.6081,  1.1049, -0.0651,  0.7497, -0.7880,\n",
      "         -0.5863, -1.3046],\n",
      "        [-0.6158, -1.5932, -0.8620, -0.6872, -0.6985,  0.4782,  0.1076,  0.6572,\n",
      "          0.4630,  0.6855],\n",
      "        [-1.9491, -1.4414,  2.4471, -1.3414,  1.4204,  0.1594, -0.6199, -0.6909,\n",
      "          0.1817,  0.6155]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3187,  0.3570,  1.3214,  0.8875,  1.3603, -0.1093,  1.7963, -2.7218,\n",
      "          0.3233, -0.8527],\n",
      "        [ 0.4638,  1.0487, -0.7206, -0.6081,  1.1049, -0.0653,  0.7497, -0.7880,\n",
      "         -0.5865, -1.3046],\n",
      "        [-0.6161, -1.5932, -0.8620, -0.6873, -0.6985,  0.4784,  0.1076,  0.6572,\n",
      "          0.4630,  0.6855],\n",
      "        [-1.9492, -1.4414,  2.4471, -1.3414,  1.4204,  0.1595, -0.6199, -0.6909,\n",
      "          0.1817,  0.6155]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3187,  0.3571,  1.3213,  0.8875,  1.3603, -0.1094,  1.7963, -2.7218,\n",
      "          0.3231, -0.8528],\n",
      "        [ 0.4640,  1.0488, -0.7207, -0.6081,  1.1049, -0.0655,  0.7497, -0.7880,\n",
      "         -0.5867, -1.3047],\n",
      "        [-0.6163, -1.5932, -0.8621, -0.6874, -0.6985,  0.4786,  0.1076,  0.6572,\n",
      "          0.4630,  0.6855],\n",
      "        [-1.9493, -1.4414,  2.4471, -1.3415,  1.4204,  0.1596, -0.6199, -0.6909,\n",
      "          0.1817,  0.6155]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3188,  0.3572,  1.3212,  0.8875,  1.3603, -0.1095,  1.7963, -2.7218,\n",
      "          0.3228, -0.8528],\n",
      "        [ 0.4642,  1.0489, -0.7208, -0.6080,  1.1049, -0.0656,  0.7497, -0.7880,\n",
      "         -0.5869, -1.3047],\n",
      "        [-0.6166, -1.5932, -0.8621, -0.6875, -0.6985,  0.4788,  0.1076,  0.6572,\n",
      "          0.4630,  0.6855],\n",
      "        [-1.9494, -1.4414,  2.4471, -1.3415,  1.4204,  0.1597, -0.6199, -0.6909,\n",
      "          0.1817,  0.6155]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3188,  0.3574,  1.3211,  0.8874,  1.3603, -0.1096,  1.7963, -2.7218,\n",
      "          0.3226, -0.8528],\n",
      "        [ 0.4643,  1.0490, -0.7209, -0.6080,  1.1049, -0.0658,  0.7497, -0.7880,\n",
      "         -0.5872, -1.3047],\n",
      "        [-0.6169, -1.5932, -0.8621, -0.6876, -0.6985,  0.4789,  0.1076,  0.6572,\n",
      "          0.4630,  0.6855],\n",
      "        [-1.9495, -1.4414,  2.4471, -1.3416,  1.4204,  0.1598, -0.6199, -0.6909,\n",
      "          0.1818,  0.6155]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3189,  0.3575,  1.3210,  0.8874,  1.3603, -0.1097,  1.7963, -2.7218,\n",
      "          0.3223, -0.8528],\n",
      "        [ 0.4645,  1.0492, -0.7210, -0.6080,  1.1049, -0.0659,  0.7497, -0.7880,\n",
      "         -0.5874, -1.3047],\n",
      "        [-0.6171, -1.5932, -0.8621, -0.6878, -0.6985,  0.4791,  0.1076,  0.6572,\n",
      "          0.4629,  0.6855],\n",
      "        [-1.9496, -1.4414,  2.4471, -1.3416,  1.4204,  0.1599, -0.6199, -0.6909,\n",
      "          0.1818,  0.6155]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3189,  0.3576,  1.3209,  0.8874,  1.3603, -0.1097,  1.7963, -2.7218,\n",
      "          0.3220, -0.8528],\n",
      "        [ 0.4647,  1.0493, -0.7210, -0.6079,  1.1049, -0.0661,  0.7497, -0.7880,\n",
      "         -0.5876, -1.3047],\n",
      "        [-0.6174, -1.5932, -0.8622, -0.6879, -0.6985,  0.4793,  0.1076,  0.6572,\n",
      "          0.4629,  0.6854],\n",
      "        [-1.9497, -1.4414,  2.4471, -1.3417,  1.4204,  0.1600, -0.6199, -0.6909,\n",
      "          0.1818,  0.6155]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3190,  0.3578,  1.3207,  0.8873,  1.3603, -0.1098,  1.7963, -2.7218,\n",
      "          0.3218, -0.8528],\n",
      "        [ 0.4649,  1.0494, -0.7211, -0.6079,  1.1049, -0.0663,  0.7497, -0.7880,\n",
      "         -0.5878, -1.3047],\n",
      "        [-0.6176, -1.5932, -0.8622, -0.6880, -0.6985,  0.4795,  0.1076,  0.6572,\n",
      "          0.4629,  0.6854],\n",
      "        [-1.9499, -1.4414,  2.4471, -1.3417,  1.4204,  0.1600, -0.6199, -0.6909,\n",
      "          0.1818,  0.6155]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3191,  0.3579,  1.3206,  0.8873,  1.3603, -0.1099,  1.7963, -2.7218,\n",
      "          0.3215, -0.8529],\n",
      "        [ 0.4650,  1.0495, -0.7212, -0.6079,  1.1049, -0.0664,  0.7497, -0.7880,\n",
      "         -0.5880, -1.3047],\n",
      "        [-0.6179, -1.5932, -0.8622, -0.6881, -0.6985,  0.4797,  0.1076,  0.6572,\n",
      "          0.4629,  0.6854],\n",
      "        [-1.9500, -1.4414,  2.4471, -1.3418,  1.4204,  0.1601, -0.6199, -0.6909,\n",
      "          0.1818,  0.6155]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3191,  0.3580,  1.3205,  0.8873,  1.3603, -0.1100,  1.7963, -2.7218,\n",
      "          0.3213, -0.8529],\n",
      "        [ 0.4652,  1.0496, -0.7213, -0.6078,  1.1049, -0.0666,  0.7497, -0.7880,\n",
      "         -0.5882, -1.3047],\n",
      "        [-0.6182, -1.5932, -0.8622, -0.6882, -0.6985,  0.4799,  0.1076,  0.6572,\n",
      "          0.4629,  0.6854],\n",
      "        [-1.9501, -1.4415,  2.4471, -1.3418,  1.4204,  0.1602, -0.6199, -0.6909,\n",
      "          0.1818,  0.6155]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3192,  0.3581,  1.3204,  0.8873,  1.3603, -0.1101,  1.7963, -2.7218,\n",
      "          0.3210, -0.8529],\n",
      "        [ 0.4654,  1.0497, -0.7214, -0.6078,  1.1049, -0.0668,  0.7497, -0.7880,\n",
      "         -0.5884, -1.3047],\n",
      "        [-0.6184, -1.5932, -0.8622, -0.6883, -0.6985,  0.4801,  0.1076,  0.6572,\n",
      "          0.4629,  0.6854],\n",
      "        [-1.9502, -1.4415,  2.4471, -1.3419,  1.4204,  0.1603, -0.6199, -0.6909,\n",
      "          0.1819,  0.6155]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3192,  0.3583,  1.3203,  0.8872,  1.3603, -0.1102,  1.7963, -2.7218,\n",
      "          0.3208, -0.8529],\n",
      "        [ 0.4656,  1.0498, -0.7215, -0.6078,  1.1049, -0.0669,  0.7497, -0.7880,\n",
      "         -0.5886, -1.3047],\n",
      "        [-0.6187, -1.5932, -0.8623, -0.6884, -0.6985,  0.4803,  0.1076,  0.6572,\n",
      "          0.4629,  0.6854],\n",
      "        [-1.9503, -1.4415,  2.4471, -1.3419,  1.4204,  0.1604, -0.6199, -0.6909,\n",
      "          0.1819,  0.6155]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3193,  0.3584,  1.3202,  0.8872,  1.3603, -0.1103,  1.7963, -2.7218,\n",
      "          0.3205, -0.8529],\n",
      "        [ 0.4658,  1.0499, -0.7215, -0.6077,  1.1049, -0.0671,  0.7497, -0.7880,\n",
      "         -0.5888, -1.3047],\n",
      "        [-0.6189, -1.5932, -0.8623, -0.6885, -0.6985,  0.4805,  0.1076,  0.6572,\n",
      "          0.4629,  0.6854],\n",
      "        [-1.9504, -1.4415,  2.4471, -1.3419,  1.4204,  0.1605, -0.6199, -0.6909,\n",
      "          0.1819,  0.6155]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3193,  0.3585,  1.3201,  0.8872,  1.3603, -0.1103,  1.7963, -2.7218,\n",
      "          0.3203, -0.8529],\n",
      "        [ 0.4659,  1.0500, -0.7216, -0.6077,  1.1049, -0.0672,  0.7497, -0.7880,\n",
      "         -0.5890, -1.3047],\n",
      "        [-0.6192, -1.5932, -0.8623, -0.6887, -0.6985,  0.4807,  0.1076,  0.6572,\n",
      "          0.4629,  0.6853],\n",
      "        [-1.9505, -1.4415,  2.4471, -1.3420,  1.4204,  0.1606, -0.6199, -0.6909,\n",
      "          0.1819,  0.6155]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3194,  0.3586,  1.3200,  0.8871,  1.3603, -0.1104,  1.7963, -2.7218,\n",
      "          0.3200, -0.8530],\n",
      "        [ 0.4661,  1.0501, -0.7217, -0.6077,  1.1049, -0.0674,  0.7497, -0.7880,\n",
      "         -0.5892, -1.3047],\n",
      "        [-0.6195, -1.5932, -0.8623, -0.6888, -0.6985,  0.4809,  0.1076,  0.6572,\n",
      "          0.4629,  0.6853],\n",
      "        [-1.9506, -1.4415,  2.4471, -1.3420,  1.4204,  0.1607, -0.6199, -0.6909,\n",
      "          0.1819,  0.6155]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3194,  0.3588,  1.3198,  0.8871,  1.3603, -0.1105,  1.7963, -2.7218,\n",
      "          0.3197, -0.8530],\n",
      "        [ 0.4663,  1.0502, -0.7218, -0.6076,  1.1049, -0.0676,  0.7497, -0.7880,\n",
      "         -0.5894, -1.3048],\n",
      "        [-0.6197, -1.5932, -0.8624, -0.6889, -0.6985,  0.4811,  0.1076,  0.6572,\n",
      "          0.4629,  0.6853],\n",
      "        [-1.9507, -1.4415,  2.4471, -1.3421,  1.4204,  0.1608, -0.6199, -0.6909,\n",
      "          0.1819,  0.6155]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3195,  0.3589,  1.3197,  0.8871,  1.3603, -0.1106,  1.7963, -2.7218,\n",
      "          0.3195, -0.8530],\n",
      "        [ 0.4665,  1.0503, -0.7219, -0.6076,  1.1049, -0.0677,  0.7497, -0.7880,\n",
      "         -0.5896, -1.3048],\n",
      "        [-0.6200, -1.5932, -0.8624, -0.6890, -0.6985,  0.4812,  0.1076,  0.6572,\n",
      "          0.4629,  0.6853],\n",
      "        [-1.9508, -1.4415,  2.4471, -1.3421,  1.4204,  0.1608, -0.6199, -0.6909,\n",
      "          0.1820,  0.6155]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3195,  0.3590,  1.3196,  0.8870,  1.3603, -0.1107,  1.7963, -2.7218,\n",
      "          0.3192, -0.8530],\n",
      "        [ 0.4666,  1.0504, -0.7220, -0.6076,  1.1049, -0.0679,  0.7497, -0.7880,\n",
      "         -0.5898, -1.3048],\n",
      "        [-0.6202, -1.5932, -0.8624, -0.6891, -0.6985,  0.4814,  0.1076,  0.6572,\n",
      "          0.4629,  0.6853],\n",
      "        [-1.9510, -1.4415,  2.4471, -1.3422,  1.4204,  0.1609, -0.6199, -0.6909,\n",
      "          0.1820,  0.6154]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3196,  0.3591,  1.3195,  0.8870,  1.3603, -0.1108,  1.7963, -2.7218,\n",
      "          0.3190, -0.8530],\n",
      "        [ 0.4668,  1.0505, -0.7220, -0.6075,  1.1049, -0.0680,  0.7497, -0.7880,\n",
      "         -0.5900, -1.3048],\n",
      "        [-0.6205, -1.5932, -0.8624, -0.6892, -0.6985,  0.4816,  0.1076,  0.6572,\n",
      "          0.4629,  0.6853],\n",
      "        [-1.9511, -1.4416,  2.4471, -1.3422,  1.4204,  0.1610, -0.6199, -0.6909,\n",
      "          0.1820,  0.6154]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3196,  0.3593,  1.3194,  0.8870,  1.3603, -0.1109,  1.7963, -2.7218,\n",
      "          0.3187, -0.8531],\n",
      "        [ 0.4670,  1.0506, -0.7221, -0.6075,  1.1049, -0.0682,  0.7497, -0.7880,\n",
      "         -0.5903, -1.3048],\n",
      "        [-0.6208, -1.5933, -0.8624, -0.6893, -0.6985,  0.4818,  0.1076,  0.6572,\n",
      "          0.4629,  0.6853],\n",
      "        [-1.9512, -1.4416,  2.4471, -1.3422,  1.4204,  0.1611, -0.6199, -0.6909,\n",
      "          0.1820,  0.6154]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3197,  0.3594,  1.3193,  0.8869,  1.3603, -0.1109,  1.7963, -2.7218,\n",
      "          0.3185, -0.8531],\n",
      "        [ 0.4672,  1.0508, -0.7222, -0.6075,  1.1049, -0.0684,  0.7497, -0.7880,\n",
      "         -0.5905, -1.3048],\n",
      "        [-0.6210, -1.5933, -0.8625, -0.6894, -0.6985,  0.4820,  0.1076,  0.6572,\n",
      "          0.4629,  0.6852],\n",
      "        [-1.9513, -1.4416,  2.4471, -1.3423,  1.4204,  0.1612, -0.6199, -0.6909,\n",
      "          0.1820,  0.6154]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3197,  0.3595,  1.3192,  0.8869,  1.3603, -0.1110,  1.7963, -2.7218,\n",
      "          0.3182, -0.8531],\n",
      "        [ 0.4673,  1.0509, -0.7223, -0.6074,  1.1049, -0.0685,  0.7497, -0.7880,\n",
      "         -0.5907, -1.3048],\n",
      "        [-0.6213, -1.5933, -0.8625, -0.6895, -0.6985,  0.4822,  0.1076,  0.6572,\n",
      "          0.4628,  0.6852],\n",
      "        [-1.9514, -1.4416,  2.4471, -1.3423,  1.4204,  0.1613, -0.6199, -0.6909,\n",
      "          0.1821,  0.6154]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3198,  0.3596,  1.3191,  0.8869,  1.3603, -0.1111,  1.7963, -2.7218,\n",
      "          0.3180, -0.8531],\n",
      "        [ 0.4675,  1.0510, -0.7224, -0.6074,  1.1049, -0.0687,  0.7497, -0.7880,\n",
      "         -0.5909, -1.3048],\n",
      "        [-0.6215, -1.5933, -0.8625, -0.6897, -0.6985,  0.4824,  0.1076,  0.6572,\n",
      "          0.4628,  0.6852],\n",
      "        [-1.9515, -1.4416,  2.4471, -1.3424,  1.4204,  0.1614, -0.6199, -0.6909,\n",
      "          0.1821,  0.6154]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3198,  0.3598,  1.3190,  0.8869,  1.3603, -0.1112,  1.7963, -2.7218,\n",
      "          0.3177, -0.8531],\n",
      "        [ 0.4677,  1.0511, -0.7224, -0.6074,  1.1049, -0.0689,  0.7497, -0.7880,\n",
      "         -0.5911, -1.3048],\n",
      "        [-0.6218, -1.5933, -0.8625, -0.6898, -0.6985,  0.4826,  0.1076,  0.6572,\n",
      "          0.4628,  0.6852],\n",
      "        [-1.9516, -1.4416,  2.4471, -1.3424,  1.4204,  0.1615, -0.6199, -0.6909,\n",
      "          0.1821,  0.6154]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3199,  0.3599,  1.3188,  0.8868,  1.3603, -0.1113,  1.7963, -2.7218,\n",
      "          0.3175, -0.8531],\n",
      "        [ 0.4679,  1.0512, -0.7225, -0.6073,  1.1049, -0.0690,  0.7497, -0.7880,\n",
      "         -0.5913, -1.3048],\n",
      "        [-0.6221, -1.5933, -0.8626, -0.6899, -0.6985,  0.4828,  0.1076,  0.6572,\n",
      "          0.4628,  0.6852],\n",
      "        [-1.9517, -1.4416,  2.4471, -1.3425,  1.4204,  0.1616, -0.6199, -0.6909,\n",
      "          0.1821,  0.6154]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3199,  0.3600,  1.3187,  0.8868,  1.3603, -0.1114,  1.7963, -2.7218,\n",
      "          0.3172, -0.8532],\n",
      "        [ 0.4680,  1.0513, -0.7226, -0.6073,  1.1049, -0.0692,  0.7497, -0.7880,\n",
      "         -0.5915, -1.3048],\n",
      "        [-0.6223, -1.5933, -0.8626, -0.6900, -0.6985,  0.4830,  0.1076,  0.6572,\n",
      "          0.4628,  0.6852],\n",
      "        [-1.9518, -1.4416,  2.4471, -1.3425,  1.4204,  0.1616, -0.6199, -0.6909,\n",
      "          0.1821,  0.6154]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3200,  0.3601,  1.3186,  0.8868,  1.3603, -0.1114,  1.7963, -2.7218,\n",
      "          0.3170, -0.8532],\n",
      "        [ 0.4682,  1.0514, -0.7227, -0.6073,  1.1049, -0.0693,  0.7497, -0.7880,\n",
      "         -0.5917, -1.3048],\n",
      "        [-0.6226, -1.5933, -0.8626, -0.6901, -0.6985,  0.4831,  0.1076,  0.6572,\n",
      "          0.4628,  0.6852],\n",
      "        [-1.9519, -1.4417,  2.4471, -1.3426,  1.4204,  0.1617, -0.6199, -0.6909,\n",
      "          0.1821,  0.6154]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3200,  0.3602,  1.3185,  0.8867,  1.3603, -0.1115,  1.7963, -2.7218,\n",
      "          0.3167, -0.8532],\n",
      "        [ 0.4684,  1.0515, -0.7228, -0.6072,  1.1049, -0.0695,  0.7497, -0.7880,\n",
      "         -0.5919, -1.3048],\n",
      "        [-0.6228, -1.5933, -0.8626, -0.6902, -0.6985,  0.4833,  0.1076,  0.6572,\n",
      "          0.4628,  0.6851],\n",
      "        [-1.9520, -1.4417,  2.4471, -1.3426,  1.4204,  0.1618, -0.6199, -0.6909,\n",
      "          0.1822,  0.6154]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3201,  0.3604,  1.3184,  0.8867,  1.3603, -0.1116,  1.7963, -2.7218,\n",
      "          0.3165, -0.8532],\n",
      "        [ 0.4686,  1.0516, -0.7229, -0.6072,  1.1049, -0.0697,  0.7497, -0.7880,\n",
      "         -0.5921, -1.3049],\n",
      "        [-0.6231, -1.5933, -0.8626, -0.6903, -0.6985,  0.4835,  0.1076,  0.6572,\n",
      "          0.4628,  0.6851],\n",
      "        [-1.9521, -1.4417,  2.4471, -1.3426,  1.4204,  0.1619, -0.6199, -0.6909,\n",
      "          0.1822,  0.6154]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3201,  0.3605,  1.3183,  0.8867,  1.3603, -0.1117,  1.7963, -2.7218,\n",
      "          0.3162, -0.8532],\n",
      "        [ 0.4687,  1.0517, -0.7229, -0.6072,  1.1049, -0.0698,  0.7497, -0.7880,\n",
      "         -0.5923, -1.3049],\n",
      "        [-0.6233, -1.5933, -0.8627, -0.6904, -0.6985,  0.4837,  0.1076,  0.6572,\n",
      "          0.4628,  0.6851],\n",
      "        [-1.9523, -1.4417,  2.4471, -1.3427,  1.4204,  0.1620, -0.6199, -0.6909,\n",
      "          0.1822,  0.6154]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3202,  0.3606,  1.3182,  0.8866,  1.3603, -0.1118,  1.7963, -2.7218,\n",
      "          0.3160, -0.8532],\n",
      "        [ 0.4689,  1.0518, -0.7230, -0.6071,  1.1049, -0.0700,  0.7497, -0.7880,\n",
      "         -0.5925, -1.3049],\n",
      "        [-0.6236, -1.5933, -0.8627, -0.6905, -0.6985,  0.4839,  0.1076,  0.6572,\n",
      "          0.4628,  0.6851],\n",
      "        [-1.9524, -1.4417,  2.4471, -1.3427,  1.4204,  0.1621, -0.6199, -0.6909,\n",
      "          0.1822,  0.6154]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3202,  0.3607,  1.3181,  0.8866,  1.3603, -0.1119,  1.7963, -2.7218,\n",
      "          0.3157, -0.8533],\n",
      "        [ 0.4691,  1.0519, -0.7231, -0.6071,  1.1049, -0.0701,  0.7497, -0.7880,\n",
      "         -0.5927, -1.3049],\n",
      "        [-0.6239, -1.5933, -0.8627, -0.6907, -0.6985,  0.4841,  0.1076,  0.6572,\n",
      "          0.4628,  0.6851],\n",
      "        [-1.9525, -1.4417,  2.4471, -1.3428,  1.4204,  0.1622, -0.6199, -0.6909,\n",
      "          0.1822,  0.6154]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3203,  0.3608,  1.3179,  0.8866,  1.3603, -0.1119,  1.7963, -2.7218,\n",
      "          0.3155, -0.8533],\n",
      "        [ 0.4693,  1.0520, -0.7232, -0.6071,  1.1049, -0.0703,  0.7497, -0.7880,\n",
      "         -0.5929, -1.3049],\n",
      "        [-0.6241, -1.5933, -0.8627, -0.6908, -0.6985,  0.4843,  0.1076,  0.6572,\n",
      "          0.4628,  0.6851],\n",
      "        [-1.9526, -1.4417,  2.4471, -1.3428,  1.4204,  0.1623, -0.6199, -0.6909,\n",
      "          0.1822,  0.6154]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3203,  0.3610,  1.3178,  0.8866,  1.3603, -0.1120,  1.7963, -2.7218,\n",
      "          0.3152, -0.8533],\n",
      "        [ 0.4694,  1.0521, -0.7233, -0.6070,  1.1049, -0.0705,  0.7497, -0.7880,\n",
      "         -0.5931, -1.3049],\n",
      "        [-0.6244, -1.5933, -0.8628, -0.6909, -0.6985,  0.4845,  0.1076,  0.6572,\n",
      "          0.4628,  0.6851],\n",
      "        [-1.9527, -1.4417,  2.4471, -1.3429,  1.4204,  0.1624, -0.6199, -0.6909,\n",
      "          0.1823,  0.6154]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3204,  0.3611,  1.3177,  0.8865,  1.3603, -0.1121,  1.7963, -2.7218,\n",
      "          0.3150, -0.8533],\n",
      "        [ 0.4696,  1.0522, -0.7234, -0.6070,  1.1049, -0.0706,  0.7497, -0.7880,\n",
      "         -0.5933, -1.3049],\n",
      "        [-0.6246, -1.5934, -0.8628, -0.6910, -0.6985,  0.4847,  0.1076,  0.6572,\n",
      "          0.4628,  0.6851],\n",
      "        [-1.9528, -1.4417,  2.4471, -1.3429,  1.4204,  0.1624, -0.6199, -0.6909,\n",
      "          0.1823,  0.6154]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3204,  0.3612,  1.3176,  0.8865,  1.3603, -0.1122,  1.7963, -2.7218,\n",
      "          0.3147, -0.8533],\n",
      "        [ 0.4698,  1.0523, -0.7234, -0.6070,  1.1049, -0.0708,  0.7497, -0.7880,\n",
      "         -0.5935, -1.3049],\n",
      "        [-0.6249, -1.5934, -0.8628, -0.6911, -0.6985,  0.4849,  0.1076,  0.6572,\n",
      "          0.4628,  0.6850],\n",
      "        [-1.9529, -1.4418,  2.4471, -1.3429,  1.4204,  0.1625, -0.6199, -0.6909,\n",
      "          0.1823,  0.6154]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3205,  0.3613,  1.3175,  0.8865,  1.3603, -0.1123,  1.7963, -2.7218,\n",
      "          0.3145, -0.8533],\n",
      "        [ 0.4699,  1.0524, -0.7235, -0.6069,  1.1049, -0.0709,  0.7497, -0.7880,\n",
      "         -0.5937, -1.3049],\n",
      "        [-0.6251, -1.5934, -0.8628, -0.6912, -0.6985,  0.4850,  0.1076,  0.6572,\n",
      "          0.4628,  0.6850],\n",
      "        [-1.9530, -1.4418,  2.4471, -1.3430,  1.4204,  0.1626, -0.6199, -0.6909,\n",
      "          0.1823,  0.6154]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3205,  0.3614,  1.3174,  0.8864,  1.3603, -0.1124,  1.7963, -2.7218,\n",
      "          0.3142, -0.8534],\n",
      "        [ 0.4701,  1.0525, -0.7236, -0.6069,  1.1049, -0.0711,  0.7497, -0.7880,\n",
      "         -0.5939, -1.3049],\n",
      "        [-0.6254, -1.5934, -0.8628, -0.6913, -0.6985,  0.4852,  0.1076,  0.6572,\n",
      "          0.4628,  0.6850],\n",
      "        [-1.9531, -1.4418,  2.4471, -1.3430,  1.4204,  0.1627, -0.6199, -0.6909,\n",
      "          0.1823,  0.6154]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3206,  0.3616,  1.3173,  0.8864,  1.3603, -0.1124,  1.7963, -2.7218,\n",
      "          0.3140, -0.8534],\n",
      "        [ 0.4703,  1.0526, -0.7237, -0.6069,  1.1049, -0.0713,  0.7497, -0.7880,\n",
      "         -0.5941, -1.3049],\n",
      "        [-0.6256, -1.5934, -0.8629, -0.6914, -0.6985,  0.4854,  0.1076,  0.6572,\n",
      "          0.4628,  0.6850],\n",
      "        [-1.9532, -1.4418,  2.4471, -1.3431,  1.4204,  0.1628, -0.6199, -0.6909,\n",
      "          0.1824,  0.6153]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3206,  0.3617,  1.3172,  0.8864,  1.3603, -0.1125,  1.7963, -2.7218,\n",
      "          0.3137, -0.8534],\n",
      "        [ 0.4705,  1.0527, -0.7238, -0.6068,  1.1049, -0.0714,  0.7497, -0.7880,\n",
      "         -0.5943, -1.3049],\n",
      "        [-0.6259, -1.5934, -0.8629, -0.6915, -0.6985,  0.4856,  0.1076,  0.6572,\n",
      "          0.4628,  0.6850],\n",
      "        [-1.9533, -1.4418,  2.4471, -1.3431,  1.4204,  0.1629, -0.6199, -0.6909,\n",
      "          0.1824,  0.6153]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3207,  0.3618,  1.3171,  0.8864,  1.3603, -0.1126,  1.7963, -2.7218,\n",
      "          0.3135, -0.8534],\n",
      "        [ 0.4706,  1.0528, -0.7238, -0.6068,  1.1049, -0.0716,  0.7497, -0.7880,\n",
      "         -0.5945, -1.3049],\n",
      "        [-0.6262, -1.5934, -0.8629, -0.6916, -0.6985,  0.4858,  0.1076,  0.6572,\n",
      "          0.4628,  0.6850],\n",
      "        [-1.9534, -1.4418,  2.4471, -1.3432,  1.4204,  0.1630, -0.6199, -0.6909,\n",
      "          0.1824,  0.6153]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3207,  0.3619,  1.3169,  0.8863,  1.3603, -0.1127,  1.7963, -2.7218,\n",
      "          0.3132, -0.8534],\n",
      "        [ 0.4708,  1.0529, -0.7239, -0.6068,  1.1049, -0.0717,  0.7497, -0.7880,\n",
      "         -0.5947, -1.3050],\n",
      "        [-0.6264, -1.5934, -0.8629, -0.6918, -0.6985,  0.4860,  0.1076,  0.6572,\n",
      "          0.4628,  0.6850],\n",
      "        [-1.9535, -1.4418,  2.4471, -1.3432,  1.4204,  0.1631, -0.6199, -0.6909,\n",
      "          0.1824,  0.6153]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3208,  0.3620,  1.3168,  0.8863,  1.3603, -0.1128,  1.7963, -2.7218,\n",
      "          0.3130, -0.8534],\n",
      "        [ 0.4710,  1.0530, -0.7240, -0.6067,  1.1049, -0.0719,  0.7497, -0.7880,\n",
      "         -0.5949, -1.3050],\n",
      "        [-0.6267, -1.5934, -0.8629, -0.6919, -0.6985,  0.4862,  0.1076,  0.6572,\n",
      "          0.4628,  0.6849],\n",
      "        [-1.9537, -1.4418,  2.4471, -1.3433,  1.4204,  0.1631, -0.6199, -0.6909,\n",
      "          0.1824,  0.6153]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3208,  0.3621,  1.3167,  0.8863,  1.3603, -0.1129,  1.7963, -2.7218,\n",
      "          0.3127, -0.8535],\n",
      "        [ 0.4712,  1.0531, -0.7241, -0.6067,  1.1049, -0.0721,  0.7497, -0.7880,\n",
      "         -0.5951, -1.3050],\n",
      "        [-0.6269, -1.5934, -0.8630, -0.6920, -0.6985,  0.4864,  0.1076,  0.6572,\n",
      "          0.4628,  0.6849],\n",
      "        [-1.9538, -1.4419,  2.4471, -1.3433,  1.4204,  0.1632, -0.6199, -0.6909,\n",
      "          0.1824,  0.6153]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3209,  0.3623,  1.3166,  0.8862,  1.3603, -0.1129,  1.7963, -2.7218,\n",
      "          0.3125, -0.8535],\n",
      "        [ 0.4713,  1.0532, -0.7242, -0.6067,  1.1049, -0.0722,  0.7497, -0.7880,\n",
      "         -0.5954, -1.3050],\n",
      "        [-0.6272, -1.5934, -0.8630, -0.6921, -0.6985,  0.4865,  0.1076,  0.6572,\n",
      "          0.4628,  0.6849],\n",
      "        [-1.9539, -1.4419,  2.4471, -1.3433,  1.4204,  0.1633, -0.6199, -0.6909,\n",
      "          0.1825,  0.6153]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3209,  0.3624,  1.3165,  0.8862,  1.3603, -0.1130,  1.7963, -2.7218,\n",
      "          0.3122, -0.8535],\n",
      "        [ 0.4715,  1.0533, -0.7243, -0.6066,  1.1049, -0.0724,  0.7497, -0.7880,\n",
      "         -0.5956, -1.3050],\n",
      "        [-0.6274, -1.5934, -0.8630, -0.6922, -0.6985,  0.4867,  0.1076,  0.6572,\n",
      "          0.4628,  0.6849],\n",
      "        [-1.9540, -1.4419,  2.4471, -1.3434,  1.4204,  0.1634, -0.6199, -0.6909,\n",
      "          0.1825,  0.6153]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3210,  0.3625,  1.3164,  0.8862,  1.3603, -0.1131,  1.7963, -2.7218,\n",
      "          0.3120, -0.8535],\n",
      "        [ 0.4717,  1.0534, -0.7243, -0.6066,  1.1049, -0.0725,  0.7497, -0.7880,\n",
      "         -0.5958, -1.3050],\n",
      "        [-0.6277, -1.5935, -0.8630, -0.6923, -0.6985,  0.4869,  0.1076,  0.6572,\n",
      "          0.4628,  0.6849],\n",
      "        [-1.9541, -1.4419,  2.4471, -1.3434,  1.4204,  0.1635, -0.6199, -0.6909,\n",
      "          0.1825,  0.6153]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3210,  0.3626,  1.3163,  0.8862,  1.3603, -0.1132,  1.7963, -2.7218,\n",
      "          0.3117, -0.8535],\n",
      "        [ 0.4718,  1.0535, -0.7244, -0.6066,  1.1049, -0.0727,  0.7497, -0.7880,\n",
      "         -0.5960, -1.3050],\n",
      "        [-0.6279, -1.5935, -0.8631, -0.6924, -0.6985,  0.4871,  0.1076,  0.6572,\n",
      "          0.4628,  0.6849],\n",
      "        [-1.9542, -1.4419,  2.4471, -1.3435,  1.4204,  0.1636, -0.6199, -0.6909,\n",
      "          0.1825,  0.6153]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3211,  0.3627,  1.3162,  0.8861,  1.3603, -0.1133,  1.7963, -2.7218,\n",
      "          0.3115, -0.8535],\n",
      "        [ 0.4720,  1.0536, -0.7245, -0.6065,  1.1049, -0.0728,  0.7497, -0.7880,\n",
      "         -0.5962, -1.3050],\n",
      "        [-0.6282, -1.5935, -0.8631, -0.6925, -0.6985,  0.4873,  0.1076,  0.6572,\n",
      "          0.4628,  0.6849],\n",
      "        [-1.9543, -1.4419,  2.4471, -1.3435,  1.4204,  0.1637, -0.6199, -0.6909,\n",
      "          0.1825,  0.6153]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3211,  0.3628,  1.3160,  0.8861,  1.3603, -0.1134,  1.7963, -2.7218,\n",
      "          0.3112, -0.8536],\n",
      "        [ 0.4722,  1.0537, -0.7246, -0.6065,  1.1049, -0.0730,  0.7497, -0.7880,\n",
      "         -0.5964, -1.3050],\n",
      "        [-0.6284, -1.5935, -0.8631, -0.6926, -0.6985,  0.4875,  0.1076,  0.6572,\n",
      "          0.4628,  0.6848],\n",
      "        [-1.9544, -1.4419,  2.4471, -1.3436,  1.4204,  0.1638, -0.6199, -0.6909,\n",
      "          0.1826,  0.6153]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3212,  0.3629,  1.3159,  0.8861,  1.3603, -0.1134,  1.7963, -2.7218,\n",
      "          0.3110, -0.8536],\n",
      "        [ 0.4724,  1.0538, -0.7247, -0.6065,  1.1049, -0.0732,  0.7497, -0.7880,\n",
      "         -0.5966, -1.3050],\n",
      "        [-0.6287, -1.5935, -0.8631, -0.6927, -0.6985,  0.4877,  0.1076,  0.6572,\n",
      "          0.4628,  0.6848],\n",
      "        [-1.9545, -1.4419,  2.4471, -1.3436,  1.4204,  0.1638, -0.6199, -0.6909,\n",
      "          0.1826,  0.6153]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3212,  0.3630,  1.3158,  0.8861,  1.3603, -0.1135,  1.7963, -2.7218,\n",
      "          0.3108, -0.8536],\n",
      "        [ 0.4725,  1.0539, -0.7248, -0.6064,  1.1049, -0.0733,  0.7497, -0.7880,\n",
      "         -0.5968, -1.3050],\n",
      "        [-0.6289, -1.5935, -0.8631, -0.6928, -0.6985,  0.4879,  0.1076,  0.6572,\n",
      "          0.4628,  0.6848],\n",
      "        [-1.9546, -1.4420,  2.4471, -1.3436,  1.4204,  0.1639, -0.6199, -0.6909,\n",
      "          0.1826,  0.6153]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3213,  0.3632,  1.3157,  0.8860,  1.3603, -0.1136,  1.7963, -2.7218,\n",
      "          0.3105, -0.8536],\n",
      "        [ 0.4727,  1.0540, -0.7248, -0.6064,  1.1049, -0.0735,  0.7497, -0.7880,\n",
      "         -0.5970, -1.3050],\n",
      "        [-0.6292, -1.5935, -0.8632, -0.6930, -0.6985,  0.4881,  0.1076,  0.6572,\n",
      "          0.4628,  0.6848],\n",
      "        [-1.9547, -1.4420,  2.4471, -1.3437,  1.4204,  0.1640, -0.6199, -0.6909,\n",
      "          0.1826,  0.6153]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3213,  0.3633,  1.3156,  0.8860,  1.3603, -0.1137,  1.7963, -2.7218,\n",
      "          0.3103, -0.8536],\n",
      "        [ 0.4729,  1.0541, -0.7249, -0.6064,  1.1049, -0.0736,  0.7497, -0.7880,\n",
      "         -0.5972, -1.3050],\n",
      "        [-0.6294, -1.5935, -0.8632, -0.6931, -0.6985,  0.4882,  0.1076,  0.6572,\n",
      "          0.4628,  0.6848],\n",
      "        [-1.9548, -1.4420,  2.4471, -1.3437,  1.4204,  0.1641, -0.6199, -0.6909,\n",
      "          0.1826,  0.6153]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3214,  0.3634,  1.3155,  0.8860,  1.3603, -0.1138,  1.7963, -2.7218,\n",
      "          0.3100, -0.8536],\n",
      "        [ 0.4730,  1.0542, -0.7250, -0.6063,  1.1049, -0.0738,  0.7497, -0.7880,\n",
      "         -0.5974, -1.3050],\n",
      "        [-0.6297, -1.5935, -0.8632, -0.6932, -0.6985,  0.4884,  0.1076,  0.6572,\n",
      "          0.4628,  0.6848],\n",
      "        [-1.9549, -1.4420,  2.4471, -1.3438,  1.4204,  0.1642, -0.6199, -0.6909,\n",
      "          0.1827,  0.6153]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3214,  0.3635,  1.3154,  0.8859,  1.3603, -0.1139,  1.7963, -2.7218,\n",
      "          0.3098, -0.8537],\n",
      "        [ 0.4732,  1.0543, -0.7251, -0.6063,  1.1049, -0.0740,  0.7497, -0.7880,\n",
      "         -0.5976, -1.3051],\n",
      "        [-0.6299, -1.5935, -0.8632, -0.6933, -0.6985,  0.4886,  0.1076,  0.6572,\n",
      "          0.4628,  0.6848],\n",
      "        [-1.9550, -1.4420,  2.4471, -1.3438,  1.4204,  0.1643, -0.6199, -0.6909,\n",
      "          0.1827,  0.6153]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3215,  0.3636,  1.3153,  0.8859,  1.3603, -0.1139,  1.7963, -2.7218,\n",
      "          0.3095, -0.8537],\n",
      "        [ 0.4734,  1.0544, -0.7252, -0.6063,  1.1049, -0.0741,  0.7497, -0.7880,\n",
      "         -0.5978, -1.3051],\n",
      "        [-0.6302, -1.5935, -0.8633, -0.6934, -0.6985,  0.4888,  0.1076,  0.6572,\n",
      "          0.4628,  0.6848],\n",
      "        [-1.9551, -1.4420,  2.4471, -1.3439,  1.4204,  0.1644, -0.6199, -0.6909,\n",
      "          0.1827,  0.6153]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3215,  0.3637,  1.3151,  0.8859,  1.3603, -0.1140,  1.7963, -2.7218,\n",
      "          0.3093, -0.8537],\n",
      "        [ 0.4735,  1.0545, -0.7253, -0.6062,  1.1049, -0.0743,  0.7497, -0.7880,\n",
      "         -0.5980, -1.3051],\n",
      "        [-0.6304, -1.5936, -0.8633, -0.6935, -0.6985,  0.4890,  0.1076,  0.6572,\n",
      "          0.4628,  0.6847],\n",
      "        [-1.9552, -1.4420,  2.4471, -1.3439,  1.4204,  0.1645, -0.6199, -0.6909,\n",
      "          0.1827,  0.6153]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3216,  0.3638,  1.3150,  0.8859,  1.3603, -0.1141,  1.7963, -2.7218,\n",
      "          0.3091, -0.8537],\n",
      "        [ 0.4737,  1.0546, -0.7253, -0.6062,  1.1049, -0.0744,  0.7497, -0.7880,\n",
      "         -0.5982, -1.3051],\n",
      "        [-0.6307, -1.5936, -0.8633, -0.6936, -0.6985,  0.4892,  0.1076,  0.6572,\n",
      "          0.4628,  0.6847],\n",
      "        [-1.9553, -1.4420,  2.4471, -1.3439,  1.4204,  0.1645, -0.6199, -0.6909,\n",
      "          0.1827,  0.6153]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3216,  0.3639,  1.3149,  0.8858,  1.3603, -0.1142,  1.7963, -2.7218,\n",
      "          0.3088, -0.8537],\n",
      "        [ 0.4739,  1.0547, -0.7254, -0.6061,  1.1049, -0.0746,  0.7497, -0.7880,\n",
      "         -0.5984, -1.3051],\n",
      "        [-0.6309, -1.5936, -0.8633, -0.6937, -0.6985,  0.4894,  0.1076,  0.6572,\n",
      "          0.4628,  0.6847],\n",
      "        [-1.9555, -1.4421,  2.4471, -1.3440,  1.4204,  0.1646, -0.6199, -0.6909,\n",
      "          0.1828,  0.6152]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3217,  0.3641,  1.3148,  0.8858,  1.3603, -0.1143,  1.7963, -2.7218,\n",
      "          0.3086, -0.8537],\n",
      "        [ 0.4740,  1.0548, -0.7255, -0.6061,  1.1049, -0.0747,  0.7497, -0.7880,\n",
      "         -0.5986, -1.3051],\n",
      "        [-0.6312, -1.5936, -0.8633, -0.6938, -0.6985,  0.4895,  0.1076,  0.6572,\n",
      "          0.4628,  0.6847],\n",
      "        [-1.9556, -1.4421,  2.4471, -1.3440,  1.4204,  0.1647, -0.6199, -0.6909,\n",
      "          0.1828,  0.6152]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3217,  0.3642,  1.3147,  0.8858,  1.3603, -0.1143,  1.7963, -2.7218,\n",
      "          0.3083, -0.8538],\n",
      "        [ 0.4742,  1.0549, -0.7256, -0.6061,  1.1049, -0.0749,  0.7497, -0.7880,\n",
      "         -0.5988, -1.3051],\n",
      "        [-0.6314, -1.5936, -0.8634, -0.6939, -0.6985,  0.4897,  0.1076,  0.6572,\n",
      "          0.4628,  0.6847],\n",
      "        [-1.9557, -1.4421,  2.4471, -1.3441,  1.4204,  0.1648, -0.6199, -0.6909,\n",
      "          0.1828,  0.6152]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3218,  0.3643,  1.3146,  0.8858,  1.3603, -0.1144,  1.7963, -2.7218,\n",
      "          0.3081, -0.8538],\n",
      "        [ 0.4744,  1.0550, -0.7257, -0.6060,  1.1049, -0.0751,  0.7497, -0.7880,\n",
      "         -0.5990, -1.3051],\n",
      "        [-0.6317, -1.5936, -0.8634, -0.6940, -0.6985,  0.4899,  0.1076,  0.6572,\n",
      "          0.4628,  0.6847],\n",
      "        [-1.9558, -1.4421,  2.4471, -1.3441,  1.4204,  0.1649, -0.6199, -0.6909,\n",
      "          0.1828,  0.6152]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3218,  0.3644,  1.3145,  0.8857,  1.3603, -0.1145,  1.7963, -2.7218,\n",
      "          0.3078, -0.8538],\n",
      "        [ 0.4746,  1.0551, -0.7257, -0.6060,  1.1049, -0.0752,  0.7497, -0.7880,\n",
      "         -0.5992, -1.3051],\n",
      "        [-0.6319, -1.5936, -0.8634, -0.6941, -0.6985,  0.4901,  0.1076,  0.6572,\n",
      "          0.4628,  0.6847],\n",
      "        [-1.9559, -1.4421,  2.4471, -1.3442,  1.4204,  0.1650, -0.6199, -0.6909,\n",
      "          0.1828,  0.6152]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3219,  0.3645,  1.3144,  0.8857,  1.3603, -0.1146,  1.7963, -2.7218,\n",
      "          0.3076, -0.8538],\n",
      "        [ 0.4747,  1.0552, -0.7258, -0.6060,  1.1049, -0.0754,  0.7497, -0.7880,\n",
      "         -0.5994, -1.3051],\n",
      "        [-0.6322, -1.5936, -0.8634, -0.6942, -0.6985,  0.4903,  0.1076,  0.6572,\n",
      "          0.4628,  0.6846],\n",
      "        [-1.9560, -1.4421,  2.4471, -1.3442,  1.4204,  0.1651, -0.6199, -0.6909,\n",
      "          0.1829,  0.6152]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3219,  0.3646,  1.3142,  0.8857,  1.3603, -0.1147,  1.7963, -2.7218,\n",
      "          0.3074, -0.8538],\n",
      "        [ 0.4749,  1.0553, -0.7259, -0.6059,  1.1049, -0.0755,  0.7497, -0.7880,\n",
      "         -0.5996, -1.3051],\n",
      "        [-0.6324, -1.5936, -0.8635, -0.6944, -0.6985,  0.4905,  0.1076,  0.6572,\n",
      "          0.4628,  0.6846],\n",
      "        [-1.9561, -1.4421,  2.4471, -1.3442,  1.4204,  0.1652, -0.6199, -0.6909,\n",
      "          0.1829,  0.6152]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3220,  0.3647,  1.3141,  0.8857,  1.3603, -0.1148,  1.7963, -2.7218,\n",
      "          0.3071, -0.8538],\n",
      "        [ 0.4751,  1.0553, -0.7260, -0.6059,  1.1049, -0.0757,  0.7497, -0.7880,\n",
      "         -0.5998, -1.3051],\n",
      "        [-0.6327, -1.5937, -0.8635, -0.6945, -0.6985,  0.4907,  0.1076,  0.6572,\n",
      "          0.4628,  0.6846],\n",
      "        [-1.9562, -1.4421,  2.4471, -1.3443,  1.4204,  0.1652, -0.6199, -0.6909,\n",
      "          0.1829,  0.6152]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3220,  0.3648,  1.3140,  0.8856,  1.3603, -0.1148,  1.7963, -2.7218,\n",
      "          0.3069, -0.8539],\n",
      "        [ 0.4752,  1.0554, -0.7261, -0.6059,  1.1049, -0.0759,  0.7497, -0.7880,\n",
      "         -0.6000, -1.3051],\n",
      "        [-0.6329, -1.5937, -0.8635, -0.6946, -0.6985,  0.4909,  0.1076,  0.6572,\n",
      "          0.4628,  0.6846],\n",
      "        [-1.9563, -1.4422,  2.4471, -1.3443,  1.4204,  0.1653, -0.6199, -0.6909,\n",
      "          0.1829,  0.6152]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3221,  0.3649,  1.3139,  0.8856,  1.3603, -0.1149,  1.7963, -2.7218,\n",
      "          0.3066, -0.8539],\n",
      "        [ 0.4754,  1.0555, -0.7262, -0.6058,  1.1049, -0.0760,  0.7497, -0.7880,\n",
      "         -0.6002, -1.3051],\n",
      "        [-0.6332, -1.5937, -0.8635, -0.6947, -0.6985,  0.4910,  0.1076,  0.6572,\n",
      "          0.4628,  0.6846],\n",
      "        [-1.9564, -1.4422,  2.4471, -1.3444,  1.4204,  0.1654, -0.6199, -0.6909,\n",
      "          0.1829,  0.6152]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3221,  0.3650,  1.3138,  0.8856,  1.3603, -0.1150,  1.7963, -2.7218,\n",
      "          0.3064, -0.8539],\n",
      "        [ 0.4756,  1.0556, -0.7262, -0.6058,  1.1049, -0.0762,  0.7497, -0.7880,\n",
      "         -0.6004, -1.3052],\n",
      "        [-0.6334, -1.5937, -0.8635, -0.6948, -0.6985,  0.4912,  0.1076,  0.6572,\n",
      "          0.4628,  0.6846],\n",
      "        [-1.9565, -1.4422,  2.4471, -1.3444,  1.4204,  0.1655, -0.6199, -0.6909,\n",
      "          0.1830,  0.6152]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3221,  0.3651,  1.3137,  0.8855,  1.3603, -0.1151,  1.7963, -2.7218,\n",
      "          0.3062, -0.8539],\n",
      "        [ 0.4757,  1.0557, -0.7263, -0.6058,  1.1049, -0.0763,  0.7497, -0.7880,\n",
      "         -0.6006, -1.3052],\n",
      "        [-0.6337, -1.5937, -0.8636, -0.6949, -0.6985,  0.4914,  0.1076,  0.6572,\n",
      "          0.4628,  0.6846],\n",
      "        [-1.9566, -1.4422,  2.4471, -1.3445,  1.4204,  0.1656, -0.6199, -0.6909,\n",
      "          0.1830,  0.6152]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3222,  0.3652,  1.3136,  0.8855,  1.3603, -0.1152,  1.7963, -2.7218,\n",
      "          0.3059, -0.8539],\n",
      "        [ 0.4759,  1.0558, -0.7264, -0.6057,  1.1049, -0.0765,  0.7497, -0.7880,\n",
      "         -0.6008, -1.3052],\n",
      "        [-0.6339, -1.5937, -0.8636, -0.6950, -0.6985,  0.4916,  0.1076,  0.6572,\n",
      "          0.4628,  0.6845],\n",
      "        [-1.9567, -1.4422,  2.4471, -1.3445,  1.4204,  0.1657, -0.6199, -0.6909,\n",
      "          0.1830,  0.6152]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3222,  0.3654,  1.3135,  0.8855,  1.3603, -0.1152,  1.7963, -2.7218,\n",
      "          0.3057, -0.8539],\n",
      "        [ 0.4761,  1.0559, -0.7265, -0.6057,  1.1049, -0.0766,  0.7497, -0.7880,\n",
      "         -0.6010, -1.3052],\n",
      "        [-0.6342, -1.5937, -0.8636, -0.6951, -0.6985,  0.4918,  0.1076,  0.6572,\n",
      "          0.4628,  0.6845],\n",
      "        [-1.9568, -1.4422,  2.4471, -1.3445,  1.4204,  0.1658, -0.6199, -0.6909,\n",
      "          0.1830,  0.6152]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3223,  0.3655,  1.3134,  0.8855,  1.3603, -0.1153,  1.7963, -2.7218,\n",
      "          0.3054, -0.8540],\n",
      "        [ 0.4762,  1.0560, -0.7266, -0.6057,  1.1049, -0.0768,  0.7497, -0.7880,\n",
      "         -0.6012, -1.3052],\n",
      "        [-0.6344, -1.5937, -0.8636, -0.6952, -0.6985,  0.4920,  0.1076,  0.6572,\n",
      "          0.4628,  0.6845],\n",
      "        [-1.9569, -1.4422,  2.4471, -1.3446,  1.4204,  0.1659, -0.6199, -0.6909,\n",
      "          0.1830,  0.6152]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3223,  0.3656,  1.3132,  0.8854,  1.3603, -0.1154,  1.7963, -2.7218,\n",
      "          0.3052, -0.8540],\n",
      "        [ 0.4764,  1.0561, -0.7267, -0.6056,  1.1049, -0.0769,  0.7497, -0.7880,\n",
      "         -0.6014, -1.3052],\n",
      "        [-0.6347, -1.5938, -0.8636, -0.6953, -0.6985,  0.4922,  0.1076,  0.6572,\n",
      "          0.4628,  0.6845],\n",
      "        [-1.9570, -1.4422,  2.4471, -1.3446,  1.4204,  0.1659, -0.6199, -0.6909,\n",
      "          0.1831,  0.6152]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3224,  0.3657,  1.3131,  0.8854,  1.3603, -0.1155,  1.7963, -2.7218,\n",
      "          0.3050, -0.8540],\n",
      "        [ 0.4766,  1.0562, -0.7267, -0.6056,  1.1049, -0.0771,  0.7497, -0.7880,\n",
      "         -0.6016, -1.3052],\n",
      "        [-0.6349, -1.5938, -0.8637, -0.6954, -0.6985,  0.4923,  0.1076,  0.6572,\n",
      "          0.4628,  0.6845],\n",
      "        [-1.9571, -1.4423,  2.4471, -1.3447,  1.4204,  0.1660, -0.6199, -0.6909,\n",
      "          0.1831,  0.6152]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3224,  0.3658,  1.3130,  0.8854,  1.3603, -0.1156,  1.7963, -2.7218,\n",
      "          0.3047, -0.8540],\n",
      "        [ 0.4767,  1.0563, -0.7268, -0.6056,  1.1049, -0.0773,  0.7497, -0.7880,\n",
      "         -0.6017, -1.3052],\n",
      "        [-0.6352, -1.5938, -0.8637, -0.6955, -0.6985,  0.4925,  0.1076,  0.6572,\n",
      "          0.4628,  0.6845],\n",
      "        [-1.9572, -1.4423,  2.4471, -1.3447,  1.4204,  0.1661, -0.6199, -0.6909,\n",
      "          0.1831,  0.6152]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3225,  0.3659,  1.3129,  0.8854,  1.3603, -0.1157,  1.7963, -2.7218,\n",
      "          0.3045, -0.8540],\n",
      "        [ 0.4769,  1.0564, -0.7269, -0.6055,  1.1049, -0.0774,  0.7497, -0.7880,\n",
      "         -0.6019, -1.3052],\n",
      "        [-0.6354, -1.5938, -0.8637, -0.6956, -0.6985,  0.4927,  0.1076,  0.6572,\n",
      "          0.4629,  0.6845],\n",
      "        [-1.9573, -1.4423,  2.4471, -1.3448,  1.4204,  0.1662, -0.6199, -0.6909,\n",
      "          0.1831,  0.6152]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3225,  0.3660,  1.3128,  0.8853,  1.3603, -0.1157,  1.7963, -2.7218,\n",
      "          0.3043, -0.8540],\n",
      "        [ 0.4771,  1.0565, -0.7270, -0.6055,  1.1049, -0.0776,  0.7497, -0.7880,\n",
      "         -0.6021, -1.3052],\n",
      "        [-0.6356, -1.5938, -0.8637, -0.6957, -0.6985,  0.4929,  0.1076,  0.6572,\n",
      "          0.4629,  0.6845],\n",
      "        [-1.9574, -1.4423,  2.4471, -1.3448,  1.4204,  0.1663, -0.6199, -0.6909,\n",
      "          0.1831,  0.6152]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3226,  0.3661,  1.3127,  0.8853,  1.3603, -0.1158,  1.7963, -2.7218,\n",
      "          0.3040, -0.8541],\n",
      "        [ 0.4772,  1.0566, -0.7271, -0.6055,  1.1049, -0.0777,  0.7497, -0.7880,\n",
      "         -0.6023, -1.3052],\n",
      "        [-0.6359, -1.5938, -0.8638, -0.6958, -0.6985,  0.4931,  0.1076,  0.6572,\n",
      "          0.4629,  0.6844],\n",
      "        [-1.9575, -1.4423,  2.4471, -1.3448,  1.4204,  0.1664, -0.6199, -0.6909,\n",
      "          0.1832,  0.6152]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3226,  0.3662,  1.3126,  0.8853,  1.3603, -0.1159,  1.7963, -2.7218,\n",
      "          0.3038, -0.8541],\n",
      "        [ 0.4774,  1.0567, -0.7272, -0.6054,  1.1049, -0.0779,  0.7497, -0.7880,\n",
      "         -0.6025, -1.3052],\n",
      "        [-0.6361, -1.5938, -0.8638, -0.6960, -0.6985,  0.4933,  0.1076,  0.6572,\n",
      "          0.4629,  0.6844],\n",
      "        [-1.9576, -1.4423,  2.4471, -1.3449,  1.4204,  0.1665, -0.6199, -0.6909,\n",
      "          0.1832,  0.6152]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3227,  0.3663,  1.3125,  0.8853,  1.3603, -0.1160,  1.7963, -2.7218,\n",
      "          0.3035, -0.8541],\n",
      "        [ 0.4776,  1.0568, -0.7272, -0.6054,  1.1049, -0.0780,  0.7497, -0.7880,\n",
      "         -0.6027, -1.3052],\n",
      "        [-0.6364, -1.5938, -0.8638, -0.6961, -0.6985,  0.4935,  0.1076,  0.6572,\n",
      "          0.4629,  0.6844],\n",
      "        [-1.9577, -1.4423,  2.4471, -1.3449,  1.4204,  0.1665, -0.6199, -0.6909,\n",
      "          0.1832,  0.6151]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3227,  0.3664,  1.3123,  0.8852,  1.3603, -0.1161,  1.7963, -2.7218,\n",
      "          0.3033, -0.8541],\n",
      "        [ 0.4777,  1.0568, -0.7273, -0.6053,  1.1049, -0.0782,  0.7497, -0.7880,\n",
      "         -0.6029, -1.3053],\n",
      "        [-0.6366, -1.5939, -0.8638, -0.6962, -0.6985,  0.4936,  0.1076,  0.6572,\n",
      "          0.4629,  0.6844],\n",
      "        [-1.9578, -1.4424,  2.4471, -1.3450,  1.4204,  0.1666, -0.6199, -0.6909,\n",
      "          0.1832,  0.6151]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3228,  0.3665,  1.3122,  0.8852,  1.3603, -0.1161,  1.7963, -2.7218,\n",
      "          0.3031, -0.8541],\n",
      "        [ 0.4779,  1.0569, -0.7274, -0.6053,  1.1049, -0.0784,  0.7497, -0.7880,\n",
      "         -0.6031, -1.3053],\n",
      "        [-0.6369, -1.5939, -0.8638, -0.6963, -0.6985,  0.4938,  0.1076,  0.6572,\n",
      "          0.4629,  0.6844],\n",
      "        [-1.9580, -1.4424,  2.4471, -1.3450,  1.4204,  0.1667, -0.6199, -0.6909,\n",
      "          0.1832,  0.6151]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3228,  0.3666,  1.3121,  0.8852,  1.3603, -0.1162,  1.7963, -2.7218,\n",
      "          0.3028, -0.8541],\n",
      "        [ 0.4781,  1.0570, -0.7275, -0.6053,  1.1049, -0.0785,  0.7497, -0.7880,\n",
      "         -0.6033, -1.3053],\n",
      "        [-0.6371, -1.5939, -0.8639, -0.6964, -0.6985,  0.4940,  0.1076,  0.6572,\n",
      "          0.4629,  0.6844],\n",
      "        [-1.9581, -1.4424,  2.4471, -1.3450,  1.4204,  0.1668, -0.6199, -0.6909,\n",
      "          0.1833,  0.6151]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3229,  0.3667,  1.3120,  0.8852,  1.3603, -0.1163,  1.7963, -2.7218,\n",
      "          0.3026, -0.8541],\n",
      "        [ 0.4782,  1.0571, -0.7276, -0.6052,  1.1049, -0.0787,  0.7497, -0.7880,\n",
      "         -0.6035, -1.3053],\n",
      "        [-0.6374, -1.5939, -0.8639, -0.6965, -0.6985,  0.4942,  0.1076,  0.6572,\n",
      "          0.4629,  0.6844],\n",
      "        [-1.9582, -1.4424,  2.4471, -1.3451,  1.4204,  0.1669, -0.6199, -0.6909,\n",
      "          0.1833,  0.6151]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3229,  0.3668,  1.3119,  0.8851,  1.3603, -0.1164,  1.7963, -2.7218,\n",
      "          0.3024, -0.8542],\n",
      "        [ 0.4784,  1.0572, -0.7276, -0.6052,  1.1049, -0.0788,  0.7497, -0.7880,\n",
      "         -0.6037, -1.3053],\n",
      "        [-0.6376, -1.5939, -0.8639, -0.6966, -0.6985,  0.4944,  0.1076,  0.6572,\n",
      "          0.4629,  0.6844],\n",
      "        [-1.9583, -1.4424,  2.4471, -1.3451,  1.4204,  0.1670, -0.6199, -0.6909,\n",
      "          0.1833,  0.6151]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3230,  0.3669,  1.3118,  0.8851,  1.3603, -0.1165,  1.7963, -2.7218,\n",
      "          0.3021, -0.8542],\n",
      "        [ 0.4785,  1.0573, -0.7277, -0.6052,  1.1049, -0.0790,  0.7497, -0.7880,\n",
      "         -0.6039, -1.3053],\n",
      "        [-0.6378, -1.5939, -0.8639, -0.6967, -0.6985,  0.4946,  0.1076,  0.6572,\n",
      "          0.4629,  0.6843],\n",
      "        [-1.9584, -1.4424,  2.4471, -1.3452,  1.4204,  0.1671, -0.6199, -0.6909,\n",
      "          0.1833,  0.6151]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3230,  0.3670,  1.3117,  0.8851,  1.3603, -0.1165,  1.7963, -2.7218,\n",
      "          0.3019, -0.8542],\n",
      "        [ 0.4787,  1.0574, -0.7278, -0.6051,  1.1049, -0.0791,  0.7497, -0.7880,\n",
      "         -0.6041, -1.3053],\n",
      "        [-0.6381, -1.5939, -0.8640, -0.6968, -0.6985,  0.4947,  0.1076,  0.6572,\n",
      "          0.4629,  0.6843],\n",
      "        [-1.9585, -1.4424,  2.4471, -1.3452,  1.4204,  0.1671, -0.6199, -0.6909,\n",
      "          0.1833,  0.6151]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3231,  0.3671,  1.3116,  0.8851,  1.3603, -0.1166,  1.7963, -2.7218,\n",
      "          0.3017, -0.8542],\n",
      "        [ 0.4789,  1.0575, -0.7279, -0.6051,  1.1049, -0.0793,  0.7497, -0.7880,\n",
      "         -0.6043, -1.3053],\n",
      "        [-0.6383, -1.5939, -0.8640, -0.6969, -0.6985,  0.4949,  0.1076,  0.6572,\n",
      "          0.4629,  0.6843],\n",
      "        [-1.9586, -1.4424,  2.4471, -1.3453,  1.4204,  0.1672, -0.6199, -0.6909,\n",
      "          0.1834,  0.6151]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3231,  0.3672,  1.3114,  0.8851,  1.3603, -0.1167,  1.7963, -2.7218,\n",
      "          0.3014, -0.8542],\n",
      "        [ 0.4790,  1.0576, -0.7280, -0.6051,  1.1049, -0.0794,  0.7497, -0.7880,\n",
      "         -0.6045, -1.3053],\n",
      "        [-0.6386, -1.5940, -0.8640, -0.6970, -0.6985,  0.4951,  0.1076,  0.6572,\n",
      "          0.4629,  0.6843],\n",
      "        [-1.9587, -1.4425,  2.4471, -1.3453,  1.4204,  0.1673, -0.6199, -0.6909,\n",
      "          0.1834,  0.6151]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3231,  0.3673,  1.3113,  0.8850,  1.3603, -0.1168,  1.7963, -2.7218,\n",
      "          0.3012, -0.8542],\n",
      "        [ 0.4792,  1.0577, -0.7281, -0.6050,  1.1049, -0.0796,  0.7497, -0.7880,\n",
      "         -0.6047, -1.3053],\n",
      "        [-0.6388, -1.5940, -0.8640, -0.6971, -0.6985,  0.4953,  0.1076,  0.6572,\n",
      "          0.4629,  0.6843],\n",
      "        [-1.9588, -1.4425,  2.4471, -1.3453,  1.4204,  0.1674, -0.6199, -0.6909,\n",
      "          0.1834,  0.6151]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3232,  0.3674,  1.3112,  0.8850,  1.3603, -0.1169,  1.7963, -2.7218,\n",
      "          0.3010, -0.8543],\n",
      "        [ 0.4794,  1.0578, -0.7281, -0.6050,  1.1049, -0.0798,  0.7497, -0.7880,\n",
      "         -0.6049, -1.3053],\n",
      "        [-0.6391, -1.5940, -0.8640, -0.6972, -0.6985,  0.4955,  0.1076,  0.6572,\n",
      "          0.4630,  0.6843],\n",
      "        [-1.9589, -1.4425,  2.4471, -1.3454,  1.4204,  0.1675, -0.6199, -0.6909,\n",
      "          0.1834,  0.6151]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3232,  0.3675,  1.3111,  0.8850,  1.3603, -0.1169,  1.7963, -2.7218,\n",
      "          0.3007, -0.8543],\n",
      "        [ 0.4795,  1.0578, -0.7282, -0.6050,  1.1049, -0.0799,  0.7497, -0.7880,\n",
      "         -0.6051, -1.3053],\n",
      "        [-0.6393, -1.5940, -0.8641, -0.6973, -0.6985,  0.4957,  0.1076,  0.6572,\n",
      "          0.4630,  0.6843],\n",
      "        [-1.9590, -1.4425,  2.4471, -1.3454,  1.4204,  0.1676, -0.6199, -0.6909,\n",
      "          0.1835,  0.6151]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3233,  0.3676,  1.3110,  0.8850,  1.3603, -0.1170,  1.7963, -2.7218,\n",
      "          0.3005, -0.8543],\n",
      "        [ 0.4797,  1.0579, -0.7283, -0.6049,  1.1049, -0.0801,  0.7497, -0.7880,\n",
      "         -0.6053, -1.3053],\n",
      "        [-0.6395, -1.5940, -0.8641, -0.6974, -0.6985,  0.4958,  0.1076,  0.6572,\n",
      "          0.4630,  0.6842],\n",
      "        [-1.9591, -1.4425,  2.4471, -1.3455,  1.4204,  0.1677, -0.6199, -0.6909,\n",
      "          0.1835,  0.6151]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3233,  0.3677,  1.3109,  0.8849,  1.3603, -0.1171,  1.7963, -2.7218,\n",
      "          0.3003, -0.8543],\n",
      "        [ 0.4799,  1.0580, -0.7284, -0.6049,  1.1049, -0.0802,  0.7497, -0.7880,\n",
      "         -0.6055, -1.3053],\n",
      "        [-0.6398, -1.5940, -0.8641, -0.6975, -0.6985,  0.4960,  0.1076,  0.6572,\n",
      "          0.4630,  0.6842],\n",
      "        [-1.9592, -1.4425,  2.4471, -1.3455,  1.4204,  0.1677, -0.6199, -0.6909,\n",
      "          0.1835,  0.6151]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3234,  0.3678,  1.3108,  0.8849,  1.3603, -0.1172,  1.7963, -2.7218,\n",
      "          0.3000, -0.8543],\n",
      "        [ 0.4800,  1.0581, -0.7285, -0.6048,  1.1049, -0.0804,  0.7497, -0.7880,\n",
      "         -0.6057, -1.3053],\n",
      "        [-0.6400, -1.5940, -0.8641, -0.6976, -0.6985,  0.4962,  0.1076,  0.6572,\n",
      "          0.4630,  0.6842],\n",
      "        [-1.9593, -1.4425,  2.4471, -1.3456,  1.4204,  0.1678, -0.6199, -0.6909,\n",
      "          0.1835,  0.6151]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3234,  0.3679,  1.3107,  0.8849,  1.3603, -0.1173,  1.7963, -2.7218,\n",
      "          0.2998, -0.8543],\n",
      "        [ 0.4802,  1.0582, -0.7286, -0.6048,  1.1049, -0.0805,  0.7497, -0.7880,\n",
      "         -0.6059, -1.3054],\n",
      "        [-0.6403, -1.5941, -0.8642, -0.6977, -0.6985,  0.4964,  0.1076,  0.6572,\n",
      "          0.4630,  0.6842],\n",
      "        [-1.9594, -1.4426,  2.4471, -1.3456,  1.4204,  0.1679, -0.6199, -0.6909,\n",
      "          0.1835,  0.6151]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3235,  0.3680,  1.3105,  0.8849,  1.3603, -0.1173,  1.7963, -2.7218,\n",
      "          0.2996, -0.8544],\n",
      "        [ 0.4803,  1.0583, -0.7286, -0.6048,  1.1049, -0.0807,  0.7497, -0.7880,\n",
      "         -0.6061, -1.3054],\n",
      "        [-0.6405, -1.5941, -0.8642, -0.6979, -0.6985,  0.4966,  0.1076,  0.6572,\n",
      "          0.4630,  0.6842],\n",
      "        [-1.9595, -1.4426,  2.4471, -1.3456,  1.4204,  0.1680, -0.6199, -0.6909,\n",
      "          0.1836,  0.6151]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3235,  0.3681,  1.3104,  0.8848,  1.3603, -0.1174,  1.7963, -2.7218,\n",
      "          0.2993, -0.8544],\n",
      "        [ 0.4805,  1.0584, -0.7287, -0.6047,  1.1049, -0.0808,  0.7497, -0.7880,\n",
      "         -0.6063, -1.3054],\n",
      "        [-0.6408, -1.5941, -0.8642, -0.6980, -0.6985,  0.4968,  0.1076,  0.6572,\n",
      "          0.4630,  0.6842],\n",
      "        [-1.9596, -1.4426,  2.4471, -1.3457,  1.4204,  0.1681, -0.6199, -0.6909,\n",
      "          0.1836,  0.6151]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3236,  0.3682,  1.3103,  0.8848,  1.3603, -0.1175,  1.7963, -2.7218,\n",
      "          0.2991, -0.8544],\n",
      "        [ 0.4807,  1.0585, -0.7288, -0.6047,  1.1049, -0.0810,  0.7497, -0.7880,\n",
      "         -0.6064, -1.3054],\n",
      "        [-0.6410, -1.5941, -0.8642, -0.6981, -0.6985,  0.4969,  0.1076,  0.6572,\n",
      "          0.4630,  0.6842],\n",
      "        [-1.9597, -1.4426,  2.4471, -1.3457,  1.4204,  0.1682, -0.6199, -0.6909,\n",
      "          0.1836,  0.6151]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3236,  0.3683,  1.3102,  0.8848,  1.3603, -0.1176,  1.7963, -2.7218,\n",
      "          0.2989, -0.8544],\n",
      "        [ 0.4808,  1.0586, -0.7289, -0.6047,  1.1049, -0.0811,  0.7497, -0.7880,\n",
      "         -0.6066, -1.3054],\n",
      "        [-0.6412, -1.5941, -0.8642, -0.6982, -0.6985,  0.4971,  0.1076,  0.6572,\n",
      "          0.4630,  0.6842],\n",
      "        [-1.9598, -1.4426,  2.4471, -1.3458,  1.4204,  0.1683, -0.6199, -0.6909,\n",
      "          0.1836,  0.6151]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3237,  0.3684,  1.3101,  0.8848,  1.3603, -0.1177,  1.7963, -2.7218,\n",
      "          0.2986, -0.8544],\n",
      "        [ 0.4810,  1.0586, -0.7290, -0.6046,  1.1049, -0.0813,  0.7497, -0.7880,\n",
      "         -0.6068, -1.3054],\n",
      "        [-0.6415, -1.5941, -0.8643, -0.6983, -0.6985,  0.4973,  0.1076,  0.6572,\n",
      "          0.4630,  0.6841],\n",
      "        [-1.9599, -1.4426,  2.4471, -1.3458,  1.4204,  0.1683, -0.6199, -0.6909,\n",
      "          0.1837,  0.6151]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3237,  0.3685,  1.3100,  0.8847,  1.3603, -0.1177,  1.7963, -2.7218,\n",
      "          0.2984, -0.8544],\n",
      "        [ 0.4812,  1.0587, -0.7291, -0.6046,  1.1049, -0.0815,  0.7497, -0.7880,\n",
      "         -0.6070, -1.3054],\n",
      "        [-0.6417, -1.5942, -0.8643, -0.6984, -0.6985,  0.4975,  0.1076,  0.6572,\n",
      "          0.4631,  0.6841],\n",
      "        [-1.9600, -1.4426,  2.4471, -1.3458,  1.4204,  0.1684, -0.6199, -0.6909,\n",
      "          0.1837,  0.6151]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3237,  0.3686,  1.3099,  0.8847,  1.3603, -0.1178,  1.7963, -2.7218,\n",
      "          0.2982, -0.8545],\n",
      "        [ 0.4813,  1.0588, -0.7291, -0.6046,  1.1049, -0.0816,  0.7497, -0.7880,\n",
      "         -0.6072, -1.3054],\n",
      "        [-0.6420, -1.5942, -0.8643, -0.6985, -0.6985,  0.4977,  0.1076,  0.6572,\n",
      "          0.4631,  0.6841],\n",
      "        [-1.9601, -1.4427,  2.4471, -1.3459,  1.4204,  0.1685, -0.6199, -0.6909,\n",
      "          0.1837,  0.6150]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3238,  0.3687,  1.3098,  0.8847,  1.3603, -0.1179,  1.7963, -2.7218,\n",
      "          0.2980, -0.8545],\n",
      "        [ 0.4815,  1.0589, -0.7292, -0.6045,  1.1049, -0.0818,  0.7497, -0.7880,\n",
      "         -0.6074, -1.3054],\n",
      "        [-0.6422, -1.5942, -0.8643, -0.6986, -0.6985,  0.4979,  0.1076,  0.6572,\n",
      "          0.4631,  0.6841],\n",
      "        [-1.9602, -1.4427,  2.4471, -1.3459,  1.4204,  0.1686, -0.6199, -0.6909,\n",
      "          0.1837,  0.6150]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3238,  0.3688,  1.3096,  0.8847,  1.3603, -0.1180,  1.7963, -2.7218,\n",
      "          0.2977, -0.8545],\n",
      "        [ 0.4816,  1.0590, -0.7293, -0.6045,  1.1049, -0.0819,  0.7497, -0.7880,\n",
      "         -0.6076, -1.3054],\n",
      "        [-0.6424, -1.5942, -0.8643, -0.6987, -0.6985,  0.4980,  0.1076,  0.6572,\n",
      "          0.4631,  0.6841],\n",
      "        [-1.9603, -1.4427,  2.4471, -1.3460,  1.4204,  0.1687, -0.6199, -0.6909,\n",
      "          0.1837,  0.6150]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3239,  0.3689,  1.3095,  0.8847,  1.3603, -0.1181,  1.7963, -2.7218,\n",
      "          0.2975, -0.8545],\n",
      "        [ 0.4818,  1.0591, -0.7294, -0.6045,  1.1049, -0.0821,  0.7497, -0.7880,\n",
      "         -0.6078, -1.3054],\n",
      "        [-0.6427, -1.5942, -0.8644, -0.6988, -0.6985,  0.4982,  0.1076,  0.6572,\n",
      "          0.4631,  0.6841],\n",
      "        [-1.9604, -1.4427,  2.4471, -1.3460,  1.4204,  0.1688, -0.6199, -0.6909,\n",
      "          0.1838,  0.6150]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3239,  0.3690,  1.3094,  0.8846,  1.3603, -0.1181,  1.7963, -2.7218,\n",
      "          0.2973, -0.8545],\n",
      "        [ 0.4820,  1.0592, -0.7295, -0.6044,  1.1049, -0.0822,  0.7497, -0.7880,\n",
      "         -0.6080, -1.3054],\n",
      "        [-0.6429, -1.5942, -0.8644, -0.6989, -0.6985,  0.4984,  0.1076,  0.6572,\n",
      "          0.4631,  0.6841],\n",
      "        [-1.9605, -1.4427,  2.4471, -1.3461,  1.4204,  0.1689, -0.6199, -0.6909,\n",
      "          0.1838,  0.6150]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3240,  0.3691,  1.3093,  0.8846,  1.3603, -0.1182,  1.7963, -2.7218,\n",
      "          0.2970, -0.8545],\n",
      "        [ 0.4821,  1.0593, -0.7296, -0.6044,  1.1049, -0.0824,  0.7497, -0.7880,\n",
      "         -0.6082, -1.3054],\n",
      "        [-0.6432, -1.5942, -0.8644, -0.6990, -0.6985,  0.4986,  0.1076,  0.6572,\n",
      "          0.4631,  0.6841],\n",
      "        [-1.9606, -1.4427,  2.4471, -1.3461,  1.4204,  0.1689, -0.6199, -0.6909,\n",
      "          0.1838,  0.6150]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3240,  0.3692,  1.3092,  0.8846,  1.3603, -0.1183,  1.7963, -2.7218,\n",
      "          0.2968, -0.8545],\n",
      "        [ 0.4823,  1.0594, -0.7296, -0.6043,  1.1049, -0.0825,  0.7497, -0.7880,\n",
      "         -0.6084, -1.3054],\n",
      "        [-0.6434, -1.5943, -0.8644, -0.6991, -0.6985,  0.4988,  0.1076,  0.6572,\n",
      "          0.4631,  0.6840],\n",
      "        [-1.9607, -1.4427,  2.4471, -1.3461,  1.4204,  0.1690, -0.6199, -0.6909,\n",
      "          0.1838,  0.6150]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3241,  0.3693,  1.3091,  0.8846,  1.3603, -0.1184,  1.7963, -2.7218,\n",
      "          0.2966, -0.8546],\n",
      "        [ 0.4825,  1.0594, -0.7297, -0.6043,  1.1049, -0.0827,  0.7497, -0.7880,\n",
      "         -0.6086, -1.3055],\n",
      "        [-0.6436, -1.5943, -0.8645, -0.6992, -0.6985,  0.4990,  0.1076,  0.6572,\n",
      "          0.4631,  0.6840],\n",
      "        [-1.9608, -1.4427,  2.4471, -1.3462,  1.4204,  0.1691, -0.6199, -0.6909,\n",
      "          0.1839,  0.6150]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3241,  0.3694,  1.3090,  0.8845,  1.3603, -0.1185,  1.7963, -2.7218,\n",
      "          0.2964, -0.8546],\n",
      "        [ 0.4826,  1.0595, -0.7298, -0.6043,  1.1049, -0.0828,  0.7497, -0.7880,\n",
      "         -0.6088, -1.3055],\n",
      "        [-0.6439, -1.5943, -0.8645, -0.6993, -0.6985,  0.4991,  0.1076,  0.6572,\n",
      "          0.4632,  0.6840],\n",
      "        [-1.9609, -1.4428,  2.4471, -1.3462,  1.4204,  0.1692, -0.6199, -0.6909,\n",
      "          0.1839,  0.6150]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3242,  0.3695,  1.3089,  0.8845,  1.3603, -0.1185,  1.7963, -2.7218,\n",
      "          0.2961, -0.8546],\n",
      "        [ 0.4828,  1.0596, -0.7299, -0.6042,  1.1049, -0.0830,  0.7497, -0.7880,\n",
      "         -0.6089, -1.3055],\n",
      "        [-0.6441, -1.5943, -0.8645, -0.6994, -0.6985,  0.4993,  0.1076,  0.6572,\n",
      "          0.4632,  0.6840],\n",
      "        [-1.9610, -1.4428,  2.4471, -1.3463,  1.4204,  0.1693, -0.6199, -0.6909,\n",
      "          0.1839,  0.6150]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3242,  0.3696,  1.3087,  0.8845,  1.3603, -0.1186,  1.7963, -2.7218,\n",
      "          0.2959, -0.8546],\n",
      "        [ 0.4829,  1.0597, -0.7300, -0.6042,  1.1049, -0.0831,  0.7497, -0.7880,\n",
      "         -0.6091, -1.3055],\n",
      "        [-0.6443, -1.5943, -0.8645, -0.6995, -0.6985,  0.4995,  0.1076,  0.6572,\n",
      "          0.4632,  0.6840],\n",
      "        [-1.9611, -1.4428,  2.4471, -1.3463,  1.4204,  0.1694, -0.6199, -0.6909,\n",
      "          0.1839,  0.6150]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3243,  0.3697,  1.3086,  0.8845,  1.3603, -0.1187,  1.7963, -2.7218,\n",
      "          0.2957, -0.8546],\n",
      "        [ 0.4831,  1.0598, -0.7301, -0.6042,  1.1049, -0.0833,  0.7497, -0.7880,\n",
      "         -0.6093, -1.3055],\n",
      "        [-0.6446, -1.5943, -0.8645, -0.6996, -0.6985,  0.4997,  0.1076,  0.6572,\n",
      "          0.4632,  0.6840],\n",
      "        [-1.9612, -1.4428,  2.4471, -1.3463,  1.4204,  0.1694, -0.6199, -0.6909,\n",
      "          0.1839,  0.6150]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3243,  0.3698,  1.3085,  0.8845,  1.3603, -0.1188,  1.7963, -2.7218,\n",
      "          0.2955, -0.8546],\n",
      "        [ 0.4833,  1.0599, -0.7301, -0.6041,  1.1049, -0.0834,  0.7497, -0.7880,\n",
      "         -0.6095, -1.3055],\n",
      "        [-0.6448, -1.5944, -0.8646, -0.6997, -0.6985,  0.4999,  0.1076,  0.6572,\n",
      "          0.4632,  0.6840],\n",
      "        [-1.9613, -1.4428,  2.4471, -1.3464,  1.4204,  0.1695, -0.6199, -0.6909,\n",
      "          0.1840,  0.6150]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3243,  0.3699,  1.3084,  0.8844,  1.3603, -0.1189,  1.7963, -2.7218,\n",
      "          0.2952, -0.8547],\n",
      "        [ 0.4834,  1.0600, -0.7302, -0.6041,  1.1049, -0.0836,  0.7497, -0.7880,\n",
      "         -0.6097, -1.3055],\n",
      "        [-0.6451, -1.5944, -0.8646, -0.6998, -0.6985,  0.5000,  0.1076,  0.6572,\n",
      "          0.4632,  0.6840],\n",
      "        [-1.9614, -1.4428,  2.4471, -1.3464,  1.4204,  0.1696, -0.6199, -0.6909,\n",
      "          0.1840,  0.6150]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3244,  0.3699,  1.3083,  0.8844,  1.3603, -0.1189,  1.7963, -2.7218,\n",
      "          0.2950, -0.8547],\n",
      "        [ 0.4836,  1.0600, -0.7303, -0.6041,  1.1049, -0.0837,  0.7497, -0.7880,\n",
      "         -0.6099, -1.3055],\n",
      "        [-0.6453, -1.5944, -0.8646, -0.6999, -0.6985,  0.5002,  0.1076,  0.6572,\n",
      "          0.4632,  0.6839],\n",
      "        [-1.9615, -1.4428,  2.4471, -1.3465,  1.4204,  0.1697, -0.6199, -0.6909,\n",
      "          0.1840,  0.6150]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3244,  0.3700,  1.3082,  0.8844,  1.3603, -0.1190,  1.7963, -2.7218,\n",
      "          0.2948, -0.8547],\n",
      "        [ 0.4837,  1.0601, -0.7304, -0.6040,  1.1049, -0.0839,  0.7497, -0.7880,\n",
      "         -0.6101, -1.3055],\n",
      "        [-0.6455, -1.5944, -0.8646, -0.7000, -0.6985,  0.5004,  0.1076,  0.6572,\n",
      "          0.4632,  0.6839],\n",
      "        [-1.9616, -1.4429,  2.4471, -1.3465,  1.4204,  0.1698, -0.6199, -0.6909,\n",
      "          0.1840,  0.6150]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3245,  0.3701,  1.3081,  0.8844,  1.3603, -0.1191,  1.7963, -2.7218,\n",
      "          0.2946, -0.8547],\n",
      "        [ 0.4839,  1.0602, -0.7305, -0.6040,  1.1049, -0.0841,  0.7497, -0.7880,\n",
      "         -0.6103, -1.3055],\n",
      "        [-0.6458, -1.5944, -0.8647, -0.7001, -0.6985,  0.5006,  0.1076,  0.6572,\n",
      "          0.4633,  0.6839],\n",
      "        [-1.9617, -1.4429,  2.4471, -1.3465,  1.4204,  0.1699, -0.6199, -0.6909,\n",
      "          0.1841,  0.6150]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3245,  0.3702,  1.3080,  0.8843,  1.3603, -0.1192,  1.7963, -2.7218,\n",
      "          0.2943, -0.8547],\n",
      "        [ 0.4841,  1.0603, -0.7306, -0.6040,  1.1049, -0.0842,  0.7497, -0.7880,\n",
      "         -0.6105, -1.3055],\n",
      "        [-0.6460, -1.5944, -0.8647, -0.7002, -0.6985,  0.5008,  0.1076,  0.6572,\n",
      "          0.4633,  0.6839],\n",
      "        [-1.9618, -1.4429,  2.4471, -1.3466,  1.4204,  0.1700, -0.6199, -0.6909,\n",
      "          0.1841,  0.6150]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3246,  0.3703,  1.3078,  0.8843,  1.3603, -0.1193,  1.7963, -2.7218,\n",
      "          0.2941, -0.8547],\n",
      "        [ 0.4842,  1.0604, -0.7306, -0.6039,  1.1049, -0.0844,  0.7497, -0.7880,\n",
      "         -0.6107, -1.3055],\n",
      "        [-0.6462, -1.5945, -0.8647, -0.7003, -0.6985,  0.5010,  0.1076,  0.6572,\n",
      "          0.4633,  0.6839],\n",
      "        [-1.9619, -1.4429,  2.4471, -1.3466,  1.4204,  0.1700, -0.6199, -0.6909,\n",
      "          0.1841,  0.6150]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3246,  0.3704,  1.3077,  0.8843,  1.3603, -0.1193,  1.7963, -2.7218,\n",
      "          0.2939, -0.8548],\n",
      "        [ 0.4844,  1.0605, -0.7307, -0.6039,  1.1049, -0.0845,  0.7497, -0.7880,\n",
      "         -0.6109, -1.3055],\n",
      "        [-0.6465, -1.5945, -0.8647, -0.7004, -0.6985,  0.5011,  0.1076,  0.6572,\n",
      "          0.4633,  0.6839],\n",
      "        [-1.9620, -1.4429,  2.4471, -1.3467,  1.4204,  0.1701, -0.6199, -0.6909,\n",
      "          0.1841,  0.6150]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3247,  0.3705,  1.3076,  0.8843,  1.3603, -0.1194,  1.7963, -2.7218,\n",
      "          0.2937, -0.8548],\n",
      "        [ 0.4845,  1.0606, -0.7308, -0.6038,  1.1049, -0.0847,  0.7497, -0.7880,\n",
      "         -0.6110, -1.3055],\n",
      "        [-0.6467, -1.5945, -0.8647, -0.7005, -0.6985,  0.5013,  0.1076,  0.6572,\n",
      "          0.4633,  0.6839],\n",
      "        [-1.9621, -1.4429,  2.4471, -1.3467,  1.4204,  0.1702, -0.6199, -0.6909,\n",
      "          0.1842,  0.6150]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3247,  0.3706,  1.3075,  0.8843,  1.3603, -0.1195,  1.7963, -2.7218,\n",
      "          0.2934, -0.8548],\n",
      "        [ 0.4847,  1.0606, -0.7309, -0.6038,  1.1049, -0.0848,  0.7497, -0.7880,\n",
      "         -0.6112, -1.3056],\n",
      "        [-0.6469, -1.5945, -0.8648, -0.7007, -0.6985,  0.5015,  0.1076,  0.6572,\n",
      "          0.4633,  0.6839],\n",
      "        [-1.9622, -1.4429,  2.4471, -1.3468,  1.4204,  0.1703, -0.6199, -0.6909,\n",
      "          0.1842,  0.6150]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3248,  0.3707,  1.3074,  0.8842,  1.3603, -0.1196,  1.7963, -2.7218,\n",
      "          0.2932, -0.8548],\n",
      "        [ 0.4849,  1.0607, -0.7310, -0.6038,  1.1049, -0.0850,  0.7497, -0.7880,\n",
      "         -0.6114, -1.3056],\n",
      "        [-0.6472, -1.5945, -0.8648, -0.7008, -0.6985,  0.5017,  0.1076,  0.6572,\n",
      "          0.4633,  0.6838],\n",
      "        [-1.9623, -1.4430,  2.4471, -1.3468,  1.4204,  0.1704, -0.6199, -0.6909,\n",
      "          0.1842,  0.6149]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3248,  0.3708,  1.3073,  0.8842,  1.3603, -0.1196,  1.7963, -2.7218,\n",
      "          0.2930, -0.8548],\n",
      "        [ 0.4850,  1.0608, -0.7310, -0.6037,  1.1049, -0.0851,  0.7497, -0.7880,\n",
      "         -0.6116, -1.3056],\n",
      "        [-0.6474, -1.5945, -0.8648, -0.7009, -0.6985,  0.5019,  0.1076,  0.6572,\n",
      "          0.4634,  0.6838],\n",
      "        [-1.9624, -1.4430,  2.4471, -1.3468,  1.4204,  0.1705, -0.6199, -0.6909,\n",
      "          0.1842,  0.6149]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3248,  0.3709,  1.3072,  0.8842,  1.3603, -0.1197,  1.7963, -2.7218,\n",
      "          0.2928, -0.8548],\n",
      "        [ 0.4852,  1.0609, -0.7311, -0.6037,  1.1049, -0.0853,  0.7497, -0.7880,\n",
      "         -0.6118, -1.3056],\n",
      "        [-0.6477, -1.5946, -0.8648, -0.7010, -0.6985,  0.5020,  0.1076,  0.6572,\n",
      "          0.4634,  0.6838],\n",
      "        [-1.9625, -1.4430,  2.4471, -1.3469,  1.4204,  0.1705, -0.6199, -0.6909,\n",
      "          0.1842,  0.6149]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3249,  0.3710,  1.3071,  0.8842,  1.3603, -0.1198,  1.7963, -2.7218,\n",
      "          0.2926, -0.8548],\n",
      "        [ 0.4853,  1.0610, -0.7312, -0.6037,  1.1049, -0.0854,  0.7497, -0.7880,\n",
      "         -0.6120, -1.3056],\n",
      "        [-0.6479, -1.5946, -0.8648, -0.7011, -0.6985,  0.5022,  0.1076,  0.6572,\n",
      "          0.4634,  0.6838],\n",
      "        [-1.9626, -1.4430,  2.4471, -1.3469,  1.4204,  0.1706, -0.6199, -0.6909,\n",
      "          0.1843,  0.6149]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3249,  0.3711,  1.3069,  0.8841,  1.3603, -0.1199,  1.7963, -2.7218,\n",
      "          0.2923, -0.8549],\n",
      "        [ 0.4855,  1.0611, -0.7313, -0.6036,  1.1049, -0.0856,  0.7497, -0.7880,\n",
      "         -0.6122, -1.3056],\n",
      "        [-0.6481, -1.5946, -0.8649, -0.7012, -0.6985,  0.5024,  0.1076,  0.6572,\n",
      "          0.4634,  0.6838],\n",
      "        [-1.9627, -1.4430,  2.4471, -1.3470,  1.4204,  0.1707, -0.6199, -0.6909,\n",
      "          0.1843,  0.6149]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3250,  0.3711,  1.3068,  0.8841,  1.3603, -0.1200,  1.7963, -2.7218,\n",
      "          0.2921, -0.8549],\n",
      "        [ 0.4856,  1.0611, -0.7314, -0.6036,  1.1049, -0.0857,  0.7497, -0.7880,\n",
      "         -0.6124, -1.3056],\n",
      "        [-0.6484, -1.5946, -0.8649, -0.7013, -0.6985,  0.5026,  0.1076,  0.6572,\n",
      "          0.4634,  0.6838],\n",
      "        [-1.9628, -1.4430,  2.4471, -1.3470,  1.4204,  0.1708, -0.6199, -0.6909,\n",
      "          0.1843,  0.6149]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3250,  0.3712,  1.3067,  0.8841,  1.3603, -0.1200,  1.7963, -2.7218,\n",
      "          0.2919, -0.8549],\n",
      "        [ 0.4858,  1.0612, -0.7315, -0.6036,  1.1049, -0.0859,  0.7497, -0.7880,\n",
      "         -0.6126, -1.3056],\n",
      "        [-0.6486, -1.5946, -0.8649, -0.7014, -0.6985,  0.5028,  0.1076,  0.6572,\n",
      "          0.4634,  0.6838],\n",
      "        [-1.9629, -1.4430,  2.4471, -1.3470,  1.4204,  0.1709, -0.6199, -0.6909,\n",
      "          0.1843,  0.6149]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3251,  0.3713,  1.3066,  0.8841,  1.3603, -0.1201,  1.7963, -2.7218,\n",
      "          0.2917, -0.8549],\n",
      "        [ 0.4860,  1.0613, -0.7315, -0.6035,  1.1049, -0.0860,  0.7497, -0.7880,\n",
      "         -0.6127, -1.3056],\n",
      "        [-0.6488, -1.5947, -0.8649, -0.7015, -0.6985,  0.5029,  0.1076,  0.6572,\n",
      "          0.4634,  0.6838],\n",
      "        [-1.9630, -1.4431,  2.4471, -1.3471,  1.4204,  0.1710, -0.6199, -0.6909,\n",
      "          0.1844,  0.6149]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3251,  0.3714,  1.3065,  0.8841,  1.3603, -0.1202,  1.7963, -2.7218,\n",
      "          0.2915, -0.8549],\n",
      "        [ 0.4861,  1.0614, -0.7316, -0.6035,  1.1049, -0.0862,  0.7497, -0.7880,\n",
      "         -0.6129, -1.3056],\n",
      "        [-0.6491, -1.5947, -0.8650, -0.7016, -0.6985,  0.5031,  0.1076,  0.6572,\n",
      "          0.4635,  0.6837],\n",
      "        [-1.9631, -1.4431,  2.4471, -1.3471,  1.4204,  0.1710, -0.6199, -0.6909,\n",
      "          0.1844,  0.6149]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3252,  0.3715,  1.3064,  0.8840,  1.3603, -0.1203,  1.7963, -2.7218,\n",
      "          0.2912, -0.8549],\n",
      "        [ 0.4863,  1.0615, -0.7317, -0.6034,  1.1049, -0.0863,  0.7497, -0.7880,\n",
      "         -0.6131, -1.3056],\n",
      "        [-0.6493, -1.5947, -0.8650, -0.7017, -0.6985,  0.5033,  0.1076,  0.6572,\n",
      "          0.4635,  0.6837],\n",
      "        [-1.9632, -1.4431,  2.4471, -1.3472,  1.4204,  0.1711, -0.6199, -0.6909,\n",
      "          0.1844,  0.6149]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3252,  0.3716,  1.3063,  0.8840,  1.3603, -0.1203,  1.7963, -2.7218,\n",
      "          0.2910, -0.8550],\n",
      "        [ 0.4864,  1.0616, -0.7318, -0.6034,  1.1049, -0.0865,  0.7497, -0.7880,\n",
      "         -0.6133, -1.3056],\n",
      "        [-0.6495, -1.5947, -0.8650, -0.7018, -0.6985,  0.5035,  0.1076,  0.6572,\n",
      "          0.4635,  0.6837],\n",
      "        [-1.9633, -1.4431,  2.4471, -1.3472,  1.4204,  0.1712, -0.6199, -0.6909,\n",
      "          0.1844,  0.6149]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3252,  0.3717,  1.3062,  0.8840,  1.3603, -0.1204,  1.7963, -2.7218,\n",
      "          0.2908, -0.8550],\n",
      "        [ 0.4866,  1.0616, -0.7319, -0.6034,  1.1049, -0.0866,  0.7497, -0.7880,\n",
      "         -0.6135, -1.3056],\n",
      "        [-0.6498, -1.5947, -0.8650, -0.7019, -0.6985,  0.5037,  0.1076,  0.6572,\n",
      "          0.4635,  0.6837],\n",
      "        [-1.9634, -1.4431,  2.4471, -1.3472,  1.4204,  0.1713, -0.6199, -0.6909,\n",
      "          0.1845,  0.6149]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3253,  0.3718,  1.3060,  0.8840,  1.3603, -0.1205,  1.7963, -2.7218,\n",
      "          0.2906, -0.8550],\n",
      "        [ 0.4867,  1.0617, -0.7320, -0.6033,  1.1049, -0.0868,  0.7497, -0.7880,\n",
      "         -0.6137, -1.3056],\n",
      "        [-0.6500, -1.5947, -0.8650, -0.7020, -0.6985,  0.5038,  0.1076,  0.6572,\n",
      "          0.4635,  0.6837],\n",
      "        [-1.9635, -1.4431,  2.4471, -1.3473,  1.4204,  0.1714, -0.6199, -0.6909,\n",
      "          0.1845,  0.6149]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3253,  0.3719,  1.3059,  0.8840,  1.3603, -0.1206,  1.7963, -2.7218,\n",
      "          0.2904, -0.8550],\n",
      "        [ 0.4869,  1.0618, -0.7320, -0.6033,  1.1049, -0.0869,  0.7497, -0.7880,\n",
      "         -0.6139, -1.3056],\n",
      "        [-0.6502, -1.5948, -0.8651, -0.7021, -0.6985,  0.5040,  0.1076,  0.6572,\n",
      "          0.4635,  0.6837],\n",
      "        [-1.9636, -1.4431,  2.4471, -1.3473,  1.4204,  0.1715, -0.6199, -0.6909,\n",
      "          0.1845,  0.6149]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3254,  0.3720,  1.3058,  0.8839,  1.3603, -0.1207,  1.7963, -2.7218,\n",
      "          0.2901, -0.8550],\n",
      "        [ 0.4871,  1.0619, -0.7321, -0.6033,  1.1049, -0.0871,  0.7497, -0.7880,\n",
      "         -0.6141, -1.3057],\n",
      "        [-0.6505, -1.5948, -0.8651, -0.7022, -0.6985,  0.5042,  0.1076,  0.6572,\n",
      "          0.4636,  0.6837],\n",
      "        [-1.9637, -1.4432,  2.4471, -1.3474,  1.4204,  0.1715, -0.6199, -0.6909,\n",
      "          0.1845,  0.6149]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3254,  0.3720,  1.3057,  0.8839,  1.3603, -0.1207,  1.7963, -2.7218,\n",
      "          0.2899, -0.8550],\n",
      "        [ 0.4872,  1.0620, -0.7322, -0.6032,  1.1049, -0.0872,  0.7497, -0.7880,\n",
      "         -0.6142, -1.3057],\n",
      "        [-0.6507, -1.5948, -0.8651, -0.7023, -0.6985,  0.5044,  0.1076,  0.6572,\n",
      "          0.4636,  0.6837],\n",
      "        [-1.9638, -1.4432,  2.4471, -1.3474,  1.4204,  0.1716, -0.6199, -0.6909,\n",
      "          0.1846,  0.6149]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3255,  0.3721,  1.3056,  0.8839,  1.3603, -0.1208,  1.7963, -2.7218,\n",
      "          0.2897, -0.8550],\n",
      "        [ 0.4874,  1.0621, -0.7323, -0.6032,  1.1049, -0.0874,  0.7497, -0.7880,\n",
      "         -0.6144, -1.3057],\n",
      "        [-0.6509, -1.5948, -0.8651, -0.7024, -0.6985,  0.5046,  0.1076,  0.6572,\n",
      "          0.4636,  0.6836],\n",
      "        [-1.9639, -1.4432,  2.4471, -1.3474,  1.4204,  0.1717, -0.6199, -0.6909,\n",
      "          0.1846,  0.6149]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3255,  0.3722,  1.3055,  0.8839,  1.3603, -0.1209,  1.7963, -2.7218,\n",
      "          0.2895, -0.8551],\n",
      "        [ 0.4875,  1.0621, -0.7324, -0.6031,  1.1049, -0.0875,  0.7497, -0.7880,\n",
      "         -0.6146, -1.3057],\n",
      "        [-0.6512, -1.5948, -0.8652, -0.7025, -0.6985,  0.5047,  0.1076,  0.6572,\n",
      "          0.4636,  0.6836],\n",
      "        [-1.9640, -1.4432,  2.4471, -1.3475,  1.4204,  0.1718, -0.6199, -0.6909,\n",
      "          0.1846,  0.6149]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3256,  0.3723,  1.3054,  0.8839,  1.3603, -0.1210,  1.7963, -2.7218,\n",
      "          0.2893, -0.8551],\n",
      "        [ 0.4877,  1.0622, -0.7325, -0.6031,  1.1049, -0.0877,  0.7497, -0.7880,\n",
      "         -0.6148, -1.3057],\n",
      "        [-0.6514, -1.5949, -0.8652, -0.7026, -0.6985,  0.5049,  0.1076,  0.6572,\n",
      "          0.4636,  0.6836],\n",
      "        [-1.9641, -1.4432,  2.4471, -1.3475,  1.4204,  0.1719, -0.6199, -0.6909,\n",
      "          0.1846,  0.6149]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3256,  0.3724,  1.3053,  0.8838,  1.3603, -0.1210,  1.7963, -2.7218,\n",
      "          0.2891, -0.8551],\n",
      "        [ 0.4878,  1.0623, -0.7325, -0.6031,  1.1049, -0.0878,  0.7497, -0.7880,\n",
      "         -0.6150, -1.3057],\n",
      "        [-0.6516, -1.5949, -0.8652, -0.7027, -0.6985,  0.5051,  0.1076,  0.6572,\n",
      "          0.4636,  0.6836],\n",
      "        [-1.9642, -1.4432,  2.4471, -1.3476,  1.4204,  0.1720, -0.6199, -0.6909,\n",
      "          0.1847,  0.6149]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3256,  0.3725,  1.3051,  0.8838,  1.3603, -0.1211,  1.7963, -2.7218,\n",
      "          0.2888, -0.8551],\n",
      "        [ 0.4880,  1.0624, -0.7326, -0.6030,  1.1049, -0.0880,  0.7497, -0.7880,\n",
      "         -0.6152, -1.3057],\n",
      "        [-0.6519, -1.5949, -0.8652, -0.7028, -0.6985,  0.5053,  0.1076,  0.6572,\n",
      "          0.4637,  0.6836],\n",
      "        [-1.9643, -1.4432,  2.4471, -1.3476,  1.4204,  0.1721, -0.6199, -0.6909,\n",
      "          0.1847,  0.6149]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3257,  0.3726,  1.3050,  0.8838,  1.3603, -0.1212,  1.7963, -2.7218,\n",
      "          0.2886, -0.8551],\n",
      "        [ 0.4882,  1.0625, -0.7327, -0.6030,  1.1049, -0.0881,  0.7497, -0.7880,\n",
      "         -0.6154, -1.3057],\n",
      "        [-0.6521, -1.5949, -0.8652, -0.7029, -0.6985,  0.5055,  0.1076,  0.6572,\n",
      "          0.4637,  0.6836],\n",
      "        [-1.9644, -1.4433,  2.4471, -1.3476,  1.4204,  0.1721, -0.6199, -0.6909,\n",
      "          0.1847,  0.6149]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3257,  0.3726,  1.3049,  0.8838,  1.3603, -0.1213,  1.7963, -2.7218,\n",
      "          0.2884, -0.8551],\n",
      "        [ 0.4883,  1.0625, -0.7328, -0.6030,  1.1049, -0.0883,  0.7497, -0.7880,\n",
      "         -0.6155, -1.3057],\n",
      "        [-0.6523, -1.5949, -0.8653, -0.7030, -0.6985,  0.5056,  0.1076,  0.6572,\n",
      "          0.4637,  0.6836],\n",
      "        [-1.9645, -1.4433,  2.4471, -1.3477,  1.4204,  0.1722, -0.6199, -0.6909,\n",
      "          0.1847,  0.6149]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3258,  0.3727,  1.3048,  0.8838,  1.3603, -0.1214,  1.7963, -2.7218,\n",
      "          0.2882, -0.8552],\n",
      "        [ 0.4885,  1.0626, -0.7329, -0.6029,  1.1049, -0.0884,  0.7497, -0.7880,\n",
      "         -0.6157, -1.3057],\n",
      "        [-0.6525, -1.5949, -0.8653, -0.7031, -0.6985,  0.5058,  0.1076,  0.6572,\n",
      "          0.4637,  0.6836],\n",
      "        [-1.9645, -1.4433,  2.4471, -1.3477,  1.4204,  0.1723, -0.6199, -0.6909,\n",
      "          0.1848,  0.6149]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3258,  0.3728,  1.3047,  0.8837,  1.3603, -0.1214,  1.7963, -2.7218,\n",
      "          0.2880, -0.8552],\n",
      "        [ 0.4886,  1.0627, -0.7330, -0.6029,  1.1049, -0.0886,  0.7497, -0.7880,\n",
      "         -0.6159, -1.3057],\n",
      "        [-0.6528, -1.5950, -0.8653, -0.7032, -0.6985,  0.5060,  0.1076,  0.6572,\n",
      "          0.4637,  0.6835],\n",
      "        [-1.9646, -1.4433,  2.4471, -1.3478,  1.4204,  0.1724, -0.6199, -0.6909,\n",
      "          0.1848,  0.6148]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3259,  0.3729,  1.3046,  0.8837,  1.3603, -0.1215,  1.7963, -2.7218,\n",
      "          0.2878, -0.8552],\n",
      "        [ 0.4888,  1.0628, -0.7330, -0.6029,  1.1049, -0.0887,  0.7497, -0.7880,\n",
      "         -0.6161, -1.3057],\n",
      "        [-0.6530, -1.5950, -0.8653, -0.7033, -0.6985,  0.5062,  0.1076,  0.6572,\n",
      "          0.4638,  0.6835],\n",
      "        [-1.9647, -1.4433,  2.4470, -1.3478,  1.4204,  0.1725, -0.6199, -0.6909,\n",
      "          0.1848,  0.6148]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3259,  0.3730,  1.3045,  0.8837,  1.3603, -0.1216,  1.7963, -2.7218,\n",
      "          0.2875, -0.8552],\n",
      "        [ 0.4889,  1.0629, -0.7331, -0.6028,  1.1049, -0.0889,  0.7497, -0.7880,\n",
      "         -0.6163, -1.3057],\n",
      "        [-0.6532, -1.5950, -0.8653, -0.7034, -0.6985,  0.5064,  0.1076,  0.6572,\n",
      "          0.4638,  0.6835],\n",
      "        [-1.9648, -1.4433,  2.4470, -1.3478,  1.4204,  0.1726, -0.6199, -0.6909,\n",
      "          0.1848,  0.6148]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3260,  0.3731,  1.3043,  0.8837,  1.3603, -0.1217,  1.7963, -2.7218,\n",
      "          0.2873, -0.8552],\n",
      "        [ 0.4891,  1.0629, -0.7332, -0.6028,  1.1049, -0.0890,  0.7497, -0.7880,\n",
      "         -0.6165, -1.3057],\n",
      "        [-0.6535, -1.5950, -0.8654, -0.7035, -0.6985,  0.5065,  0.1076,  0.6572,\n",
      "          0.4638,  0.6835],\n",
      "        [-1.9649, -1.4433,  2.4470, -1.3479,  1.4204,  0.1726, -0.6199, -0.6909,\n",
      "          0.1849,  0.6148]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3260,  0.3732,  1.3042,  0.8837,  1.3603, -0.1217,  1.7963, -2.7218,\n",
      "          0.2871, -0.8552],\n",
      "        [ 0.4892,  1.0630, -0.7333, -0.6027,  1.1049, -0.0892,  0.7497, -0.7880,\n",
      "         -0.6167, -1.3057],\n",
      "        [-0.6537, -1.5950, -0.8654, -0.7036, -0.6985,  0.5067,  0.1076,  0.6572,\n",
      "          0.4638,  0.6835],\n",
      "        [-1.9650, -1.4434,  2.4470, -1.3479,  1.4204,  0.1727, -0.6199, -0.6909,\n",
      "          0.1849,  0.6148]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3260,  0.3732,  1.3041,  0.8836,  1.3603, -0.1218,  1.7963, -2.7218,\n",
      "          0.2869, -0.8552],\n",
      "        [ 0.4894,  1.0631, -0.7334, -0.6027,  1.1049, -0.0893,  0.7497, -0.7880,\n",
      "         -0.6168, -1.3058],\n",
      "        [-0.6539, -1.5951, -0.8654, -0.7037, -0.6985,  0.5069,  0.1076,  0.6572,\n",
      "          0.4638,  0.6835],\n",
      "        [-1.9651, -1.4434,  2.4470, -1.3480,  1.4204,  0.1728, -0.6199, -0.6909,\n",
      "          0.1849,  0.6148]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3261,  0.3733,  1.3040,  0.8836,  1.3603, -0.1219,  1.7963, -2.7218,\n",
      "          0.2867, -0.8553],\n",
      "        [ 0.4895,  1.0632, -0.7335, -0.6027,  1.1049, -0.0895,  0.7497, -0.7880,\n",
      "         -0.6170, -1.3058],\n",
      "        [-0.6542, -1.5951, -0.8654, -0.7038, -0.6985,  0.5071,  0.1076,  0.6572,\n",
      "          0.4639,  0.6835],\n",
      "        [-1.9652, -1.4434,  2.4470, -1.3480,  1.4204,  0.1729, -0.6199, -0.6909,\n",
      "          0.1849,  0.6148]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3261,  0.3734,  1.3039,  0.8836,  1.3603, -0.1220,  1.7963, -2.7218,\n",
      "          0.2865, -0.8553],\n",
      "        [ 0.4897,  1.0633, -0.7335, -0.6026,  1.1049, -0.0896,  0.7497, -0.7880,\n",
      "         -0.6172, -1.3058],\n",
      "        [-0.6544, -1.5951, -0.8655, -0.7039, -0.6985,  0.5073,  0.1076,  0.6572,\n",
      "          0.4639,  0.6835],\n",
      "        [-1.9653, -1.4434,  2.4470, -1.3481,  1.4204,  0.1730, -0.6199, -0.6909,\n",
      "          0.1850,  0.6148]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3262,  0.3735,  1.3038,  0.8836,  1.3603, -0.1220,  1.7963, -2.7218,\n",
      "          0.2863, -0.8553],\n",
      "        [ 0.4899,  1.0633, -0.7336, -0.6026,  1.1049, -0.0898,  0.7497, -0.7880,\n",
      "         -0.6174, -1.3058],\n",
      "        [-0.6546, -1.5951, -0.8655, -0.7040, -0.6985,  0.5074,  0.1076,  0.6572,\n",
      "          0.4639,  0.6834],\n",
      "        [-1.9654, -1.4434,  2.4470, -1.3481,  1.4204,  0.1730, -0.6199, -0.6909,\n",
      "          0.1850,  0.6148]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3262,  0.3736,  1.3037,  0.8836,  1.3603, -0.1221,  1.7963, -2.7218,\n",
      "          0.2861, -0.8553],\n",
      "        [ 0.4900,  1.0634, -0.7337, -0.6026,  1.1049, -0.0899,  0.7497, -0.7880,\n",
      "         -0.6176, -1.3058],\n",
      "        [-0.6548, -1.5951, -0.8655, -0.7041, -0.6985,  0.5076,  0.1076,  0.6572,\n",
      "          0.4639,  0.6834],\n",
      "        [-1.9655, -1.4434,  2.4470, -1.3481,  1.4204,  0.1731, -0.6199, -0.6909,\n",
      "          0.1850,  0.6148]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3263,  0.3737,  1.3036,  0.8836,  1.3603, -0.1222,  1.7963, -2.7218,\n",
      "          0.2858, -0.8553],\n",
      "        [ 0.4902,  1.0635, -0.7338, -0.6025,  1.1049, -0.0901,  0.7497, -0.7880,\n",
      "         -0.6178, -1.3058],\n",
      "        [-0.6551, -1.5952, -0.8655, -0.7042, -0.6985,  0.5078,  0.1076,  0.6572,\n",
      "          0.4639,  0.6834],\n",
      "        [-1.9656, -1.4434,  2.4470, -1.3482,  1.4204,  0.1732, -0.6199, -0.6909,\n",
      "          0.1850,  0.6148]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3263,  0.3738,  1.3034,  0.8835,  1.3603, -0.1223,  1.7963, -2.7218,\n",
      "          0.2856, -0.8553],\n",
      "        [ 0.4903,  1.0636, -0.7339, -0.6025,  1.1049, -0.0902,  0.7497, -0.7880,\n",
      "         -0.6179, -1.3058],\n",
      "        [-0.6553, -1.5952, -0.8655, -0.7043, -0.6985,  0.5080,  0.1076,  0.6572,\n",
      "          0.4640,  0.6834],\n",
      "        [-1.9657, -1.4435,  2.4470, -1.3482,  1.4204,  0.1733, -0.6199, -0.6909,\n",
      "          0.1851,  0.6148]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3263,  0.3738,  1.3033,  0.8835,  1.3603, -0.1224,  1.7963, -2.7218,\n",
      "          0.2854, -0.8553],\n",
      "        [ 0.4905,  1.0637, -0.7340, -0.6024,  1.1049, -0.0904,  0.7497, -0.7880,\n",
      "         -0.6181, -1.3058],\n",
      "        [-0.6555, -1.5952, -0.8656, -0.7044, -0.6985,  0.5081,  0.1076,  0.6572,\n",
      "          0.4640,  0.6834],\n",
      "        [-1.9658, -1.4435,  2.4470, -1.3483,  1.4204,  0.1734, -0.6199, -0.6909,\n",
      "          0.1851,  0.6148]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3264,  0.3739,  1.3032,  0.8835,  1.3603, -0.1224,  1.7963, -2.7218,\n",
      "          0.2852, -0.8554],\n",
      "        [ 0.4906,  1.0637, -0.7340, -0.6024,  1.1049, -0.0905,  0.7497, -0.7880,\n",
      "         -0.6183, -1.3058],\n",
      "        [-0.6558, -1.5952, -0.8656, -0.7045, -0.6985,  0.5083,  0.1076,  0.6572,\n",
      "          0.4640,  0.6834],\n",
      "        [-1.9659, -1.4435,  2.4470, -1.3483,  1.4204,  0.1735, -0.6199, -0.6909,\n",
      "          0.1851,  0.6148]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3264,  0.3740,  1.3031,  0.8835,  1.3603, -0.1225,  1.7963, -2.7218,\n",
      "          0.2850, -0.8554],\n",
      "        [ 0.4908,  1.0638, -0.7341, -0.6024,  1.1049, -0.0907,  0.7497, -0.7880,\n",
      "         -0.6185, -1.3058],\n",
      "        [-0.6560, -1.5952, -0.8656, -0.7046, -0.6985,  0.5085,  0.1076,  0.6572,\n",
      "          0.4640,  0.6834],\n",
      "        [-1.9660, -1.4435,  2.4470, -1.3483,  1.4204,  0.1735, -0.6199, -0.6909,\n",
      "          0.1851,  0.6148]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3265,  0.3741,  1.3030,  0.8835,  1.3603, -0.1226,  1.7963, -2.7218,\n",
      "          0.2848, -0.8554],\n",
      "        [ 0.4909,  1.0639, -0.7342, -0.6023,  1.1049, -0.0908,  0.7497, -0.7880,\n",
      "         -0.6187, -1.3058],\n",
      "        [-0.6562, -1.5953, -0.8656, -0.7047, -0.6985,  0.5087,  0.1076,  0.6572,\n",
      "          0.4640,  0.6834],\n",
      "        [-1.9661, -1.4435,  2.4470, -1.3484,  1.4204,  0.1736, -0.6199, -0.6909,\n",
      "          0.1852,  0.6148]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3265,  0.3742,  1.3029,  0.8834,  1.3603, -0.1227,  1.7963, -2.7218,\n",
      "          0.2846, -0.8554],\n",
      "        [ 0.4911,  1.0640, -0.7343, -0.6023,  1.1049, -0.0910,  0.7497, -0.7880,\n",
      "         -0.6189, -1.3058],\n",
      "        [-0.6564, -1.5953, -0.8657, -0.7048, -0.6985,  0.5089,  0.1076,  0.6572,\n",
      "          0.4641,  0.6833],\n",
      "        [-1.9662, -1.4435,  2.4470, -1.3484,  1.4204,  0.1737, -0.6199, -0.6909,\n",
      "          0.1852,  0.6148]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3266,  0.3742,  1.3028,  0.8834,  1.3603, -0.1227,  1.7963, -2.7218,\n",
      "          0.2844, -0.8554],\n",
      "        [ 0.4912,  1.0641, -0.7344, -0.6023,  1.1049, -0.0911,  0.7497, -0.7880,\n",
      "         -0.6190, -1.3058],\n",
      "        [-0.6567, -1.5953, -0.8657, -0.7049, -0.6985,  0.5090,  0.1076,  0.6572,\n",
      "          0.4641,  0.6833],\n",
      "        [-1.9663, -1.4436,  2.4470, -1.3485,  1.4204,  0.1738, -0.6199, -0.6909,\n",
      "          0.1852,  0.6148]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3266,  0.3743,  1.3027,  0.8834,  1.3603, -0.1228,  1.7963, -2.7218,\n",
      "          0.2842, -0.8554],\n",
      "        [ 0.4914,  1.0641, -0.7345, -0.6022,  1.1049, -0.0913,  0.7497, -0.7880,\n",
      "         -0.6192, -1.3058],\n",
      "        [-0.6569, -1.5953, -0.8657, -0.7050, -0.6985,  0.5092,  0.1076,  0.6572,\n",
      "          0.4641,  0.6833],\n",
      "        [-1.9664, -1.4436,  2.4470, -1.3485,  1.4204,  0.1739, -0.6199, -0.6909,\n",
      "          0.1852,  0.6148]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3267,  0.3744,  1.3025,  0.8834,  1.3603, -0.1229,  1.7963, -2.7218,\n",
      "          0.2839, -0.8555],\n",
      "        [ 0.4915,  1.0642, -0.7345, -0.6022,  1.1049, -0.0914,  0.7497, -0.7880,\n",
      "         -0.6194, -1.3058],\n",
      "        [-0.6571, -1.5953, -0.8657, -0.7051, -0.6985,  0.5094,  0.1076,  0.6572,\n",
      "          0.4641,  0.6833],\n",
      "        [-1.9665, -1.4436,  2.4470, -1.3485,  1.4204,  0.1740, -0.6199, -0.6909,\n",
      "          0.1853,  0.6148]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3267,  0.3745,  1.3024,  0.8834,  1.3603, -0.1230,  1.7963, -2.7218,\n",
      "          0.2837, -0.8555],\n",
      "        [ 0.4917,  1.0643, -0.7346, -0.6022,  1.1049, -0.0916,  0.7497, -0.7880,\n",
      "         -0.6196, -1.3059],\n",
      "        [-0.6573, -1.5954, -0.8657, -0.7052, -0.6985,  0.5096,  0.1076,  0.6572,\n",
      "          0.4642,  0.6833],\n",
      "        [-1.9666, -1.4436,  2.4470, -1.3486,  1.4204,  0.1740, -0.6199, -0.6909,\n",
      "          0.1853,  0.6148]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3267,  0.3746,  1.3023,  0.8833,  1.3603, -0.1230,  1.7963, -2.7218,\n",
      "          0.2835, -0.8555],\n",
      "        [ 0.4919,  1.0644, -0.7347, -0.6021,  1.1049, -0.0917,  0.7497, -0.7880,\n",
      "         -0.6198, -1.3059],\n",
      "        [-0.6576, -1.5954, -0.8658, -0.7053, -0.6985,  0.5097,  0.1076,  0.6572,\n",
      "          0.4642,  0.6833],\n",
      "        [-1.9667, -1.4436,  2.4470, -1.3486,  1.4204,  0.1741, -0.6199, -0.6909,\n",
      "          0.1853,  0.6148]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3268,  0.3747,  1.3022,  0.8833,  1.3603, -0.1231,  1.7963, -2.7218,\n",
      "          0.2833, -0.8555],\n",
      "        [ 0.4920,  1.0644, -0.7348, -0.6021,  1.1049, -0.0919,  0.7497, -0.7880,\n",
      "         -0.6200, -1.3059],\n",
      "        [-0.6578, -1.5954, -0.8658, -0.7054, -0.6985,  0.5099,  0.1076,  0.6572,\n",
      "          0.4642,  0.6833],\n",
      "        [-1.9668, -1.4436,  2.4470, -1.3487,  1.4204,  0.1742, -0.6199, -0.6909,\n",
      "          0.1853,  0.6148]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3268,  0.3747,  1.3021,  0.8833,  1.3603, -0.1232,  1.7963, -2.7218,\n",
      "          0.2831, -0.8555],\n",
      "        [ 0.4922,  1.0645, -0.7349, -0.6020,  1.1049, -0.0920,  0.7497, -0.7880,\n",
      "         -0.6201, -1.3059],\n",
      "        [-0.6580, -1.5954, -0.8658, -0.7055, -0.6985,  0.5101,  0.1076,  0.6572,\n",
      "          0.4642,  0.6833],\n",
      "        [-1.9669, -1.4436,  2.4470, -1.3487,  1.4204,  0.1743, -0.6199, -0.6909,\n",
      "          0.1854,  0.6148]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3269,  0.3748,  1.3020,  0.8833,  1.3603, -0.1233,  1.7963, -2.7218,\n",
      "          0.2829, -0.8555],\n",
      "        [ 0.4923,  1.0646, -0.7350, -0.6020,  1.1049, -0.0922,  0.7497, -0.7880,\n",
      "         -0.6203, -1.3059],\n",
      "        [-0.6583, -1.5955, -0.8658, -0.7056, -0.6985,  0.5103,  0.1076,  0.6572,\n",
      "          0.4642,  0.6832],\n",
      "        [-1.9669, -1.4437,  2.4470, -1.3487,  1.4204,  0.1744, -0.6199, -0.6909,\n",
      "          0.1854,  0.6147]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3269,  0.3749,  1.3019,  0.8833,  1.3603, -0.1233,  1.7963, -2.7218,\n",
      "          0.2827, -0.8555],\n",
      "        [ 0.4925,  1.0647, -0.7350, -0.6020,  1.1049, -0.0923,  0.7497, -0.7880,\n",
      "         -0.6205, -1.3059],\n",
      "        [-0.6585, -1.5955, -0.8658, -0.7057, -0.6985,  0.5104,  0.1076,  0.6572,\n",
      "          0.4643,  0.6832],\n",
      "        [-1.9670, -1.4437,  2.4470, -1.3488,  1.4204,  0.1745, -0.6199, -0.6909,\n",
      "          0.1854,  0.6147]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3270,  0.3750,  1.3017,  0.8833,  1.3603, -0.1234,  1.7963, -2.7218,\n",
      "          0.2825, -0.8556],\n",
      "        [ 0.4926,  1.0648, -0.7351, -0.6019,  1.1049, -0.0925,  0.7497, -0.7880,\n",
      "         -0.6207, -1.3059],\n",
      "        [-0.6587, -1.5955, -0.8659, -0.7058, -0.6985,  0.5106,  0.1076,  0.6572,\n",
      "          0.4643,  0.6832],\n",
      "        [-1.9671, -1.4437,  2.4470, -1.3488,  1.4204,  0.1745, -0.6199, -0.6909,\n",
      "          0.1854,  0.6147]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3270,  0.3751,  1.3016,  0.8832,  1.3603, -0.1235,  1.7963, -2.7218,\n",
      "          0.2823, -0.8556],\n",
      "        [ 0.4928,  1.0648, -0.7352, -0.6019,  1.1049, -0.0926,  0.7497, -0.7880,\n",
      "         -0.6209, -1.3059],\n",
      "        [-0.6589, -1.5955, -0.8659, -0.7059, -0.6985,  0.5108,  0.1076,  0.6572,\n",
      "          0.4643,  0.6832],\n",
      "        [-1.9672, -1.4437,  2.4470, -1.3488,  1.4204,  0.1746, -0.6199, -0.6909,\n",
      "          0.1855,  0.6147]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3270,  0.3751,  1.3015,  0.8832,  1.3603, -0.1236,  1.7963, -2.7218,\n",
      "          0.2821, -0.8556],\n",
      "        [ 0.4929,  1.0649, -0.7353, -0.6019,  1.1049, -0.0928,  0.7497, -0.7880,\n",
      "         -0.6210, -1.3059],\n",
      "        [-0.6592, -1.5955, -0.8659, -0.7060, -0.6985,  0.5110,  0.1076,  0.6572,\n",
      "          0.4643,  0.6832],\n",
      "        [-1.9673, -1.4437,  2.4470, -1.3489,  1.4204,  0.1747, -0.6199, -0.6909,\n",
      "          0.1855,  0.6147]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3271,  0.3752,  1.3014,  0.8832,  1.3603, -0.1236,  1.7963, -2.7218,\n",
      "          0.2819, -0.8556],\n",
      "        [ 0.4931,  1.0650, -0.7354, -0.6018,  1.1049, -0.0929,  0.7497, -0.7880,\n",
      "         -0.6212, -1.3059],\n",
      "        [-0.6594, -1.5956, -0.8659, -0.7061, -0.6985,  0.5112,  0.1076,  0.6572,\n",
      "          0.4644,  0.6832],\n",
      "        [-1.9674, -1.4437,  2.4470, -1.3489,  1.4204,  0.1748, -0.6199, -0.6909,\n",
      "          0.1855,  0.6147]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3271,  0.3753,  1.3013,  0.8832,  1.3603, -0.1237,  1.7963, -2.7218,\n",
      "          0.2817, -0.8556],\n",
      "        [ 0.4932,  1.0651, -0.7355, -0.6018,  1.1049, -0.0931,  0.7497, -0.7880,\n",
      "         -0.6214, -1.3059],\n",
      "        [-0.6596, -1.5956, -0.8660, -0.7062, -0.6985,  0.5113,  0.1076,  0.6572,\n",
      "          0.4644,  0.6832],\n",
      "        [-1.9675, -1.4437,  2.4470, -1.3490,  1.4204,  0.1749, -0.6199, -0.6909,\n",
      "          0.1855,  0.6147]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3272,  0.3754,  1.3012,  0.8832,  1.3603, -0.1238,  1.7963, -2.7218,\n",
      "          0.2815, -0.8556],\n",
      "        [ 0.4934,  1.0651, -0.7356, -0.6017,  1.1049, -0.0932,  0.7497, -0.7880,\n",
      "         -0.6216, -1.3059],\n",
      "        [-0.6598, -1.5956, -0.8660, -0.7063, -0.6985,  0.5115,  0.1076,  0.6572,\n",
      "          0.4644,  0.6832],\n",
      "        [-1.9676, -1.4438,  2.4470, -1.3490,  1.4204,  0.1749, -0.6199, -0.6909,\n",
      "          0.1856,  0.6147]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3272,  0.3755,  1.3011,  0.8832,  1.3603, -0.1239,  1.7963, -2.7218,\n",
      "          0.2813, -0.8556],\n",
      "        [ 0.4935,  1.0652, -0.7356, -0.6017,  1.1049, -0.0933,  0.7497, -0.7880,\n",
      "         -0.6218, -1.3059],\n",
      "        [-0.6601, -1.5956, -0.8660, -0.7064, -0.6985,  0.5117,  0.1076,  0.6572,\n",
      "          0.4644,  0.6832],\n",
      "        [-1.9677, -1.4438,  2.4470, -1.3490,  1.4204,  0.1750, -0.6199, -0.6909,\n",
      "          0.1856,  0.6147]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3273,  0.3755,  1.3010,  0.8831,  1.3603, -0.1239,  1.7963, -2.7218,\n",
      "          0.2811, -0.8557],\n",
      "        [ 0.4937,  1.0653, -0.7357, -0.6017,  1.1049, -0.0935,  0.7497, -0.7880,\n",
      "         -0.6219, -1.3059],\n",
      "        [-0.6603, -1.5956, -0.8660, -0.7065, -0.6985,  0.5119,  0.1076,  0.6572,\n",
      "          0.4645,  0.6831],\n",
      "        [-1.9678, -1.4438,  2.4470, -1.3491,  1.4204,  0.1751, -0.6199, -0.6909,\n",
      "          0.1856,  0.6147]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3273,  0.3756,  1.3008,  0.8831,  1.3603, -0.1240,  1.7963, -2.7218,\n",
      "          0.2808, -0.8557],\n",
      "        [ 0.4938,  1.0654, -0.7358, -0.6016,  1.1049, -0.0936,  0.7497, -0.7880,\n",
      "         -0.6221, -1.3059],\n",
      "        [-0.6605, -1.5957, -0.8660, -0.7066, -0.6985,  0.5120,  0.1076,  0.6572,\n",
      "          0.4645,  0.6831],\n",
      "        [-1.9679, -1.4438,  2.4470, -1.3491,  1.4204,  0.1752, -0.6199, -0.6909,\n",
      "          0.1857,  0.6147]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3273,  0.3757,  1.3007,  0.8831,  1.3603, -0.1241,  1.7963, -2.7218,\n",
      "          0.2806, -0.8557],\n",
      "        [ 0.4940,  1.0654, -0.7359, -0.6016,  1.1049, -0.0938,  0.7497, -0.7880,\n",
      "         -0.6223, -1.3060],\n",
      "        [-0.6607, -1.5957, -0.8661, -0.7067, -0.6985,  0.5122,  0.1076,  0.6572,\n",
      "          0.4645,  0.6831],\n",
      "        [-1.9680, -1.4438,  2.4470, -1.3492,  1.4204,  0.1753, -0.6199, -0.6909,\n",
      "          0.1857,  0.6147]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3274,  0.3758,  1.3006,  0.8831,  1.3603, -0.1242,  1.7963, -2.7218,\n",
      "          0.2804, -0.8557],\n",
      "        [ 0.4941,  1.0655, -0.7360, -0.6016,  1.1049, -0.0939,  0.7497, -0.7880,\n",
      "         -0.6225, -1.3060],\n",
      "        [-0.6610, -1.5957, -0.8661, -0.7068, -0.6985,  0.5124,  0.1076,  0.6572,\n",
      "          0.4645,  0.6831],\n",
      "        [-1.9681, -1.4438,  2.4470, -1.3492,  1.4204,  0.1754, -0.6199, -0.6909,\n",
      "          0.1857,  0.6147]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3274,  0.3758,  1.3005,  0.8831,  1.3603, -0.1242,  1.7963, -2.7218,\n",
      "          0.2802, -0.8557],\n",
      "        [ 0.4943,  1.0656, -0.7361, -0.6015,  1.1049, -0.0941,  0.7497, -0.7880,\n",
      "         -0.6227, -1.3060],\n",
      "        [-0.6612, -1.5957, -0.8661, -0.7069, -0.6985,  0.5126,  0.1076,  0.6572,\n",
      "          0.4646,  0.6831],\n",
      "        [-1.9682, -1.4439,  2.4470, -1.3492,  1.4204,  0.1754, -0.6199, -0.6909,\n",
      "          0.1857,  0.6147]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3275,  0.3759,  1.3004,  0.8830,  1.3603, -0.1243,  1.7963, -2.7218,\n",
      "          0.2800, -0.8557],\n",
      "        [ 0.4944,  1.0657, -0.7361, -0.6015,  1.1049, -0.0942,  0.7497, -0.7880,\n",
      "         -0.6228, -1.3060],\n",
      "        [-0.6614, -1.5958, -0.8661, -0.7070, -0.6985,  0.5127,  0.1076,  0.6572,\n",
      "          0.4646,  0.6831],\n",
      "        [-1.9683, -1.4439,  2.4470, -1.3493,  1.4204,  0.1755, -0.6199, -0.6909,\n",
      "          0.1858,  0.6147]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3275,  0.3760,  1.3003,  0.8830,  1.3603, -0.1244,  1.7963, -2.7218,\n",
      "          0.2798, -0.8557],\n",
      "        [ 0.4946,  1.0657, -0.7362, -0.6014,  1.1049, -0.0944,  0.7497, -0.7880,\n",
      "         -0.6230, -1.3060],\n",
      "        [-0.6616, -1.5958, -0.8662, -0.7071, -0.6985,  0.5129,  0.1076,  0.6572,\n",
      "          0.4646,  0.6831],\n",
      "        [-1.9684, -1.4439,  2.4470, -1.3493,  1.4204,  0.1756, -0.6199, -0.6909,\n",
      "          0.1858,  0.6147]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3275,  0.3761,  1.3002,  0.8830,  1.3603, -0.1245,  1.7963, -2.7218,\n",
      "          0.2796, -0.8558],\n",
      "        [ 0.4947,  1.0658, -0.7363, -0.6014,  1.1049, -0.0945,  0.7497, -0.7880,\n",
      "         -0.6232, -1.3060],\n",
      "        [-0.6618, -1.5958, -0.8662, -0.7072, -0.6985,  0.5131,  0.1076,  0.6572,\n",
      "          0.4646,  0.6831],\n",
      "        [-1.9685, -1.4439,  2.4470, -1.3494,  1.4204,  0.1757, -0.6199, -0.6909,\n",
      "          0.1858,  0.6147]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3276,  0.3762,  1.3000,  0.8830,  1.3603, -0.1245,  1.7963, -2.7218,\n",
      "          0.2794, -0.8558],\n",
      "        [ 0.4949,  1.0659, -0.7364, -0.6014,  1.1049, -0.0947,  0.7497, -0.7880,\n",
      "         -0.6234, -1.3060],\n",
      "        [-0.6621, -1.5958, -0.8662, -0.7073, -0.6985,  0.5133,  0.1076,  0.6572,\n",
      "          0.4647,  0.6830],\n",
      "        [-1.9686, -1.4439,  2.4470, -1.3494,  1.4204,  0.1758, -0.6199, -0.6909,\n",
      "          0.1858,  0.6147]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3276,  0.3762,  1.2999,  0.8830,  1.3603, -0.1246,  1.7963, -2.7218,\n",
      "          0.2792, -0.8558],\n",
      "        [ 0.4950,  1.0660, -0.7365, -0.6013,  1.1049, -0.0948,  0.7497, -0.7880,\n",
      "         -0.6235, -1.3060],\n",
      "        [-0.6623, -1.5958, -0.8662, -0.7074, -0.6985,  0.5134,  0.1076,  0.6572,\n",
      "          0.4647,  0.6830],\n",
      "        [-1.9686, -1.4439,  2.4470, -1.3494,  1.4204,  0.1758, -0.6199, -0.6909,\n",
      "          0.1859,  0.6147]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 0.3277,  0.3763,  1.2998,  0.8830,  1.3603, -0.1247,  1.7963, -2.7218,\n",
      "          0.2790, -0.8558],\n",
      "        [ 0.4952,  1.0660, -0.7366, -0.6013,  1.1049, -0.0950,  0.7497, -0.7880,\n",
      "         -0.6237, -1.3060],\n",
      "        [-0.6625, -1.5959, -0.8662, -0.7075, -0.6985,  0.5136,  0.1076,  0.6572,\n",
      "          0.4647,  0.6830],\n",
      "        [-1.9687, -1.4439,  2.4470, -1.3495,  1.4204,  0.1759, -0.6199, -0.6909,\n",
      "          0.1859,  0.6147]], dtype=torch.float64, grad_fn=<SubBackward0>)]\n",
      "[tensor([[ 1.9746],\n",
      "        [ 1.0707],\n",
      "        [-1.7374],\n",
      "        [ 0.1851],\n",
      "        [-0.1557],\n",
      "        [-0.6680],\n",
      "        [ 1.2140],\n",
      "        [ 0.7924],\n",
      "        [-0.4397],\n",
      "        [ 0.4996]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9754],\n",
      "        [ 1.0710],\n",
      "        [-1.7369],\n",
      "        [ 0.1861],\n",
      "        [-0.1552],\n",
      "        [-0.6679],\n",
      "        [ 1.2145],\n",
      "        [ 0.7924],\n",
      "        [-0.4394],\n",
      "        [ 0.4996]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9761],\n",
      "        [ 1.0714],\n",
      "        [-1.7364],\n",
      "        [ 0.1870],\n",
      "        [-0.1547],\n",
      "        [-0.6678],\n",
      "        [ 1.2150],\n",
      "        [ 0.7924],\n",
      "        [-0.4391],\n",
      "        [ 0.4995]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9768],\n",
      "        [ 1.0717],\n",
      "        [-1.7360],\n",
      "        [ 0.1880],\n",
      "        [-0.1543],\n",
      "        [-0.6678],\n",
      "        [ 1.2155],\n",
      "        [ 0.7924],\n",
      "        [-0.4389],\n",
      "        [ 0.4995]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9776],\n",
      "        [ 1.0721],\n",
      "        [-1.7356],\n",
      "        [ 0.1889],\n",
      "        [-0.1538],\n",
      "        [-0.6678],\n",
      "        [ 1.2159],\n",
      "        [ 0.7924],\n",
      "        [-0.4386],\n",
      "        [ 0.4995]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9783],\n",
      "        [ 1.0725],\n",
      "        [-1.7352],\n",
      "        [ 0.1898],\n",
      "        [-0.1534],\n",
      "        [-0.6677],\n",
      "        [ 1.2163],\n",
      "        [ 0.7924],\n",
      "        [-0.4384],\n",
      "        [ 0.4995]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9791],\n",
      "        [ 1.0728],\n",
      "        [-1.7348],\n",
      "        [ 0.1907],\n",
      "        [-0.1530],\n",
      "        [-0.6677],\n",
      "        [ 1.2167],\n",
      "        [ 0.7924],\n",
      "        [-0.4382],\n",
      "        [ 0.4995]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9799],\n",
      "        [ 1.0732],\n",
      "        [-1.7345],\n",
      "        [ 0.1915],\n",
      "        [-0.1527],\n",
      "        [-0.6677],\n",
      "        [ 1.2171],\n",
      "        [ 0.7924],\n",
      "        [-0.4380],\n",
      "        [ 0.4995]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9806],\n",
      "        [ 1.0735],\n",
      "        [-1.7341],\n",
      "        [ 0.1924],\n",
      "        [-0.1523],\n",
      "        [-0.6677],\n",
      "        [ 1.2175],\n",
      "        [ 0.7924],\n",
      "        [-0.4378],\n",
      "        [ 0.4994]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9814],\n",
      "        [ 1.0739],\n",
      "        [-1.7338],\n",
      "        [ 0.1932],\n",
      "        [-0.1520],\n",
      "        [-0.6678],\n",
      "        [ 1.2178],\n",
      "        [ 0.7924],\n",
      "        [-0.4377],\n",
      "        [ 0.4994]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9822],\n",
      "        [ 1.0743],\n",
      "        [-1.7335],\n",
      "        [ 0.1941],\n",
      "        [-0.1516],\n",
      "        [-0.6678],\n",
      "        [ 1.2181],\n",
      "        [ 0.7924],\n",
      "        [-0.4375],\n",
      "        [ 0.4994]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9829],\n",
      "        [ 1.0746],\n",
      "        [-1.7332],\n",
      "        [ 0.1949],\n",
      "        [-0.1513],\n",
      "        [-0.6678],\n",
      "        [ 1.2184],\n",
      "        [ 0.7924],\n",
      "        [-0.4374],\n",
      "        [ 0.4994]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9837],\n",
      "        [ 1.0750],\n",
      "        [-1.7330],\n",
      "        [ 0.1957],\n",
      "        [-0.1510],\n",
      "        [-0.6679],\n",
      "        [ 1.2187],\n",
      "        [ 0.7924],\n",
      "        [-0.4373],\n",
      "        [ 0.4994]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9845],\n",
      "        [ 1.0753],\n",
      "        [-1.7327],\n",
      "        [ 0.1965],\n",
      "        [-0.1508],\n",
      "        [-0.6680],\n",
      "        [ 1.2190],\n",
      "        [ 0.7924],\n",
      "        [-0.4372],\n",
      "        [ 0.4994]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9852],\n",
      "        [ 1.0757],\n",
      "        [-1.7325],\n",
      "        [ 0.1972],\n",
      "        [-0.1505],\n",
      "        [-0.6680],\n",
      "        [ 1.2192],\n",
      "        [ 0.7924],\n",
      "        [-0.4371],\n",
      "        [ 0.4993]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9860],\n",
      "        [ 1.0760],\n",
      "        [-1.7323],\n",
      "        [ 0.1980],\n",
      "        [-0.1503],\n",
      "        [-0.6681],\n",
      "        [ 1.2195],\n",
      "        [ 0.7924],\n",
      "        [-0.4371],\n",
      "        [ 0.4993]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9868],\n",
      "        [ 1.0764],\n",
      "        [-1.7321],\n",
      "        [ 0.1987],\n",
      "        [-0.1501],\n",
      "        [-0.6682],\n",
      "        [ 1.2197],\n",
      "        [ 0.7924],\n",
      "        [-0.4370],\n",
      "        [ 0.4993]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9876],\n",
      "        [ 1.0767],\n",
      "        [-1.7319],\n",
      "        [ 0.1995],\n",
      "        [-0.1499],\n",
      "        [-0.6683],\n",
      "        [ 1.2199],\n",
      "        [ 0.7924],\n",
      "        [-0.4370],\n",
      "        [ 0.4993]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9883],\n",
      "        [ 1.0771],\n",
      "        [-1.7318],\n",
      "        [ 0.2002],\n",
      "        [-0.1497],\n",
      "        [-0.6685],\n",
      "        [ 1.2201],\n",
      "        [ 0.7924],\n",
      "        [-0.4370],\n",
      "        [ 0.4993]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9891],\n",
      "        [ 1.0775],\n",
      "        [-1.7316],\n",
      "        [ 0.2009],\n",
      "        [-0.1495],\n",
      "        [-0.6686],\n",
      "        [ 1.2202],\n",
      "        [ 0.7924],\n",
      "        [-0.4370],\n",
      "        [ 0.4992]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9899],\n",
      "        [ 1.0778],\n",
      "        [-1.7315],\n",
      "        [ 0.2016],\n",
      "        [-0.1494],\n",
      "        [-0.6687],\n",
      "        [ 1.2204],\n",
      "        [ 0.7924],\n",
      "        [-0.4370],\n",
      "        [ 0.4992]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9907],\n",
      "        [ 1.0782],\n",
      "        [-1.7314],\n",
      "        [ 0.2023],\n",
      "        [-0.1492],\n",
      "        [-0.6689],\n",
      "        [ 1.2205],\n",
      "        [ 0.7924],\n",
      "        [-0.4371],\n",
      "        [ 0.4992]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9914],\n",
      "        [ 1.0785],\n",
      "        [-1.7313],\n",
      "        [ 0.2030],\n",
      "        [-0.1491],\n",
      "        [-0.6690],\n",
      "        [ 1.2206],\n",
      "        [ 0.7924],\n",
      "        [-0.4371],\n",
      "        [ 0.4992]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9922],\n",
      "        [ 1.0789],\n",
      "        [-1.7312],\n",
      "        [ 0.2036],\n",
      "        [-0.1490],\n",
      "        [-0.6692],\n",
      "        [ 1.2207],\n",
      "        [ 0.7924],\n",
      "        [-0.4372],\n",
      "        [ 0.4992]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9930],\n",
      "        [ 1.0792],\n",
      "        [-1.7311],\n",
      "        [ 0.2043],\n",
      "        [-0.1489],\n",
      "        [-0.6693],\n",
      "        [ 1.2208],\n",
      "        [ 0.7924],\n",
      "        [-0.4372],\n",
      "        [ 0.4992]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9938],\n",
      "        [ 1.0796],\n",
      "        [-1.7311],\n",
      "        [ 0.2049],\n",
      "        [-0.1488],\n",
      "        [-0.6695],\n",
      "        [ 1.2209],\n",
      "        [ 0.7924],\n",
      "        [-0.4373],\n",
      "        [ 0.4991]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9945],\n",
      "        [ 1.0800],\n",
      "        [-1.7310],\n",
      "        [ 0.2055],\n",
      "        [-0.1488],\n",
      "        [-0.6697],\n",
      "        [ 1.2210],\n",
      "        [ 0.7924],\n",
      "        [-0.4374],\n",
      "        [ 0.4991]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9953],\n",
      "        [ 1.0803],\n",
      "        [-1.7310],\n",
      "        [ 0.2062],\n",
      "        [-0.1487],\n",
      "        [-0.6699],\n",
      "        [ 1.2210],\n",
      "        [ 0.7924],\n",
      "        [-0.4375],\n",
      "        [ 0.4991]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9961],\n",
      "        [ 1.0807],\n",
      "        [-1.7310],\n",
      "        [ 0.2068],\n",
      "        [-0.1487],\n",
      "        [-0.6701],\n",
      "        [ 1.2211],\n",
      "        [ 0.7924],\n",
      "        [-0.4376],\n",
      "        [ 0.4991]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9969],\n",
      "        [ 1.0810],\n",
      "        [-1.7310],\n",
      "        [ 0.2074],\n",
      "        [-0.1486],\n",
      "        [-0.6703],\n",
      "        [ 1.2211],\n",
      "        [ 0.7924],\n",
      "        [-0.4378],\n",
      "        [ 0.4991]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9976],\n",
      "        [ 1.0814],\n",
      "        [-1.7310],\n",
      "        [ 0.2080],\n",
      "        [-0.1486],\n",
      "        [-0.6705],\n",
      "        [ 1.2211],\n",
      "        [ 0.7924],\n",
      "        [-0.4379],\n",
      "        [ 0.4991]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9984],\n",
      "        [ 1.0817],\n",
      "        [-1.7310],\n",
      "        [ 0.2086],\n",
      "        [-0.1486],\n",
      "        [-0.6707],\n",
      "        [ 1.2211],\n",
      "        [ 0.7924],\n",
      "        [-0.4381],\n",
      "        [ 0.4990]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9991],\n",
      "        [ 1.0821],\n",
      "        [-1.7310],\n",
      "        [ 0.2091],\n",
      "        [-0.1486],\n",
      "        [-0.6710],\n",
      "        [ 1.2211],\n",
      "        [ 0.7924],\n",
      "        [-0.4382],\n",
      "        [ 0.4990]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 1.9999],\n",
      "        [ 1.0825],\n",
      "        [-1.7310],\n",
      "        [ 0.2097],\n",
      "        [-0.1486],\n",
      "        [-0.6712],\n",
      "        [ 1.2211],\n",
      "        [ 0.7924],\n",
      "        [-0.4384],\n",
      "        [ 0.4990]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0007],\n",
      "        [ 1.0828],\n",
      "        [-1.7311],\n",
      "        [ 0.2103],\n",
      "        [-0.1487],\n",
      "        [-0.6715],\n",
      "        [ 1.2211],\n",
      "        [ 0.7924],\n",
      "        [-0.4386],\n",
      "        [ 0.4990]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0014],\n",
      "        [ 1.0832],\n",
      "        [-1.7311],\n",
      "        [ 0.2108],\n",
      "        [-0.1487],\n",
      "        [-0.6717],\n",
      "        [ 1.2211],\n",
      "        [ 0.7924],\n",
      "        [-0.4388],\n",
      "        [ 0.4990]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0022],\n",
      "        [ 1.0835],\n",
      "        [-1.7312],\n",
      "        [ 0.2114],\n",
      "        [-0.1488],\n",
      "        [-0.6720],\n",
      "        [ 1.2210],\n",
      "        [ 0.7924],\n",
      "        [-0.4390],\n",
      "        [ 0.4989]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0029],\n",
      "        [ 1.0839],\n",
      "        [-1.7313],\n",
      "        [ 0.2119],\n",
      "        [-0.1488],\n",
      "        [-0.6722],\n",
      "        [ 1.2210],\n",
      "        [ 0.7924],\n",
      "        [-0.4392],\n",
      "        [ 0.4989]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0037],\n",
      "        [ 1.0842],\n",
      "        [-1.7314],\n",
      "        [ 0.2125],\n",
      "        [-0.1489],\n",
      "        [-0.6725],\n",
      "        [ 1.2209],\n",
      "        [ 0.7924],\n",
      "        [-0.4394],\n",
      "        [ 0.4989]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0044],\n",
      "        [ 1.0846],\n",
      "        [-1.7315],\n",
      "        [ 0.2130],\n",
      "        [-0.1489],\n",
      "        [-0.6728],\n",
      "        [ 1.2208],\n",
      "        [ 0.7924],\n",
      "        [-0.4396],\n",
      "        [ 0.4989]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0052],\n",
      "        [ 1.0850],\n",
      "        [-1.7316],\n",
      "        [ 0.2135],\n",
      "        [-0.1490],\n",
      "        [-0.6730],\n",
      "        [ 1.2207],\n",
      "        [ 0.7924],\n",
      "        [-0.4398],\n",
      "        [ 0.4989]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0059],\n",
      "        [ 1.0853],\n",
      "        [-1.7317],\n",
      "        [ 0.2140],\n",
      "        [-0.1491],\n",
      "        [-0.6733],\n",
      "        [ 1.2206],\n",
      "        [ 0.7924],\n",
      "        [-0.4401],\n",
      "        [ 0.4989]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0067],\n",
      "        [ 1.0857],\n",
      "        [-1.7318],\n",
      "        [ 0.2145],\n",
      "        [-0.1492],\n",
      "        [-0.6736],\n",
      "        [ 1.2205],\n",
      "        [ 0.7924],\n",
      "        [-0.4403],\n",
      "        [ 0.4988]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0074],\n",
      "        [ 1.0861],\n",
      "        [-1.7319],\n",
      "        [ 0.2150],\n",
      "        [-0.1493],\n",
      "        [-0.6739],\n",
      "        [ 1.2204],\n",
      "        [ 0.7924],\n",
      "        [-0.4406],\n",
      "        [ 0.4988]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0082],\n",
      "        [ 1.0864],\n",
      "        [-1.7320],\n",
      "        [ 0.2155],\n",
      "        [-0.1494],\n",
      "        [-0.6742],\n",
      "        [ 1.2203],\n",
      "        [ 0.7924],\n",
      "        [-0.4409],\n",
      "        [ 0.4988]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0089],\n",
      "        [ 1.0868],\n",
      "        [-1.7322],\n",
      "        [ 0.2160],\n",
      "        [-0.1496],\n",
      "        [-0.6745],\n",
      "        [ 1.2202],\n",
      "        [ 0.7924],\n",
      "        [-0.4411],\n",
      "        [ 0.4988]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0096],\n",
      "        [ 1.0872],\n",
      "        [-1.7323],\n",
      "        [ 0.2165],\n",
      "        [-0.1497],\n",
      "        [-0.6748],\n",
      "        [ 1.2201],\n",
      "        [ 0.7924],\n",
      "        [-0.4414],\n",
      "        [ 0.4988]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0104],\n",
      "        [ 1.0875],\n",
      "        [-1.7325],\n",
      "        [ 0.2170],\n",
      "        [-0.1498],\n",
      "        [-0.6751],\n",
      "        [ 1.2199],\n",
      "        [ 0.7924],\n",
      "        [-0.4417],\n",
      "        [ 0.4987]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0111],\n",
      "        [ 1.0879],\n",
      "        [-1.7326],\n",
      "        [ 0.2175],\n",
      "        [-0.1500],\n",
      "        [-0.6754],\n",
      "        [ 1.2198],\n",
      "        [ 0.7924],\n",
      "        [-0.4420],\n",
      "        [ 0.4987]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0118],\n",
      "        [ 1.0883],\n",
      "        [-1.7328],\n",
      "        [ 0.2179],\n",
      "        [-0.1501],\n",
      "        [-0.6757],\n",
      "        [ 1.2196],\n",
      "        [ 0.7924],\n",
      "        [-0.4423],\n",
      "        [ 0.4987]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0126],\n",
      "        [ 1.0886],\n",
      "        [-1.7330],\n",
      "        [ 0.2184],\n",
      "        [-0.1503],\n",
      "        [-0.6761],\n",
      "        [ 1.2195],\n",
      "        [ 0.7924],\n",
      "        [-0.4426],\n",
      "        [ 0.4987]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0133],\n",
      "        [ 1.0890],\n",
      "        [-1.7332],\n",
      "        [ 0.2189],\n",
      "        [-0.1504],\n",
      "        [-0.6764],\n",
      "        [ 1.2193],\n",
      "        [ 0.7924],\n",
      "        [-0.4429],\n",
      "        [ 0.4987]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0140],\n",
      "        [ 1.0894],\n",
      "        [-1.7333],\n",
      "        [ 0.2193],\n",
      "        [-0.1506],\n",
      "        [-0.6767],\n",
      "        [ 1.2192],\n",
      "        [ 0.7924],\n",
      "        [-0.4432],\n",
      "        [ 0.4987]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0148],\n",
      "        [ 1.0897],\n",
      "        [-1.7335],\n",
      "        [ 0.2198],\n",
      "        [-0.1508],\n",
      "        [-0.6771],\n",
      "        [ 1.2190],\n",
      "        [ 0.7924],\n",
      "        [-0.4435],\n",
      "        [ 0.4986]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0155],\n",
      "        [ 1.0901],\n",
      "        [-1.7337],\n",
      "        [ 0.2202],\n",
      "        [-0.1510],\n",
      "        [-0.6774],\n",
      "        [ 1.2188],\n",
      "        [ 0.7924],\n",
      "        [-0.4438],\n",
      "        [ 0.4986]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0162],\n",
      "        [ 1.0905],\n",
      "        [-1.7339],\n",
      "        [ 0.2207],\n",
      "        [-0.1511],\n",
      "        [-0.6777],\n",
      "        [ 1.2186],\n",
      "        [ 0.7924],\n",
      "        [-0.4441],\n",
      "        [ 0.4986]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0169],\n",
      "        [ 1.0909],\n",
      "        [-1.7341],\n",
      "        [ 0.2211],\n",
      "        [-0.1513],\n",
      "        [-0.6781],\n",
      "        [ 1.2184],\n",
      "        [ 0.7924],\n",
      "        [-0.4445],\n",
      "        [ 0.4986]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0176],\n",
      "        [ 1.0912],\n",
      "        [-1.7344],\n",
      "        [ 0.2215],\n",
      "        [-0.1515],\n",
      "        [-0.6784],\n",
      "        [ 1.2182],\n",
      "        [ 0.7924],\n",
      "        [-0.4448],\n",
      "        [ 0.4986]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0183],\n",
      "        [ 1.0916],\n",
      "        [-1.7346],\n",
      "        [ 0.2220],\n",
      "        [-0.1517],\n",
      "        [-0.6788],\n",
      "        [ 1.2180],\n",
      "        [ 0.7924],\n",
      "        [-0.4452],\n",
      "        [ 0.4985]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0190],\n",
      "        [ 1.0920],\n",
      "        [-1.7348],\n",
      "        [ 0.2224],\n",
      "        [-0.1519],\n",
      "        [-0.6791],\n",
      "        [ 1.2178],\n",
      "        [ 0.7924],\n",
      "        [-0.4455],\n",
      "        [ 0.4985]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0198],\n",
      "        [ 1.0924],\n",
      "        [-1.7350],\n",
      "        [ 0.2228],\n",
      "        [-0.1521],\n",
      "        [-0.6795],\n",
      "        [ 1.2176],\n",
      "        [ 0.7924],\n",
      "        [-0.4458],\n",
      "        [ 0.4985]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0205],\n",
      "        [ 1.0928],\n",
      "        [-1.7352],\n",
      "        [ 0.2233],\n",
      "        [-0.1523],\n",
      "        [-0.6799],\n",
      "        [ 1.2174],\n",
      "        [ 0.7924],\n",
      "        [-0.4462],\n",
      "        [ 0.4985]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0212],\n",
      "        [ 1.0931],\n",
      "        [-1.7355],\n",
      "        [ 0.2237],\n",
      "        [-0.1525],\n",
      "        [-0.6802],\n",
      "        [ 1.2172],\n",
      "        [ 0.7924],\n",
      "        [-0.4465],\n",
      "        [ 0.4985]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0219],\n",
      "        [ 1.0935],\n",
      "        [-1.7357],\n",
      "        [ 0.2241],\n",
      "        [-0.1528],\n",
      "        [-0.6806],\n",
      "        [ 1.2170],\n",
      "        [ 0.7924],\n",
      "        [-0.4469],\n",
      "        [ 0.4985]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0226],\n",
      "        [ 1.0939],\n",
      "        [-1.7359],\n",
      "        [ 0.2245],\n",
      "        [-0.1530],\n",
      "        [-0.6810],\n",
      "        [ 1.2168],\n",
      "        [ 0.7924],\n",
      "        [-0.4473],\n",
      "        [ 0.4984]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0233],\n",
      "        [ 1.0943],\n",
      "        [-1.7362],\n",
      "        [ 0.2249],\n",
      "        [-0.1532],\n",
      "        [-0.6813],\n",
      "        [ 1.2165],\n",
      "        [ 0.7924],\n",
      "        [-0.4476],\n",
      "        [ 0.4984]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0240],\n",
      "        [ 1.0947],\n",
      "        [-1.7364],\n",
      "        [ 0.2253],\n",
      "        [-0.1534],\n",
      "        [-0.6817],\n",
      "        [ 1.2163],\n",
      "        [ 0.7924],\n",
      "        [-0.4480],\n",
      "        [ 0.4984]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0247],\n",
      "        [ 1.0951],\n",
      "        [-1.7367],\n",
      "        [ 0.2257],\n",
      "        [-0.1537],\n",
      "        [-0.6821],\n",
      "        [ 1.2161],\n",
      "        [ 0.7924],\n",
      "        [-0.4484],\n",
      "        [ 0.4984]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0254],\n",
      "        [ 1.0955],\n",
      "        [-1.7369],\n",
      "        [ 0.2262],\n",
      "        [-0.1539],\n",
      "        [-0.6825],\n",
      "        [ 1.2158],\n",
      "        [ 0.7924],\n",
      "        [-0.4487],\n",
      "        [ 0.4984]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0261],\n",
      "        [ 1.0959],\n",
      "        [-1.7372],\n",
      "        [ 0.2266],\n",
      "        [-0.1542],\n",
      "        [-0.6828],\n",
      "        [ 1.2156],\n",
      "        [ 0.7924],\n",
      "        [-0.4491],\n",
      "        [ 0.4984]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0267],\n",
      "        [ 1.0962],\n",
      "        [-1.7375],\n",
      "        [ 0.2270],\n",
      "        [-0.1544],\n",
      "        [-0.6832],\n",
      "        [ 1.2154],\n",
      "        [ 0.7924],\n",
      "        [-0.4495],\n",
      "        [ 0.4983]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0274],\n",
      "        [ 1.0966],\n",
      "        [-1.7377],\n",
      "        [ 0.2274],\n",
      "        [-0.1546],\n",
      "        [-0.6836],\n",
      "        [ 1.2151],\n",
      "        [ 0.7924],\n",
      "        [-0.4499],\n",
      "        [ 0.4983]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0281],\n",
      "        [ 1.0970],\n",
      "        [-1.7380],\n",
      "        [ 0.2278],\n",
      "        [-0.1549],\n",
      "        [-0.6840],\n",
      "        [ 1.2149],\n",
      "        [ 0.7924],\n",
      "        [-0.4503],\n",
      "        [ 0.4983]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0288],\n",
      "        [ 1.0974],\n",
      "        [-1.7382],\n",
      "        [ 0.2281],\n",
      "        [-0.1551],\n",
      "        [-0.6844],\n",
      "        [ 1.2146],\n",
      "        [ 0.7924],\n",
      "        [-0.4507],\n",
      "        [ 0.4983]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0295],\n",
      "        [ 1.0978],\n",
      "        [-1.7385],\n",
      "        [ 0.2285],\n",
      "        [-0.1554],\n",
      "        [-0.6848],\n",
      "        [ 1.2144],\n",
      "        [ 0.7924],\n",
      "        [-0.4510],\n",
      "        [ 0.4983]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0302],\n",
      "        [ 1.0982],\n",
      "        [-1.7388],\n",
      "        [ 0.2289],\n",
      "        [-0.1556],\n",
      "        [-0.6852],\n",
      "        [ 1.2141],\n",
      "        [ 0.7924],\n",
      "        [-0.4514],\n",
      "        [ 0.4982]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0308],\n",
      "        [ 1.0986],\n",
      "        [-1.7391],\n",
      "        [ 0.2293],\n",
      "        [-0.1559],\n",
      "        [-0.6856],\n",
      "        [ 1.2139],\n",
      "        [ 0.7924],\n",
      "        [-0.4518],\n",
      "        [ 0.4982]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0315],\n",
      "        [ 1.0990],\n",
      "        [-1.7393],\n",
      "        [ 0.2297],\n",
      "        [-0.1562],\n",
      "        [-0.6860],\n",
      "        [ 1.2136],\n",
      "        [ 0.7924],\n",
      "        [-0.4522],\n",
      "        [ 0.4982]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0322],\n",
      "        [ 1.0994],\n",
      "        [-1.7396],\n",
      "        [ 0.2301],\n",
      "        [-0.1564],\n",
      "        [-0.6864],\n",
      "        [ 1.2133],\n",
      "        [ 0.7924],\n",
      "        [-0.4526],\n",
      "        [ 0.4982]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0329],\n",
      "        [ 1.0998],\n",
      "        [-1.7399],\n",
      "        [ 0.2305],\n",
      "        [-0.1567],\n",
      "        [-0.6868],\n",
      "        [ 1.2131],\n",
      "        [ 0.7924],\n",
      "        [-0.4530],\n",
      "        [ 0.4982]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0336],\n",
      "        [ 1.1002],\n",
      "        [-1.7402],\n",
      "        [ 0.2308],\n",
      "        [-0.1570],\n",
      "        [-0.6872],\n",
      "        [ 1.2128],\n",
      "        [ 0.7924],\n",
      "        [-0.4534],\n",
      "        [ 0.4982]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0342],\n",
      "        [ 1.1007],\n",
      "        [-1.7405],\n",
      "        [ 0.2312],\n",
      "        [-0.1572],\n",
      "        [-0.6876],\n",
      "        [ 1.2125],\n",
      "        [ 0.7924],\n",
      "        [-0.4538],\n",
      "        [ 0.4981]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0349],\n",
      "        [ 1.1011],\n",
      "        [-1.7408],\n",
      "        [ 0.2316],\n",
      "        [-0.1575],\n",
      "        [-0.6880],\n",
      "        [ 1.2123],\n",
      "        [ 0.7924],\n",
      "        [-0.4542],\n",
      "        [ 0.4981]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0356],\n",
      "        [ 1.1015],\n",
      "        [-1.7410],\n",
      "        [ 0.2320],\n",
      "        [-0.1578],\n",
      "        [-0.6884],\n",
      "        [ 1.2120],\n",
      "        [ 0.7924],\n",
      "        [-0.4546],\n",
      "        [ 0.4981]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0362],\n",
      "        [ 1.1019],\n",
      "        [-1.7413],\n",
      "        [ 0.2324],\n",
      "        [-0.1580],\n",
      "        [-0.6888],\n",
      "        [ 1.2117],\n",
      "        [ 0.7924],\n",
      "        [-0.4550],\n",
      "        [ 0.4981]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0369],\n",
      "        [ 1.1023],\n",
      "        [-1.7416],\n",
      "        [ 0.2327],\n",
      "        [-0.1583],\n",
      "        [-0.6892],\n",
      "        [ 1.2114],\n",
      "        [ 0.7924],\n",
      "        [-0.4554],\n",
      "        [ 0.4981]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0376],\n",
      "        [ 1.1027],\n",
      "        [-1.7419],\n",
      "        [ 0.2331],\n",
      "        [-0.1586],\n",
      "        [-0.6896],\n",
      "        [ 1.2112],\n",
      "        [ 0.7924],\n",
      "        [-0.4559],\n",
      "        [ 0.4981]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0382],\n",
      "        [ 1.1031],\n",
      "        [-1.7422],\n",
      "        [ 0.2335],\n",
      "        [-0.1589],\n",
      "        [-0.6900],\n",
      "        [ 1.2109],\n",
      "        [ 0.7924],\n",
      "        [-0.4563],\n",
      "        [ 0.4980]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0389],\n",
      "        [ 1.1036],\n",
      "        [-1.7425],\n",
      "        [ 0.2338],\n",
      "        [-0.1591],\n",
      "        [-0.6904],\n",
      "        [ 1.2106],\n",
      "        [ 0.7924],\n",
      "        [-0.4567],\n",
      "        [ 0.4980]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0396],\n",
      "        [ 1.1040],\n",
      "        [-1.7428],\n",
      "        [ 0.2342],\n",
      "        [-0.1594],\n",
      "        [-0.6908],\n",
      "        [ 1.2103],\n",
      "        [ 0.7924],\n",
      "        [-0.4571],\n",
      "        [ 0.4980]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0402],\n",
      "        [ 1.1044],\n",
      "        [-1.7431],\n",
      "        [ 0.2346],\n",
      "        [-0.1597],\n",
      "        [-0.6912],\n",
      "        [ 1.2101],\n",
      "        [ 0.7924],\n",
      "        [-0.4575],\n",
      "        [ 0.4980]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0409],\n",
      "        [ 1.1048],\n",
      "        [-1.7434],\n",
      "        [ 0.2349],\n",
      "        [-0.1600],\n",
      "        [-0.6917],\n",
      "        [ 1.2098],\n",
      "        [ 0.7924],\n",
      "        [-0.4579],\n",
      "        [ 0.4980]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0415],\n",
      "        [ 1.1052],\n",
      "        [-1.7437],\n",
      "        [ 0.2353],\n",
      "        [-0.1603],\n",
      "        [-0.6921],\n",
      "        [ 1.2095],\n",
      "        [ 0.7924],\n",
      "        [-0.4583],\n",
      "        [ 0.4980]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0422],\n",
      "        [ 1.1057],\n",
      "        [-1.7440],\n",
      "        [ 0.2357],\n",
      "        [-0.1606],\n",
      "        [-0.6925],\n",
      "        [ 1.2092],\n",
      "        [ 0.7924],\n",
      "        [-0.4588],\n",
      "        [ 0.4979]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0428],\n",
      "        [ 1.1061],\n",
      "        [-1.7443],\n",
      "        [ 0.2360],\n",
      "        [-0.1608],\n",
      "        [-0.6929],\n",
      "        [ 1.2089],\n",
      "        [ 0.7924],\n",
      "        [-0.4592],\n",
      "        [ 0.4979]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0435],\n",
      "        [ 1.1065],\n",
      "        [-1.7446],\n",
      "        [ 0.2364],\n",
      "        [-0.1611],\n",
      "        [-0.6933],\n",
      "        [ 1.2086],\n",
      "        [ 0.7924],\n",
      "        [-0.4596],\n",
      "        [ 0.4979]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0441],\n",
      "        [ 1.1070],\n",
      "        [-1.7449],\n",
      "        [ 0.2367],\n",
      "        [-0.1614],\n",
      "        [-0.6937],\n",
      "        [ 1.2083],\n",
      "        [ 0.7924],\n",
      "        [-0.4600],\n",
      "        [ 0.4979]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0448],\n",
      "        [ 1.1074],\n",
      "        [-1.7452],\n",
      "        [ 0.2371],\n",
      "        [-0.1617],\n",
      "        [-0.6942],\n",
      "        [ 1.2080],\n",
      "        [ 0.7924],\n",
      "        [-0.4604],\n",
      "        [ 0.4979]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0454],\n",
      "        [ 1.1078],\n",
      "        [-1.7455],\n",
      "        [ 0.2375],\n",
      "        [-0.1620],\n",
      "        [-0.6946],\n",
      "        [ 1.2078],\n",
      "        [ 0.7924],\n",
      "        [-0.4609],\n",
      "        [ 0.4978]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0461],\n",
      "        [ 1.1083],\n",
      "        [-1.7458],\n",
      "        [ 0.2378],\n",
      "        [-0.1623],\n",
      "        [-0.6950],\n",
      "        [ 1.2075],\n",
      "        [ 0.7924],\n",
      "        [-0.4613],\n",
      "        [ 0.4978]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0467],\n",
      "        [ 1.1087],\n",
      "        [-1.7461],\n",
      "        [ 0.2382],\n",
      "        [-0.1626],\n",
      "        [-0.6954],\n",
      "        [ 1.2072],\n",
      "        [ 0.7924],\n",
      "        [-0.4617],\n",
      "        [ 0.4978]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0474],\n",
      "        [ 1.1091],\n",
      "        [-1.7464],\n",
      "        [ 0.2385],\n",
      "        [-0.1629],\n",
      "        [-0.6958],\n",
      "        [ 1.2069],\n",
      "        [ 0.7924],\n",
      "        [-0.4621],\n",
      "        [ 0.4978]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0480],\n",
      "        [ 1.1096],\n",
      "        [-1.7468],\n",
      "        [ 0.2389],\n",
      "        [-0.1632],\n",
      "        [-0.6963],\n",
      "        [ 1.2066],\n",
      "        [ 0.7924],\n",
      "        [-0.4626],\n",
      "        [ 0.4978]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0487],\n",
      "        [ 1.1100],\n",
      "        [-1.7471],\n",
      "        [ 0.2392],\n",
      "        [-0.1635],\n",
      "        [-0.6967],\n",
      "        [ 1.2063],\n",
      "        [ 0.7924],\n",
      "        [-0.4630],\n",
      "        [ 0.4978]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0493],\n",
      "        [ 1.1105],\n",
      "        [-1.7474],\n",
      "        [ 0.2396],\n",
      "        [-0.1638],\n",
      "        [-0.6971],\n",
      "        [ 1.2060],\n",
      "        [ 0.7924],\n",
      "        [-0.4634],\n",
      "        [ 0.4977]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0499],\n",
      "        [ 1.1109],\n",
      "        [-1.7477],\n",
      "        [ 0.2400],\n",
      "        [-0.1641],\n",
      "        [-0.6975],\n",
      "        [ 1.2057],\n",
      "        [ 0.7924],\n",
      "        [-0.4638],\n",
      "        [ 0.4977]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0506],\n",
      "        [ 1.1114],\n",
      "        [-1.7480],\n",
      "        [ 0.2403],\n",
      "        [-0.1644],\n",
      "        [-0.6980],\n",
      "        [ 1.2054],\n",
      "        [ 0.7924],\n",
      "        [-0.4643],\n",
      "        [ 0.4977]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0512],\n",
      "        [ 1.1118],\n",
      "        [-1.7483],\n",
      "        [ 0.2407],\n",
      "        [-0.1646],\n",
      "        [-0.6984],\n",
      "        [ 1.2051],\n",
      "        [ 0.7924],\n",
      "        [-0.4647],\n",
      "        [ 0.4977]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0519],\n",
      "        [ 1.1123],\n",
      "        [-1.7486],\n",
      "        [ 0.2410],\n",
      "        [-0.1649],\n",
      "        [-0.6988],\n",
      "        [ 1.2048],\n",
      "        [ 0.7924],\n",
      "        [-0.4651],\n",
      "        [ 0.4977]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0525],\n",
      "        [ 1.1127],\n",
      "        [-1.7489],\n",
      "        [ 0.2414],\n",
      "        [-0.1652],\n",
      "        [-0.6992],\n",
      "        [ 1.2045],\n",
      "        [ 0.7924],\n",
      "        [-0.4655],\n",
      "        [ 0.4977]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0531],\n",
      "        [ 1.1132],\n",
      "        [-1.7493],\n",
      "        [ 0.2417],\n",
      "        [-0.1655],\n",
      "        [-0.6997],\n",
      "        [ 1.2042],\n",
      "        [ 0.7924],\n",
      "        [-0.4660],\n",
      "        [ 0.4976]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0538],\n",
      "        [ 1.1136],\n",
      "        [-1.7496],\n",
      "        [ 0.2420],\n",
      "        [-0.1658],\n",
      "        [-0.7001],\n",
      "        [ 1.2039],\n",
      "        [ 0.7924],\n",
      "        [-0.4664],\n",
      "        [ 0.4976]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0544],\n",
      "        [ 1.1141],\n",
      "        [-1.7499],\n",
      "        [ 0.2424],\n",
      "        [-0.1661],\n",
      "        [-0.7005],\n",
      "        [ 1.2036],\n",
      "        [ 0.7924],\n",
      "        [-0.4668],\n",
      "        [ 0.4976]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0550],\n",
      "        [ 1.1145],\n",
      "        [-1.7502],\n",
      "        [ 0.2427],\n",
      "        [-0.1664],\n",
      "        [-0.7010],\n",
      "        [ 1.2033],\n",
      "        [ 0.7924],\n",
      "        [-0.4673],\n",
      "        [ 0.4976]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0557],\n",
      "        [ 1.1150],\n",
      "        [-1.7505],\n",
      "        [ 0.2431],\n",
      "        [-0.1667],\n",
      "        [-0.7014],\n",
      "        [ 1.2030],\n",
      "        [ 0.7924],\n",
      "        [-0.4677],\n",
      "        [ 0.4976]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0563],\n",
      "        [ 1.1154],\n",
      "        [-1.7508],\n",
      "        [ 0.2434],\n",
      "        [-0.1670],\n",
      "        [-0.7018],\n",
      "        [ 1.2027],\n",
      "        [ 0.7924],\n",
      "        [-0.4681],\n",
      "        [ 0.4976]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0569],\n",
      "        [ 1.1159],\n",
      "        [-1.7511],\n",
      "        [ 0.2438],\n",
      "        [-0.1673],\n",
      "        [-0.7022],\n",
      "        [ 1.2024],\n",
      "        [ 0.7924],\n",
      "        [-0.4686],\n",
      "        [ 0.4976]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0575],\n",
      "        [ 1.1164],\n",
      "        [-1.7515],\n",
      "        [ 0.2441],\n",
      "        [-0.1676],\n",
      "        [-0.7027],\n",
      "        [ 1.2021],\n",
      "        [ 0.7924],\n",
      "        [-0.4690],\n",
      "        [ 0.4975]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0582],\n",
      "        [ 1.1168],\n",
      "        [-1.7518],\n",
      "        [ 0.2445],\n",
      "        [-0.1679],\n",
      "        [-0.7031],\n",
      "        [ 1.2018],\n",
      "        [ 0.7924],\n",
      "        [-0.4694],\n",
      "        [ 0.4975]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0588],\n",
      "        [ 1.1173],\n",
      "        [-1.7521],\n",
      "        [ 0.2448],\n",
      "        [-0.1682],\n",
      "        [-0.7035],\n",
      "        [ 1.2015],\n",
      "        [ 0.7924],\n",
      "        [-0.4698],\n",
      "        [ 0.4975]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0594],\n",
      "        [ 1.1178],\n",
      "        [-1.7524],\n",
      "        [ 0.2452],\n",
      "        [-0.1685],\n",
      "        [-0.7040],\n",
      "        [ 1.2012],\n",
      "        [ 0.7924],\n",
      "        [-0.4703],\n",
      "        [ 0.4975]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0600],\n",
      "        [ 1.1182],\n",
      "        [-1.7527],\n",
      "        [ 0.2455],\n",
      "        [-0.1688],\n",
      "        [-0.7044],\n",
      "        [ 1.2009],\n",
      "        [ 0.7924],\n",
      "        [-0.4707],\n",
      "        [ 0.4975]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0606],\n",
      "        [ 1.1187],\n",
      "        [-1.7530],\n",
      "        [ 0.2458],\n",
      "        [-0.1691],\n",
      "        [-0.7048],\n",
      "        [ 1.2006],\n",
      "        [ 0.7924],\n",
      "        [-0.4711],\n",
      "        [ 0.4975]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0613],\n",
      "        [ 1.1192],\n",
      "        [-1.7534],\n",
      "        [ 0.2462],\n",
      "        [-0.1694],\n",
      "        [-0.7053],\n",
      "        [ 1.2003],\n",
      "        [ 0.7924],\n",
      "        [-0.4716],\n",
      "        [ 0.4974]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0619],\n",
      "        [ 1.1196],\n",
      "        [-1.7537],\n",
      "        [ 0.2465],\n",
      "        [-0.1697],\n",
      "        [-0.7057],\n",
      "        [ 1.2000],\n",
      "        [ 0.7924],\n",
      "        [-0.4720],\n",
      "        [ 0.4974]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0625],\n",
      "        [ 1.1201],\n",
      "        [-1.7540],\n",
      "        [ 0.2469],\n",
      "        [-0.1700],\n",
      "        [-0.7061],\n",
      "        [ 1.1997],\n",
      "        [ 0.7924],\n",
      "        [-0.4724],\n",
      "        [ 0.4974]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0631],\n",
      "        [ 1.1206],\n",
      "        [-1.7543],\n",
      "        [ 0.2472],\n",
      "        [-0.1704],\n",
      "        [-0.7066],\n",
      "        [ 1.1994],\n",
      "        [ 0.7924],\n",
      "        [-0.4729],\n",
      "        [ 0.4974]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0637],\n",
      "        [ 1.1211],\n",
      "        [-1.7546],\n",
      "        [ 0.2475],\n",
      "        [-0.1707],\n",
      "        [-0.7070],\n",
      "        [ 1.1991],\n",
      "        [ 0.7924],\n",
      "        [-0.4733],\n",
      "        [ 0.4974]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0643],\n",
      "        [ 1.1216],\n",
      "        [-1.7549],\n",
      "        [ 0.2479],\n",
      "        [-0.1710],\n",
      "        [-0.7074],\n",
      "        [ 1.1988],\n",
      "        [ 0.7924],\n",
      "        [-0.4737],\n",
      "        [ 0.4974]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0650],\n",
      "        [ 1.1220],\n",
      "        [-1.7553],\n",
      "        [ 0.2482],\n",
      "        [-0.1713],\n",
      "        [-0.7079],\n",
      "        [ 1.1985],\n",
      "        [ 0.7924],\n",
      "        [-0.4741],\n",
      "        [ 0.4973]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0656],\n",
      "        [ 1.1225],\n",
      "        [-1.7556],\n",
      "        [ 0.2486],\n",
      "        [-0.1716],\n",
      "        [-0.7083],\n",
      "        [ 1.1982],\n",
      "        [ 0.7924],\n",
      "        [-0.4746],\n",
      "        [ 0.4973]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0662],\n",
      "        [ 1.1230],\n",
      "        [-1.7559],\n",
      "        [ 0.2489],\n",
      "        [-0.1719],\n",
      "        [-0.7087],\n",
      "        [ 1.1979],\n",
      "        [ 0.7924],\n",
      "        [-0.4750],\n",
      "        [ 0.4973]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0668],\n",
      "        [ 1.1235],\n",
      "        [-1.7562],\n",
      "        [ 0.2492],\n",
      "        [-0.1722],\n",
      "        [-0.7092],\n",
      "        [ 1.1976],\n",
      "        [ 0.7924],\n",
      "        [-0.4754],\n",
      "        [ 0.4973]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0674],\n",
      "        [ 1.1240],\n",
      "        [-1.7565],\n",
      "        [ 0.2496],\n",
      "        [-0.1725],\n",
      "        [-0.7096],\n",
      "        [ 1.1973],\n",
      "        [ 0.7924],\n",
      "        [-0.4759],\n",
      "        [ 0.4973]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0680],\n",
      "        [ 1.1245],\n",
      "        [-1.7569],\n",
      "        [ 0.2499],\n",
      "        [-0.1728],\n",
      "        [-0.7100],\n",
      "        [ 1.1970],\n",
      "        [ 0.7924],\n",
      "        [-0.4763],\n",
      "        [ 0.4973]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0686],\n",
      "        [ 1.1250],\n",
      "        [-1.7572],\n",
      "        [ 0.2502],\n",
      "        [-0.1731],\n",
      "        [-0.7105],\n",
      "        [ 1.1967],\n",
      "        [ 0.7924],\n",
      "        [-0.4767],\n",
      "        [ 0.4972]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0692],\n",
      "        [ 1.1254],\n",
      "        [-1.7575],\n",
      "        [ 0.2506],\n",
      "        [-0.1734],\n",
      "        [-0.7109],\n",
      "        [ 1.1964],\n",
      "        [ 0.7924],\n",
      "        [-0.4772],\n",
      "        [ 0.4972]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0698],\n",
      "        [ 1.1259],\n",
      "        [-1.7578],\n",
      "        [ 0.2509],\n",
      "        [-0.1737],\n",
      "        [-0.7113],\n",
      "        [ 1.1961],\n",
      "        [ 0.7924],\n",
      "        [-0.4776],\n",
      "        [ 0.4972]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0704],\n",
      "        [ 1.1264],\n",
      "        [-1.7581],\n",
      "        [ 0.2512],\n",
      "        [-0.1740],\n",
      "        [-0.7118],\n",
      "        [ 1.1958],\n",
      "        [ 0.7924],\n",
      "        [-0.4780],\n",
      "        [ 0.4972]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0710],\n",
      "        [ 1.1269],\n",
      "        [-1.7584],\n",
      "        [ 0.2516],\n",
      "        [-0.1743],\n",
      "        [-0.7122],\n",
      "        [ 1.1955],\n",
      "        [ 0.7924],\n",
      "        [-0.4785],\n",
      "        [ 0.4972]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0716],\n",
      "        [ 1.1274],\n",
      "        [-1.7588],\n",
      "        [ 0.2519],\n",
      "        [-0.1746],\n",
      "        [-0.7126],\n",
      "        [ 1.1952],\n",
      "        [ 0.7924],\n",
      "        [-0.4789],\n",
      "        [ 0.4972]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0722],\n",
      "        [ 1.1279],\n",
      "        [-1.7591],\n",
      "        [ 0.2522],\n",
      "        [-0.1749],\n",
      "        [-0.7131],\n",
      "        [ 1.1949],\n",
      "        [ 0.7924],\n",
      "        [-0.4793],\n",
      "        [ 0.4972]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0728],\n",
      "        [ 1.1284],\n",
      "        [-1.7594],\n",
      "        [ 0.2526],\n",
      "        [-0.1752],\n",
      "        [-0.7135],\n",
      "        [ 1.1946],\n",
      "        [ 0.7924],\n",
      "        [-0.4797],\n",
      "        [ 0.4971]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0734],\n",
      "        [ 1.1289],\n",
      "        [-1.7597],\n",
      "        [ 0.2529],\n",
      "        [-0.1755],\n",
      "        [-0.7139],\n",
      "        [ 1.1943],\n",
      "        [ 0.7924],\n",
      "        [-0.4802],\n",
      "        [ 0.4971]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0740],\n",
      "        [ 1.1294],\n",
      "        [-1.7600],\n",
      "        [ 0.2532],\n",
      "        [-0.1758],\n",
      "        [-0.7144],\n",
      "        [ 1.1940],\n",
      "        [ 0.7924],\n",
      "        [-0.4806],\n",
      "        [ 0.4971]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0746],\n",
      "        [ 1.1299],\n",
      "        [-1.7603],\n",
      "        [ 0.2536],\n",
      "        [-0.1761],\n",
      "        [-0.7148],\n",
      "        [ 1.1937],\n",
      "        [ 0.7924],\n",
      "        [-0.4810],\n",
      "        [ 0.4971]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0752],\n",
      "        [ 1.1304],\n",
      "        [-1.7607],\n",
      "        [ 0.2539],\n",
      "        [-0.1764],\n",
      "        [-0.7152],\n",
      "        [ 1.1934],\n",
      "        [ 0.7924],\n",
      "        [-0.4815],\n",
      "        [ 0.4971]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0758],\n",
      "        [ 1.1309],\n",
      "        [-1.7610],\n",
      "        [ 0.2542],\n",
      "        [-0.1767],\n",
      "        [-0.7157],\n",
      "        [ 1.1931],\n",
      "        [ 0.7924],\n",
      "        [-0.4819],\n",
      "        [ 0.4971]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0764],\n",
      "        [ 1.1314],\n",
      "        [-1.7613],\n",
      "        [ 0.2546],\n",
      "        [-0.1770],\n",
      "        [-0.7161],\n",
      "        [ 1.1928],\n",
      "        [ 0.7924],\n",
      "        [-0.4823],\n",
      "        [ 0.4970]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0770],\n",
      "        [ 1.1319],\n",
      "        [-1.7616],\n",
      "        [ 0.2549],\n",
      "        [-0.1773],\n",
      "        [-0.7165],\n",
      "        [ 1.1925],\n",
      "        [ 0.7924],\n",
      "        [-0.4827],\n",
      "        [ 0.4970]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0776],\n",
      "        [ 1.1325],\n",
      "        [-1.7619],\n",
      "        [ 0.2552],\n",
      "        [-0.1776],\n",
      "        [-0.7170],\n",
      "        [ 1.1922],\n",
      "        [ 0.7924],\n",
      "        [-0.4832],\n",
      "        [ 0.4970]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0782],\n",
      "        [ 1.1330],\n",
      "        [-1.7622],\n",
      "        [ 0.2556],\n",
      "        [-0.1779],\n",
      "        [-0.7174],\n",
      "        [ 1.1919],\n",
      "        [ 0.7924],\n",
      "        [-0.4836],\n",
      "        [ 0.4970]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0788],\n",
      "        [ 1.1335],\n",
      "        [-1.7626],\n",
      "        [ 0.2559],\n",
      "        [-0.1782],\n",
      "        [-0.7178],\n",
      "        [ 1.1916],\n",
      "        [ 0.7924],\n",
      "        [-0.4840],\n",
      "        [ 0.4970]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0794],\n",
      "        [ 1.1340],\n",
      "        [-1.7629],\n",
      "        [ 0.2562],\n",
      "        [-0.1785],\n",
      "        [-0.7182],\n",
      "        [ 1.1913],\n",
      "        [ 0.7924],\n",
      "        [-0.4845],\n",
      "        [ 0.4970]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0800],\n",
      "        [ 1.1345],\n",
      "        [-1.7632],\n",
      "        [ 0.2565],\n",
      "        [-0.1788],\n",
      "        [-0.7187],\n",
      "        [ 1.1910],\n",
      "        [ 0.7924],\n",
      "        [-0.4849],\n",
      "        [ 0.4970]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0806],\n",
      "        [ 1.1350],\n",
      "        [-1.7635],\n",
      "        [ 0.2569],\n",
      "        [-0.1791],\n",
      "        [-0.7191],\n",
      "        [ 1.1907],\n",
      "        [ 0.7924],\n",
      "        [-0.4853],\n",
      "        [ 0.4969]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0812],\n",
      "        [ 1.1355],\n",
      "        [-1.7638],\n",
      "        [ 0.2572],\n",
      "        [-0.1794],\n",
      "        [-0.7195],\n",
      "        [ 1.1904],\n",
      "        [ 0.7924],\n",
      "        [-0.4857],\n",
      "        [ 0.4969]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0817],\n",
      "        [ 1.1361],\n",
      "        [-1.7641],\n",
      "        [ 0.2575],\n",
      "        [-0.1797],\n",
      "        [-0.7200],\n",
      "        [ 1.1901],\n",
      "        [ 0.7924],\n",
      "        [-0.4862],\n",
      "        [ 0.4969]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0823],\n",
      "        [ 1.1366],\n",
      "        [-1.7644],\n",
      "        [ 0.2579],\n",
      "        [-0.1800],\n",
      "        [-0.7204],\n",
      "        [ 1.1898],\n",
      "        [ 0.7924],\n",
      "        [-0.4866],\n",
      "        [ 0.4969]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0829],\n",
      "        [ 1.1371],\n",
      "        [-1.7648],\n",
      "        [ 0.2582],\n",
      "        [-0.1803],\n",
      "        [-0.7208],\n",
      "        [ 1.1895],\n",
      "        [ 0.7924],\n",
      "        [-0.4870],\n",
      "        [ 0.4969]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0835],\n",
      "        [ 1.1376],\n",
      "        [-1.7651],\n",
      "        [ 0.2585],\n",
      "        [-0.1806],\n",
      "        [-0.7213],\n",
      "        [ 1.1892],\n",
      "        [ 0.7924],\n",
      "        [-0.4874],\n",
      "        [ 0.4969]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0841],\n",
      "        [ 1.1381],\n",
      "        [-1.7654],\n",
      "        [ 0.2588],\n",
      "        [-0.1809],\n",
      "        [-0.7217],\n",
      "        [ 1.1889],\n",
      "        [ 0.7924],\n",
      "        [-0.4879],\n",
      "        [ 0.4969]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0847],\n",
      "        [ 1.1387],\n",
      "        [-1.7657],\n",
      "        [ 0.2592],\n",
      "        [-0.1812],\n",
      "        [-0.7221],\n",
      "        [ 1.1886],\n",
      "        [ 0.7924],\n",
      "        [-0.4883],\n",
      "        [ 0.4968]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0852],\n",
      "        [ 1.1392],\n",
      "        [-1.7660],\n",
      "        [ 0.2595],\n",
      "        [-0.1815],\n",
      "        [-0.7226],\n",
      "        [ 1.1883],\n",
      "        [ 0.7924],\n",
      "        [-0.4887],\n",
      "        [ 0.4968]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0858],\n",
      "        [ 1.1397],\n",
      "        [-1.7663],\n",
      "        [ 0.2598],\n",
      "        [-0.1818],\n",
      "        [-0.7230],\n",
      "        [ 1.1880],\n",
      "        [ 0.7924],\n",
      "        [-0.4891],\n",
      "        [ 0.4968]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0864],\n",
      "        [ 1.1402],\n",
      "        [-1.7666],\n",
      "        [ 0.2601],\n",
      "        [-0.1821],\n",
      "        [-0.7234],\n",
      "        [ 1.1877],\n",
      "        [ 0.7924],\n",
      "        [-0.4896],\n",
      "        [ 0.4968]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0870],\n",
      "        [ 1.1408],\n",
      "        [-1.7670],\n",
      "        [ 0.2605],\n",
      "        [-0.1824],\n",
      "        [-0.7239],\n",
      "        [ 1.1874],\n",
      "        [ 0.7924],\n",
      "        [-0.4900],\n",
      "        [ 0.4968]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0876],\n",
      "        [ 1.1413],\n",
      "        [-1.7673],\n",
      "        [ 0.2608],\n",
      "        [-0.1827],\n",
      "        [-0.7243],\n",
      "        [ 1.1871],\n",
      "        [ 0.7924],\n",
      "        [-0.4904],\n",
      "        [ 0.4968]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0881],\n",
      "        [ 1.1418],\n",
      "        [-1.7676],\n",
      "        [ 0.2611],\n",
      "        [-0.1830],\n",
      "        [-0.7247],\n",
      "        [ 1.1868],\n",
      "        [ 0.7924],\n",
      "        [-0.4908],\n",
      "        [ 0.4968]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0887],\n",
      "        [ 1.1424],\n",
      "        [-1.7679],\n",
      "        [ 0.2614],\n",
      "        [-0.1833],\n",
      "        [-0.7251],\n",
      "        [ 1.1865],\n",
      "        [ 0.7924],\n",
      "        [-0.4913],\n",
      "        [ 0.4967]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0893],\n",
      "        [ 1.1429],\n",
      "        [-1.7682],\n",
      "        [ 0.2618],\n",
      "        [-0.1836],\n",
      "        [-0.7256],\n",
      "        [ 1.1862],\n",
      "        [ 0.7924],\n",
      "        [-0.4917],\n",
      "        [ 0.4967]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0899],\n",
      "        [ 1.1434],\n",
      "        [-1.7685],\n",
      "        [ 0.2621],\n",
      "        [-0.1839],\n",
      "        [-0.7260],\n",
      "        [ 1.1859],\n",
      "        [ 0.7924],\n",
      "        [-0.4921],\n",
      "        [ 0.4967]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0904],\n",
      "        [ 1.1440],\n",
      "        [-1.7688],\n",
      "        [ 0.2624],\n",
      "        [-0.1842],\n",
      "        [-0.7264],\n",
      "        [ 1.1856],\n",
      "        [ 0.7924],\n",
      "        [-0.4925],\n",
      "        [ 0.4967]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0910],\n",
      "        [ 1.1445],\n",
      "        [-1.7691],\n",
      "        [ 0.2627],\n",
      "        [-0.1845],\n",
      "        [-0.7269],\n",
      "        [ 1.1853],\n",
      "        [ 0.7924],\n",
      "        [-0.4929],\n",
      "        [ 0.4967]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0916],\n",
      "        [ 1.1450],\n",
      "        [-1.7694],\n",
      "        [ 0.2631],\n",
      "        [-0.1848],\n",
      "        [-0.7273],\n",
      "        [ 1.1850],\n",
      "        [ 0.7924],\n",
      "        [-0.4934],\n",
      "        [ 0.4967]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0922],\n",
      "        [ 1.1456],\n",
      "        [-1.7697],\n",
      "        [ 0.2634],\n",
      "        [-0.1851],\n",
      "        [-0.7277],\n",
      "        [ 1.1847],\n",
      "        [ 0.7924],\n",
      "        [-0.4938],\n",
      "        [ 0.4967]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0927],\n",
      "        [ 1.1461],\n",
      "        [-1.7701],\n",
      "        [ 0.2637],\n",
      "        [-0.1853],\n",
      "        [-0.7281],\n",
      "        [ 1.1844],\n",
      "        [ 0.7924],\n",
      "        [-0.4942],\n",
      "        [ 0.4966]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0933],\n",
      "        [ 1.1466],\n",
      "        [-1.7704],\n",
      "        [ 0.2640],\n",
      "        [-0.1856],\n",
      "        [-0.7286],\n",
      "        [ 1.1841],\n",
      "        [ 0.7924],\n",
      "        [-0.4946],\n",
      "        [ 0.4966]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0939],\n",
      "        [ 1.1472],\n",
      "        [-1.7707],\n",
      "        [ 0.2644],\n",
      "        [-0.1859],\n",
      "        [-0.7290],\n",
      "        [ 1.1838],\n",
      "        [ 0.7924],\n",
      "        [-0.4950],\n",
      "        [ 0.4966]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0944],\n",
      "        [ 1.1477],\n",
      "        [-1.7710],\n",
      "        [ 0.2647],\n",
      "        [-0.1862],\n",
      "        [-0.7294],\n",
      "        [ 1.1835],\n",
      "        [ 0.7924],\n",
      "        [-0.4955],\n",
      "        [ 0.4966]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0950],\n",
      "        [ 1.1483],\n",
      "        [-1.7713],\n",
      "        [ 0.2650],\n",
      "        [-0.1865],\n",
      "        [-0.7299],\n",
      "        [ 1.1832],\n",
      "        [ 0.7924],\n",
      "        [-0.4959],\n",
      "        [ 0.4966]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0956],\n",
      "        [ 1.1488],\n",
      "        [-1.7716],\n",
      "        [ 0.2653],\n",
      "        [-0.1868],\n",
      "        [-0.7303],\n",
      "        [ 1.1829],\n",
      "        [ 0.7924],\n",
      "        [-0.4963],\n",
      "        [ 0.4966]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0961],\n",
      "        [ 1.1494],\n",
      "        [-1.7719],\n",
      "        [ 0.2656],\n",
      "        [-0.1871],\n",
      "        [-0.7307],\n",
      "        [ 1.1827],\n",
      "        [ 0.7924],\n",
      "        [-0.4967],\n",
      "        [ 0.4966]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0967],\n",
      "        [ 1.1499],\n",
      "        [-1.7722],\n",
      "        [ 0.2660],\n",
      "        [-0.1874],\n",
      "        [-0.7311],\n",
      "        [ 1.1824],\n",
      "        [ 0.7924],\n",
      "        [-0.4971],\n",
      "        [ 0.4965]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0973],\n",
      "        [ 1.1504],\n",
      "        [-1.7725],\n",
      "        [ 0.2663],\n",
      "        [-0.1877],\n",
      "        [-0.7316],\n",
      "        [ 1.1821],\n",
      "        [ 0.7924],\n",
      "        [-0.4975],\n",
      "        [ 0.4965]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0978],\n",
      "        [ 1.1510],\n",
      "        [-1.7728],\n",
      "        [ 0.2666],\n",
      "        [-0.1880],\n",
      "        [-0.7320],\n",
      "        [ 1.1818],\n",
      "        [ 0.7924],\n",
      "        [-0.4980],\n",
      "        [ 0.4965]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0984],\n",
      "        [ 1.1515],\n",
      "        [-1.7731],\n",
      "        [ 0.2669],\n",
      "        [-0.1883],\n",
      "        [-0.7324],\n",
      "        [ 1.1815],\n",
      "        [ 0.7924],\n",
      "        [-0.4984],\n",
      "        [ 0.4965]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0990],\n",
      "        [ 1.1521],\n",
      "        [-1.7734],\n",
      "        [ 0.2672],\n",
      "        [-0.1886],\n",
      "        [-0.7328],\n",
      "        [ 1.1812],\n",
      "        [ 0.7924],\n",
      "        [-0.4988],\n",
      "        [ 0.4965]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.0995],\n",
      "        [ 1.1526],\n",
      "        [-1.7737],\n",
      "        [ 0.2676],\n",
      "        [-0.1889],\n",
      "        [-0.7333],\n",
      "        [ 1.1809],\n",
      "        [ 0.7924],\n",
      "        [-0.4992],\n",
      "        [ 0.4965]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1001],\n",
      "        [ 1.1532],\n",
      "        [-1.7740],\n",
      "        [ 0.2679],\n",
      "        [-0.1891],\n",
      "        [-0.7337],\n",
      "        [ 1.1806],\n",
      "        [ 0.7924],\n",
      "        [-0.4996],\n",
      "        [ 0.4965]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1007],\n",
      "        [ 1.1537],\n",
      "        [-1.7743],\n",
      "        [ 0.2682],\n",
      "        [-0.1894],\n",
      "        [-0.7341],\n",
      "        [ 1.1803],\n",
      "        [ 0.7924],\n",
      "        [-0.5000],\n",
      "        [ 0.4964]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1012],\n",
      "        [ 1.1543],\n",
      "        [-1.7747],\n",
      "        [ 0.2685],\n",
      "        [-0.1897],\n",
      "        [-0.7345],\n",
      "        [ 1.1800],\n",
      "        [ 0.7924],\n",
      "        [-0.5005],\n",
      "        [ 0.4964]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1018],\n",
      "        [ 1.1548],\n",
      "        [-1.7750],\n",
      "        [ 0.2688],\n",
      "        [-0.1900],\n",
      "        [-0.7350],\n",
      "        [ 1.1797],\n",
      "        [ 0.7924],\n",
      "        [-0.5009],\n",
      "        [ 0.4964]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1023],\n",
      "        [ 1.1554],\n",
      "        [-1.7753],\n",
      "        [ 0.2692],\n",
      "        [-0.1903],\n",
      "        [-0.7354],\n",
      "        [ 1.1795],\n",
      "        [ 0.7924],\n",
      "        [-0.5013],\n",
      "        [ 0.4964]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1029],\n",
      "        [ 1.1559],\n",
      "        [-1.7756],\n",
      "        [ 0.2695],\n",
      "        [-0.1906],\n",
      "        [-0.7358],\n",
      "        [ 1.1792],\n",
      "        [ 0.7924],\n",
      "        [-0.5017],\n",
      "        [ 0.4964]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1035],\n",
      "        [ 1.1565],\n",
      "        [-1.7759],\n",
      "        [ 0.2698],\n",
      "        [-0.1909],\n",
      "        [-0.7362],\n",
      "        [ 1.1789],\n",
      "        [ 0.7924],\n",
      "        [-0.5021],\n",
      "        [ 0.4964]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1040],\n",
      "        [ 1.1571],\n",
      "        [-1.7762],\n",
      "        [ 0.2701],\n",
      "        [-0.1912],\n",
      "        [-0.7366],\n",
      "        [ 1.1786],\n",
      "        [ 0.7924],\n",
      "        [-0.5025],\n",
      "        [ 0.4964]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1046],\n",
      "        [ 1.1576],\n",
      "        [-1.7765],\n",
      "        [ 0.2704],\n",
      "        [-0.1914],\n",
      "        [-0.7371],\n",
      "        [ 1.1783],\n",
      "        [ 0.7924],\n",
      "        [-0.5029],\n",
      "        [ 0.4963]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1051],\n",
      "        [ 1.1582],\n",
      "        [-1.7768],\n",
      "        [ 0.2708],\n",
      "        [-0.1917],\n",
      "        [-0.7375],\n",
      "        [ 1.1780],\n",
      "        [ 0.7924],\n",
      "        [-0.5033],\n",
      "        [ 0.4963]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1057],\n",
      "        [ 1.1587],\n",
      "        [-1.7771],\n",
      "        [ 0.2711],\n",
      "        [-0.1920],\n",
      "        [-0.7379],\n",
      "        [ 1.1777],\n",
      "        [ 0.7924],\n",
      "        [-0.5038],\n",
      "        [ 0.4963]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1062],\n",
      "        [ 1.1593],\n",
      "        [-1.7774],\n",
      "        [ 0.2714],\n",
      "        [-0.1923],\n",
      "        [-0.7383],\n",
      "        [ 1.1775],\n",
      "        [ 0.7924],\n",
      "        [-0.5042],\n",
      "        [ 0.4963]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1068],\n",
      "        [ 1.1598],\n",
      "        [-1.7777],\n",
      "        [ 0.2717],\n",
      "        [-0.1926],\n",
      "        [-0.7387],\n",
      "        [ 1.1772],\n",
      "        [ 0.7924],\n",
      "        [-0.5046],\n",
      "        [ 0.4963]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1073],\n",
      "        [ 1.1604],\n",
      "        [-1.7780],\n",
      "        [ 0.2720],\n",
      "        [-0.1929],\n",
      "        [-0.7392],\n",
      "        [ 1.1769],\n",
      "        [ 0.7924],\n",
      "        [-0.5050],\n",
      "        [ 0.4963]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1079],\n",
      "        [ 1.1610],\n",
      "        [-1.7783],\n",
      "        [ 0.2724],\n",
      "        [-0.1932],\n",
      "        [-0.7396],\n",
      "        [ 1.1766],\n",
      "        [ 0.7924],\n",
      "        [-0.5054],\n",
      "        [ 0.4963]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1084],\n",
      "        [ 1.1615],\n",
      "        [-1.7786],\n",
      "        [ 0.2727],\n",
      "        [-0.1934],\n",
      "        [-0.7400],\n",
      "        [ 1.1763],\n",
      "        [ 0.7924],\n",
      "        [-0.5058],\n",
      "        [ 0.4962]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1090],\n",
      "        [ 1.1621],\n",
      "        [-1.7789],\n",
      "        [ 0.2730],\n",
      "        [-0.1937],\n",
      "        [-0.7404],\n",
      "        [ 1.1760],\n",
      "        [ 0.7924],\n",
      "        [-0.5062],\n",
      "        [ 0.4962]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1095],\n",
      "        [ 1.1626],\n",
      "        [-1.7792],\n",
      "        [ 0.2733],\n",
      "        [-0.1940],\n",
      "        [-0.7408],\n",
      "        [ 1.1757],\n",
      "        [ 0.7924],\n",
      "        [-0.5066],\n",
      "        [ 0.4962]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1101],\n",
      "        [ 1.1632],\n",
      "        [-1.7795],\n",
      "        [ 0.2736],\n",
      "        [-0.1943],\n",
      "        [-0.7413],\n",
      "        [ 1.1755],\n",
      "        [ 0.7924],\n",
      "        [-0.5070],\n",
      "        [ 0.4962]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1106],\n",
      "        [ 1.1638],\n",
      "        [-1.7797],\n",
      "        [ 0.2739],\n",
      "        [-0.1946],\n",
      "        [-0.7417],\n",
      "        [ 1.1752],\n",
      "        [ 0.7924],\n",
      "        [-0.5074],\n",
      "        [ 0.4962]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1112],\n",
      "        [ 1.1643],\n",
      "        [-1.7800],\n",
      "        [ 0.2743],\n",
      "        [-0.1949],\n",
      "        [-0.7421],\n",
      "        [ 1.1749],\n",
      "        [ 0.7924],\n",
      "        [-0.5078],\n",
      "        [ 0.4962]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1117],\n",
      "        [ 1.1649],\n",
      "        [-1.7803],\n",
      "        [ 0.2746],\n",
      "        [-0.1951],\n",
      "        [-0.7425],\n",
      "        [ 1.1746],\n",
      "        [ 0.7924],\n",
      "        [-0.5082],\n",
      "        [ 0.4962]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1123],\n",
      "        [ 1.1655],\n",
      "        [-1.7806],\n",
      "        [ 0.2749],\n",
      "        [-0.1954],\n",
      "        [-0.7429],\n",
      "        [ 1.1743],\n",
      "        [ 0.7924],\n",
      "        [-0.5087],\n",
      "        [ 0.4962]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1128],\n",
      "        [ 1.1660],\n",
      "        [-1.7809],\n",
      "        [ 0.2752],\n",
      "        [-0.1957],\n",
      "        [-0.7434],\n",
      "        [ 1.1741],\n",
      "        [ 0.7924],\n",
      "        [-0.5091],\n",
      "        [ 0.4961]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1134],\n",
      "        [ 1.1666],\n",
      "        [-1.7812],\n",
      "        [ 0.2755],\n",
      "        [-0.1960],\n",
      "        [-0.7438],\n",
      "        [ 1.1738],\n",
      "        [ 0.7924],\n",
      "        [-0.5095],\n",
      "        [ 0.4961]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1139],\n",
      "        [ 1.1672],\n",
      "        [-1.7815],\n",
      "        [ 0.2758],\n",
      "        [-0.1963],\n",
      "        [-0.7442],\n",
      "        [ 1.1735],\n",
      "        [ 0.7924],\n",
      "        [-0.5099],\n",
      "        [ 0.4961]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1145],\n",
      "        [ 1.1677],\n",
      "        [-1.7818],\n",
      "        [ 0.2762],\n",
      "        [-0.1965],\n",
      "        [-0.7446],\n",
      "        [ 1.1732],\n",
      "        [ 0.7924],\n",
      "        [-0.5103],\n",
      "        [ 0.4961]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1150],\n",
      "        [ 1.1683],\n",
      "        [-1.7821],\n",
      "        [ 0.2765],\n",
      "        [-0.1968],\n",
      "        [-0.7450],\n",
      "        [ 1.1729],\n",
      "        [ 0.7924],\n",
      "        [-0.5107],\n",
      "        [ 0.4961]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1155],\n",
      "        [ 1.1689],\n",
      "        [-1.7824],\n",
      "        [ 0.2768],\n",
      "        [-0.1971],\n",
      "        [-0.7454],\n",
      "        [ 1.1727],\n",
      "        [ 0.7924],\n",
      "        [-0.5111],\n",
      "        [ 0.4961]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1161],\n",
      "        [ 1.1694],\n",
      "        [-1.7827],\n",
      "        [ 0.2771],\n",
      "        [-0.1974],\n",
      "        [-0.7458],\n",
      "        [ 1.1724],\n",
      "        [ 0.7924],\n",
      "        [-0.5115],\n",
      "        [ 0.4961]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1166],\n",
      "        [ 1.1700],\n",
      "        [-1.7830],\n",
      "        [ 0.2774],\n",
      "        [-0.1977],\n",
      "        [-0.7463],\n",
      "        [ 1.1721],\n",
      "        [ 0.7924],\n",
      "        [-0.5119],\n",
      "        [ 0.4961]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1172],\n",
      "        [ 1.1706],\n",
      "        [-1.7833],\n",
      "        [ 0.2777],\n",
      "        [-0.1979],\n",
      "        [-0.7467],\n",
      "        [ 1.1718],\n",
      "        [ 0.7924],\n",
      "        [-0.5123],\n",
      "        [ 0.4960]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1177],\n",
      "        [ 1.1711],\n",
      "        [-1.7836],\n",
      "        [ 0.2780],\n",
      "        [-0.1982],\n",
      "        [-0.7471],\n",
      "        [ 1.1716],\n",
      "        [ 0.7924],\n",
      "        [-0.5127],\n",
      "        [ 0.4960]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1183],\n",
      "        [ 1.1717],\n",
      "        [-1.7839],\n",
      "        [ 0.2784],\n",
      "        [-0.1985],\n",
      "        [-0.7475],\n",
      "        [ 1.1713],\n",
      "        [ 0.7924],\n",
      "        [-0.5131],\n",
      "        [ 0.4960]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1188],\n",
      "        [ 1.1723],\n",
      "        [-1.7841],\n",
      "        [ 0.2787],\n",
      "        [-0.1988],\n",
      "        [-0.7479],\n",
      "        [ 1.1710],\n",
      "        [ 0.7924],\n",
      "        [-0.5135],\n",
      "        [ 0.4960]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1193],\n",
      "        [ 1.1729],\n",
      "        [-1.7844],\n",
      "        [ 0.2790],\n",
      "        [-0.1990],\n",
      "        [-0.7483],\n",
      "        [ 1.1707],\n",
      "        [ 0.7924],\n",
      "        [-0.5139],\n",
      "        [ 0.4960]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1199],\n",
      "        [ 1.1734],\n",
      "        [-1.7847],\n",
      "        [ 0.2793],\n",
      "        [-0.1993],\n",
      "        [-0.7487],\n",
      "        [ 1.1704],\n",
      "        [ 0.7924],\n",
      "        [-0.5143],\n",
      "        [ 0.4960]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1204],\n",
      "        [ 1.1740],\n",
      "        [-1.7850],\n",
      "        [ 0.2796],\n",
      "        [-0.1996],\n",
      "        [-0.7491],\n",
      "        [ 1.1702],\n",
      "        [ 0.7924],\n",
      "        [-0.5147],\n",
      "        [ 0.4960]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1209],\n",
      "        [ 1.1746],\n",
      "        [-1.7853],\n",
      "        [ 0.2799],\n",
      "        [-0.1999],\n",
      "        [-0.7496],\n",
      "        [ 1.1699],\n",
      "        [ 0.7924],\n",
      "        [-0.5151],\n",
      "        [ 0.4959]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1215],\n",
      "        [ 1.1752],\n",
      "        [-1.7856],\n",
      "        [ 0.2803],\n",
      "        [-0.2001],\n",
      "        [-0.7500],\n",
      "        [ 1.1696],\n",
      "        [ 0.7924],\n",
      "        [-0.5155],\n",
      "        [ 0.4959]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1220],\n",
      "        [ 1.1757],\n",
      "        [-1.7859],\n",
      "        [ 0.2806],\n",
      "        [-0.2004],\n",
      "        [-0.7504],\n",
      "        [ 1.1694],\n",
      "        [ 0.7924],\n",
      "        [-0.5159],\n",
      "        [ 0.4959]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1226],\n",
      "        [ 1.1763],\n",
      "        [-1.7862],\n",
      "        [ 0.2809],\n",
      "        [-0.2007],\n",
      "        [-0.7508],\n",
      "        [ 1.1691],\n",
      "        [ 0.7924],\n",
      "        [-0.5163],\n",
      "        [ 0.4959]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1231],\n",
      "        [ 1.1769],\n",
      "        [-1.7864],\n",
      "        [ 0.2812],\n",
      "        [-0.2009],\n",
      "        [-0.7512],\n",
      "        [ 1.1688],\n",
      "        [ 0.7924],\n",
      "        [-0.5167],\n",
      "        [ 0.4959]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1236],\n",
      "        [ 1.1775],\n",
      "        [-1.7867],\n",
      "        [ 0.2815],\n",
      "        [-0.2012],\n",
      "        [-0.7516],\n",
      "        [ 1.1685],\n",
      "        [ 0.7924],\n",
      "        [-0.5171],\n",
      "        [ 0.4959]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1242],\n",
      "        [ 1.1780],\n",
      "        [-1.7870],\n",
      "        [ 0.2818],\n",
      "        [-0.2015],\n",
      "        [-0.7520],\n",
      "        [ 1.1683],\n",
      "        [ 0.7924],\n",
      "        [-0.5175],\n",
      "        [ 0.4959]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1247],\n",
      "        [ 1.1786],\n",
      "        [-1.7873],\n",
      "        [ 0.2821],\n",
      "        [-0.2018],\n",
      "        [-0.7524],\n",
      "        [ 1.1680],\n",
      "        [ 0.7924],\n",
      "        [-0.5179],\n",
      "        [ 0.4959]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1252],\n",
      "        [ 1.1792],\n",
      "        [-1.7876],\n",
      "        [ 0.2824],\n",
      "        [-0.2020],\n",
      "        [-0.7528],\n",
      "        [ 1.1677],\n",
      "        [ 0.7924],\n",
      "        [-0.5183],\n",
      "        [ 0.4958]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1258],\n",
      "        [ 1.1798],\n",
      "        [-1.7879],\n",
      "        [ 0.2828],\n",
      "        [-0.2023],\n",
      "        [-0.7532],\n",
      "        [ 1.1675],\n",
      "        [ 0.7924],\n",
      "        [-0.5187],\n",
      "        [ 0.4958]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1263],\n",
      "        [ 1.1803],\n",
      "        [-1.7882],\n",
      "        [ 0.2831],\n",
      "        [-0.2026],\n",
      "        [-0.7536],\n",
      "        [ 1.1672],\n",
      "        [ 0.7924],\n",
      "        [-0.5190],\n",
      "        [ 0.4958]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1268],\n",
      "        [ 1.1809],\n",
      "        [-1.7884],\n",
      "        [ 0.2834],\n",
      "        [-0.2028],\n",
      "        [-0.7540],\n",
      "        [ 1.1669],\n",
      "        [ 0.7924],\n",
      "        [-0.5194],\n",
      "        [ 0.4958]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1274],\n",
      "        [ 1.1815],\n",
      "        [-1.7887],\n",
      "        [ 0.2837],\n",
      "        [-0.2031],\n",
      "        [-0.7545],\n",
      "        [ 1.1667],\n",
      "        [ 0.7924],\n",
      "        [-0.5198],\n",
      "        [ 0.4958]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1279],\n",
      "        [ 1.1821],\n",
      "        [-1.7890],\n",
      "        [ 0.2840],\n",
      "        [-0.2034],\n",
      "        [-0.7549],\n",
      "        [ 1.1664],\n",
      "        [ 0.7924],\n",
      "        [-0.5202],\n",
      "        [ 0.4958]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1284],\n",
      "        [ 1.1827],\n",
      "        [-1.7893],\n",
      "        [ 0.2843],\n",
      "        [-0.2036],\n",
      "        [-0.7553],\n",
      "        [ 1.1661],\n",
      "        [ 0.7924],\n",
      "        [-0.5206],\n",
      "        [ 0.4958]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1289],\n",
      "        [ 1.1832],\n",
      "        [-1.7896],\n",
      "        [ 0.2846],\n",
      "        [-0.2039],\n",
      "        [-0.7557],\n",
      "        [ 1.1658],\n",
      "        [ 0.7924],\n",
      "        [-0.5210],\n",
      "        [ 0.4958]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1295],\n",
      "        [ 1.1838],\n",
      "        [-1.7898],\n",
      "        [ 0.2849],\n",
      "        [-0.2042],\n",
      "        [-0.7561],\n",
      "        [ 1.1656],\n",
      "        [ 0.7924],\n",
      "        [-0.5214],\n",
      "        [ 0.4957]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1300],\n",
      "        [ 1.1844],\n",
      "        [-1.7901],\n",
      "        [ 0.2853],\n",
      "        [-0.2044],\n",
      "        [-0.7565],\n",
      "        [ 1.1653],\n",
      "        [ 0.7924],\n",
      "        [-0.5218],\n",
      "        [ 0.4957]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1305],\n",
      "        [ 1.1850],\n",
      "        [-1.7904],\n",
      "        [ 0.2856],\n",
      "        [-0.2047],\n",
      "        [-0.7569],\n",
      "        [ 1.1650],\n",
      "        [ 0.7924],\n",
      "        [-0.5222],\n",
      "        [ 0.4957]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1311],\n",
      "        [ 1.1856],\n",
      "        [-1.7907],\n",
      "        [ 0.2859],\n",
      "        [-0.2050],\n",
      "        [-0.7573],\n",
      "        [ 1.1648],\n",
      "        [ 0.7924],\n",
      "        [-0.5226],\n",
      "        [ 0.4957]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1316],\n",
      "        [ 1.1861],\n",
      "        [-1.7910],\n",
      "        [ 0.2862],\n",
      "        [-0.2052],\n",
      "        [-0.7577],\n",
      "        [ 1.1645],\n",
      "        [ 0.7924],\n",
      "        [-0.5230],\n",
      "        [ 0.4957]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1321],\n",
      "        [ 1.1867],\n",
      "        [-1.7912],\n",
      "        [ 0.2865],\n",
      "        [-0.2055],\n",
      "        [-0.7581],\n",
      "        [ 1.1643],\n",
      "        [ 0.7924],\n",
      "        [-0.5234],\n",
      "        [ 0.4957]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1326],\n",
      "        [ 1.1873],\n",
      "        [-1.7915],\n",
      "        [ 0.2868],\n",
      "        [-0.2058],\n",
      "        [-0.7585],\n",
      "        [ 1.1640],\n",
      "        [ 0.7924],\n",
      "        [-0.5237],\n",
      "        [ 0.4957]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1332],\n",
      "        [ 1.1879],\n",
      "        [-1.7918],\n",
      "        [ 0.2871],\n",
      "        [-0.2060],\n",
      "        [-0.7589],\n",
      "        [ 1.1637],\n",
      "        [ 0.7924],\n",
      "        [-0.5241],\n",
      "        [ 0.4957]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1337],\n",
      "        [ 1.1885],\n",
      "        [-1.7921],\n",
      "        [ 0.2874],\n",
      "        [-0.2063],\n",
      "        [-0.7593],\n",
      "        [ 1.1635],\n",
      "        [ 0.7924],\n",
      "        [-0.5245],\n",
      "        [ 0.4956]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1342],\n",
      "        [ 1.1891],\n",
      "        [-1.7923],\n",
      "        [ 0.2878],\n",
      "        [-0.2066],\n",
      "        [-0.7597],\n",
      "        [ 1.1632],\n",
      "        [ 0.7924],\n",
      "        [-0.5249],\n",
      "        [ 0.4956]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1347],\n",
      "        [ 1.1896],\n",
      "        [-1.7926],\n",
      "        [ 0.2881],\n",
      "        [-0.2068],\n",
      "        [-0.7601],\n",
      "        [ 1.1629],\n",
      "        [ 0.7924],\n",
      "        [-0.5253],\n",
      "        [ 0.4956]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1353],\n",
      "        [ 1.1902],\n",
      "        [-1.7929],\n",
      "        [ 0.2884],\n",
      "        [-0.2071],\n",
      "        [-0.7605],\n",
      "        [ 1.1627],\n",
      "        [ 0.7924],\n",
      "        [-0.5257],\n",
      "        [ 0.4956]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1358],\n",
      "        [ 1.1908],\n",
      "        [-1.7932],\n",
      "        [ 0.2887],\n",
      "        [-0.2073],\n",
      "        [-0.7609],\n",
      "        [ 1.1624],\n",
      "        [ 0.7924],\n",
      "        [-0.5261],\n",
      "        [ 0.4956]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1363],\n",
      "        [ 1.1914],\n",
      "        [-1.7934],\n",
      "        [ 0.2890],\n",
      "        [-0.2076],\n",
      "        [-0.7613],\n",
      "        [ 1.1622],\n",
      "        [ 0.7924],\n",
      "        [-0.5265],\n",
      "        [ 0.4956]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1368],\n",
      "        [ 1.1920],\n",
      "        [-1.7937],\n",
      "        [ 0.2893],\n",
      "        [-0.2079],\n",
      "        [-0.7617],\n",
      "        [ 1.1619],\n",
      "        [ 0.7924],\n",
      "        [-0.5268],\n",
      "        [ 0.4956]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1373],\n",
      "        [ 1.1926],\n",
      "        [-1.7940],\n",
      "        [ 0.2896],\n",
      "        [-0.2081],\n",
      "        [-0.7621],\n",
      "        [ 1.1616],\n",
      "        [ 0.7924],\n",
      "        [-0.5272],\n",
      "        [ 0.4956]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1379],\n",
      "        [ 1.1931],\n",
      "        [-1.7943],\n",
      "        [ 0.2899],\n",
      "        [-0.2084],\n",
      "        [-0.7625],\n",
      "        [ 1.1614],\n",
      "        [ 0.7924],\n",
      "        [-0.5276],\n",
      "        [ 0.4955]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1384],\n",
      "        [ 1.1937],\n",
      "        [-1.7945],\n",
      "        [ 0.2902],\n",
      "        [-0.2086],\n",
      "        [-0.7629],\n",
      "        [ 1.1611],\n",
      "        [ 0.7924],\n",
      "        [-0.5280],\n",
      "        [ 0.4955]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1389],\n",
      "        [ 1.1943],\n",
      "        [-1.7948],\n",
      "        [ 0.2906],\n",
      "        [-0.2089],\n",
      "        [-0.7633],\n",
      "        [ 1.1609],\n",
      "        [ 0.7924],\n",
      "        [-0.5284],\n",
      "        [ 0.4955]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1394],\n",
      "        [ 1.1949],\n",
      "        [-1.7951],\n",
      "        [ 0.2909],\n",
      "        [-0.2092],\n",
      "        [-0.7637],\n",
      "        [ 1.1606],\n",
      "        [ 0.7924],\n",
      "        [-0.5288],\n",
      "        [ 0.4955]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1399],\n",
      "        [ 1.1955],\n",
      "        [-1.7953],\n",
      "        [ 0.2912],\n",
      "        [-0.2094],\n",
      "        [-0.7641],\n",
      "        [ 1.1603],\n",
      "        [ 0.7924],\n",
      "        [-0.5291],\n",
      "        [ 0.4955]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1405],\n",
      "        [ 1.1961],\n",
      "        [-1.7956],\n",
      "        [ 0.2915],\n",
      "        [-0.2097],\n",
      "        [-0.7645],\n",
      "        [ 1.1601],\n",
      "        [ 0.7924],\n",
      "        [-0.5295],\n",
      "        [ 0.4955]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1410],\n",
      "        [ 1.1967],\n",
      "        [-1.7959],\n",
      "        [ 0.2918],\n",
      "        [-0.2099],\n",
      "        [-0.7649],\n",
      "        [ 1.1598],\n",
      "        [ 0.7924],\n",
      "        [-0.5299],\n",
      "        [ 0.4955]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1415],\n",
      "        [ 1.1972],\n",
      "        [-1.7962],\n",
      "        [ 0.2921],\n",
      "        [-0.2102],\n",
      "        [-0.7653],\n",
      "        [ 1.1596],\n",
      "        [ 0.7924],\n",
      "        [-0.5303],\n",
      "        [ 0.4955]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1420],\n",
      "        [ 1.1978],\n",
      "        [-1.7964],\n",
      "        [ 0.2924],\n",
      "        [-0.2104],\n",
      "        [-0.7657],\n",
      "        [ 1.1593],\n",
      "        [ 0.7924],\n",
      "        [-0.5307],\n",
      "        [ 0.4955]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1425],\n",
      "        [ 1.1984],\n",
      "        [-1.7967],\n",
      "        [ 0.2927],\n",
      "        [-0.2107],\n",
      "        [-0.7661],\n",
      "        [ 1.1591],\n",
      "        [ 0.7924],\n",
      "        [-0.5310],\n",
      "        [ 0.4954]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1430],\n",
      "        [ 1.1990],\n",
      "        [-1.7970],\n",
      "        [ 0.2930],\n",
      "        [-0.2109],\n",
      "        [-0.7664],\n",
      "        [ 1.1588],\n",
      "        [ 0.7924],\n",
      "        [-0.5314],\n",
      "        [ 0.4954]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1436],\n",
      "        [ 1.1996],\n",
      "        [-1.7972],\n",
      "        [ 0.2933],\n",
      "        [-0.2112],\n",
      "        [-0.7668],\n",
      "        [ 1.1586],\n",
      "        [ 0.7924],\n",
      "        [-0.5318],\n",
      "        [ 0.4954]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1441],\n",
      "        [ 1.2002],\n",
      "        [-1.7975],\n",
      "        [ 0.2937],\n",
      "        [-0.2115],\n",
      "        [-0.7672],\n",
      "        [ 1.1583],\n",
      "        [ 0.7924],\n",
      "        [-0.5322],\n",
      "        [ 0.4954]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1446],\n",
      "        [ 1.2008],\n",
      "        [-1.7978],\n",
      "        [ 0.2940],\n",
      "        [-0.2117],\n",
      "        [-0.7676],\n",
      "        [ 1.1581],\n",
      "        [ 0.7924],\n",
      "        [-0.5326],\n",
      "        [ 0.4954]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1451],\n",
      "        [ 1.2014],\n",
      "        [-1.7980],\n",
      "        [ 0.2943],\n",
      "        [-0.2120],\n",
      "        [-0.7680],\n",
      "        [ 1.1578],\n",
      "        [ 0.7924],\n",
      "        [-0.5329],\n",
      "        [ 0.4954]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1456],\n",
      "        [ 1.2019],\n",
      "        [-1.7983],\n",
      "        [ 0.2946],\n",
      "        [-0.2122],\n",
      "        [-0.7684],\n",
      "        [ 1.1576],\n",
      "        [ 0.7924],\n",
      "        [-0.5333],\n",
      "        [ 0.4954]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1461],\n",
      "        [ 1.2025],\n",
      "        [-1.7986],\n",
      "        [ 0.2949],\n",
      "        [-0.2125],\n",
      "        [-0.7688],\n",
      "        [ 1.1573],\n",
      "        [ 0.7924],\n",
      "        [-0.5337],\n",
      "        [ 0.4954]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1466],\n",
      "        [ 1.2031],\n",
      "        [-1.7988],\n",
      "        [ 0.2952],\n",
      "        [-0.2127],\n",
      "        [-0.7692],\n",
      "        [ 1.1570],\n",
      "        [ 0.7924],\n",
      "        [-0.5341],\n",
      "        [ 0.4953]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1472],\n",
      "        [ 1.2037],\n",
      "        [-1.7991],\n",
      "        [ 0.2955],\n",
      "        [-0.2130],\n",
      "        [-0.7696],\n",
      "        [ 1.1568],\n",
      "        [ 0.7924],\n",
      "        [-0.5345],\n",
      "        [ 0.4953]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1477],\n",
      "        [ 1.2043],\n",
      "        [-1.7994],\n",
      "        [ 0.2958],\n",
      "        [-0.2132],\n",
      "        [-0.7700],\n",
      "        [ 1.1565],\n",
      "        [ 0.7924],\n",
      "        [-0.5348],\n",
      "        [ 0.4953]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1482],\n",
      "        [ 1.2049],\n",
      "        [-1.7996],\n",
      "        [ 0.2961],\n",
      "        [-0.2135],\n",
      "        [-0.7704],\n",
      "        [ 1.1563],\n",
      "        [ 0.7924],\n",
      "        [-0.5352],\n",
      "        [ 0.4953]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1487],\n",
      "        [ 1.2055],\n",
      "        [-1.7999],\n",
      "        [ 0.2964],\n",
      "        [-0.2137],\n",
      "        [-0.7708],\n",
      "        [ 1.1560],\n",
      "        [ 0.7924],\n",
      "        [-0.5356],\n",
      "        [ 0.4953]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1492],\n",
      "        [ 1.2061],\n",
      "        [-1.8001],\n",
      "        [ 0.2967],\n",
      "        [-0.2140],\n",
      "        [-0.7711],\n",
      "        [ 1.1558],\n",
      "        [ 0.7924],\n",
      "        [-0.5360],\n",
      "        [ 0.4953]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1497],\n",
      "        [ 1.2066],\n",
      "        [-1.8004],\n",
      "        [ 0.2971],\n",
      "        [-0.2142],\n",
      "        [-0.7715],\n",
      "        [ 1.1556],\n",
      "        [ 0.7924],\n",
      "        [-0.5363],\n",
      "        [ 0.4953]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1502],\n",
      "        [ 1.2072],\n",
      "        [-1.8007],\n",
      "        [ 0.2974],\n",
      "        [-0.2145],\n",
      "        [-0.7719],\n",
      "        [ 1.1553],\n",
      "        [ 0.7924],\n",
      "        [-0.5367],\n",
      "        [ 0.4953]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1507],\n",
      "        [ 1.2078],\n",
      "        [-1.8009],\n",
      "        [ 0.2977],\n",
      "        [-0.2147],\n",
      "        [-0.7723],\n",
      "        [ 1.1551],\n",
      "        [ 0.7924],\n",
      "        [-0.5371],\n",
      "        [ 0.4953]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1512],\n",
      "        [ 1.2084],\n",
      "        [-1.8012],\n",
      "        [ 0.2980],\n",
      "        [-0.2149],\n",
      "        [-0.7727],\n",
      "        [ 1.1548],\n",
      "        [ 0.7924],\n",
      "        [-0.5374],\n",
      "        [ 0.4952]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1517],\n",
      "        [ 1.2090],\n",
      "        [-1.8014],\n",
      "        [ 0.2983],\n",
      "        [-0.2152],\n",
      "        [-0.7731],\n",
      "        [ 1.1546],\n",
      "        [ 0.7924],\n",
      "        [-0.5378],\n",
      "        [ 0.4952]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1523],\n",
      "        [ 1.2096],\n",
      "        [-1.8017],\n",
      "        [ 0.2986],\n",
      "        [-0.2154],\n",
      "        [-0.7735],\n",
      "        [ 1.1543],\n",
      "        [ 0.7924],\n",
      "        [-0.5382],\n",
      "        [ 0.4952]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1528],\n",
      "        [ 1.2102],\n",
      "        [-1.8020],\n",
      "        [ 0.2989],\n",
      "        [-0.2157],\n",
      "        [-0.7739],\n",
      "        [ 1.1541],\n",
      "        [ 0.7924],\n",
      "        [-0.5386],\n",
      "        [ 0.4952]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1533],\n",
      "        [ 1.2108],\n",
      "        [-1.8022],\n",
      "        [ 0.2992],\n",
      "        [-0.2159],\n",
      "        [-0.7742],\n",
      "        [ 1.1538],\n",
      "        [ 0.7924],\n",
      "        [-0.5389],\n",
      "        [ 0.4952]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1538],\n",
      "        [ 1.2114],\n",
      "        [-1.8025],\n",
      "        [ 0.2995],\n",
      "        [-0.2162],\n",
      "        [-0.7746],\n",
      "        [ 1.1536],\n",
      "        [ 0.7924],\n",
      "        [-0.5393],\n",
      "        [ 0.4952]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1543],\n",
      "        [ 1.2119],\n",
      "        [-1.8027],\n",
      "        [ 0.2998],\n",
      "        [-0.2164],\n",
      "        [-0.7750],\n",
      "        [ 1.1533],\n",
      "        [ 0.7924],\n",
      "        [-0.5397],\n",
      "        [ 0.4952]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1548],\n",
      "        [ 1.2125],\n",
      "        [-1.8030],\n",
      "        [ 0.3001],\n",
      "        [-0.2167],\n",
      "        [-0.7754],\n",
      "        [ 1.1531],\n",
      "        [ 0.7924],\n",
      "        [-0.5400],\n",
      "        [ 0.4952]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1553],\n",
      "        [ 1.2131],\n",
      "        [-1.8033],\n",
      "        [ 0.3004],\n",
      "        [-0.2169],\n",
      "        [-0.7758],\n",
      "        [ 1.1529],\n",
      "        [ 0.7924],\n",
      "        [-0.5404],\n",
      "        [ 0.4952]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1558],\n",
      "        [ 1.2137],\n",
      "        [-1.8035],\n",
      "        [ 0.3007],\n",
      "        [-0.2172],\n",
      "        [-0.7762],\n",
      "        [ 1.1526],\n",
      "        [ 0.7924],\n",
      "        [-0.5408],\n",
      "        [ 0.4951]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1563],\n",
      "        [ 1.2143],\n",
      "        [-1.8038],\n",
      "        [ 0.3011],\n",
      "        [-0.2174],\n",
      "        [-0.7766],\n",
      "        [ 1.1524],\n",
      "        [ 0.7924],\n",
      "        [-0.5412],\n",
      "        [ 0.4951]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1568],\n",
      "        [ 1.2149],\n",
      "        [-1.8040],\n",
      "        [ 0.3014],\n",
      "        [-0.2176],\n",
      "        [-0.7769],\n",
      "        [ 1.1521],\n",
      "        [ 0.7924],\n",
      "        [-0.5415],\n",
      "        [ 0.4951]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1573],\n",
      "        [ 1.2155],\n",
      "        [-1.8043],\n",
      "        [ 0.3017],\n",
      "        [-0.2179],\n",
      "        [-0.7773],\n",
      "        [ 1.1519],\n",
      "        [ 0.7924],\n",
      "        [-0.5419],\n",
      "        [ 0.4951]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1578],\n",
      "        [ 1.2161],\n",
      "        [-1.8045],\n",
      "        [ 0.3020],\n",
      "        [-0.2181],\n",
      "        [-0.7777],\n",
      "        [ 1.1516],\n",
      "        [ 0.7924],\n",
      "        [-0.5423],\n",
      "        [ 0.4951]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1583],\n",
      "        [ 1.2167],\n",
      "        [-1.8048],\n",
      "        [ 0.3023],\n",
      "        [-0.2184],\n",
      "        [-0.7781],\n",
      "        [ 1.1514],\n",
      "        [ 0.7924],\n",
      "        [-0.5426],\n",
      "        [ 0.4951]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1588],\n",
      "        [ 1.2172],\n",
      "        [-1.8050],\n",
      "        [ 0.3026],\n",
      "        [-0.2186],\n",
      "        [-0.7785],\n",
      "        [ 1.1512],\n",
      "        [ 0.7924],\n",
      "        [-0.5430],\n",
      "        [ 0.4951]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1593],\n",
      "        [ 1.2178],\n",
      "        [-1.8053],\n",
      "        [ 0.3029],\n",
      "        [-0.2188],\n",
      "        [-0.7788],\n",
      "        [ 1.1509],\n",
      "        [ 0.7924],\n",
      "        [-0.5434],\n",
      "        [ 0.4951]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1598],\n",
      "        [ 1.2184],\n",
      "        [-1.8055],\n",
      "        [ 0.3032],\n",
      "        [-0.2191],\n",
      "        [-0.7792],\n",
      "        [ 1.1507],\n",
      "        [ 0.7924],\n",
      "        [-0.5437],\n",
      "        [ 0.4951]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1603],\n",
      "        [ 1.2190],\n",
      "        [-1.8058],\n",
      "        [ 0.3035],\n",
      "        [-0.2193],\n",
      "        [-0.7796],\n",
      "        [ 1.1504],\n",
      "        [ 0.7924],\n",
      "        [-0.5441],\n",
      "        [ 0.4950]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1608],\n",
      "        [ 1.2196],\n",
      "        [-1.8061],\n",
      "        [ 0.3038],\n",
      "        [-0.2196],\n",
      "        [-0.7800],\n",
      "        [ 1.1502],\n",
      "        [ 0.7924],\n",
      "        [-0.5445],\n",
      "        [ 0.4950]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1613],\n",
      "        [ 1.2202],\n",
      "        [-1.8063],\n",
      "        [ 0.3041],\n",
      "        [-0.2198],\n",
      "        [-0.7804],\n",
      "        [ 1.1500],\n",
      "        [ 0.7924],\n",
      "        [-0.5448],\n",
      "        [ 0.4950]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1618],\n",
      "        [ 1.2208],\n",
      "        [-1.8066],\n",
      "        [ 0.3044],\n",
      "        [-0.2200],\n",
      "        [-0.7807],\n",
      "        [ 1.1497],\n",
      "        [ 0.7924],\n",
      "        [-0.5452],\n",
      "        [ 0.4950]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1623],\n",
      "        [ 1.2214],\n",
      "        [-1.8068],\n",
      "        [ 0.3047],\n",
      "        [-0.2203],\n",
      "        [-0.7811],\n",
      "        [ 1.1495],\n",
      "        [ 0.7924],\n",
      "        [-0.5456],\n",
      "        [ 0.4950]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1628],\n",
      "        [ 1.2220],\n",
      "        [-1.8071],\n",
      "        [ 0.3050],\n",
      "        [-0.2205],\n",
      "        [-0.7815],\n",
      "        [ 1.1493],\n",
      "        [ 0.7924],\n",
      "        [-0.5459],\n",
      "        [ 0.4950]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1633],\n",
      "        [ 1.2225],\n",
      "        [-1.8073],\n",
      "        [ 0.3054],\n",
      "        [-0.2207],\n",
      "        [-0.7819],\n",
      "        [ 1.1490],\n",
      "        [ 0.7924],\n",
      "        [-0.5463],\n",
      "        [ 0.4950]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1638],\n",
      "        [ 1.2231],\n",
      "        [-1.8076],\n",
      "        [ 0.3057],\n",
      "        [-0.2210],\n",
      "        [-0.7823],\n",
      "        [ 1.1488],\n",
      "        [ 0.7924],\n",
      "        [-0.5466],\n",
      "        [ 0.4950]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1643],\n",
      "        [ 1.2237],\n",
      "        [-1.8078],\n",
      "        [ 0.3060],\n",
      "        [-0.2212],\n",
      "        [-0.7826],\n",
      "        [ 1.1485],\n",
      "        [ 0.7924],\n",
      "        [-0.5470],\n",
      "        [ 0.4950]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1648],\n",
      "        [ 1.2243],\n",
      "        [-1.8081],\n",
      "        [ 0.3063],\n",
      "        [-0.2214],\n",
      "        [-0.7830],\n",
      "        [ 1.1483],\n",
      "        [ 0.7924],\n",
      "        [-0.5474],\n",
      "        [ 0.4949]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1653],\n",
      "        [ 1.2249],\n",
      "        [-1.8083],\n",
      "        [ 0.3066],\n",
      "        [-0.2217],\n",
      "        [-0.7834],\n",
      "        [ 1.1481],\n",
      "        [ 0.7924],\n",
      "        [-0.5477],\n",
      "        [ 0.4949]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1658],\n",
      "        [ 1.2255],\n",
      "        [-1.8085],\n",
      "        [ 0.3069],\n",
      "        [-0.2219],\n",
      "        [-0.7838],\n",
      "        [ 1.1478],\n",
      "        [ 0.7924],\n",
      "        [-0.5481],\n",
      "        [ 0.4949]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1663],\n",
      "        [ 1.2261],\n",
      "        [-1.8088],\n",
      "        [ 0.3072],\n",
      "        [-0.2221],\n",
      "        [-0.7841],\n",
      "        [ 1.1476],\n",
      "        [ 0.7924],\n",
      "        [-0.5485],\n",
      "        [ 0.4949]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1668],\n",
      "        [ 1.2267],\n",
      "        [-1.8090],\n",
      "        [ 0.3075],\n",
      "        [-0.2224],\n",
      "        [-0.7845],\n",
      "        [ 1.1474],\n",
      "        [ 0.7924],\n",
      "        [-0.5488],\n",
      "        [ 0.4949]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1673],\n",
      "        [ 1.2273],\n",
      "        [-1.8093],\n",
      "        [ 0.3078],\n",
      "        [-0.2226],\n",
      "        [-0.7849],\n",
      "        [ 1.1471],\n",
      "        [ 0.7924],\n",
      "        [-0.5492],\n",
      "        [ 0.4949]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1678],\n",
      "        [ 1.2279],\n",
      "        [-1.8095],\n",
      "        [ 0.3081],\n",
      "        [-0.2228],\n",
      "        [-0.7853],\n",
      "        [ 1.1469],\n",
      "        [ 0.7924],\n",
      "        [-0.5495],\n",
      "        [ 0.4949]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1683],\n",
      "        [ 1.2284],\n",
      "        [-1.8098],\n",
      "        [ 0.3084],\n",
      "        [-0.2231],\n",
      "        [-0.7856],\n",
      "        [ 1.1467],\n",
      "        [ 0.7924],\n",
      "        [-0.5499],\n",
      "        [ 0.4949]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1688],\n",
      "        [ 1.2290],\n",
      "        [-1.8100],\n",
      "        [ 0.3087],\n",
      "        [-0.2233],\n",
      "        [-0.7860],\n",
      "        [ 1.1464],\n",
      "        [ 0.7924],\n",
      "        [-0.5503],\n",
      "        [ 0.4949]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1693],\n",
      "        [ 1.2296],\n",
      "        [-1.8103],\n",
      "        [ 0.3090],\n",
      "        [-0.2235],\n",
      "        [-0.7864],\n",
      "        [ 1.1462],\n",
      "        [ 0.7924],\n",
      "        [-0.5506],\n",
      "        [ 0.4948]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1698],\n",
      "        [ 1.2302],\n",
      "        [-1.8105],\n",
      "        [ 0.3093],\n",
      "        [-0.2238],\n",
      "        [-0.7868],\n",
      "        [ 1.1460],\n",
      "        [ 0.7924],\n",
      "        [-0.5510],\n",
      "        [ 0.4948]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1703],\n",
      "        [ 1.2308],\n",
      "        [-1.8108],\n",
      "        [ 0.3096],\n",
      "        [-0.2240],\n",
      "        [-0.7871],\n",
      "        [ 1.1458],\n",
      "        [ 0.7924],\n",
      "        [-0.5513],\n",
      "        [ 0.4948]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1708],\n",
      "        [ 1.2314],\n",
      "        [-1.8110],\n",
      "        [ 0.3099],\n",
      "        [-0.2242],\n",
      "        [-0.7875],\n",
      "        [ 1.1455],\n",
      "        [ 0.7924],\n",
      "        [-0.5517],\n",
      "        [ 0.4948]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1713],\n",
      "        [ 1.2320],\n",
      "        [-1.8112],\n",
      "        [ 0.3102],\n",
      "        [-0.2245],\n",
      "        [-0.7879],\n",
      "        [ 1.1453],\n",
      "        [ 0.7924],\n",
      "        [-0.5520],\n",
      "        [ 0.4948]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1718],\n",
      "        [ 1.2326],\n",
      "        [-1.8115],\n",
      "        [ 0.3105],\n",
      "        [-0.2247],\n",
      "        [-0.7883],\n",
      "        [ 1.1451],\n",
      "        [ 0.7924],\n",
      "        [-0.5524],\n",
      "        [ 0.4948]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1723],\n",
      "        [ 1.2331],\n",
      "        [-1.8117],\n",
      "        [ 0.3108],\n",
      "        [-0.2249],\n",
      "        [-0.7886],\n",
      "        [ 1.1448],\n",
      "        [ 0.7924],\n",
      "        [-0.5528],\n",
      "        [ 0.4948]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1728],\n",
      "        [ 1.2337],\n",
      "        [-1.8120],\n",
      "        [ 0.3111],\n",
      "        [-0.2251],\n",
      "        [-0.7890],\n",
      "        [ 1.1446],\n",
      "        [ 0.7924],\n",
      "        [-0.5531],\n",
      "        [ 0.4948]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1733],\n",
      "        [ 1.2343],\n",
      "        [-1.8122],\n",
      "        [ 0.3115],\n",
      "        [-0.2254],\n",
      "        [-0.7894],\n",
      "        [ 1.1444],\n",
      "        [ 0.7924],\n",
      "        [-0.5535],\n",
      "        [ 0.4948]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1737],\n",
      "        [ 1.2349],\n",
      "        [-1.8125],\n",
      "        [ 0.3118],\n",
      "        [-0.2256],\n",
      "        [-0.7897],\n",
      "        [ 1.1442],\n",
      "        [ 0.7924],\n",
      "        [-0.5538],\n",
      "        [ 0.4947]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1742],\n",
      "        [ 1.2355],\n",
      "        [-1.8127],\n",
      "        [ 0.3121],\n",
      "        [-0.2258],\n",
      "        [-0.7901],\n",
      "        [ 1.1439],\n",
      "        [ 0.7924],\n",
      "        [-0.5542],\n",
      "        [ 0.4947]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1747],\n",
      "        [ 1.2361],\n",
      "        [-1.8129],\n",
      "        [ 0.3124],\n",
      "        [-0.2261],\n",
      "        [-0.7905],\n",
      "        [ 1.1437],\n",
      "        [ 0.7924],\n",
      "        [-0.5545],\n",
      "        [ 0.4947]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1752],\n",
      "        [ 1.2367],\n",
      "        [-1.8132],\n",
      "        [ 0.3127],\n",
      "        [-0.2263],\n",
      "        [-0.7908],\n",
      "        [ 1.1435],\n",
      "        [ 0.7924],\n",
      "        [-0.5549],\n",
      "        [ 0.4947]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1757],\n",
      "        [ 1.2373],\n",
      "        [-1.8134],\n",
      "        [ 0.3130],\n",
      "        [-0.2265],\n",
      "        [-0.7912],\n",
      "        [ 1.1433],\n",
      "        [ 0.7924],\n",
      "        [-0.5553],\n",
      "        [ 0.4947]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1762],\n",
      "        [ 1.2379],\n",
      "        [-1.8136],\n",
      "        [ 0.3133],\n",
      "        [-0.2267],\n",
      "        [-0.7916],\n",
      "        [ 1.1430],\n",
      "        [ 0.7924],\n",
      "        [-0.5556],\n",
      "        [ 0.4947]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1767],\n",
      "        [ 1.2384],\n",
      "        [-1.8139],\n",
      "        [ 0.3136],\n",
      "        [-0.2270],\n",
      "        [-0.7920],\n",
      "        [ 1.1428],\n",
      "        [ 0.7924],\n",
      "        [-0.5560],\n",
      "        [ 0.4947]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1772],\n",
      "        [ 1.2390],\n",
      "        [-1.8141],\n",
      "        [ 0.3139],\n",
      "        [-0.2272],\n",
      "        [-0.7923],\n",
      "        [ 1.1426],\n",
      "        [ 0.7924],\n",
      "        [-0.5563],\n",
      "        [ 0.4947]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1777],\n",
      "        [ 1.2396],\n",
      "        [-1.8144],\n",
      "        [ 0.3142],\n",
      "        [-0.2274],\n",
      "        [-0.7927],\n",
      "        [ 1.1424],\n",
      "        [ 0.7924],\n",
      "        [-0.5567],\n",
      "        [ 0.4947]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1782],\n",
      "        [ 1.2402],\n",
      "        [-1.8146],\n",
      "        [ 0.3145],\n",
      "        [-0.2276],\n",
      "        [-0.7931],\n",
      "        [ 1.1421],\n",
      "        [ 0.7924],\n",
      "        [-0.5570],\n",
      "        [ 0.4947]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1786],\n",
      "        [ 1.2408],\n",
      "        [-1.8148],\n",
      "        [ 0.3148],\n",
      "        [-0.2279],\n",
      "        [-0.7934],\n",
      "        [ 1.1419],\n",
      "        [ 0.7924],\n",
      "        [-0.5574],\n",
      "        [ 0.4946]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1791],\n",
      "        [ 1.2414],\n",
      "        [-1.8151],\n",
      "        [ 0.3151],\n",
      "        [-0.2281],\n",
      "        [-0.7938],\n",
      "        [ 1.1417],\n",
      "        [ 0.7924],\n",
      "        [-0.5577],\n",
      "        [ 0.4946]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1796],\n",
      "        [ 1.2420],\n",
      "        [-1.8153],\n",
      "        [ 0.3154],\n",
      "        [-0.2283],\n",
      "        [-0.7942],\n",
      "        [ 1.1415],\n",
      "        [ 0.7924],\n",
      "        [-0.5581],\n",
      "        [ 0.4946]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1801],\n",
      "        [ 1.2425],\n",
      "        [-1.8155],\n",
      "        [ 0.3157],\n",
      "        [-0.2285],\n",
      "        [-0.7945],\n",
      "        [ 1.1412],\n",
      "        [ 0.7924],\n",
      "        [-0.5584],\n",
      "        [ 0.4946]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1806],\n",
      "        [ 1.2431],\n",
      "        [-1.8158],\n",
      "        [ 0.3160],\n",
      "        [-0.2287],\n",
      "        [-0.7949],\n",
      "        [ 1.1410],\n",
      "        [ 0.7924],\n",
      "        [-0.5588],\n",
      "        [ 0.4946]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1811],\n",
      "        [ 1.2437],\n",
      "        [-1.8160],\n",
      "        [ 0.3163],\n",
      "        [-0.2290],\n",
      "        [-0.7952],\n",
      "        [ 1.1408],\n",
      "        [ 0.7924],\n",
      "        [-0.5591],\n",
      "        [ 0.4946]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1816],\n",
      "        [ 1.2443],\n",
      "        [-1.8162],\n",
      "        [ 0.3166],\n",
      "        [-0.2292],\n",
      "        [-0.7956],\n",
      "        [ 1.1406],\n",
      "        [ 0.7924],\n",
      "        [-0.5595],\n",
      "        [ 0.4946]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1821],\n",
      "        [ 1.2449],\n",
      "        [-1.8165],\n",
      "        [ 0.3169],\n",
      "        [-0.2294],\n",
      "        [-0.7960],\n",
      "        [ 1.1404],\n",
      "        [ 0.7924],\n",
      "        [-0.5598],\n",
      "        [ 0.4946]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1825],\n",
      "        [ 1.2455],\n",
      "        [-1.8167],\n",
      "        [ 0.3172],\n",
      "        [-0.2296],\n",
      "        [-0.7963],\n",
      "        [ 1.1401],\n",
      "        [ 0.7924],\n",
      "        [-0.5602],\n",
      "        [ 0.4946]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1830],\n",
      "        [ 1.2461],\n",
      "        [-1.8169],\n",
      "        [ 0.3175],\n",
      "        [-0.2298],\n",
      "        [-0.7967],\n",
      "        [ 1.1399],\n",
      "        [ 0.7924],\n",
      "        [-0.5605],\n",
      "        [ 0.4945]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1835],\n",
      "        [ 1.2466],\n",
      "        [-1.8172],\n",
      "        [ 0.3178],\n",
      "        [-0.2301],\n",
      "        [-0.7971],\n",
      "        [ 1.1397],\n",
      "        [ 0.7924],\n",
      "        [-0.5609],\n",
      "        [ 0.4945]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1840],\n",
      "        [ 1.2472],\n",
      "        [-1.8174],\n",
      "        [ 0.3181],\n",
      "        [-0.2303],\n",
      "        [-0.7974],\n",
      "        [ 1.1395],\n",
      "        [ 0.7924],\n",
      "        [-0.5612],\n",
      "        [ 0.4945]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1845],\n",
      "        [ 1.2478],\n",
      "        [-1.8176],\n",
      "        [ 0.3184],\n",
      "        [-0.2305],\n",
      "        [-0.7978],\n",
      "        [ 1.1393],\n",
      "        [ 0.7924],\n",
      "        [-0.5616],\n",
      "        [ 0.4945]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1850],\n",
      "        [ 1.2484],\n",
      "        [-1.8179],\n",
      "        [ 0.3187],\n",
      "        [-0.2307],\n",
      "        [-0.7982],\n",
      "        [ 1.1390],\n",
      "        [ 0.7924],\n",
      "        [-0.5619],\n",
      "        [ 0.4945]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1854],\n",
      "        [ 1.2490],\n",
      "        [-1.8181],\n",
      "        [ 0.3190],\n",
      "        [-0.2309],\n",
      "        [-0.7985],\n",
      "        [ 1.1388],\n",
      "        [ 0.7924],\n",
      "        [-0.5623],\n",
      "        [ 0.4945]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1859],\n",
      "        [ 1.2496],\n",
      "        [-1.8183],\n",
      "        [ 0.3193],\n",
      "        [-0.2312],\n",
      "        [-0.7989],\n",
      "        [ 1.1386],\n",
      "        [ 0.7924],\n",
      "        [-0.5626],\n",
      "        [ 0.4945]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1864],\n",
      "        [ 1.2502],\n",
      "        [-1.8186],\n",
      "        [ 0.3196],\n",
      "        [-0.2314],\n",
      "        [-0.7992],\n",
      "        [ 1.1384],\n",
      "        [ 0.7924],\n",
      "        [-0.5630],\n",
      "        [ 0.4945]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1869],\n",
      "        [ 1.2507],\n",
      "        [-1.8188],\n",
      "        [ 0.3199],\n",
      "        [-0.2316],\n",
      "        [-0.7996],\n",
      "        [ 1.1382],\n",
      "        [ 0.7924],\n",
      "        [-0.5633],\n",
      "        [ 0.4945]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1874],\n",
      "        [ 1.2513],\n",
      "        [-1.8190],\n",
      "        [ 0.3202],\n",
      "        [-0.2318],\n",
      "        [-0.8000],\n",
      "        [ 1.1380],\n",
      "        [ 0.7924],\n",
      "        [-0.5637],\n",
      "        [ 0.4945]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1879],\n",
      "        [ 1.2519],\n",
      "        [-1.8193],\n",
      "        [ 0.3205],\n",
      "        [-0.2320],\n",
      "        [-0.8003],\n",
      "        [ 1.1377],\n",
      "        [ 0.7924],\n",
      "        [-0.5640],\n",
      "        [ 0.4944]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1883],\n",
      "        [ 1.2525],\n",
      "        [-1.8195],\n",
      "        [ 0.3208],\n",
      "        [-0.2322],\n",
      "        [-0.8007],\n",
      "        [ 1.1375],\n",
      "        [ 0.7924],\n",
      "        [-0.5644],\n",
      "        [ 0.4944]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1888],\n",
      "        [ 1.2531],\n",
      "        [-1.8197],\n",
      "        [ 0.3211],\n",
      "        [-0.2325],\n",
      "        [-0.8010],\n",
      "        [ 1.1373],\n",
      "        [ 0.7924],\n",
      "        [-0.5647],\n",
      "        [ 0.4944]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1893],\n",
      "        [ 1.2537],\n",
      "        [-1.8199],\n",
      "        [ 0.3214],\n",
      "        [-0.2327],\n",
      "        [-0.8014],\n",
      "        [ 1.1371],\n",
      "        [ 0.7924],\n",
      "        [-0.5650],\n",
      "        [ 0.4944]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1898],\n",
      "        [ 1.2542],\n",
      "        [-1.8202],\n",
      "        [ 0.3217],\n",
      "        [-0.2329],\n",
      "        [-0.8018],\n",
      "        [ 1.1369],\n",
      "        [ 0.7924],\n",
      "        [-0.5654],\n",
      "        [ 0.4944]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1903],\n",
      "        [ 1.2548],\n",
      "        [-1.8204],\n",
      "        [ 0.3220],\n",
      "        [-0.2331],\n",
      "        [-0.8021],\n",
      "        [ 1.1367],\n",
      "        [ 0.7924],\n",
      "        [-0.5657],\n",
      "        [ 0.4944]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1907],\n",
      "        [ 1.2554],\n",
      "        [-1.8206],\n",
      "        [ 0.3223],\n",
      "        [-0.2333],\n",
      "        [-0.8025],\n",
      "        [ 1.1364],\n",
      "        [ 0.7924],\n",
      "        [-0.5661],\n",
      "        [ 0.4944]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1912],\n",
      "        [ 1.2560],\n",
      "        [-1.8209],\n",
      "        [ 0.3226],\n",
      "        [-0.2335],\n",
      "        [-0.8028],\n",
      "        [ 1.1362],\n",
      "        [ 0.7924],\n",
      "        [-0.5664],\n",
      "        [ 0.4944]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1917],\n",
      "        [ 1.2566],\n",
      "        [-1.8211],\n",
      "        [ 0.3229],\n",
      "        [-0.2337],\n",
      "        [-0.8032],\n",
      "        [ 1.1360],\n",
      "        [ 0.7924],\n",
      "        [-0.5668],\n",
      "        [ 0.4944]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1922],\n",
      "        [ 1.2572],\n",
      "        [-1.8213],\n",
      "        [ 0.3232],\n",
      "        [-0.2339],\n",
      "        [-0.8036],\n",
      "        [ 1.1358],\n",
      "        [ 0.7924],\n",
      "        [-0.5671],\n",
      "        [ 0.4944]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1927],\n",
      "        [ 1.2577],\n",
      "        [-1.8215],\n",
      "        [ 0.3235],\n",
      "        [-0.2342],\n",
      "        [-0.8039],\n",
      "        [ 1.1356],\n",
      "        [ 0.7924],\n",
      "        [-0.5675],\n",
      "        [ 0.4943]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1931],\n",
      "        [ 1.2583],\n",
      "        [-1.8218],\n",
      "        [ 0.3238],\n",
      "        [-0.2344],\n",
      "        [-0.8043],\n",
      "        [ 1.1354],\n",
      "        [ 0.7924],\n",
      "        [-0.5678],\n",
      "        [ 0.4943]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1936],\n",
      "        [ 1.2589],\n",
      "        [-1.8220],\n",
      "        [ 0.3241],\n",
      "        [-0.2346],\n",
      "        [-0.8046],\n",
      "        [ 1.1352],\n",
      "        [ 0.7924],\n",
      "        [-0.5681],\n",
      "        [ 0.4943]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1941],\n",
      "        [ 1.2595],\n",
      "        [-1.8222],\n",
      "        [ 0.3244],\n",
      "        [-0.2348],\n",
      "        [-0.8050],\n",
      "        [ 1.1350],\n",
      "        [ 0.7924],\n",
      "        [-0.5685],\n",
      "        [ 0.4943]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1946],\n",
      "        [ 1.2601],\n",
      "        [-1.8224],\n",
      "        [ 0.3247],\n",
      "        [-0.2350],\n",
      "        [-0.8053],\n",
      "        [ 1.1348],\n",
      "        [ 0.7924],\n",
      "        [-0.5688],\n",
      "        [ 0.4943]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1950],\n",
      "        [ 1.2606],\n",
      "        [-1.8227],\n",
      "        [ 0.3250],\n",
      "        [-0.2352],\n",
      "        [-0.8057],\n",
      "        [ 1.1345],\n",
      "        [ 0.7924],\n",
      "        [-0.5692],\n",
      "        [ 0.4943]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1955],\n",
      "        [ 1.2612],\n",
      "        [-1.8229],\n",
      "        [ 0.3253],\n",
      "        [-0.2354],\n",
      "        [-0.8060],\n",
      "        [ 1.1343],\n",
      "        [ 0.7924],\n",
      "        [-0.5695],\n",
      "        [ 0.4943]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1960],\n",
      "        [ 1.2618],\n",
      "        [-1.8231],\n",
      "        [ 0.3256],\n",
      "        [-0.2356],\n",
      "        [-0.8064],\n",
      "        [ 1.1341],\n",
      "        [ 0.7924],\n",
      "        [-0.5698],\n",
      "        [ 0.4943]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1965],\n",
      "        [ 1.2624],\n",
      "        [-1.8233],\n",
      "        [ 0.3259],\n",
      "        [-0.2358],\n",
      "        [-0.8068],\n",
      "        [ 1.1339],\n",
      "        [ 0.7924],\n",
      "        [-0.5702],\n",
      "        [ 0.4943]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1970],\n",
      "        [ 1.2630],\n",
      "        [-1.8235],\n",
      "        [ 0.3262],\n",
      "        [-0.2361],\n",
      "        [-0.8071],\n",
      "        [ 1.1337],\n",
      "        [ 0.7924],\n",
      "        [-0.5705],\n",
      "        [ 0.4943]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1974],\n",
      "        [ 1.2636],\n",
      "        [-1.8238],\n",
      "        [ 0.3265],\n",
      "        [-0.2363],\n",
      "        [-0.8075],\n",
      "        [ 1.1335],\n",
      "        [ 0.7924],\n",
      "        [-0.5709],\n",
      "        [ 0.4942]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1979],\n",
      "        [ 1.2641],\n",
      "        [-1.8240],\n",
      "        [ 0.3268],\n",
      "        [-0.2365],\n",
      "        [-0.8078],\n",
      "        [ 1.1333],\n",
      "        [ 0.7924],\n",
      "        [-0.5712],\n",
      "        [ 0.4942]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1984],\n",
      "        [ 1.2647],\n",
      "        [-1.8242],\n",
      "        [ 0.3271],\n",
      "        [-0.2367],\n",
      "        [-0.8082],\n",
      "        [ 1.1331],\n",
      "        [ 0.7924],\n",
      "        [-0.5715],\n",
      "        [ 0.4942]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1989],\n",
      "        [ 1.2653],\n",
      "        [-1.8244],\n",
      "        [ 0.3274],\n",
      "        [-0.2369],\n",
      "        [-0.8085],\n",
      "        [ 1.1329],\n",
      "        [ 0.7924],\n",
      "        [-0.5719],\n",
      "        [ 0.4942]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1993],\n",
      "        [ 1.2659],\n",
      "        [-1.8247],\n",
      "        [ 0.3277],\n",
      "        [-0.2371],\n",
      "        [-0.8089],\n",
      "        [ 1.1327],\n",
      "        [ 0.7924],\n",
      "        [-0.5722],\n",
      "        [ 0.4942]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.1998],\n",
      "        [ 1.2664],\n",
      "        [-1.8249],\n",
      "        [ 0.3280],\n",
      "        [-0.2373],\n",
      "        [-0.8092],\n",
      "        [ 1.1325],\n",
      "        [ 0.7924],\n",
      "        [-0.5726],\n",
      "        [ 0.4942]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2003],\n",
      "        [ 1.2670],\n",
      "        [-1.8251],\n",
      "        [ 0.3283],\n",
      "        [-0.2375],\n",
      "        [-0.8096],\n",
      "        [ 1.1323],\n",
      "        [ 0.7924],\n",
      "        [-0.5729],\n",
      "        [ 0.4942]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2007],\n",
      "        [ 1.2676],\n",
      "        [-1.8253],\n",
      "        [ 0.3286],\n",
      "        [-0.2377],\n",
      "        [-0.8099],\n",
      "        [ 1.1320],\n",
      "        [ 0.7924],\n",
      "        [-0.5732],\n",
      "        [ 0.4942]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2012],\n",
      "        [ 1.2682],\n",
      "        [-1.8255],\n",
      "        [ 0.3289],\n",
      "        [-0.2379],\n",
      "        [-0.8103],\n",
      "        [ 1.1318],\n",
      "        [ 0.7924],\n",
      "        [-0.5736],\n",
      "        [ 0.4942]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2017],\n",
      "        [ 1.2688],\n",
      "        [-1.8257],\n",
      "        [ 0.3292],\n",
      "        [-0.2381],\n",
      "        [-0.8106],\n",
      "        [ 1.1316],\n",
      "        [ 0.7924],\n",
      "        [-0.5739],\n",
      "        [ 0.4942]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2022],\n",
      "        [ 1.2693],\n",
      "        [-1.8260],\n",
      "        [ 0.3295],\n",
      "        [-0.2383],\n",
      "        [-0.8110],\n",
      "        [ 1.1314],\n",
      "        [ 0.7924],\n",
      "        [-0.5743],\n",
      "        [ 0.4941]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2026],\n",
      "        [ 1.2699],\n",
      "        [-1.8262],\n",
      "        [ 0.3298],\n",
      "        [-0.2385],\n",
      "        [-0.8113],\n",
      "        [ 1.1312],\n",
      "        [ 0.7924],\n",
      "        [-0.5746],\n",
      "        [ 0.4941]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2031],\n",
      "        [ 1.2705],\n",
      "        [-1.8264],\n",
      "        [ 0.3301],\n",
      "        [-0.2387],\n",
      "        [-0.8117],\n",
      "        [ 1.1310],\n",
      "        [ 0.7924],\n",
      "        [-0.5749],\n",
      "        [ 0.4941]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2036],\n",
      "        [ 1.2711],\n",
      "        [-1.8266],\n",
      "        [ 0.3304],\n",
      "        [-0.2389],\n",
      "        [-0.8120],\n",
      "        [ 1.1308],\n",
      "        [ 0.7924],\n",
      "        [-0.5753],\n",
      "        [ 0.4941]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2040],\n",
      "        [ 1.2717],\n",
      "        [-1.8268],\n",
      "        [ 0.3307],\n",
      "        [-0.2391],\n",
      "        [-0.8124],\n",
      "        [ 1.1306],\n",
      "        [ 0.7924],\n",
      "        [-0.5756],\n",
      "        [ 0.4941]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2045],\n",
      "        [ 1.2722],\n",
      "        [-1.8271],\n",
      "        [ 0.3310],\n",
      "        [-0.2394],\n",
      "        [-0.8127],\n",
      "        [ 1.1304],\n",
      "        [ 0.7924],\n",
      "        [-0.5759],\n",
      "        [ 0.4941]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2050],\n",
      "        [ 1.2728],\n",
      "        [-1.8273],\n",
      "        [ 0.3313],\n",
      "        [-0.2396],\n",
      "        [-0.8131],\n",
      "        [ 1.1302],\n",
      "        [ 0.7924],\n",
      "        [-0.5763],\n",
      "        [ 0.4941]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2055],\n",
      "        [ 1.2734],\n",
      "        [-1.8275],\n",
      "        [ 0.3316],\n",
      "        [-0.2398],\n",
      "        [-0.8134],\n",
      "        [ 1.1300],\n",
      "        [ 0.7924],\n",
      "        [-0.5766],\n",
      "        [ 0.4941]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2059],\n",
      "        [ 1.2740],\n",
      "        [-1.8277],\n",
      "        [ 0.3319],\n",
      "        [-0.2400],\n",
      "        [-0.8138],\n",
      "        [ 1.1298],\n",
      "        [ 0.7924],\n",
      "        [-0.5770],\n",
      "        [ 0.4941]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2064],\n",
      "        [ 1.2745],\n",
      "        [-1.8279],\n",
      "        [ 0.3322],\n",
      "        [-0.2402],\n",
      "        [-0.8141],\n",
      "        [ 1.1296],\n",
      "        [ 0.7924],\n",
      "        [-0.5773],\n",
      "        [ 0.4941]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2069],\n",
      "        [ 1.2751],\n",
      "        [-1.8281],\n",
      "        [ 0.3325],\n",
      "        [-0.2404],\n",
      "        [-0.8145],\n",
      "        [ 1.1294],\n",
      "        [ 0.7924],\n",
      "        [-0.5776],\n",
      "        [ 0.4941]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2073],\n",
      "        [ 1.2757],\n",
      "        [-1.8284],\n",
      "        [ 0.3328],\n",
      "        [-0.2406],\n",
      "        [-0.8148],\n",
      "        [ 1.1292],\n",
      "        [ 0.7924],\n",
      "        [-0.5780],\n",
      "        [ 0.4940]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2078],\n",
      "        [ 1.2763],\n",
      "        [-1.8286],\n",
      "        [ 0.3331],\n",
      "        [-0.2408],\n",
      "        [-0.8152],\n",
      "        [ 1.1290],\n",
      "        [ 0.7924],\n",
      "        [-0.5783],\n",
      "        [ 0.4940]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2083],\n",
      "        [ 1.2768],\n",
      "        [-1.8288],\n",
      "        [ 0.3334],\n",
      "        [-0.2410],\n",
      "        [-0.8155],\n",
      "        [ 1.1288],\n",
      "        [ 0.7924],\n",
      "        [-0.5786],\n",
      "        [ 0.4940]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2087],\n",
      "        [ 1.2774],\n",
      "        [-1.8290],\n",
      "        [ 0.3337],\n",
      "        [-0.2412],\n",
      "        [-0.8159],\n",
      "        [ 1.1286],\n",
      "        [ 0.7924],\n",
      "        [-0.5790],\n",
      "        [ 0.4940]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2092],\n",
      "        [ 1.2780],\n",
      "        [-1.8292],\n",
      "        [ 0.3340],\n",
      "        [-0.2414],\n",
      "        [-0.8162],\n",
      "        [ 1.1284],\n",
      "        [ 0.7924],\n",
      "        [-0.5793],\n",
      "        [ 0.4940]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2097],\n",
      "        [ 1.2786],\n",
      "        [-1.8294],\n",
      "        [ 0.3343],\n",
      "        [-0.2416],\n",
      "        [-0.8165],\n",
      "        [ 1.1282],\n",
      "        [ 0.7924],\n",
      "        [-0.5796],\n",
      "        [ 0.4940]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2101],\n",
      "        [ 1.2791],\n",
      "        [-1.8296],\n",
      "        [ 0.3346],\n",
      "        [-0.2418],\n",
      "        [-0.8169],\n",
      "        [ 1.1280],\n",
      "        [ 0.7924],\n",
      "        [-0.5800],\n",
      "        [ 0.4940]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2106],\n",
      "        [ 1.2797],\n",
      "        [-1.8298],\n",
      "        [ 0.3349],\n",
      "        [-0.2420],\n",
      "        [-0.8172],\n",
      "        [ 1.1278],\n",
      "        [ 0.7924],\n",
      "        [-0.5803],\n",
      "        [ 0.4940]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2111],\n",
      "        [ 1.2803],\n",
      "        [-1.8301],\n",
      "        [ 0.3352],\n",
      "        [-0.2422],\n",
      "        [-0.8176],\n",
      "        [ 1.1276],\n",
      "        [ 0.7924],\n",
      "        [-0.5806],\n",
      "        [ 0.4940]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2115],\n",
      "        [ 1.2808],\n",
      "        [-1.8303],\n",
      "        [ 0.3354],\n",
      "        [-0.2424],\n",
      "        [-0.8179],\n",
      "        [ 1.1274],\n",
      "        [ 0.7924],\n",
      "        [-0.5810],\n",
      "        [ 0.4940]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2120],\n",
      "        [ 1.2814],\n",
      "        [-1.8305],\n",
      "        [ 0.3357],\n",
      "        [-0.2426],\n",
      "        [-0.8183],\n",
      "        [ 1.1272],\n",
      "        [ 0.7924],\n",
      "        [-0.5813],\n",
      "        [ 0.4939]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2125],\n",
      "        [ 1.2820],\n",
      "        [-1.8307],\n",
      "        [ 0.3360],\n",
      "        [-0.2428],\n",
      "        [-0.8186],\n",
      "        [ 1.1270],\n",
      "        [ 0.7924],\n",
      "        [-0.5816],\n",
      "        [ 0.4939]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2129],\n",
      "        [ 1.2826],\n",
      "        [-1.8309],\n",
      "        [ 0.3363],\n",
      "        [-0.2430],\n",
      "        [-0.8190],\n",
      "        [ 1.1268],\n",
      "        [ 0.7924],\n",
      "        [-0.5820],\n",
      "        [ 0.4939]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2134],\n",
      "        [ 1.2831],\n",
      "        [-1.8311],\n",
      "        [ 0.3366],\n",
      "        [-0.2432],\n",
      "        [-0.8193],\n",
      "        [ 1.1266],\n",
      "        [ 0.7924],\n",
      "        [-0.5823],\n",
      "        [ 0.4939]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2139],\n",
      "        [ 1.2837],\n",
      "        [-1.8313],\n",
      "        [ 0.3369],\n",
      "        [-0.2434],\n",
      "        [-0.8196],\n",
      "        [ 1.1264],\n",
      "        [ 0.7924],\n",
      "        [-0.5826],\n",
      "        [ 0.4939]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2143],\n",
      "        [ 1.2843],\n",
      "        [-1.8315],\n",
      "        [ 0.3372],\n",
      "        [-0.2436],\n",
      "        [-0.8200],\n",
      "        [ 1.1262],\n",
      "        [ 0.7924],\n",
      "        [-0.5830],\n",
      "        [ 0.4939]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2148],\n",
      "        [ 1.2848],\n",
      "        [-1.8317],\n",
      "        [ 0.3375],\n",
      "        [-0.2438],\n",
      "        [-0.8203],\n",
      "        [ 1.1260],\n",
      "        [ 0.7924],\n",
      "        [-0.5833],\n",
      "        [ 0.4939]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2153],\n",
      "        [ 1.2854],\n",
      "        [-1.8320],\n",
      "        [ 0.3378],\n",
      "        [-0.2439],\n",
      "        [-0.8207],\n",
      "        [ 1.1258],\n",
      "        [ 0.7924],\n",
      "        [-0.5836],\n",
      "        [ 0.4939]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2157],\n",
      "        [ 1.2860],\n",
      "        [-1.8322],\n",
      "        [ 0.3381],\n",
      "        [-0.2441],\n",
      "        [-0.8210],\n",
      "        [ 1.1256],\n",
      "        [ 0.7924],\n",
      "        [-0.5839],\n",
      "        [ 0.4939]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2162],\n",
      "        [ 1.2866],\n",
      "        [-1.8324],\n",
      "        [ 0.3384],\n",
      "        [-0.2443],\n",
      "        [-0.8214],\n",
      "        [ 1.1254],\n",
      "        [ 0.7924],\n",
      "        [-0.5843],\n",
      "        [ 0.4939]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2166],\n",
      "        [ 1.2871],\n",
      "        [-1.8326],\n",
      "        [ 0.3387],\n",
      "        [-0.2445],\n",
      "        [-0.8217],\n",
      "        [ 1.1252],\n",
      "        [ 0.7924],\n",
      "        [-0.5846],\n",
      "        [ 0.4939]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2171],\n",
      "        [ 1.2877],\n",
      "        [-1.8328],\n",
      "        [ 0.3390],\n",
      "        [-0.2447],\n",
      "        [-0.8220],\n",
      "        [ 1.1250],\n",
      "        [ 0.7924],\n",
      "        [-0.5849],\n",
      "        [ 0.4938]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2176],\n",
      "        [ 1.2883],\n",
      "        [-1.8330],\n",
      "        [ 0.3393],\n",
      "        [-0.2449],\n",
      "        [-0.8224],\n",
      "        [ 1.1248],\n",
      "        [ 0.7924],\n",
      "        [-0.5853],\n",
      "        [ 0.4938]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2180],\n",
      "        [ 1.2888],\n",
      "        [-1.8332],\n",
      "        [ 0.3396],\n",
      "        [-0.2451],\n",
      "        [-0.8227],\n",
      "        [ 1.1246],\n",
      "        [ 0.7924],\n",
      "        [-0.5856],\n",
      "        [ 0.4938]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2185],\n",
      "        [ 1.2894],\n",
      "        [-1.8334],\n",
      "        [ 0.3399],\n",
      "        [-0.2453],\n",
      "        [-0.8231],\n",
      "        [ 1.1244],\n",
      "        [ 0.7924],\n",
      "        [-0.5859],\n",
      "        [ 0.4938]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2189],\n",
      "        [ 1.2900],\n",
      "        [-1.8336],\n",
      "        [ 0.3402],\n",
      "        [-0.2455],\n",
      "        [-0.8234],\n",
      "        [ 1.1243],\n",
      "        [ 0.7924],\n",
      "        [-0.5863],\n",
      "        [ 0.4938]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2194],\n",
      "        [ 1.2905],\n",
      "        [-1.8338],\n",
      "        [ 0.3404],\n",
      "        [-0.2457],\n",
      "        [-0.8237],\n",
      "        [ 1.1241],\n",
      "        [ 0.7924],\n",
      "        [-0.5866],\n",
      "        [ 0.4938]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2199],\n",
      "        [ 1.2911],\n",
      "        [-1.8340],\n",
      "        [ 0.3407],\n",
      "        [-0.2459],\n",
      "        [-0.8241],\n",
      "        [ 1.1239],\n",
      "        [ 0.7924],\n",
      "        [-0.5869],\n",
      "        [ 0.4938]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2203],\n",
      "        [ 1.2917],\n",
      "        [-1.8342],\n",
      "        [ 0.3410],\n",
      "        [-0.2461],\n",
      "        [-0.8244],\n",
      "        [ 1.1237],\n",
      "        [ 0.7924],\n",
      "        [-0.5872],\n",
      "        [ 0.4938]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2208],\n",
      "        [ 1.2922],\n",
      "        [-1.8344],\n",
      "        [ 0.3413],\n",
      "        [-0.2463],\n",
      "        [-0.8248],\n",
      "        [ 1.1235],\n",
      "        [ 0.7924],\n",
      "        [-0.5876],\n",
      "        [ 0.4938]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2212],\n",
      "        [ 1.2928],\n",
      "        [-1.8347],\n",
      "        [ 0.3416],\n",
      "        [-0.2465],\n",
      "        [-0.8251],\n",
      "        [ 1.1233],\n",
      "        [ 0.7924],\n",
      "        [-0.5879],\n",
      "        [ 0.4938]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2217],\n",
      "        [ 1.2934],\n",
      "        [-1.8349],\n",
      "        [ 0.3419],\n",
      "        [-0.2467],\n",
      "        [-0.8254],\n",
      "        [ 1.1231],\n",
      "        [ 0.7924],\n",
      "        [-0.5882],\n",
      "        [ 0.4938]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2222],\n",
      "        [ 1.2939],\n",
      "        [-1.8351],\n",
      "        [ 0.3422],\n",
      "        [-0.2469],\n",
      "        [-0.8258],\n",
      "        [ 1.1229],\n",
      "        [ 0.7924],\n",
      "        [-0.5886],\n",
      "        [ 0.4937]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2226],\n",
      "        [ 1.2945],\n",
      "        [-1.8353],\n",
      "        [ 0.3425],\n",
      "        [-0.2470],\n",
      "        [-0.8261],\n",
      "        [ 1.1227],\n",
      "        [ 0.7924],\n",
      "        [-0.5889],\n",
      "        [ 0.4937]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2231],\n",
      "        [ 1.2951],\n",
      "        [-1.8355],\n",
      "        [ 0.3428],\n",
      "        [-0.2472],\n",
      "        [-0.8265],\n",
      "        [ 1.1225],\n",
      "        [ 0.7924],\n",
      "        [-0.5892],\n",
      "        [ 0.4937]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2235],\n",
      "        [ 1.2956],\n",
      "        [-1.8357],\n",
      "        [ 0.3431],\n",
      "        [-0.2474],\n",
      "        [-0.8268],\n",
      "        [ 1.1223],\n",
      "        [ 0.7924],\n",
      "        [-0.5895],\n",
      "        [ 0.4937]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2240],\n",
      "        [ 1.2962],\n",
      "        [-1.8359],\n",
      "        [ 0.3434],\n",
      "        [-0.2476],\n",
      "        [-0.8271],\n",
      "        [ 1.1221],\n",
      "        [ 0.7924],\n",
      "        [-0.5899],\n",
      "        [ 0.4937]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2245],\n",
      "        [ 1.2968],\n",
      "        [-1.8361],\n",
      "        [ 0.3437],\n",
      "        [-0.2478],\n",
      "        [-0.8275],\n",
      "        [ 1.1219],\n",
      "        [ 0.7924],\n",
      "        [-0.5902],\n",
      "        [ 0.4937]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2249],\n",
      "        [ 1.2973],\n",
      "        [-1.8363],\n",
      "        [ 0.3440],\n",
      "        [-0.2480],\n",
      "        [-0.8278],\n",
      "        [ 1.1218],\n",
      "        [ 0.7924],\n",
      "        [-0.5905],\n",
      "        [ 0.4937]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2254],\n",
      "        [ 1.2979],\n",
      "        [-1.8365],\n",
      "        [ 0.3442],\n",
      "        [-0.2482],\n",
      "        [-0.8281],\n",
      "        [ 1.1216],\n",
      "        [ 0.7924],\n",
      "        [-0.5908],\n",
      "        [ 0.4937]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2258],\n",
      "        [ 1.2985],\n",
      "        [-1.8367],\n",
      "        [ 0.3445],\n",
      "        [-0.2484],\n",
      "        [-0.8285],\n",
      "        [ 1.1214],\n",
      "        [ 0.7924],\n",
      "        [-0.5912],\n",
      "        [ 0.4937]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2263],\n",
      "        [ 1.2990],\n",
      "        [-1.8369],\n",
      "        [ 0.3448],\n",
      "        [-0.2486],\n",
      "        [-0.8288],\n",
      "        [ 1.1212],\n",
      "        [ 0.7924],\n",
      "        [-0.5915],\n",
      "        [ 0.4937]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2267],\n",
      "        [ 1.2996],\n",
      "        [-1.8371],\n",
      "        [ 0.3451],\n",
      "        [-0.2488],\n",
      "        [-0.8292],\n",
      "        [ 1.1210],\n",
      "        [ 0.7924],\n",
      "        [-0.5918],\n",
      "        [ 0.4937]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2272],\n",
      "        [ 1.3002],\n",
      "        [-1.8373],\n",
      "        [ 0.3454],\n",
      "        [-0.2490],\n",
      "        [-0.8295],\n",
      "        [ 1.1208],\n",
      "        [ 0.7924],\n",
      "        [-0.5922],\n",
      "        [ 0.4936]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2276],\n",
      "        [ 1.3007],\n",
      "        [-1.8375],\n",
      "        [ 0.3457],\n",
      "        [-0.2491],\n",
      "        [-0.8298],\n",
      "        [ 1.1206],\n",
      "        [ 0.7924],\n",
      "        [-0.5925],\n",
      "        [ 0.4936]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2281],\n",
      "        [ 1.3013],\n",
      "        [-1.8377],\n",
      "        [ 0.3460],\n",
      "        [-0.2493],\n",
      "        [-0.8302],\n",
      "        [ 1.1204],\n",
      "        [ 0.7924],\n",
      "        [-0.5928],\n",
      "        [ 0.4936]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2286],\n",
      "        [ 1.3018],\n",
      "        [-1.8379],\n",
      "        [ 0.3463],\n",
      "        [-0.2495],\n",
      "        [-0.8305],\n",
      "        [ 1.1202],\n",
      "        [ 0.7924],\n",
      "        [-0.5931],\n",
      "        [ 0.4936]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2290],\n",
      "        [ 1.3024],\n",
      "        [-1.8381],\n",
      "        [ 0.3466],\n",
      "        [-0.2497],\n",
      "        [-0.8308],\n",
      "        [ 1.1201],\n",
      "        [ 0.7924],\n",
      "        [-0.5935],\n",
      "        [ 0.4936]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2295],\n",
      "        [ 1.3030],\n",
      "        [-1.8383],\n",
      "        [ 0.3469],\n",
      "        [-0.2499],\n",
      "        [-0.8312],\n",
      "        [ 1.1199],\n",
      "        [ 0.7924],\n",
      "        [-0.5938],\n",
      "        [ 0.4936]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2299],\n",
      "        [ 1.3035],\n",
      "        [-1.8385],\n",
      "        [ 0.3472],\n",
      "        [-0.2501],\n",
      "        [-0.8315],\n",
      "        [ 1.1197],\n",
      "        [ 0.7924],\n",
      "        [-0.5941],\n",
      "        [ 0.4936]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2304],\n",
      "        [ 1.3041],\n",
      "        [-1.8387],\n",
      "        [ 0.3474],\n",
      "        [-0.2503],\n",
      "        [-0.8318],\n",
      "        [ 1.1195],\n",
      "        [ 0.7924],\n",
      "        [-0.5944],\n",
      "        [ 0.4936]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2308],\n",
      "        [ 1.3047],\n",
      "        [-1.8389],\n",
      "        [ 0.3477],\n",
      "        [-0.2505],\n",
      "        [-0.8322],\n",
      "        [ 1.1193],\n",
      "        [ 0.7924],\n",
      "        [-0.5948],\n",
      "        [ 0.4936]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2313],\n",
      "        [ 1.3052],\n",
      "        [-1.8391],\n",
      "        [ 0.3480],\n",
      "        [-0.2506],\n",
      "        [-0.8325],\n",
      "        [ 1.1191],\n",
      "        [ 0.7924],\n",
      "        [-0.5951],\n",
      "        [ 0.4936]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2317],\n",
      "        [ 1.3058],\n",
      "        [-1.8393],\n",
      "        [ 0.3483],\n",
      "        [-0.2508],\n",
      "        [-0.8328],\n",
      "        [ 1.1189],\n",
      "        [ 0.7924],\n",
      "        [-0.5954],\n",
      "        [ 0.4936]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2322],\n",
      "        [ 1.3063],\n",
      "        [-1.8395],\n",
      "        [ 0.3486],\n",
      "        [-0.2510],\n",
      "        [-0.8332],\n",
      "        [ 1.1187],\n",
      "        [ 0.7924],\n",
      "        [-0.5957],\n",
      "        [ 0.4935]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2326],\n",
      "        [ 1.3069],\n",
      "        [-1.8397],\n",
      "        [ 0.3489],\n",
      "        [-0.2512],\n",
      "        [-0.8335],\n",
      "        [ 1.1186],\n",
      "        [ 0.7924],\n",
      "        [-0.5960],\n",
      "        [ 0.4935]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2331],\n",
      "        [ 1.3074],\n",
      "        [-1.8399],\n",
      "        [ 0.3492],\n",
      "        [-0.2514],\n",
      "        [-0.8338],\n",
      "        [ 1.1184],\n",
      "        [ 0.7924],\n",
      "        [-0.5964],\n",
      "        [ 0.4935]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2335],\n",
      "        [ 1.3080],\n",
      "        [-1.8401],\n",
      "        [ 0.3495],\n",
      "        [-0.2516],\n",
      "        [-0.8342],\n",
      "        [ 1.1182],\n",
      "        [ 0.7924],\n",
      "        [-0.5967],\n",
      "        [ 0.4935]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2340],\n",
      "        [ 1.3086],\n",
      "        [-1.8403],\n",
      "        [ 0.3498],\n",
      "        [-0.2518],\n",
      "        [-0.8345],\n",
      "        [ 1.1180],\n",
      "        [ 0.7924],\n",
      "        [-0.5970],\n",
      "        [ 0.4935]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2344],\n",
      "        [ 1.3091],\n",
      "        [-1.8405],\n",
      "        [ 0.3500],\n",
      "        [-0.2519],\n",
      "        [-0.8348],\n",
      "        [ 1.1178],\n",
      "        [ 0.7924],\n",
      "        [-0.5973],\n",
      "        [ 0.4935]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2349],\n",
      "        [ 1.3097],\n",
      "        [-1.8407],\n",
      "        [ 0.3503],\n",
      "        [-0.2521],\n",
      "        [-0.8352],\n",
      "        [ 1.1176],\n",
      "        [ 0.7924],\n",
      "        [-0.5977],\n",
      "        [ 0.4935]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2353],\n",
      "        [ 1.3102],\n",
      "        [-1.8409],\n",
      "        [ 0.3506],\n",
      "        [-0.2523],\n",
      "        [-0.8355],\n",
      "        [ 1.1175],\n",
      "        [ 0.7924],\n",
      "        [-0.5980],\n",
      "        [ 0.4935]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2358],\n",
      "        [ 1.3108],\n",
      "        [-1.8411],\n",
      "        [ 0.3509],\n",
      "        [-0.2525],\n",
      "        [-0.8358],\n",
      "        [ 1.1173],\n",
      "        [ 0.7924],\n",
      "        [-0.5983],\n",
      "        [ 0.4935]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2362],\n",
      "        [ 1.3114],\n",
      "        [-1.8413],\n",
      "        [ 0.3512],\n",
      "        [-0.2527],\n",
      "        [-0.8361],\n",
      "        [ 1.1171],\n",
      "        [ 0.7924],\n",
      "        [-0.5986],\n",
      "        [ 0.4935]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2367],\n",
      "        [ 1.3119],\n",
      "        [-1.8415],\n",
      "        [ 0.3515],\n",
      "        [-0.2529],\n",
      "        [-0.8365],\n",
      "        [ 1.1169],\n",
      "        [ 0.7924],\n",
      "        [-0.5990],\n",
      "        [ 0.4935]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2371],\n",
      "        [ 1.3125],\n",
      "        [-1.8417],\n",
      "        [ 0.3518],\n",
      "        [-0.2530],\n",
      "        [-0.8368],\n",
      "        [ 1.1167],\n",
      "        [ 0.7924],\n",
      "        [-0.5993],\n",
      "        [ 0.4935]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2376],\n",
      "        [ 1.3130],\n",
      "        [-1.8419],\n",
      "        [ 0.3521],\n",
      "        [-0.2532],\n",
      "        [-0.8371],\n",
      "        [ 1.1165],\n",
      "        [ 0.7924],\n",
      "        [-0.5996],\n",
      "        [ 0.4934]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2380],\n",
      "        [ 1.3136],\n",
      "        [-1.8421],\n",
      "        [ 0.3523],\n",
      "        [-0.2534],\n",
      "        [-0.8375],\n",
      "        [ 1.1164],\n",
      "        [ 0.7924],\n",
      "        [-0.5999],\n",
      "        [ 0.4934]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2385],\n",
      "        [ 1.3141],\n",
      "        [-1.8423],\n",
      "        [ 0.3526],\n",
      "        [-0.2536],\n",
      "        [-0.8378],\n",
      "        [ 1.1162],\n",
      "        [ 0.7924],\n",
      "        [-0.6002],\n",
      "        [ 0.4934]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2389],\n",
      "        [ 1.3147],\n",
      "        [-1.8425],\n",
      "        [ 0.3529],\n",
      "        [-0.2538],\n",
      "        [-0.8381],\n",
      "        [ 1.1160],\n",
      "        [ 0.7924],\n",
      "        [-0.6006],\n",
      "        [ 0.4934]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2394],\n",
      "        [ 1.3152],\n",
      "        [-1.8427],\n",
      "        [ 0.3532],\n",
      "        [-0.2540],\n",
      "        [-0.8385],\n",
      "        [ 1.1158],\n",
      "        [ 0.7924],\n",
      "        [-0.6009],\n",
      "        [ 0.4934]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2398],\n",
      "        [ 1.3158],\n",
      "        [-1.8429],\n",
      "        [ 0.3535],\n",
      "        [-0.2541],\n",
      "        [-0.8388],\n",
      "        [ 1.1156],\n",
      "        [ 0.7924],\n",
      "        [-0.6012],\n",
      "        [ 0.4934]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2403],\n",
      "        [ 1.3164],\n",
      "        [-1.8431],\n",
      "        [ 0.3538],\n",
      "        [-0.2543],\n",
      "        [-0.8391],\n",
      "        [ 1.1154],\n",
      "        [ 0.7924],\n",
      "        [-0.6015],\n",
      "        [ 0.4934]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2407],\n",
      "        [ 1.3169],\n",
      "        [-1.8432],\n",
      "        [ 0.3541],\n",
      "        [-0.2545],\n",
      "        [-0.8394],\n",
      "        [ 1.1153],\n",
      "        [ 0.7924],\n",
      "        [-0.6018],\n",
      "        [ 0.4934]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2412],\n",
      "        [ 1.3175],\n",
      "        [-1.8434],\n",
      "        [ 0.3544],\n",
      "        [-0.2547],\n",
      "        [-0.8398],\n",
      "        [ 1.1151],\n",
      "        [ 0.7924],\n",
      "        [-0.6022],\n",
      "        [ 0.4934]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2416],\n",
      "        [ 1.3180],\n",
      "        [-1.8436],\n",
      "        [ 0.3546],\n",
      "        [-0.2549],\n",
      "        [-0.8401],\n",
      "        [ 1.1149],\n",
      "        [ 0.7924],\n",
      "        [-0.6025],\n",
      "        [ 0.4934]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2421],\n",
      "        [ 1.3186],\n",
      "        [-1.8438],\n",
      "        [ 0.3549],\n",
      "        [-0.2550],\n",
      "        [-0.8404],\n",
      "        [ 1.1147],\n",
      "        [ 0.7924],\n",
      "        [-0.6028],\n",
      "        [ 0.4934]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2425],\n",
      "        [ 1.3191],\n",
      "        [-1.8440],\n",
      "        [ 0.3552],\n",
      "        [-0.2552],\n",
      "        [-0.8407],\n",
      "        [ 1.1145],\n",
      "        [ 0.7924],\n",
      "        [-0.6031],\n",
      "        [ 0.4933]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2429],\n",
      "        [ 1.3197],\n",
      "        [-1.8442],\n",
      "        [ 0.3555],\n",
      "        [-0.2554],\n",
      "        [-0.8411],\n",
      "        [ 1.1144],\n",
      "        [ 0.7924],\n",
      "        [-0.6034],\n",
      "        [ 0.4933]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2434],\n",
      "        [ 1.3202],\n",
      "        [-1.8444],\n",
      "        [ 0.3558],\n",
      "        [-0.2556],\n",
      "        [-0.8414],\n",
      "        [ 1.1142],\n",
      "        [ 0.7924],\n",
      "        [-0.6038],\n",
      "        [ 0.4933]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2438],\n",
      "        [ 1.3208],\n",
      "        [-1.8446],\n",
      "        [ 0.3561],\n",
      "        [-0.2558],\n",
      "        [-0.8417],\n",
      "        [ 1.1140],\n",
      "        [ 0.7924],\n",
      "        [-0.6041],\n",
      "        [ 0.4933]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2443],\n",
      "        [ 1.3213],\n",
      "        [-1.8448],\n",
      "        [ 0.3564],\n",
      "        [-0.2559],\n",
      "        [-0.8421],\n",
      "        [ 1.1138],\n",
      "        [ 0.7924],\n",
      "        [-0.6044],\n",
      "        [ 0.4933]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2447],\n",
      "        [ 1.3219],\n",
      "        [-1.8450],\n",
      "        [ 0.3566],\n",
      "        [-0.2561],\n",
      "        [-0.8424],\n",
      "        [ 1.1136],\n",
      "        [ 0.7924],\n",
      "        [-0.6047],\n",
      "        [ 0.4933]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2452],\n",
      "        [ 1.3224],\n",
      "        [-1.8452],\n",
      "        [ 0.3569],\n",
      "        [-0.2563],\n",
      "        [-0.8427],\n",
      "        [ 1.1135],\n",
      "        [ 0.7924],\n",
      "        [-0.6050],\n",
      "        [ 0.4933]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2456],\n",
      "        [ 1.3230],\n",
      "        [-1.8454],\n",
      "        [ 0.3572],\n",
      "        [-0.2565],\n",
      "        [-0.8430],\n",
      "        [ 1.1133],\n",
      "        [ 0.7924],\n",
      "        [-0.6054],\n",
      "        [ 0.4933]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2461],\n",
      "        [ 1.3235],\n",
      "        [-1.8456],\n",
      "        [ 0.3575],\n",
      "        [-0.2567],\n",
      "        [-0.8434],\n",
      "        [ 1.1131],\n",
      "        [ 0.7924],\n",
      "        [-0.6057],\n",
      "        [ 0.4933]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2465],\n",
      "        [ 1.3241],\n",
      "        [-1.8458],\n",
      "        [ 0.3578],\n",
      "        [-0.2568],\n",
      "        [-0.8437],\n",
      "        [ 1.1129],\n",
      "        [ 0.7924],\n",
      "        [-0.6060],\n",
      "        [ 0.4933]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2469],\n",
      "        [ 1.3246],\n",
      "        [-1.8459],\n",
      "        [ 0.3581],\n",
      "        [-0.2570],\n",
      "        [-0.8440],\n",
      "        [ 1.1127],\n",
      "        [ 0.7924],\n",
      "        [-0.6063],\n",
      "        [ 0.4933]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2474],\n",
      "        [ 1.3252],\n",
      "        [-1.8461],\n",
      "        [ 0.3584],\n",
      "        [-0.2572],\n",
      "        [-0.8443],\n",
      "        [ 1.1126],\n",
      "        [ 0.7924],\n",
      "        [-0.6066],\n",
      "        [ 0.4933]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2478],\n",
      "        [ 1.3257],\n",
      "        [-1.8463],\n",
      "        [ 0.3586],\n",
      "        [-0.2574],\n",
      "        [-0.8447],\n",
      "        [ 1.1124],\n",
      "        [ 0.7924],\n",
      "        [-0.6069],\n",
      "        [ 0.4932]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2483],\n",
      "        [ 1.3263],\n",
      "        [-1.8465],\n",
      "        [ 0.3589],\n",
      "        [-0.2575],\n",
      "        [-0.8450],\n",
      "        [ 1.1122],\n",
      "        [ 0.7924],\n",
      "        [-0.6073],\n",
      "        [ 0.4932]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2487],\n",
      "        [ 1.3268],\n",
      "        [-1.8467],\n",
      "        [ 0.3592],\n",
      "        [-0.2577],\n",
      "        [-0.8453],\n",
      "        [ 1.1120],\n",
      "        [ 0.7924],\n",
      "        [-0.6076],\n",
      "        [ 0.4932]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2491],\n",
      "        [ 1.3274],\n",
      "        [-1.8469],\n",
      "        [ 0.3595],\n",
      "        [-0.2579],\n",
      "        [-0.8456],\n",
      "        [ 1.1119],\n",
      "        [ 0.7924],\n",
      "        [-0.6079],\n",
      "        [ 0.4932]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2496],\n",
      "        [ 1.3279],\n",
      "        [-1.8471],\n",
      "        [ 0.3598],\n",
      "        [-0.2581],\n",
      "        [-0.8460],\n",
      "        [ 1.1117],\n",
      "        [ 0.7924],\n",
      "        [-0.6082],\n",
      "        [ 0.4932]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2500],\n",
      "        [ 1.3285],\n",
      "        [-1.8473],\n",
      "        [ 0.3601],\n",
      "        [-0.2582],\n",
      "        [-0.8463],\n",
      "        [ 1.1115],\n",
      "        [ 0.7924],\n",
      "        [-0.6085],\n",
      "        [ 0.4932]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2505],\n",
      "        [ 1.3290],\n",
      "        [-1.8475],\n",
      "        [ 0.3603],\n",
      "        [-0.2584],\n",
      "        [-0.8466],\n",
      "        [ 1.1113],\n",
      "        [ 0.7924],\n",
      "        [-0.6089],\n",
      "        [ 0.4932]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2509],\n",
      "        [ 1.3295],\n",
      "        [-1.8477],\n",
      "        [ 0.3606],\n",
      "        [-0.2586],\n",
      "        [-0.8469],\n",
      "        [ 1.1112],\n",
      "        [ 0.7924],\n",
      "        [-0.6092],\n",
      "        [ 0.4932]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2513],\n",
      "        [ 1.3301],\n",
      "        [-1.8478],\n",
      "        [ 0.3609],\n",
      "        [-0.2588],\n",
      "        [-0.8472],\n",
      "        [ 1.1110],\n",
      "        [ 0.7924],\n",
      "        [-0.6095],\n",
      "        [ 0.4932]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2518],\n",
      "        [ 1.3306],\n",
      "        [-1.8480],\n",
      "        [ 0.3612],\n",
      "        [-0.2590],\n",
      "        [-0.8476],\n",
      "        [ 1.1108],\n",
      "        [ 0.7924],\n",
      "        [-0.6098],\n",
      "        [ 0.4932]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2522],\n",
      "        [ 1.3312],\n",
      "        [-1.8482],\n",
      "        [ 0.3615],\n",
      "        [-0.2591],\n",
      "        [-0.8479],\n",
      "        [ 1.1106],\n",
      "        [ 0.7924],\n",
      "        [-0.6101],\n",
      "        [ 0.4932]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2527],\n",
      "        [ 1.3317],\n",
      "        [-1.8484],\n",
      "        [ 0.3618],\n",
      "        [-0.2593],\n",
      "        [-0.8482],\n",
      "        [ 1.1105],\n",
      "        [ 0.7924],\n",
      "        [-0.6104],\n",
      "        [ 0.4932]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2531],\n",
      "        [ 1.3323],\n",
      "        [-1.8486],\n",
      "        [ 0.3620],\n",
      "        [-0.2595],\n",
      "        [-0.8485],\n",
      "        [ 1.1103],\n",
      "        [ 0.7924],\n",
      "        [-0.6108],\n",
      "        [ 0.4931]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2535],\n",
      "        [ 1.3328],\n",
      "        [-1.8488],\n",
      "        [ 0.3623],\n",
      "        [-0.2597],\n",
      "        [-0.8489],\n",
      "        [ 1.1101],\n",
      "        [ 0.7924],\n",
      "        [-0.6111],\n",
      "        [ 0.4931]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2540],\n",
      "        [ 1.3334],\n",
      "        [-1.8490],\n",
      "        [ 0.3626],\n",
      "        [-0.2598],\n",
      "        [-0.8492],\n",
      "        [ 1.1099],\n",
      "        [ 0.7924],\n",
      "        [-0.6114],\n",
      "        [ 0.4931]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2544],\n",
      "        [ 1.3339],\n",
      "        [-1.8492],\n",
      "        [ 0.3629],\n",
      "        [-0.2600],\n",
      "        [-0.8495],\n",
      "        [ 1.1098],\n",
      "        [ 0.7924],\n",
      "        [-0.6117],\n",
      "        [ 0.4931]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2549],\n",
      "        [ 1.3344],\n",
      "        [-1.8493],\n",
      "        [ 0.3632],\n",
      "        [-0.2602],\n",
      "        [-0.8498],\n",
      "        [ 1.1096],\n",
      "        [ 0.7924],\n",
      "        [-0.6120],\n",
      "        [ 0.4931]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2553],\n",
      "        [ 1.3350],\n",
      "        [-1.8495],\n",
      "        [ 0.3634],\n",
      "        [-0.2603],\n",
      "        [-0.8501],\n",
      "        [ 1.1094],\n",
      "        [ 0.7924],\n",
      "        [-0.6123],\n",
      "        [ 0.4931]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2557],\n",
      "        [ 1.3355],\n",
      "        [-1.8497],\n",
      "        [ 0.3637],\n",
      "        [-0.2605],\n",
      "        [-0.8505],\n",
      "        [ 1.1092],\n",
      "        [ 0.7924],\n",
      "        [-0.6127],\n",
      "        [ 0.4931]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2562],\n",
      "        [ 1.3361],\n",
      "        [-1.8499],\n",
      "        [ 0.3640],\n",
      "        [-0.2607],\n",
      "        [-0.8508],\n",
      "        [ 1.1091],\n",
      "        [ 0.7924],\n",
      "        [-0.6130],\n",
      "        [ 0.4931]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2566],\n",
      "        [ 1.3366],\n",
      "        [-1.8501],\n",
      "        [ 0.3643],\n",
      "        [-0.2609],\n",
      "        [-0.8511],\n",
      "        [ 1.1089],\n",
      "        [ 0.7924],\n",
      "        [-0.6133],\n",
      "        [ 0.4931]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2570],\n",
      "        [ 1.3372],\n",
      "        [-1.8503],\n",
      "        [ 0.3646],\n",
      "        [-0.2610],\n",
      "        [-0.8514],\n",
      "        [ 1.1087],\n",
      "        [ 0.7924],\n",
      "        [-0.6136],\n",
      "        [ 0.4931]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2575],\n",
      "        [ 1.3377],\n",
      "        [-1.8505],\n",
      "        [ 0.3648],\n",
      "        [-0.2612],\n",
      "        [-0.8517],\n",
      "        [ 1.1085],\n",
      "        [ 0.7924],\n",
      "        [-0.6139],\n",
      "        [ 0.4931]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2579],\n",
      "        [ 1.3382],\n",
      "        [-1.8506],\n",
      "        [ 0.3651],\n",
      "        [-0.2614],\n",
      "        [-0.8521],\n",
      "        [ 1.1084],\n",
      "        [ 0.7924],\n",
      "        [-0.6142],\n",
      "        [ 0.4931]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2583],\n",
      "        [ 1.3388],\n",
      "        [-1.8508],\n",
      "        [ 0.3654],\n",
      "        [-0.2616],\n",
      "        [-0.8524],\n",
      "        [ 1.1082],\n",
      "        [ 0.7924],\n",
      "        [-0.6145],\n",
      "        [ 0.4930]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2588],\n",
      "        [ 1.3393],\n",
      "        [-1.8510],\n",
      "        [ 0.3657],\n",
      "        [-0.2617],\n",
      "        [-0.8527],\n",
      "        [ 1.1080],\n",
      "        [ 0.7924],\n",
      "        [-0.6149],\n",
      "        [ 0.4930]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2592],\n",
      "        [ 1.3399],\n",
      "        [-1.8512],\n",
      "        [ 0.3660],\n",
      "        [-0.2619],\n",
      "        [-0.8530],\n",
      "        [ 1.1079],\n",
      "        [ 0.7924],\n",
      "        [-0.6152],\n",
      "        [ 0.4930]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2596],\n",
      "        [ 1.3404],\n",
      "        [-1.8514],\n",
      "        [ 0.3663],\n",
      "        [-0.2621],\n",
      "        [-0.8533],\n",
      "        [ 1.1077],\n",
      "        [ 0.7924],\n",
      "        [-0.6155],\n",
      "        [ 0.4930]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2601],\n",
      "        [ 1.3409],\n",
      "        [-1.8516],\n",
      "        [ 0.3665],\n",
      "        [-0.2622],\n",
      "        [-0.8537],\n",
      "        [ 1.1075],\n",
      "        [ 0.7924],\n",
      "        [-0.6158],\n",
      "        [ 0.4930]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2605],\n",
      "        [ 1.3415],\n",
      "        [-1.8518],\n",
      "        [ 0.3668],\n",
      "        [-0.2624],\n",
      "        [-0.8540],\n",
      "        [ 1.1073],\n",
      "        [ 0.7924],\n",
      "        [-0.6161],\n",
      "        [ 0.4930]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2609],\n",
      "        [ 1.3420],\n",
      "        [-1.8519],\n",
      "        [ 0.3671],\n",
      "        [-0.2626],\n",
      "        [-0.8543],\n",
      "        [ 1.1072],\n",
      "        [ 0.7924],\n",
      "        [-0.6164],\n",
      "        [ 0.4930]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2614],\n",
      "        [ 1.3425],\n",
      "        [-1.8521],\n",
      "        [ 0.3674],\n",
      "        [-0.2628],\n",
      "        [-0.8546],\n",
      "        [ 1.1070],\n",
      "        [ 0.7924],\n",
      "        [-0.6167],\n",
      "        [ 0.4930]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2618],\n",
      "        [ 1.3431],\n",
      "        [-1.8523],\n",
      "        [ 0.3676],\n",
      "        [-0.2629],\n",
      "        [-0.8549],\n",
      "        [ 1.1068],\n",
      "        [ 0.7924],\n",
      "        [-0.6171],\n",
      "        [ 0.4930]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2622],\n",
      "        [ 1.3436],\n",
      "        [-1.8525],\n",
      "        [ 0.3679],\n",
      "        [-0.2631],\n",
      "        [-0.8553],\n",
      "        [ 1.1067],\n",
      "        [ 0.7924],\n",
      "        [-0.6174],\n",
      "        [ 0.4930]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2627],\n",
      "        [ 1.3442],\n",
      "        [-1.8527],\n",
      "        [ 0.3682],\n",
      "        [-0.2633],\n",
      "        [-0.8556],\n",
      "        [ 1.1065],\n",
      "        [ 0.7924],\n",
      "        [-0.6177],\n",
      "        [ 0.4930]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2631],\n",
      "        [ 1.3447],\n",
      "        [-1.8529],\n",
      "        [ 0.3685],\n",
      "        [-0.2634],\n",
      "        [-0.8559],\n",
      "        [ 1.1063],\n",
      "        [ 0.7924],\n",
      "        [-0.6180],\n",
      "        [ 0.4930]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2635],\n",
      "        [ 1.3452],\n",
      "        [-1.8530],\n",
      "        [ 0.3688],\n",
      "        [-0.2636],\n",
      "        [-0.8562],\n",
      "        [ 1.1061],\n",
      "        [ 0.7924],\n",
      "        [-0.6183],\n",
      "        [ 0.4929]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2640],\n",
      "        [ 1.3458],\n",
      "        [-1.8532],\n",
      "        [ 0.3690],\n",
      "        [-0.2638],\n",
      "        [-0.8565],\n",
      "        [ 1.1060],\n",
      "        [ 0.7924],\n",
      "        [-0.6186],\n",
      "        [ 0.4929]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2644],\n",
      "        [ 1.3463],\n",
      "        [-1.8534],\n",
      "        [ 0.3693],\n",
      "        [-0.2639],\n",
      "        [-0.8568],\n",
      "        [ 1.1058],\n",
      "        [ 0.7924],\n",
      "        [-0.6189],\n",
      "        [ 0.4929]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2648],\n",
      "        [ 1.3468],\n",
      "        [-1.8536],\n",
      "        [ 0.3696],\n",
      "        [-0.2641],\n",
      "        [-0.8572],\n",
      "        [ 1.1056],\n",
      "        [ 0.7924],\n",
      "        [-0.6193],\n",
      "        [ 0.4929]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2653],\n",
      "        [ 1.3474],\n",
      "        [-1.8538],\n",
      "        [ 0.3699],\n",
      "        [-0.2643],\n",
      "        [-0.8575],\n",
      "        [ 1.1055],\n",
      "        [ 0.7924],\n",
      "        [-0.6196],\n",
      "        [ 0.4929]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2657],\n",
      "        [ 1.3479],\n",
      "        [-1.8540],\n",
      "        [ 0.3702],\n",
      "        [-0.2645],\n",
      "        [-0.8578],\n",
      "        [ 1.1053],\n",
      "        [ 0.7924],\n",
      "        [-0.6199],\n",
      "        [ 0.4929]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2661],\n",
      "        [ 1.3484],\n",
      "        [-1.8541],\n",
      "        [ 0.3704],\n",
      "        [-0.2646],\n",
      "        [-0.8581],\n",
      "        [ 1.1051],\n",
      "        [ 0.7924],\n",
      "        [-0.6202],\n",
      "        [ 0.4929]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2665],\n",
      "        [ 1.3490],\n",
      "        [-1.8543],\n",
      "        [ 0.3707],\n",
      "        [-0.2648],\n",
      "        [-0.8584],\n",
      "        [ 1.1050],\n",
      "        [ 0.7924],\n",
      "        [-0.6205],\n",
      "        [ 0.4929]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2670],\n",
      "        [ 1.3495],\n",
      "        [-1.8545],\n",
      "        [ 0.3710],\n",
      "        [-0.2650],\n",
      "        [-0.8587],\n",
      "        [ 1.1048],\n",
      "        [ 0.7924],\n",
      "        [-0.6208],\n",
      "        [ 0.4929]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2674],\n",
      "        [ 1.3500],\n",
      "        [-1.8547],\n",
      "        [ 0.3713],\n",
      "        [-0.2651],\n",
      "        [-0.8590],\n",
      "        [ 1.1046],\n",
      "        [ 0.7924],\n",
      "        [-0.6211],\n",
      "        [ 0.4929]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2678],\n",
      "        [ 1.3506],\n",
      "        [-1.8549],\n",
      "        [ 0.3715],\n",
      "        [-0.2653],\n",
      "        [-0.8594],\n",
      "        [ 1.1045],\n",
      "        [ 0.7924],\n",
      "        [-0.6214],\n",
      "        [ 0.4929]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2683],\n",
      "        [ 1.3511],\n",
      "        [-1.8550],\n",
      "        [ 0.3718],\n",
      "        [-0.2655],\n",
      "        [-0.8597],\n",
      "        [ 1.1043],\n",
      "        [ 0.7924],\n",
      "        [-0.6218],\n",
      "        [ 0.4929]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2687],\n",
      "        [ 1.3516],\n",
      "        [-1.8552],\n",
      "        [ 0.3721],\n",
      "        [-0.2656],\n",
      "        [-0.8600],\n",
      "        [ 1.1041],\n",
      "        [ 0.7924],\n",
      "        [-0.6221],\n",
      "        [ 0.4929]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2691],\n",
      "        [ 1.3522],\n",
      "        [-1.8554],\n",
      "        [ 0.3724],\n",
      "        [-0.2658],\n",
      "        [-0.8603],\n",
      "        [ 1.1040],\n",
      "        [ 0.7924],\n",
      "        [-0.6224],\n",
      "        [ 0.4928]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2695],\n",
      "        [ 1.3527],\n",
      "        [-1.8556],\n",
      "        [ 0.3726],\n",
      "        [-0.2660],\n",
      "        [-0.8606],\n",
      "        [ 1.1038],\n",
      "        [ 0.7924],\n",
      "        [-0.6227],\n",
      "        [ 0.4928]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2700],\n",
      "        [ 1.3532],\n",
      "        [-1.8558],\n",
      "        [ 0.3729],\n",
      "        [-0.2661],\n",
      "        [-0.8609],\n",
      "        [ 1.1036],\n",
      "        [ 0.7924],\n",
      "        [-0.6230],\n",
      "        [ 0.4928]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2704],\n",
      "        [ 1.3538],\n",
      "        [-1.8559],\n",
      "        [ 0.3732],\n",
      "        [-0.2663],\n",
      "        [-0.8612],\n",
      "        [ 1.1035],\n",
      "        [ 0.7924],\n",
      "        [-0.6233],\n",
      "        [ 0.4928]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2708],\n",
      "        [ 1.3543],\n",
      "        [-1.8561],\n",
      "        [ 0.3735],\n",
      "        [-0.2665],\n",
      "        [-0.8616],\n",
      "        [ 1.1033],\n",
      "        [ 0.7924],\n",
      "        [-0.6236],\n",
      "        [ 0.4928]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2713],\n",
      "        [ 1.3548],\n",
      "        [-1.8563],\n",
      "        [ 0.3738],\n",
      "        [-0.2666],\n",
      "        [-0.8619],\n",
      "        [ 1.1031],\n",
      "        [ 0.7924],\n",
      "        [-0.6239],\n",
      "        [ 0.4928]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2717],\n",
      "        [ 1.3553],\n",
      "        [-1.8565],\n",
      "        [ 0.3740],\n",
      "        [-0.2668],\n",
      "        [-0.8622],\n",
      "        [ 1.1030],\n",
      "        [ 0.7924],\n",
      "        [-0.6242],\n",
      "        [ 0.4928]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2721],\n",
      "        [ 1.3559],\n",
      "        [-1.8567],\n",
      "        [ 0.3743],\n",
      "        [-0.2670],\n",
      "        [-0.8625],\n",
      "        [ 1.1028],\n",
      "        [ 0.7924],\n",
      "        [-0.6246],\n",
      "        [ 0.4928]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2725],\n",
      "        [ 1.3564],\n",
      "        [-1.8568],\n",
      "        [ 0.3746],\n",
      "        [-0.2671],\n",
      "        [-0.8628],\n",
      "        [ 1.1026],\n",
      "        [ 0.7924],\n",
      "        [-0.6249],\n",
      "        [ 0.4928]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2730],\n",
      "        [ 1.3569],\n",
      "        [-1.8570],\n",
      "        [ 0.3749],\n",
      "        [-0.2673],\n",
      "        [-0.8631],\n",
      "        [ 1.1025],\n",
      "        [ 0.7924],\n",
      "        [-0.6252],\n",
      "        [ 0.4928]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2734],\n",
      "        [ 1.3575],\n",
      "        [-1.8572],\n",
      "        [ 0.3751],\n",
      "        [-0.2675],\n",
      "        [-0.8634],\n",
      "        [ 1.1023],\n",
      "        [ 0.7924],\n",
      "        [-0.6255],\n",
      "        [ 0.4928]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2738],\n",
      "        [ 1.3580],\n",
      "        [-1.8574],\n",
      "        [ 0.3754],\n",
      "        [-0.2676],\n",
      "        [-0.8638],\n",
      "        [ 1.1021],\n",
      "        [ 0.7924],\n",
      "        [-0.6258],\n",
      "        [ 0.4928]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2742],\n",
      "        [ 1.3585],\n",
      "        [-1.8576],\n",
      "        [ 0.3757],\n",
      "        [-0.2678],\n",
      "        [-0.8641],\n",
      "        [ 1.1020],\n",
      "        [ 0.7924],\n",
      "        [-0.6261],\n",
      "        [ 0.4928]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2747],\n",
      "        [ 1.3590],\n",
      "        [-1.8577],\n",
      "        [ 0.3760],\n",
      "        [-0.2680],\n",
      "        [-0.8644],\n",
      "        [ 1.1018],\n",
      "        [ 0.7924],\n",
      "        [-0.6264],\n",
      "        [ 0.4927]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2751],\n",
      "        [ 1.3596],\n",
      "        [-1.8579],\n",
      "        [ 0.3762],\n",
      "        [-0.2681],\n",
      "        [-0.8647],\n",
      "        [ 1.1016],\n",
      "        [ 0.7924],\n",
      "        [-0.6267],\n",
      "        [ 0.4927]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2755],\n",
      "        [ 1.3601],\n",
      "        [-1.8581],\n",
      "        [ 0.3765],\n",
      "        [-0.2683],\n",
      "        [-0.8650],\n",
      "        [ 1.1015],\n",
      "        [ 0.7924],\n",
      "        [-0.6270],\n",
      "        [ 0.4927]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2759],\n",
      "        [ 1.3606],\n",
      "        [-1.8583],\n",
      "        [ 0.3768],\n",
      "        [-0.2685],\n",
      "        [-0.8653],\n",
      "        [ 1.1013],\n",
      "        [ 0.7924],\n",
      "        [-0.6274],\n",
      "        [ 0.4927]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2763],\n",
      "        [ 1.3611],\n",
      "        [-1.8584],\n",
      "        [ 0.3770],\n",
      "        [-0.2686],\n",
      "        [-0.8656],\n",
      "        [ 1.1011],\n",
      "        [ 0.7924],\n",
      "        [-0.6277],\n",
      "        [ 0.4927]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2768],\n",
      "        [ 1.3617],\n",
      "        [-1.8586],\n",
      "        [ 0.3773],\n",
      "        [-0.2688],\n",
      "        [-0.8659],\n",
      "        [ 1.1010],\n",
      "        [ 0.7924],\n",
      "        [-0.6280],\n",
      "        [ 0.4927]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2772],\n",
      "        [ 1.3622],\n",
      "        [-1.8588],\n",
      "        [ 0.3776],\n",
      "        [-0.2689],\n",
      "        [-0.8662],\n",
      "        [ 1.1008],\n",
      "        [ 0.7924],\n",
      "        [-0.6283],\n",
      "        [ 0.4927]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2776],\n",
      "        [ 1.3627],\n",
      "        [-1.8590],\n",
      "        [ 0.3779],\n",
      "        [-0.2691],\n",
      "        [-0.8666],\n",
      "        [ 1.1006],\n",
      "        [ 0.7924],\n",
      "        [-0.6286],\n",
      "        [ 0.4927]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2780],\n",
      "        [ 1.3632],\n",
      "        [-1.8592],\n",
      "        [ 0.3781],\n",
      "        [-0.2693],\n",
      "        [-0.8669],\n",
      "        [ 1.1005],\n",
      "        [ 0.7924],\n",
      "        [-0.6289],\n",
      "        [ 0.4927]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2785],\n",
      "        [ 1.3638],\n",
      "        [-1.8593],\n",
      "        [ 0.3784],\n",
      "        [-0.2694],\n",
      "        [-0.8672],\n",
      "        [ 1.1003],\n",
      "        [ 0.7924],\n",
      "        [-0.6292],\n",
      "        [ 0.4927]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2789],\n",
      "        [ 1.3643],\n",
      "        [-1.8595],\n",
      "        [ 0.3787],\n",
      "        [-0.2696],\n",
      "        [-0.8675],\n",
      "        [ 1.1002],\n",
      "        [ 0.7924],\n",
      "        [-0.6295],\n",
      "        [ 0.4927]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2793],\n",
      "        [ 1.3648],\n",
      "        [-1.8597],\n",
      "        [ 0.3790],\n",
      "        [-0.2698],\n",
      "        [-0.8678],\n",
      "        [ 1.1000],\n",
      "        [ 0.7924],\n",
      "        [-0.6298],\n",
      "        [ 0.4927]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2797],\n",
      "        [ 1.3653],\n",
      "        [-1.8599],\n",
      "        [ 0.3792],\n",
      "        [-0.2699],\n",
      "        [-0.8681],\n",
      "        [ 1.0998],\n",
      "        [ 0.7924],\n",
      "        [-0.6301],\n",
      "        [ 0.4926]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2801],\n",
      "        [ 1.3658],\n",
      "        [-1.8600],\n",
      "        [ 0.3795],\n",
      "        [-0.2701],\n",
      "        [-0.8684],\n",
      "        [ 1.0997],\n",
      "        [ 0.7924],\n",
      "        [-0.6305],\n",
      "        [ 0.4926]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2806],\n",
      "        [ 1.3664],\n",
      "        [-1.8602],\n",
      "        [ 0.3798],\n",
      "        [-0.2703],\n",
      "        [-0.8687],\n",
      "        [ 1.0995],\n",
      "        [ 0.7924],\n",
      "        [-0.6308],\n",
      "        [ 0.4926]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2810],\n",
      "        [ 1.3669],\n",
      "        [-1.8604],\n",
      "        [ 0.3800],\n",
      "        [-0.2704],\n",
      "        [-0.8690],\n",
      "        [ 1.0993],\n",
      "        [ 0.7924],\n",
      "        [-0.6311],\n",
      "        [ 0.4926]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2814],\n",
      "        [ 1.3674],\n",
      "        [-1.8606],\n",
      "        [ 0.3803],\n",
      "        [-0.2706],\n",
      "        [-0.8693],\n",
      "        [ 1.0992],\n",
      "        [ 0.7924],\n",
      "        [-0.6314],\n",
      "        [ 0.4926]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2818],\n",
      "        [ 1.3679],\n",
      "        [-1.8607],\n",
      "        [ 0.3806],\n",
      "        [-0.2707],\n",
      "        [-0.8697],\n",
      "        [ 1.0990],\n",
      "        [ 0.7924],\n",
      "        [-0.6317],\n",
      "        [ 0.4926]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2822],\n",
      "        [ 1.3685],\n",
      "        [-1.8609],\n",
      "        [ 0.3809],\n",
      "        [-0.2709],\n",
      "        [-0.8700],\n",
      "        [ 1.0989],\n",
      "        [ 0.7924],\n",
      "        [-0.6320],\n",
      "        [ 0.4926]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2827],\n",
      "        [ 1.3690],\n",
      "        [-1.8611],\n",
      "        [ 0.3811],\n",
      "        [-0.2711],\n",
      "        [-0.8703],\n",
      "        [ 1.0987],\n",
      "        [ 0.7924],\n",
      "        [-0.6323],\n",
      "        [ 0.4926]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2831],\n",
      "        [ 1.3695],\n",
      "        [-1.8613],\n",
      "        [ 0.3814],\n",
      "        [-0.2712],\n",
      "        [-0.8706],\n",
      "        [ 1.0985],\n",
      "        [ 0.7924],\n",
      "        [-0.6326],\n",
      "        [ 0.4926]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2835],\n",
      "        [ 1.3700],\n",
      "        [-1.8614],\n",
      "        [ 0.3817],\n",
      "        [-0.2714],\n",
      "        [-0.8709],\n",
      "        [ 1.0984],\n",
      "        [ 0.7924],\n",
      "        [-0.6329],\n",
      "        [ 0.4926]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2839],\n",
      "        [ 1.3705],\n",
      "        [-1.8616],\n",
      "        [ 0.3819],\n",
      "        [-0.2715],\n",
      "        [-0.8712],\n",
      "        [ 1.0982],\n",
      "        [ 0.7924],\n",
      "        [-0.6332],\n",
      "        [ 0.4926]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2843],\n",
      "        [ 1.3710],\n",
      "        [-1.8618],\n",
      "        [ 0.3822],\n",
      "        [-0.2717],\n",
      "        [-0.8715],\n",
      "        [ 1.0981],\n",
      "        [ 0.7924],\n",
      "        [-0.6335],\n",
      "        [ 0.4926]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2847],\n",
      "        [ 1.3716],\n",
      "        [-1.8620],\n",
      "        [ 0.3825],\n",
      "        [-0.2719],\n",
      "        [-0.8718],\n",
      "        [ 1.0979],\n",
      "        [ 0.7924],\n",
      "        [-0.6339],\n",
      "        [ 0.4926]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2852],\n",
      "        [ 1.3721],\n",
      "        [-1.8621],\n",
      "        [ 0.3828],\n",
      "        [-0.2720],\n",
      "        [-0.8721],\n",
      "        [ 1.0977],\n",
      "        [ 0.7924],\n",
      "        [-0.6342],\n",
      "        [ 0.4926]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2856],\n",
      "        [ 1.3726],\n",
      "        [-1.8623],\n",
      "        [ 0.3830],\n",
      "        [-0.2722],\n",
      "        [-0.8724],\n",
      "        [ 1.0976],\n",
      "        [ 0.7924],\n",
      "        [-0.6345],\n",
      "        [ 0.4925]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2860],\n",
      "        [ 1.3731],\n",
      "        [-1.8625],\n",
      "        [ 0.3833],\n",
      "        [-0.2724],\n",
      "        [-0.8727],\n",
      "        [ 1.0974],\n",
      "        [ 0.7924],\n",
      "        [-0.6348],\n",
      "        [ 0.4925]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2864],\n",
      "        [ 1.3736],\n",
      "        [-1.8626],\n",
      "        [ 0.3836],\n",
      "        [-0.2725],\n",
      "        [-0.8730],\n",
      "        [ 1.0972],\n",
      "        [ 0.7924],\n",
      "        [-0.6351],\n",
      "        [ 0.4925]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2868],\n",
      "        [ 1.3741],\n",
      "        [-1.8628],\n",
      "        [ 0.3838],\n",
      "        [-0.2727],\n",
      "        [-0.8733],\n",
      "        [ 1.0971],\n",
      "        [ 0.7924],\n",
      "        [-0.6354],\n",
      "        [ 0.4925]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2872],\n",
      "        [ 1.3747],\n",
      "        [-1.8630],\n",
      "        [ 0.3841],\n",
      "        [-0.2728],\n",
      "        [-0.8737],\n",
      "        [ 1.0969],\n",
      "        [ 0.7924],\n",
      "        [-0.6357],\n",
      "        [ 0.4925]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2877],\n",
      "        [ 1.3752],\n",
      "        [-1.8632],\n",
      "        [ 0.3844],\n",
      "        [-0.2730],\n",
      "        [-0.8740],\n",
      "        [ 1.0968],\n",
      "        [ 0.7924],\n",
      "        [-0.6360],\n",
      "        [ 0.4925]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2881],\n",
      "        [ 1.3757],\n",
      "        [-1.8633],\n",
      "        [ 0.3846],\n",
      "        [-0.2732],\n",
      "        [-0.8743],\n",
      "        [ 1.0966],\n",
      "        [ 0.7924],\n",
      "        [-0.6363],\n",
      "        [ 0.4925]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2885],\n",
      "        [ 1.3762],\n",
      "        [-1.8635],\n",
      "        [ 0.3849],\n",
      "        [-0.2733],\n",
      "        [-0.8746],\n",
      "        [ 1.0964],\n",
      "        [ 0.7924],\n",
      "        [-0.6366],\n",
      "        [ 0.4925]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2889],\n",
      "        [ 1.3767],\n",
      "        [-1.8637],\n",
      "        [ 0.3852],\n",
      "        [-0.2735],\n",
      "        [-0.8749],\n",
      "        [ 1.0963],\n",
      "        [ 0.7924],\n",
      "        [-0.6369],\n",
      "        [ 0.4925]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2893],\n",
      "        [ 1.3772],\n",
      "        [-1.8639],\n",
      "        [ 0.3855],\n",
      "        [-0.2736],\n",
      "        [-0.8752],\n",
      "        [ 1.0961],\n",
      "        [ 0.7924],\n",
      "        [-0.6372],\n",
      "        [ 0.4925]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2897],\n",
      "        [ 1.3778],\n",
      "        [-1.8640],\n",
      "        [ 0.3857],\n",
      "        [-0.2738],\n",
      "        [-0.8755],\n",
      "        [ 1.0960],\n",
      "        [ 0.7924],\n",
      "        [-0.6376],\n",
      "        [ 0.4925]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2901],\n",
      "        [ 1.3783],\n",
      "        [-1.8642],\n",
      "        [ 0.3860],\n",
      "        [-0.2739],\n",
      "        [-0.8758],\n",
      "        [ 1.0958],\n",
      "        [ 0.7924],\n",
      "        [-0.6379],\n",
      "        [ 0.4925]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2906],\n",
      "        [ 1.3788],\n",
      "        [-1.8644],\n",
      "        [ 0.3863],\n",
      "        [-0.2741],\n",
      "        [-0.8761],\n",
      "        [ 1.0957],\n",
      "        [ 0.7924],\n",
      "        [-0.6382],\n",
      "        [ 0.4925]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2910],\n",
      "        [ 1.3793],\n",
      "        [-1.8645],\n",
      "        [ 0.3865],\n",
      "        [-0.2743],\n",
      "        [-0.8764],\n",
      "        [ 1.0955],\n",
      "        [ 0.7924],\n",
      "        [-0.6385],\n",
      "        [ 0.4924]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2914],\n",
      "        [ 1.3798],\n",
      "        [-1.8647],\n",
      "        [ 0.3868],\n",
      "        [-0.2744],\n",
      "        [-0.8767],\n",
      "        [ 1.0953],\n",
      "        [ 0.7924],\n",
      "        [-0.6388],\n",
      "        [ 0.4924]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2918],\n",
      "        [ 1.3803],\n",
      "        [-1.8649],\n",
      "        [ 0.3871],\n",
      "        [-0.2746],\n",
      "        [-0.8770],\n",
      "        [ 1.0952],\n",
      "        [ 0.7924],\n",
      "        [-0.6391],\n",
      "        [ 0.4924]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2922],\n",
      "        [ 1.3808],\n",
      "        [-1.8651],\n",
      "        [ 0.3873],\n",
      "        [-0.2747],\n",
      "        [-0.8773],\n",
      "        [ 1.0950],\n",
      "        [ 0.7924],\n",
      "        [-0.6394],\n",
      "        [ 0.4924]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2926],\n",
      "        [ 1.3813],\n",
      "        [-1.8652],\n",
      "        [ 0.3876],\n",
      "        [-0.2749],\n",
      "        [-0.8776],\n",
      "        [ 1.0949],\n",
      "        [ 0.7924],\n",
      "        [-0.6397],\n",
      "        [ 0.4924]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2930],\n",
      "        [ 1.3818],\n",
      "        [-1.8654],\n",
      "        [ 0.3879],\n",
      "        [-0.2751],\n",
      "        [-0.8779],\n",
      "        [ 1.0947],\n",
      "        [ 0.7924],\n",
      "        [-0.6400],\n",
      "        [ 0.4924]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2934],\n",
      "        [ 1.3824],\n",
      "        [-1.8656],\n",
      "        [ 0.3881],\n",
      "        [-0.2752],\n",
      "        [-0.8782],\n",
      "        [ 1.0945],\n",
      "        [ 0.7924],\n",
      "        [-0.6403],\n",
      "        [ 0.4924]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2939],\n",
      "        [ 1.3829],\n",
      "        [-1.8657],\n",
      "        [ 0.3884],\n",
      "        [-0.2754],\n",
      "        [-0.8785],\n",
      "        [ 1.0944],\n",
      "        [ 0.7924],\n",
      "        [-0.6406],\n",
      "        [ 0.4924]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2943],\n",
      "        [ 1.3834],\n",
      "        [-1.8659],\n",
      "        [ 0.3887],\n",
      "        [-0.2755],\n",
      "        [-0.8788],\n",
      "        [ 1.0942],\n",
      "        [ 0.7924],\n",
      "        [-0.6409],\n",
      "        [ 0.4924]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2947],\n",
      "        [ 1.3839],\n",
      "        [-1.8661],\n",
      "        [ 0.3889],\n",
      "        [-0.2757],\n",
      "        [-0.8791],\n",
      "        [ 1.0941],\n",
      "        [ 0.7924],\n",
      "        [-0.6412],\n",
      "        [ 0.4924]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2951],\n",
      "        [ 1.3844],\n",
      "        [-1.8663],\n",
      "        [ 0.3892],\n",
      "        [-0.2758],\n",
      "        [-0.8795],\n",
      "        [ 1.0939],\n",
      "        [ 0.7924],\n",
      "        [-0.6415],\n",
      "        [ 0.4924]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2955],\n",
      "        [ 1.3849],\n",
      "        [-1.8664],\n",
      "        [ 0.3895],\n",
      "        [-0.2760],\n",
      "        [-0.8798],\n",
      "        [ 1.0938],\n",
      "        [ 0.7924],\n",
      "        [-0.6419],\n",
      "        [ 0.4924]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2959],\n",
      "        [ 1.3854],\n",
      "        [-1.8666],\n",
      "        [ 0.3897],\n",
      "        [-0.2762],\n",
      "        [-0.8801],\n",
      "        [ 1.0936],\n",
      "        [ 0.7924],\n",
      "        [-0.6422],\n",
      "        [ 0.4924]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2963],\n",
      "        [ 1.3859],\n",
      "        [-1.8668],\n",
      "        [ 0.3900],\n",
      "        [-0.2763],\n",
      "        [-0.8804],\n",
      "        [ 1.0934],\n",
      "        [ 0.7924],\n",
      "        [-0.6425],\n",
      "        [ 0.4923]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2967],\n",
      "        [ 1.3864],\n",
      "        [-1.8669],\n",
      "        [ 0.3903],\n",
      "        [-0.2765],\n",
      "        [-0.8807],\n",
      "        [ 1.0933],\n",
      "        [ 0.7924],\n",
      "        [-0.6428],\n",
      "        [ 0.4923]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2971],\n",
      "        [ 1.3869],\n",
      "        [-1.8671],\n",
      "        [ 0.3905],\n",
      "        [-0.2766],\n",
      "        [-0.8810],\n",
      "        [ 1.0931],\n",
      "        [ 0.7924],\n",
      "        [-0.6431],\n",
      "        [ 0.4923]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2975],\n",
      "        [ 1.3874],\n",
      "        [-1.8673],\n",
      "        [ 0.3908],\n",
      "        [-0.2768],\n",
      "        [-0.8813],\n",
      "        [ 1.0930],\n",
      "        [ 0.7924],\n",
      "        [-0.6434],\n",
      "        [ 0.4923]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2979],\n",
      "        [ 1.3879],\n",
      "        [-1.8674],\n",
      "        [ 0.3911],\n",
      "        [-0.2769],\n",
      "        [-0.8816],\n",
      "        [ 1.0928],\n",
      "        [ 0.7924],\n",
      "        [-0.6437],\n",
      "        [ 0.4923]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2984],\n",
      "        [ 1.3885],\n",
      "        [-1.8676],\n",
      "        [ 0.3913],\n",
      "        [-0.2771],\n",
      "        [-0.8819],\n",
      "        [ 1.0927],\n",
      "        [ 0.7924],\n",
      "        [-0.6440],\n",
      "        [ 0.4923]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2988],\n",
      "        [ 1.3890],\n",
      "        [-1.8678],\n",
      "        [ 0.3916],\n",
      "        [-0.2772],\n",
      "        [-0.8822],\n",
      "        [ 1.0925],\n",
      "        [ 0.7924],\n",
      "        [-0.6443],\n",
      "        [ 0.4923]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2992],\n",
      "        [ 1.3895],\n",
      "        [-1.8679],\n",
      "        [ 0.3919],\n",
      "        [-0.2774],\n",
      "        [-0.8825],\n",
      "        [ 1.0924],\n",
      "        [ 0.7924],\n",
      "        [-0.6446],\n",
      "        [ 0.4923]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.2996],\n",
      "        [ 1.3900],\n",
      "        [-1.8681],\n",
      "        [ 0.3921],\n",
      "        [-0.2776],\n",
      "        [-0.8828],\n",
      "        [ 1.0922],\n",
      "        [ 0.7924],\n",
      "        [-0.6449],\n",
      "        [ 0.4923]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3000],\n",
      "        [ 1.3905],\n",
      "        [-1.8683],\n",
      "        [ 0.3924],\n",
      "        [-0.2777],\n",
      "        [-0.8831],\n",
      "        [ 1.0920],\n",
      "        [ 0.7924],\n",
      "        [-0.6452],\n",
      "        [ 0.4923]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3004],\n",
      "        [ 1.3910],\n",
      "        [-1.8685],\n",
      "        [ 0.3926],\n",
      "        [-0.2779],\n",
      "        [-0.8834],\n",
      "        [ 1.0919],\n",
      "        [ 0.7924],\n",
      "        [-0.6455],\n",
      "        [ 0.4923]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3008],\n",
      "        [ 1.3915],\n",
      "        [-1.8686],\n",
      "        [ 0.3929],\n",
      "        [-0.2780],\n",
      "        [-0.8837],\n",
      "        [ 1.0917],\n",
      "        [ 0.7924],\n",
      "        [-0.6458],\n",
      "        [ 0.4923]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3012],\n",
      "        [ 1.3920],\n",
      "        [-1.8688],\n",
      "        [ 0.3932],\n",
      "        [-0.2782],\n",
      "        [-0.8840],\n",
      "        [ 1.0916],\n",
      "        [ 0.7924],\n",
      "        [-0.6461],\n",
      "        [ 0.4923]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3016],\n",
      "        [ 1.3925],\n",
      "        [-1.8690],\n",
      "        [ 0.3934],\n",
      "        [-0.2783],\n",
      "        [-0.8843],\n",
      "        [ 1.0914],\n",
      "        [ 0.7924],\n",
      "        [-0.6464],\n",
      "        [ 0.4923]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3020],\n",
      "        [ 1.3930],\n",
      "        [-1.8691],\n",
      "        [ 0.3937],\n",
      "        [-0.2785],\n",
      "        [-0.8846],\n",
      "        [ 1.0913],\n",
      "        [ 0.7924],\n",
      "        [-0.6467],\n",
      "        [ 0.4922]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3024],\n",
      "        [ 1.3935],\n",
      "        [-1.8693],\n",
      "        [ 0.3940],\n",
      "        [-0.2786],\n",
      "        [-0.8849],\n",
      "        [ 1.0911],\n",
      "        [ 0.7924],\n",
      "        [-0.6471],\n",
      "        [ 0.4922]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3028],\n",
      "        [ 1.3940],\n",
      "        [-1.8695],\n",
      "        [ 0.3942],\n",
      "        [-0.2788],\n",
      "        [-0.8852],\n",
      "        [ 1.0910],\n",
      "        [ 0.7924],\n",
      "        [-0.6474],\n",
      "        [ 0.4922]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3032],\n",
      "        [ 1.3945],\n",
      "        [-1.8696],\n",
      "        [ 0.3945],\n",
      "        [-0.2790],\n",
      "        [-0.8855],\n",
      "        [ 1.0908],\n",
      "        [ 0.7924],\n",
      "        [-0.6477],\n",
      "        [ 0.4922]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3036],\n",
      "        [ 1.3950],\n",
      "        [-1.8698],\n",
      "        [ 0.3948],\n",
      "        [-0.2791],\n",
      "        [-0.8858],\n",
      "        [ 1.0907],\n",
      "        [ 0.7924],\n",
      "        [-0.6480],\n",
      "        [ 0.4922]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3040],\n",
      "        [ 1.3955],\n",
      "        [-1.8700],\n",
      "        [ 0.3950],\n",
      "        [-0.2793],\n",
      "        [-0.8861],\n",
      "        [ 1.0905],\n",
      "        [ 0.7924],\n",
      "        [-0.6483],\n",
      "        [ 0.4922]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3044],\n",
      "        [ 1.3960],\n",
      "        [-1.8701],\n",
      "        [ 0.3953],\n",
      "        [-0.2794],\n",
      "        [-0.8864],\n",
      "        [ 1.0903],\n",
      "        [ 0.7924],\n",
      "        [-0.6486],\n",
      "        [ 0.4922]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3048],\n",
      "        [ 1.3965],\n",
      "        [-1.8703],\n",
      "        [ 0.3955],\n",
      "        [-0.2796],\n",
      "        [-0.8867],\n",
      "        [ 1.0902],\n",
      "        [ 0.7924],\n",
      "        [-0.6489],\n",
      "        [ 0.4922]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3053],\n",
      "        [ 1.3970],\n",
      "        [-1.8705],\n",
      "        [ 0.3958],\n",
      "        [-0.2797],\n",
      "        [-0.8870],\n",
      "        [ 1.0900],\n",
      "        [ 0.7924],\n",
      "        [-0.6492],\n",
      "        [ 0.4922]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3057],\n",
      "        [ 1.3975],\n",
      "        [-1.8706],\n",
      "        [ 0.3961],\n",
      "        [-0.2799],\n",
      "        [-0.8873],\n",
      "        [ 1.0899],\n",
      "        [ 0.7924],\n",
      "        [-0.6495],\n",
      "        [ 0.4922]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3061],\n",
      "        [ 1.3980],\n",
      "        [-1.8708],\n",
      "        [ 0.3963],\n",
      "        [-0.2800],\n",
      "        [-0.8876],\n",
      "        [ 1.0897],\n",
      "        [ 0.7924],\n",
      "        [-0.6498],\n",
      "        [ 0.4922]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3065],\n",
      "        [ 1.3985],\n",
      "        [-1.8710],\n",
      "        [ 0.3966],\n",
      "        [-0.2802],\n",
      "        [-0.8879],\n",
      "        [ 1.0896],\n",
      "        [ 0.7924],\n",
      "        [-0.6501],\n",
      "        [ 0.4922]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3069],\n",
      "        [ 1.3990],\n",
      "        [-1.8711],\n",
      "        [ 0.3968],\n",
      "        [-0.2803],\n",
      "        [-0.8882],\n",
      "        [ 1.0894],\n",
      "        [ 0.7924],\n",
      "        [-0.6504],\n",
      "        [ 0.4922]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3073],\n",
      "        [ 1.3995],\n",
      "        [-1.8713],\n",
      "        [ 0.3971],\n",
      "        [-0.2805],\n",
      "        [-0.8885],\n",
      "        [ 1.0893],\n",
      "        [ 0.7924],\n",
      "        [-0.6507],\n",
      "        [ 0.4922]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3077],\n",
      "        [ 1.4000],\n",
      "        [-1.8715],\n",
      "        [ 0.3974],\n",
      "        [-0.2806],\n",
      "        [-0.8888],\n",
      "        [ 1.0891],\n",
      "        [ 0.7924],\n",
      "        [-0.6510],\n",
      "        [ 0.4921]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3081],\n",
      "        [ 1.4005],\n",
      "        [-1.8716],\n",
      "        [ 0.3976],\n",
      "        [-0.2808],\n",
      "        [-0.8891],\n",
      "        [ 1.0890],\n",
      "        [ 0.7924],\n",
      "        [-0.6513],\n",
      "        [ 0.4921]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3085],\n",
      "        [ 1.4010],\n",
      "        [-1.8718],\n",
      "        [ 0.3979],\n",
      "        [-0.2809],\n",
      "        [-0.8894],\n",
      "        [ 1.0888],\n",
      "        [ 0.7924],\n",
      "        [-0.6516],\n",
      "        [ 0.4921]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3089],\n",
      "        [ 1.4015],\n",
      "        [-1.8720],\n",
      "        [ 0.3982],\n",
      "        [-0.2811],\n",
      "        [-0.8897],\n",
      "        [ 1.0887],\n",
      "        [ 0.7924],\n",
      "        [-0.6519],\n",
      "        [ 0.4921]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3093],\n",
      "        [ 1.4020],\n",
      "        [-1.8721],\n",
      "        [ 0.3984],\n",
      "        [-0.2812],\n",
      "        [-0.8900],\n",
      "        [ 1.0885],\n",
      "        [ 0.7924],\n",
      "        [-0.6522],\n",
      "        [ 0.4921]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3097],\n",
      "        [ 1.4025],\n",
      "        [-1.8723],\n",
      "        [ 0.3987],\n",
      "        [-0.2814],\n",
      "        [-0.8903],\n",
      "        [ 1.0884],\n",
      "        [ 0.7924],\n",
      "        [-0.6525],\n",
      "        [ 0.4921]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3101],\n",
      "        [ 1.4030],\n",
      "        [-1.8724],\n",
      "        [ 0.3989],\n",
      "        [-0.2816],\n",
      "        [-0.8906],\n",
      "        [ 1.0882],\n",
      "        [ 0.7924],\n",
      "        [-0.6528],\n",
      "        [ 0.4921]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3105],\n",
      "        [ 1.4035],\n",
      "        [-1.8726],\n",
      "        [ 0.3992],\n",
      "        [-0.2817],\n",
      "        [-0.8909],\n",
      "        [ 1.0881],\n",
      "        [ 0.7924],\n",
      "        [-0.6531],\n",
      "        [ 0.4921]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3109],\n",
      "        [ 1.4040],\n",
      "        [-1.8728],\n",
      "        [ 0.3995],\n",
      "        [-0.2819],\n",
      "        [-0.8912],\n",
      "        [ 1.0879],\n",
      "        [ 0.7924],\n",
      "        [-0.6535],\n",
      "        [ 0.4921]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3113],\n",
      "        [ 1.4044],\n",
      "        [-1.8729],\n",
      "        [ 0.3997],\n",
      "        [-0.2820],\n",
      "        [-0.8915],\n",
      "        [ 1.0878],\n",
      "        [ 0.7924],\n",
      "        [-0.6538],\n",
      "        [ 0.4921]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3117],\n",
      "        [ 1.4049],\n",
      "        [-1.8731],\n",
      "        [ 0.4000],\n",
      "        [-0.2822],\n",
      "        [-0.8918],\n",
      "        [ 1.0876],\n",
      "        [ 0.7924],\n",
      "        [-0.6541],\n",
      "        [ 0.4921]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3121],\n",
      "        [ 1.4054],\n",
      "        [-1.8733],\n",
      "        [ 0.4002],\n",
      "        [-0.2823],\n",
      "        [-0.8921],\n",
      "        [ 1.0875],\n",
      "        [ 0.7924],\n",
      "        [-0.6544],\n",
      "        [ 0.4921]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3125],\n",
      "        [ 1.4059],\n",
      "        [-1.8734],\n",
      "        [ 0.4005],\n",
      "        [-0.2825],\n",
      "        [-0.8924],\n",
      "        [ 1.0873],\n",
      "        [ 0.7924],\n",
      "        [-0.6547],\n",
      "        [ 0.4921]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3129],\n",
      "        [ 1.4064],\n",
      "        [-1.8736],\n",
      "        [ 0.4008],\n",
      "        [-0.2826],\n",
      "        [-0.8926],\n",
      "        [ 1.0871],\n",
      "        [ 0.7924],\n",
      "        [-0.6550],\n",
      "        [ 0.4921]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3133],\n",
      "        [ 1.4069],\n",
      "        [-1.8738],\n",
      "        [ 0.4010],\n",
      "        [-0.2828],\n",
      "        [-0.8929],\n",
      "        [ 1.0870],\n",
      "        [ 0.7924],\n",
      "        [-0.6553],\n",
      "        [ 0.4920]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3137],\n",
      "        [ 1.4074],\n",
      "        [-1.8739],\n",
      "        [ 0.4013],\n",
      "        [-0.2829],\n",
      "        [-0.8932],\n",
      "        [ 1.0868],\n",
      "        [ 0.7924],\n",
      "        [-0.6556],\n",
      "        [ 0.4920]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3141],\n",
      "        [ 1.4079],\n",
      "        [-1.8741],\n",
      "        [ 0.4015],\n",
      "        [-0.2831],\n",
      "        [-0.8935],\n",
      "        [ 1.0867],\n",
      "        [ 0.7924],\n",
      "        [-0.6559],\n",
      "        [ 0.4920]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3145],\n",
      "        [ 1.4084],\n",
      "        [-1.8743],\n",
      "        [ 0.4018],\n",
      "        [-0.2832],\n",
      "        [-0.8938],\n",
      "        [ 1.0865],\n",
      "        [ 0.7924],\n",
      "        [-0.6562],\n",
      "        [ 0.4920]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3149],\n",
      "        [ 1.4089],\n",
      "        [-1.8744],\n",
      "        [ 0.4020],\n",
      "        [-0.2834],\n",
      "        [-0.8941],\n",
      "        [ 1.0864],\n",
      "        [ 0.7924],\n",
      "        [-0.6565],\n",
      "        [ 0.4920]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3153],\n",
      "        [ 1.4094],\n",
      "        [-1.8746],\n",
      "        [ 0.4023],\n",
      "        [-0.2835],\n",
      "        [-0.8944],\n",
      "        [ 1.0862],\n",
      "        [ 0.7924],\n",
      "        [-0.6568],\n",
      "        [ 0.4920]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3156],\n",
      "        [ 1.4099],\n",
      "        [-1.8747],\n",
      "        [ 0.4026],\n",
      "        [-0.2837],\n",
      "        [-0.8947],\n",
      "        [ 1.0861],\n",
      "        [ 0.7924],\n",
      "        [-0.6571],\n",
      "        [ 0.4920]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3160],\n",
      "        [ 1.4103],\n",
      "        [-1.8749],\n",
      "        [ 0.4028],\n",
      "        [-0.2838],\n",
      "        [-0.8950],\n",
      "        [ 1.0859],\n",
      "        [ 0.7924],\n",
      "        [-0.6574],\n",
      "        [ 0.4920]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3164],\n",
      "        [ 1.4108],\n",
      "        [-1.8751],\n",
      "        [ 0.4031],\n",
      "        [-0.2840],\n",
      "        [-0.8953],\n",
      "        [ 1.0858],\n",
      "        [ 0.7924],\n",
      "        [-0.6577],\n",
      "        [ 0.4920]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3168],\n",
      "        [ 1.4113],\n",
      "        [-1.8752],\n",
      "        [ 0.4033],\n",
      "        [-0.2841],\n",
      "        [-0.8956],\n",
      "        [ 1.0856],\n",
      "        [ 0.7924],\n",
      "        [-0.6580],\n",
      "        [ 0.4920]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3172],\n",
      "        [ 1.4118],\n",
      "        [-1.8754],\n",
      "        [ 0.4036],\n",
      "        [-0.2843],\n",
      "        [-0.8959],\n",
      "        [ 1.0855],\n",
      "        [ 0.7924],\n",
      "        [-0.6583],\n",
      "        [ 0.4920]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3176],\n",
      "        [ 1.4123],\n",
      "        [-1.8756],\n",
      "        [ 0.4038],\n",
      "        [-0.2844],\n",
      "        [-0.8962],\n",
      "        [ 1.0853],\n",
      "        [ 0.7924],\n",
      "        [-0.6586],\n",
      "        [ 0.4920]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3180],\n",
      "        [ 1.4128],\n",
      "        [-1.8757],\n",
      "        [ 0.4041],\n",
      "        [-0.2846],\n",
      "        [-0.8965],\n",
      "        [ 1.0852],\n",
      "        [ 0.7924],\n",
      "        [-0.6589],\n",
      "        [ 0.4920]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3184],\n",
      "        [ 1.4133],\n",
      "        [-1.8759],\n",
      "        [ 0.4044],\n",
      "        [-0.2847],\n",
      "        [-0.8968],\n",
      "        [ 1.0850],\n",
      "        [ 0.7924],\n",
      "        [-0.6592],\n",
      "        [ 0.4920]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3188],\n",
      "        [ 1.4138],\n",
      "        [-1.8760],\n",
      "        [ 0.4046],\n",
      "        [-0.2849],\n",
      "        [-0.8971],\n",
      "        [ 1.0849],\n",
      "        [ 0.7924],\n",
      "        [-0.6595],\n",
      "        [ 0.4920]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3192],\n",
      "        [ 1.4143],\n",
      "        [-1.8762],\n",
      "        [ 0.4049],\n",
      "        [-0.2850],\n",
      "        [-0.8974],\n",
      "        [ 1.0848],\n",
      "        [ 0.7924],\n",
      "        [-0.6598],\n",
      "        [ 0.4919]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3196],\n",
      "        [ 1.4147],\n",
      "        [-1.8764],\n",
      "        [ 0.4051],\n",
      "        [-0.2852],\n",
      "        [-0.8977],\n",
      "        [ 1.0846],\n",
      "        [ 0.7924],\n",
      "        [-0.6601],\n",
      "        [ 0.4919]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3200],\n",
      "        [ 1.4152],\n",
      "        [-1.8765],\n",
      "        [ 0.4054],\n",
      "        [-0.2853],\n",
      "        [-0.8980],\n",
      "        [ 1.0845],\n",
      "        [ 0.7924],\n",
      "        [-0.6604],\n",
      "        [ 0.4919]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3204],\n",
      "        [ 1.4157],\n",
      "        [-1.8767],\n",
      "        [ 0.4056],\n",
      "        [-0.2855],\n",
      "        [-0.8983],\n",
      "        [ 1.0843],\n",
      "        [ 0.7924],\n",
      "        [-0.6607],\n",
      "        [ 0.4919]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3208],\n",
      "        [ 1.4162],\n",
      "        [-1.8768],\n",
      "        [ 0.4059],\n",
      "        [-0.2856],\n",
      "        [-0.8985],\n",
      "        [ 1.0842],\n",
      "        [ 0.7924],\n",
      "        [-0.6610],\n",
      "        [ 0.4919]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3212],\n",
      "        [ 1.4167],\n",
      "        [-1.8770],\n",
      "        [ 0.4062],\n",
      "        [-0.2858],\n",
      "        [-0.8988],\n",
      "        [ 1.0840],\n",
      "        [ 0.7924],\n",
      "        [-0.6613],\n",
      "        [ 0.4919]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3216],\n",
      "        [ 1.4172],\n",
      "        [-1.8772],\n",
      "        [ 0.4064],\n",
      "        [-0.2859],\n",
      "        [-0.8991],\n",
      "        [ 1.0839],\n",
      "        [ 0.7924],\n",
      "        [-0.6616],\n",
      "        [ 0.4919]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3220],\n",
      "        [ 1.4177],\n",
      "        [-1.8773],\n",
      "        [ 0.4067],\n",
      "        [-0.2860],\n",
      "        [-0.8994],\n",
      "        [ 1.0837],\n",
      "        [ 0.7924],\n",
      "        [-0.6619],\n",
      "        [ 0.4919]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3223],\n",
      "        [ 1.4181],\n",
      "        [-1.8775],\n",
      "        [ 0.4069],\n",
      "        [-0.2862],\n",
      "        [-0.8997],\n",
      "        [ 1.0836],\n",
      "        [ 0.7924],\n",
      "        [-0.6622],\n",
      "        [ 0.4919]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3227],\n",
      "        [ 1.4186],\n",
      "        [-1.8777],\n",
      "        [ 0.4072],\n",
      "        [-0.2863],\n",
      "        [-0.9000],\n",
      "        [ 1.0834],\n",
      "        [ 0.7924],\n",
      "        [-0.6625],\n",
      "        [ 0.4919]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3231],\n",
      "        [ 1.4191],\n",
      "        [-1.8778],\n",
      "        [ 0.4074],\n",
      "        [-0.2865],\n",
      "        [-0.9003],\n",
      "        [ 1.0833],\n",
      "        [ 0.7924],\n",
      "        [-0.6628],\n",
      "        [ 0.4919]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3235],\n",
      "        [ 1.4196],\n",
      "        [-1.8780],\n",
      "        [ 0.4077],\n",
      "        [-0.2866],\n",
      "        [-0.9006],\n",
      "        [ 1.0831],\n",
      "        [ 0.7924],\n",
      "        [-0.6632],\n",
      "        [ 0.4919]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3239],\n",
      "        [ 1.4201],\n",
      "        [-1.8781],\n",
      "        [ 0.4079],\n",
      "        [-0.2868],\n",
      "        [-0.9009],\n",
      "        [ 1.0830],\n",
      "        [ 0.7924],\n",
      "        [-0.6635],\n",
      "        [ 0.4919]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3243],\n",
      "        [ 1.4206],\n",
      "        [-1.8783],\n",
      "        [ 0.4082],\n",
      "        [-0.2869],\n",
      "        [-0.9012],\n",
      "        [ 1.0828],\n",
      "        [ 0.7924],\n",
      "        [-0.6638],\n",
      "        [ 0.4919]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3247],\n",
      "        [ 1.4210],\n",
      "        [-1.8785],\n",
      "        [ 0.4084],\n",
      "        [-0.2871],\n",
      "        [-0.9015],\n",
      "        [ 1.0827],\n",
      "        [ 0.7924],\n",
      "        [-0.6641],\n",
      "        [ 0.4918]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3251],\n",
      "        [ 1.4215],\n",
      "        [-1.8786],\n",
      "        [ 0.4087],\n",
      "        [-0.2872],\n",
      "        [-0.9018],\n",
      "        [ 1.0825],\n",
      "        [ 0.7924],\n",
      "        [-0.6644],\n",
      "        [ 0.4918]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3255],\n",
      "        [ 1.4220],\n",
      "        [-1.8788],\n",
      "        [ 0.4090],\n",
      "        [-0.2874],\n",
      "        [-0.9021],\n",
      "        [ 1.0824],\n",
      "        [ 0.7924],\n",
      "        [-0.6647],\n",
      "        [ 0.4918]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3259],\n",
      "        [ 1.4225],\n",
      "        [-1.8789],\n",
      "        [ 0.4092],\n",
      "        [-0.2875],\n",
      "        [-0.9024],\n",
      "        [ 1.0822],\n",
      "        [ 0.7924],\n",
      "        [-0.6650],\n",
      "        [ 0.4918]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3262],\n",
      "        [ 1.4230],\n",
      "        [-1.8791],\n",
      "        [ 0.4095],\n",
      "        [-0.2877],\n",
      "        [-0.9026],\n",
      "        [ 1.0821],\n",
      "        [ 0.7924],\n",
      "        [-0.6653],\n",
      "        [ 0.4918]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3266],\n",
      "        [ 1.4234],\n",
      "        [-1.8793],\n",
      "        [ 0.4097],\n",
      "        [-0.2878],\n",
      "        [-0.9029],\n",
      "        [ 1.0819],\n",
      "        [ 0.7924],\n",
      "        [-0.6656],\n",
      "        [ 0.4918]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3270],\n",
      "        [ 1.4239],\n",
      "        [-1.8794],\n",
      "        [ 0.4100],\n",
      "        [-0.2880],\n",
      "        [-0.9032],\n",
      "        [ 1.0818],\n",
      "        [ 0.7924],\n",
      "        [-0.6659],\n",
      "        [ 0.4918]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3274],\n",
      "        [ 1.4244],\n",
      "        [-1.8796],\n",
      "        [ 0.4102],\n",
      "        [-0.2881],\n",
      "        [-0.9035],\n",
      "        [ 1.0817],\n",
      "        [ 0.7924],\n",
      "        [-0.6662],\n",
      "        [ 0.4918]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3278],\n",
      "        [ 1.4249],\n",
      "        [-1.8797],\n",
      "        [ 0.4105],\n",
      "        [-0.2883],\n",
      "        [-0.9038],\n",
      "        [ 1.0815],\n",
      "        [ 0.7924],\n",
      "        [-0.6665],\n",
      "        [ 0.4918]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3282],\n",
      "        [ 1.4254],\n",
      "        [-1.8799],\n",
      "        [ 0.4107],\n",
      "        [-0.2884],\n",
      "        [-0.9041],\n",
      "        [ 1.0814],\n",
      "        [ 0.7924],\n",
      "        [-0.6668],\n",
      "        [ 0.4918]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3286],\n",
      "        [ 1.4258],\n",
      "        [-1.8801],\n",
      "        [ 0.4110],\n",
      "        [-0.2885],\n",
      "        [-0.9044],\n",
      "        [ 1.0812],\n",
      "        [ 0.7924],\n",
      "        [-0.6671],\n",
      "        [ 0.4918]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3290],\n",
      "        [ 1.4263],\n",
      "        [-1.8802],\n",
      "        [ 0.4112],\n",
      "        [-0.2887],\n",
      "        [-0.9047],\n",
      "        [ 1.0811],\n",
      "        [ 0.7924],\n",
      "        [-0.6674],\n",
      "        [ 0.4918]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3294],\n",
      "        [ 1.4268],\n",
      "        [-1.8804],\n",
      "        [ 0.4115],\n",
      "        [-0.2888],\n",
      "        [-0.9050],\n",
      "        [ 1.0809],\n",
      "        [ 0.7924],\n",
      "        [-0.6677],\n",
      "        [ 0.4918]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3297],\n",
      "        [ 1.4273],\n",
      "        [-1.8805],\n",
      "        [ 0.4117],\n",
      "        [-0.2890],\n",
      "        [-0.9053],\n",
      "        [ 1.0808],\n",
      "        [ 0.7924],\n",
      "        [-0.6680],\n",
      "        [ 0.4918]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3301],\n",
      "        [ 1.4277],\n",
      "        [-1.8807],\n",
      "        [ 0.4120],\n",
      "        [-0.2891],\n",
      "        [-0.9056],\n",
      "        [ 1.0806],\n",
      "        [ 0.7924],\n",
      "        [-0.6683],\n",
      "        [ 0.4918]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3305],\n",
      "        [ 1.4282],\n",
      "        [-1.8808],\n",
      "        [ 0.4122],\n",
      "        [-0.2893],\n",
      "        [-0.9058],\n",
      "        [ 1.0805],\n",
      "        [ 0.7924],\n",
      "        [-0.6686],\n",
      "        [ 0.4917]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3309],\n",
      "        [ 1.4287],\n",
      "        [-1.8810],\n",
      "        [ 0.4125],\n",
      "        [-0.2894],\n",
      "        [-0.9061],\n",
      "        [ 1.0803],\n",
      "        [ 0.7924],\n",
      "        [-0.6689],\n",
      "        [ 0.4917]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3313],\n",
      "        [ 1.4292],\n",
      "        [-1.8812],\n",
      "        [ 0.4127],\n",
      "        [-0.2896],\n",
      "        [-0.9064],\n",
      "        [ 1.0802],\n",
      "        [ 0.7924],\n",
      "        [-0.6692],\n",
      "        [ 0.4917]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3317],\n",
      "        [ 1.4297],\n",
      "        [-1.8813],\n",
      "        [ 0.4130],\n",
      "        [-0.2897],\n",
      "        [-0.9067],\n",
      "        [ 1.0800],\n",
      "        [ 0.7924],\n",
      "        [-0.6695],\n",
      "        [ 0.4917]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3321],\n",
      "        [ 1.4301],\n",
      "        [-1.8815],\n",
      "        [ 0.4132],\n",
      "        [-0.2899],\n",
      "        [-0.9070],\n",
      "        [ 1.0799],\n",
      "        [ 0.7924],\n",
      "        [-0.6698],\n",
      "        [ 0.4917]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3324],\n",
      "        [ 1.4306],\n",
      "        [-1.8816],\n",
      "        [ 0.4135],\n",
      "        [-0.2900],\n",
      "        [-0.9073],\n",
      "        [ 1.0798],\n",
      "        [ 0.7924],\n",
      "        [-0.6701],\n",
      "        [ 0.4917]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3328],\n",
      "        [ 1.4311],\n",
      "        [-1.8818],\n",
      "        [ 0.4137],\n",
      "        [-0.2901],\n",
      "        [-0.9076],\n",
      "        [ 1.0796],\n",
      "        [ 0.7924],\n",
      "        [-0.6704],\n",
      "        [ 0.4917]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3332],\n",
      "        [ 1.4315],\n",
      "        [-1.8820],\n",
      "        [ 0.4140],\n",
      "        [-0.2903],\n",
      "        [-0.9079],\n",
      "        [ 1.0795],\n",
      "        [ 0.7924],\n",
      "        [-0.6707],\n",
      "        [ 0.4917]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3336],\n",
      "        [ 1.4320],\n",
      "        [-1.8821],\n",
      "        [ 0.4142],\n",
      "        [-0.2904],\n",
      "        [-0.9082],\n",
      "        [ 1.0793],\n",
      "        [ 0.7924],\n",
      "        [-0.6710],\n",
      "        [ 0.4917]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3340],\n",
      "        [ 1.4325],\n",
      "        [-1.8823],\n",
      "        [ 0.4145],\n",
      "        [-0.2906],\n",
      "        [-0.9085],\n",
      "        [ 1.0792],\n",
      "        [ 0.7924],\n",
      "        [-0.6713],\n",
      "        [ 0.4917]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3344],\n",
      "        [ 1.4330],\n",
      "        [-1.8824],\n",
      "        [ 0.4147],\n",
      "        [-0.2907],\n",
      "        [-0.9087],\n",
      "        [ 1.0790],\n",
      "        [ 0.7924],\n",
      "        [-0.6716],\n",
      "        [ 0.4917]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3347],\n",
      "        [ 1.4334],\n",
      "        [-1.8826],\n",
      "        [ 0.4150],\n",
      "        [-0.2909],\n",
      "        [-0.9090],\n",
      "        [ 1.0789],\n",
      "        [ 0.7924],\n",
      "        [-0.6719],\n",
      "        [ 0.4917]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3351],\n",
      "        [ 1.4339],\n",
      "        [-1.8827],\n",
      "        [ 0.4152],\n",
      "        [-0.2910],\n",
      "        [-0.9093],\n",
      "        [ 1.0787],\n",
      "        [ 0.7924],\n",
      "        [-0.6722],\n",
      "        [ 0.4917]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3355],\n",
      "        [ 1.4344],\n",
      "        [-1.8829],\n",
      "        [ 0.4155],\n",
      "        [-0.2912],\n",
      "        [-0.9096],\n",
      "        [ 1.0786],\n",
      "        [ 0.7924],\n",
      "        [-0.6725],\n",
      "        [ 0.4917]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3359],\n",
      "        [ 1.4349],\n",
      "        [-1.8831],\n",
      "        [ 0.4157],\n",
      "        [-0.2913],\n",
      "        [-0.9099],\n",
      "        [ 1.0785],\n",
      "        [ 0.7924],\n",
      "        [-0.6728],\n",
      "        [ 0.4917]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3363],\n",
      "        [ 1.4353],\n",
      "        [-1.8832],\n",
      "        [ 0.4160],\n",
      "        [-0.2914],\n",
      "        [-0.9102],\n",
      "        [ 1.0783],\n",
      "        [ 0.7924],\n",
      "        [-0.6731],\n",
      "        [ 0.4916]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3367],\n",
      "        [ 1.4358],\n",
      "        [-1.8834],\n",
      "        [ 0.4162],\n",
      "        [-0.2916],\n",
      "        [-0.9105],\n",
      "        [ 1.0782],\n",
      "        [ 0.7924],\n",
      "        [-0.6734],\n",
      "        [ 0.4916]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3370],\n",
      "        [ 1.4363],\n",
      "        [-1.8835],\n",
      "        [ 0.4165],\n",
      "        [-0.2917],\n",
      "        [-0.9108],\n",
      "        [ 1.0780],\n",
      "        [ 0.7924],\n",
      "        [-0.6737],\n",
      "        [ 0.4916]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3374],\n",
      "        [ 1.4367],\n",
      "        [-1.8837],\n",
      "        [ 0.4167],\n",
      "        [-0.2919],\n",
      "        [-0.9110],\n",
      "        [ 1.0779],\n",
      "        [ 0.7924],\n",
      "        [-0.6740],\n",
      "        [ 0.4916]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3378],\n",
      "        [ 1.4372],\n",
      "        [-1.8838],\n",
      "        [ 0.4170],\n",
      "        [-0.2920],\n",
      "        [-0.9113],\n",
      "        [ 1.0777],\n",
      "        [ 0.7924],\n",
      "        [-0.6743],\n",
      "        [ 0.4916]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3382],\n",
      "        [ 1.4377],\n",
      "        [-1.8840],\n",
      "        [ 0.4172],\n",
      "        [-0.2922],\n",
      "        [-0.9116],\n",
      "        [ 1.0776],\n",
      "        [ 0.7924],\n",
      "        [-0.6746],\n",
      "        [ 0.4916]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3386],\n",
      "        [ 1.4381],\n",
      "        [-1.8841],\n",
      "        [ 0.4175],\n",
      "        [-0.2923],\n",
      "        [-0.9119],\n",
      "        [ 1.0775],\n",
      "        [ 0.7924],\n",
      "        [-0.6749],\n",
      "        [ 0.4916]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3389],\n",
      "        [ 1.4386],\n",
      "        [-1.8843],\n",
      "        [ 0.4177],\n",
      "        [-0.2924],\n",
      "        [-0.9122],\n",
      "        [ 1.0773],\n",
      "        [ 0.7924],\n",
      "        [-0.6752],\n",
      "        [ 0.4916]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3393],\n",
      "        [ 1.4391],\n",
      "        [-1.8845],\n",
      "        [ 0.4180],\n",
      "        [-0.2926],\n",
      "        [-0.9125],\n",
      "        [ 1.0772],\n",
      "        [ 0.7924],\n",
      "        [-0.6755],\n",
      "        [ 0.4916]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3397],\n",
      "        [ 1.4396],\n",
      "        [-1.8846],\n",
      "        [ 0.4182],\n",
      "        [-0.2927],\n",
      "        [-0.9128],\n",
      "        [ 1.0770],\n",
      "        [ 0.7924],\n",
      "        [-0.6758],\n",
      "        [ 0.4916]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3401],\n",
      "        [ 1.4400],\n",
      "        [-1.8848],\n",
      "        [ 0.4185],\n",
      "        [-0.2929],\n",
      "        [-0.9131],\n",
      "        [ 1.0769],\n",
      "        [ 0.7924],\n",
      "        [-0.6761],\n",
      "        [ 0.4916]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3405],\n",
      "        [ 1.4405],\n",
      "        [-1.8849],\n",
      "        [ 0.4187],\n",
      "        [-0.2930],\n",
      "        [-0.9133],\n",
      "        [ 1.0767],\n",
      "        [ 0.7924],\n",
      "        [-0.6764],\n",
      "        [ 0.4916]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3408],\n",
      "        [ 1.4410],\n",
      "        [-1.8851],\n",
      "        [ 0.4190],\n",
      "        [-0.2932],\n",
      "        [-0.9136],\n",
      "        [ 1.0766],\n",
      "        [ 0.7924],\n",
      "        [-0.6767],\n",
      "        [ 0.4916]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3412],\n",
      "        [ 1.4414],\n",
      "        [-1.8852],\n",
      "        [ 0.4192],\n",
      "        [-0.2933],\n",
      "        [-0.9139],\n",
      "        [ 1.0765],\n",
      "        [ 0.7924],\n",
      "        [-0.6770],\n",
      "        [ 0.4916]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3416],\n",
      "        [ 1.4419],\n",
      "        [-1.8854],\n",
      "        [ 0.4195],\n",
      "        [-0.2934],\n",
      "        [-0.9142],\n",
      "        [ 1.0763],\n",
      "        [ 0.7924],\n",
      "        [-0.6773],\n",
      "        [ 0.4916]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3420],\n",
      "        [ 1.4424],\n",
      "        [-1.8856],\n",
      "        [ 0.4197],\n",
      "        [-0.2936],\n",
      "        [-0.9145],\n",
      "        [ 1.0762],\n",
      "        [ 0.7924],\n",
      "        [-0.6776],\n",
      "        [ 0.4916]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3424],\n",
      "        [ 1.4428],\n",
      "        [-1.8857],\n",
      "        [ 0.4199],\n",
      "        [-0.2937],\n",
      "        [-0.9148],\n",
      "        [ 1.0760],\n",
      "        [ 0.7924],\n",
      "        [-0.6779],\n",
      "        [ 0.4915]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3427],\n",
      "        [ 1.4433],\n",
      "        [-1.8859],\n",
      "        [ 0.4202],\n",
      "        [-0.2939],\n",
      "        [-0.9151],\n",
      "        [ 1.0759],\n",
      "        [ 0.7924],\n",
      "        [-0.6782],\n",
      "        [ 0.4915]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3431],\n",
      "        [ 1.4438],\n",
      "        [-1.8860],\n",
      "        [ 0.4204],\n",
      "        [-0.2940],\n",
      "        [-0.9153],\n",
      "        [ 1.0757],\n",
      "        [ 0.7924],\n",
      "        [-0.6785],\n",
      "        [ 0.4915]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3435],\n",
      "        [ 1.4442],\n",
      "        [-1.8862],\n",
      "        [ 0.4207],\n",
      "        [-0.2942],\n",
      "        [-0.9156],\n",
      "        [ 1.0756],\n",
      "        [ 0.7924],\n",
      "        [-0.6788],\n",
      "        [ 0.4915]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3439],\n",
      "        [ 1.4447],\n",
      "        [-1.8863],\n",
      "        [ 0.4209],\n",
      "        [-0.2943],\n",
      "        [-0.9159],\n",
      "        [ 1.0755],\n",
      "        [ 0.7924],\n",
      "        [-0.6791],\n",
      "        [ 0.4915]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3442],\n",
      "        [ 1.4451],\n",
      "        [-1.8865],\n",
      "        [ 0.4212],\n",
      "        [-0.2944],\n",
      "        [-0.9162],\n",
      "        [ 1.0753],\n",
      "        [ 0.7924],\n",
      "        [-0.6794],\n",
      "        [ 0.4915]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3446],\n",
      "        [ 1.4456],\n",
      "        [-1.8866],\n",
      "        [ 0.4214],\n",
      "        [-0.2946],\n",
      "        [-0.9165],\n",
      "        [ 1.0752],\n",
      "        [ 0.7924],\n",
      "        [-0.6797],\n",
      "        [ 0.4915]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3450],\n",
      "        [ 1.4461],\n",
      "        [-1.8868],\n",
      "        [ 0.4217],\n",
      "        [-0.2947],\n",
      "        [-0.9168],\n",
      "        [ 1.0750],\n",
      "        [ 0.7924],\n",
      "        [-0.6800],\n",
      "        [ 0.4915]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3454],\n",
      "        [ 1.4465],\n",
      "        [-1.8869],\n",
      "        [ 0.4219],\n",
      "        [-0.2949],\n",
      "        [-0.9171],\n",
      "        [ 1.0749],\n",
      "        [ 0.7924],\n",
      "        [-0.6803],\n",
      "        [ 0.4915]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3458],\n",
      "        [ 1.4470],\n",
      "        [-1.8871],\n",
      "        [ 0.4222],\n",
      "        [-0.2950],\n",
      "        [-0.9173],\n",
      "        [ 1.0748],\n",
      "        [ 0.7924],\n",
      "        [-0.6806],\n",
      "        [ 0.4915]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3461],\n",
      "        [ 1.4475],\n",
      "        [-1.8873],\n",
      "        [ 0.4224],\n",
      "        [-0.2951],\n",
      "        [-0.9176],\n",
      "        [ 1.0746],\n",
      "        [ 0.7924],\n",
      "        [-0.6809],\n",
      "        [ 0.4915]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3465],\n",
      "        [ 1.4479],\n",
      "        [-1.8874],\n",
      "        [ 0.4226],\n",
      "        [-0.2953],\n",
      "        [-0.9179],\n",
      "        [ 1.0745],\n",
      "        [ 0.7924],\n",
      "        [-0.6812],\n",
      "        [ 0.4915]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3469],\n",
      "        [ 1.4484],\n",
      "        [-1.8876],\n",
      "        [ 0.4229],\n",
      "        [-0.2954],\n",
      "        [-0.9182],\n",
      "        [ 1.0743],\n",
      "        [ 0.7924],\n",
      "        [-0.6815],\n",
      "        [ 0.4915]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3473],\n",
      "        [ 1.4488],\n",
      "        [-1.8877],\n",
      "        [ 0.4231],\n",
      "        [-0.2956],\n",
      "        [-0.9185],\n",
      "        [ 1.0742],\n",
      "        [ 0.7924],\n",
      "        [-0.6818],\n",
      "        [ 0.4915]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3476],\n",
      "        [ 1.4493],\n",
      "        [-1.8879],\n",
      "        [ 0.4234],\n",
      "        [-0.2957],\n",
      "        [-0.9188],\n",
      "        [ 1.0740],\n",
      "        [ 0.7924],\n",
      "        [-0.6821],\n",
      "        [ 0.4915]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3480],\n",
      "        [ 1.4498],\n",
      "        [-1.8880],\n",
      "        [ 0.4236],\n",
      "        [-0.2959],\n",
      "        [-0.9190],\n",
      "        [ 1.0739],\n",
      "        [ 0.7924],\n",
      "        [-0.6824],\n",
      "        [ 0.4914]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3484],\n",
      "        [ 1.4502],\n",
      "        [-1.8882],\n",
      "        [ 0.4239],\n",
      "        [-0.2960],\n",
      "        [-0.9193],\n",
      "        [ 1.0738],\n",
      "        [ 0.7924],\n",
      "        [-0.6827],\n",
      "        [ 0.4914]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3488],\n",
      "        [ 1.4507],\n",
      "        [-1.8883],\n",
      "        [ 0.4241],\n",
      "        [-0.2961],\n",
      "        [-0.9196],\n",
      "        [ 1.0736],\n",
      "        [ 0.7924],\n",
      "        [-0.6830],\n",
      "        [ 0.4914]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3491],\n",
      "        [ 1.4511],\n",
      "        [-1.8885],\n",
      "        [ 0.4244],\n",
      "        [-0.2963],\n",
      "        [-0.9199],\n",
      "        [ 1.0735],\n",
      "        [ 0.7924],\n",
      "        [-0.6833],\n",
      "        [ 0.4914]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3495],\n",
      "        [ 1.4516],\n",
      "        [-1.8886],\n",
      "        [ 0.4246],\n",
      "        [-0.2964],\n",
      "        [-0.9202],\n",
      "        [ 1.0733],\n",
      "        [ 0.7924],\n",
      "        [-0.6836],\n",
      "        [ 0.4914]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3499],\n",
      "        [ 1.4521],\n",
      "        [-1.8888],\n",
      "        [ 0.4248],\n",
      "        [-0.2966],\n",
      "        [-0.9205],\n",
      "        [ 1.0732],\n",
      "        [ 0.7924],\n",
      "        [-0.6839],\n",
      "        [ 0.4914]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3502],\n",
      "        [ 1.4525],\n",
      "        [-1.8889],\n",
      "        [ 0.4251],\n",
      "        [-0.2967],\n",
      "        [-0.9207],\n",
      "        [ 1.0731],\n",
      "        [ 0.7924],\n",
      "        [-0.6842],\n",
      "        [ 0.4914]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3506],\n",
      "        [ 1.4530],\n",
      "        [-1.8891],\n",
      "        [ 0.4253],\n",
      "        [-0.2968],\n",
      "        [-0.9210],\n",
      "        [ 1.0729],\n",
      "        [ 0.7924],\n",
      "        [-0.6845],\n",
      "        [ 0.4914]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3510],\n",
      "        [ 1.4534],\n",
      "        [-1.8892],\n",
      "        [ 0.4256],\n",
      "        [-0.2970],\n",
      "        [-0.9213],\n",
      "        [ 1.0728],\n",
      "        [ 0.7924],\n",
      "        [-0.6848],\n",
      "        [ 0.4914]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3514],\n",
      "        [ 1.4539],\n",
      "        [-1.8894],\n",
      "        [ 0.4258],\n",
      "        [-0.2971],\n",
      "        [-0.9216],\n",
      "        [ 1.0726],\n",
      "        [ 0.7924],\n",
      "        [-0.6851],\n",
      "        [ 0.4914]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3517],\n",
      "        [ 1.4544],\n",
      "        [-1.8896],\n",
      "        [ 0.4261],\n",
      "        [-0.2973],\n",
      "        [-0.9219],\n",
      "        [ 1.0725],\n",
      "        [ 0.7924],\n",
      "        [-0.6854],\n",
      "        [ 0.4914]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3521],\n",
      "        [ 1.4548],\n",
      "        [-1.8897],\n",
      "        [ 0.4263],\n",
      "        [-0.2974],\n",
      "        [-0.9222],\n",
      "        [ 1.0724],\n",
      "        [ 0.7924],\n",
      "        [-0.6857],\n",
      "        [ 0.4914]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3525],\n",
      "        [ 1.4553],\n",
      "        [-1.8899],\n",
      "        [ 0.4265],\n",
      "        [-0.2975],\n",
      "        [-0.9224],\n",
      "        [ 1.0722],\n",
      "        [ 0.7924],\n",
      "        [-0.6860],\n",
      "        [ 0.4914]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3529],\n",
      "        [ 1.4557],\n",
      "        [-1.8900],\n",
      "        [ 0.4268],\n",
      "        [-0.2977],\n",
      "        [-0.9227],\n",
      "        [ 1.0721],\n",
      "        [ 0.7924],\n",
      "        [-0.6863],\n",
      "        [ 0.4914]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3532],\n",
      "        [ 1.4562],\n",
      "        [-1.8902],\n",
      "        [ 0.4270],\n",
      "        [-0.2978],\n",
      "        [-0.9230],\n",
      "        [ 1.0719],\n",
      "        [ 0.7924],\n",
      "        [-0.6866],\n",
      "        [ 0.4914]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3536],\n",
      "        [ 1.4566],\n",
      "        [-1.8903],\n",
      "        [ 0.4273],\n",
      "        [-0.2979],\n",
      "        [-0.9233],\n",
      "        [ 1.0718],\n",
      "        [ 0.7924],\n",
      "        [-0.6869],\n",
      "        [ 0.4914]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3540],\n",
      "        [ 1.4571],\n",
      "        [-1.8905],\n",
      "        [ 0.4275],\n",
      "        [-0.2981],\n",
      "        [-0.9236],\n",
      "        [ 1.0717],\n",
      "        [ 0.7924],\n",
      "        [-0.6872],\n",
      "        [ 0.4913]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3543],\n",
      "        [ 1.4575],\n",
      "        [-1.8906],\n",
      "        [ 0.4277],\n",
      "        [-0.2982],\n",
      "        [-0.9239],\n",
      "        [ 1.0715],\n",
      "        [ 0.7924],\n",
      "        [-0.6874],\n",
      "        [ 0.4913]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3547],\n",
      "        [ 1.4580],\n",
      "        [-1.8908],\n",
      "        [ 0.4280],\n",
      "        [-0.2984],\n",
      "        [-0.9241],\n",
      "        [ 1.0714],\n",
      "        [ 0.7924],\n",
      "        [-0.6877],\n",
      "        [ 0.4913]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3551],\n",
      "        [ 1.4585],\n",
      "        [-1.8909],\n",
      "        [ 0.4282],\n",
      "        [-0.2985],\n",
      "        [-0.9244],\n",
      "        [ 1.0713],\n",
      "        [ 0.7924],\n",
      "        [-0.6880],\n",
      "        [ 0.4913]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3554],\n",
      "        [ 1.4589],\n",
      "        [-1.8911],\n",
      "        [ 0.4285],\n",
      "        [-0.2986],\n",
      "        [-0.9247],\n",
      "        [ 1.0711],\n",
      "        [ 0.7924],\n",
      "        [-0.6883],\n",
      "        [ 0.4913]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3558],\n",
      "        [ 1.4594],\n",
      "        [-1.8912],\n",
      "        [ 0.4287],\n",
      "        [-0.2988],\n",
      "        [-0.9250],\n",
      "        [ 1.0710],\n",
      "        [ 0.7924],\n",
      "        [-0.6886],\n",
      "        [ 0.4913]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3562],\n",
      "        [ 1.4598],\n",
      "        [-1.8914],\n",
      "        [ 0.4289],\n",
      "        [-0.2989],\n",
      "        [-0.9253],\n",
      "        [ 1.0708],\n",
      "        [ 0.7924],\n",
      "        [-0.6889],\n",
      "        [ 0.4913]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3565],\n",
      "        [ 1.4603],\n",
      "        [-1.8915],\n",
      "        [ 0.4292],\n",
      "        [-0.2991],\n",
      "        [-0.9255],\n",
      "        [ 1.0707],\n",
      "        [ 0.7924],\n",
      "        [-0.6892],\n",
      "        [ 0.4913]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3569],\n",
      "        [ 1.4607],\n",
      "        [-1.8917],\n",
      "        [ 0.4294],\n",
      "        [-0.2992],\n",
      "        [-0.9258],\n",
      "        [ 1.0706],\n",
      "        [ 0.7924],\n",
      "        [-0.6895],\n",
      "        [ 0.4913]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3573],\n",
      "        [ 1.4612],\n",
      "        [-1.8918],\n",
      "        [ 0.4297],\n",
      "        [-0.2993],\n",
      "        [-0.9261],\n",
      "        [ 1.0704],\n",
      "        [ 0.7924],\n",
      "        [-0.6898],\n",
      "        [ 0.4913]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3577],\n",
      "        [ 1.4616],\n",
      "        [-1.8920],\n",
      "        [ 0.4299],\n",
      "        [-0.2995],\n",
      "        [-0.9264],\n",
      "        [ 1.0703],\n",
      "        [ 0.7924],\n",
      "        [-0.6901],\n",
      "        [ 0.4913]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3580],\n",
      "        [ 1.4621],\n",
      "        [-1.8921],\n",
      "        [ 0.4301],\n",
      "        [-0.2996],\n",
      "        [-0.9267],\n",
      "        [ 1.0701],\n",
      "        [ 0.7924],\n",
      "        [-0.6904],\n",
      "        [ 0.4913]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3584],\n",
      "        [ 1.4625],\n",
      "        [-1.8923],\n",
      "        [ 0.4304],\n",
      "        [-0.2997],\n",
      "        [-0.9269],\n",
      "        [ 1.0700],\n",
      "        [ 0.7924],\n",
      "        [-0.6907],\n",
      "        [ 0.4913]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3588],\n",
      "        [ 1.4630],\n",
      "        [-1.8924],\n",
      "        [ 0.4306],\n",
      "        [-0.2999],\n",
      "        [-0.9272],\n",
      "        [ 1.0699],\n",
      "        [ 0.7924],\n",
      "        [-0.6910],\n",
      "        [ 0.4913]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3591],\n",
      "        [ 1.4634],\n",
      "        [-1.8926],\n",
      "        [ 0.4309],\n",
      "        [-0.3000],\n",
      "        [-0.9275],\n",
      "        [ 1.0697],\n",
      "        [ 0.7924],\n",
      "        [-0.6913],\n",
      "        [ 0.4913]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3595],\n",
      "        [ 1.4639],\n",
      "        [-1.8927],\n",
      "        [ 0.4311],\n",
      "        [-0.3002],\n",
      "        [-0.9278],\n",
      "        [ 1.0696],\n",
      "        [ 0.7924],\n",
      "        [-0.6916],\n",
      "        [ 0.4913]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3599],\n",
      "        [ 1.4643],\n",
      "        [-1.8929],\n",
      "        [ 0.4313],\n",
      "        [-0.3003],\n",
      "        [-0.9281],\n",
      "        [ 1.0695],\n",
      "        [ 0.7924],\n",
      "        [-0.6919],\n",
      "        [ 0.4912]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3602],\n",
      "        [ 1.4648],\n",
      "        [-1.8930],\n",
      "        [ 0.4316],\n",
      "        [-0.3004],\n",
      "        [-0.9283],\n",
      "        [ 1.0693],\n",
      "        [ 0.7924],\n",
      "        [-0.6922],\n",
      "        [ 0.4912]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3606],\n",
      "        [ 1.4652],\n",
      "        [-1.8932],\n",
      "        [ 0.4318],\n",
      "        [-0.3006],\n",
      "        [-0.9286],\n",
      "        [ 1.0692],\n",
      "        [ 0.7924],\n",
      "        [-0.6925],\n",
      "        [ 0.4912]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3610],\n",
      "        [ 1.4657],\n",
      "        [-1.8933],\n",
      "        [ 0.4321],\n",
      "        [-0.3007],\n",
      "        [-0.9289],\n",
      "        [ 1.0690],\n",
      "        [ 0.7924],\n",
      "        [-0.6928],\n",
      "        [ 0.4912]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3613],\n",
      "        [ 1.4661],\n",
      "        [-1.8935],\n",
      "        [ 0.4323],\n",
      "        [-0.3008],\n",
      "        [-0.9292],\n",
      "        [ 1.0689],\n",
      "        [ 0.7924],\n",
      "        [-0.6931],\n",
      "        [ 0.4912]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3617],\n",
      "        [ 1.4666],\n",
      "        [-1.8936],\n",
      "        [ 0.4325],\n",
      "        [-0.3010],\n",
      "        [-0.9295],\n",
      "        [ 1.0688],\n",
      "        [ 0.7924],\n",
      "        [-0.6934],\n",
      "        [ 0.4912]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3621],\n",
      "        [ 1.4670],\n",
      "        [-1.8938],\n",
      "        [ 0.4328],\n",
      "        [-0.3011],\n",
      "        [-0.9297],\n",
      "        [ 1.0686],\n",
      "        [ 0.7924],\n",
      "        [-0.6937],\n",
      "        [ 0.4912]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3624],\n",
      "        [ 1.4675],\n",
      "        [-1.8939],\n",
      "        [ 0.4330],\n",
      "        [-0.3013],\n",
      "        [-0.9300],\n",
      "        [ 1.0685],\n",
      "        [ 0.7924],\n",
      "        [-0.6940],\n",
      "        [ 0.4912]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3628],\n",
      "        [ 1.4679],\n",
      "        [-1.8941],\n",
      "        [ 0.4332],\n",
      "        [-0.3014],\n",
      "        [-0.9303],\n",
      "        [ 1.0684],\n",
      "        [ 0.7924],\n",
      "        [-0.6943],\n",
      "        [ 0.4912]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3631],\n",
      "        [ 1.4684],\n",
      "        [-1.8942],\n",
      "        [ 0.4335],\n",
      "        [-0.3015],\n",
      "        [-0.9306],\n",
      "        [ 1.0682],\n",
      "        [ 0.7924],\n",
      "        [-0.6946],\n",
      "        [ 0.4912]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3635],\n",
      "        [ 1.4688],\n",
      "        [-1.8944],\n",
      "        [ 0.4337],\n",
      "        [-0.3017],\n",
      "        [-0.9309],\n",
      "        [ 1.0681],\n",
      "        [ 0.7924],\n",
      "        [-0.6949],\n",
      "        [ 0.4912]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3639],\n",
      "        [ 1.4692],\n",
      "        [-1.8945],\n",
      "        [ 0.4340],\n",
      "        [-0.3018],\n",
      "        [-0.9311],\n",
      "        [ 1.0680],\n",
      "        [ 0.7924],\n",
      "        [-0.6952],\n",
      "        [ 0.4912]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3642],\n",
      "        [ 1.4697],\n",
      "        [-1.8947],\n",
      "        [ 0.4342],\n",
      "        [-0.3019],\n",
      "        [-0.9314],\n",
      "        [ 1.0678],\n",
      "        [ 0.7924],\n",
      "        [-0.6955],\n",
      "        [ 0.4912]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3646],\n",
      "        [ 1.4701],\n",
      "        [-1.8948],\n",
      "        [ 0.4344],\n",
      "        [-0.3021],\n",
      "        [-0.9317],\n",
      "        [ 1.0677],\n",
      "        [ 0.7924],\n",
      "        [-0.6958],\n",
      "        [ 0.4912]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3650],\n",
      "        [ 1.4706],\n",
      "        [-1.8950],\n",
      "        [ 0.4347],\n",
      "        [-0.3022],\n",
      "        [-0.9320],\n",
      "        [ 1.0675],\n",
      "        [ 0.7924],\n",
      "        [-0.6961],\n",
      "        [ 0.4912]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3653],\n",
      "        [ 1.4710],\n",
      "        [-1.8951],\n",
      "        [ 0.4349],\n",
      "        [-0.3024],\n",
      "        [-0.9322],\n",
      "        [ 1.0674],\n",
      "        [ 0.7924],\n",
      "        [-0.6964],\n",
      "        [ 0.4912]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3657],\n",
      "        [ 1.4715],\n",
      "        [-1.8953],\n",
      "        [ 0.4351],\n",
      "        [-0.3025],\n",
      "        [-0.9325],\n",
      "        [ 1.0673],\n",
      "        [ 0.7924],\n",
      "        [-0.6967],\n",
      "        [ 0.4912]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3661],\n",
      "        [ 1.4719],\n",
      "        [-1.8954],\n",
      "        [ 0.4354],\n",
      "        [-0.3026],\n",
      "        [-0.9328],\n",
      "        [ 1.0671],\n",
      "        [ 0.7924],\n",
      "        [-0.6969],\n",
      "        [ 0.4911]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3664],\n",
      "        [ 1.4724],\n",
      "        [-1.8956],\n",
      "        [ 0.4356],\n",
      "        [-0.3028],\n",
      "        [-0.9331],\n",
      "        [ 1.0670],\n",
      "        [ 0.7924],\n",
      "        [-0.6972],\n",
      "        [ 0.4911]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3668],\n",
      "        [ 1.4728],\n",
      "        [-1.8957],\n",
      "        [ 0.4359],\n",
      "        [-0.3029],\n",
      "        [-0.9334],\n",
      "        [ 1.0669],\n",
      "        [ 0.7924],\n",
      "        [-0.6975],\n",
      "        [ 0.4911]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3671],\n",
      "        [ 1.4732],\n",
      "        [-1.8959],\n",
      "        [ 0.4361],\n",
      "        [-0.3030],\n",
      "        [-0.9336],\n",
      "        [ 1.0667],\n",
      "        [ 0.7924],\n",
      "        [-0.6978],\n",
      "        [ 0.4911]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3675],\n",
      "        [ 1.4737],\n",
      "        [-1.8960],\n",
      "        [ 0.4363],\n",
      "        [-0.3032],\n",
      "        [-0.9339],\n",
      "        [ 1.0666],\n",
      "        [ 0.7924],\n",
      "        [-0.6981],\n",
      "        [ 0.4911]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3679],\n",
      "        [ 1.4741],\n",
      "        [-1.8962],\n",
      "        [ 0.4366],\n",
      "        [-0.3033],\n",
      "        [-0.9342],\n",
      "        [ 1.0665],\n",
      "        [ 0.7924],\n",
      "        [-0.6984],\n",
      "        [ 0.4911]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3682],\n",
      "        [ 1.4746],\n",
      "        [-1.8963],\n",
      "        [ 0.4368],\n",
      "        [-0.3034],\n",
      "        [-0.9345],\n",
      "        [ 1.0663],\n",
      "        [ 0.7924],\n",
      "        [-0.6987],\n",
      "        [ 0.4911]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3686],\n",
      "        [ 1.4750],\n",
      "        [-1.8965],\n",
      "        [ 0.4370],\n",
      "        [-0.3036],\n",
      "        [-0.9347],\n",
      "        [ 1.0662],\n",
      "        [ 0.7924],\n",
      "        [-0.6990],\n",
      "        [ 0.4911]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3689],\n",
      "        [ 1.4755],\n",
      "        [-1.8966],\n",
      "        [ 0.4373],\n",
      "        [-0.3037],\n",
      "        [-0.9350],\n",
      "        [ 1.0661],\n",
      "        [ 0.7924],\n",
      "        [-0.6993],\n",
      "        [ 0.4911]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3693],\n",
      "        [ 1.4759],\n",
      "        [-1.8968],\n",
      "        [ 0.4375],\n",
      "        [-0.3038],\n",
      "        [-0.9353],\n",
      "        [ 1.0659],\n",
      "        [ 0.7924],\n",
      "        [-0.6996],\n",
      "        [ 0.4911]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3697],\n",
      "        [ 1.4763],\n",
      "        [-1.8969],\n",
      "        [ 0.4377],\n",
      "        [-0.3040],\n",
      "        [-0.9356],\n",
      "        [ 1.0658],\n",
      "        [ 0.7924],\n",
      "        [-0.6999],\n",
      "        [ 0.4911]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3700],\n",
      "        [ 1.4768],\n",
      "        [-1.8971],\n",
      "        [ 0.4380],\n",
      "        [-0.3041],\n",
      "        [-0.9358],\n",
      "        [ 1.0656],\n",
      "        [ 0.7924],\n",
      "        [-0.7002],\n",
      "        [ 0.4911]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3704],\n",
      "        [ 1.4772],\n",
      "        [-1.8972],\n",
      "        [ 0.4382],\n",
      "        [-0.3042],\n",
      "        [-0.9361],\n",
      "        [ 1.0655],\n",
      "        [ 0.7924],\n",
      "        [-0.7005],\n",
      "        [ 0.4911]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3707],\n",
      "        [ 1.4777],\n",
      "        [-1.8974],\n",
      "        [ 0.4384],\n",
      "        [-0.3044],\n",
      "        [-0.9364],\n",
      "        [ 1.0654],\n",
      "        [ 0.7924],\n",
      "        [-0.7008],\n",
      "        [ 0.4911]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3711],\n",
      "        [ 1.4781],\n",
      "        [-1.8975],\n",
      "        [ 0.4387],\n",
      "        [-0.3045],\n",
      "        [-0.9367],\n",
      "        [ 1.0652],\n",
      "        [ 0.7924],\n",
      "        [-0.7011],\n",
      "        [ 0.4911]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3715],\n",
      "        [ 1.4785],\n",
      "        [-1.8976],\n",
      "        [ 0.4389],\n",
      "        [-0.3046],\n",
      "        [-0.9370],\n",
      "        [ 1.0651],\n",
      "        [ 0.7924],\n",
      "        [-0.7014],\n",
      "        [ 0.4911]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3718],\n",
      "        [ 1.4790],\n",
      "        [-1.8978],\n",
      "        [ 0.4391],\n",
      "        [-0.3048],\n",
      "        [-0.9372],\n",
      "        [ 1.0650],\n",
      "        [ 0.7924],\n",
      "        [-0.7017],\n",
      "        [ 0.4910]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3722],\n",
      "        [ 1.4794],\n",
      "        [-1.8979],\n",
      "        [ 0.4394],\n",
      "        [-0.3049],\n",
      "        [-0.9375],\n",
      "        [ 1.0648],\n",
      "        [ 0.7924],\n",
      "        [-0.7020],\n",
      "        [ 0.4910]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3725],\n",
      "        [ 1.4798],\n",
      "        [-1.8981],\n",
      "        [ 0.4396],\n",
      "        [-0.3051],\n",
      "        [-0.9378],\n",
      "        [ 1.0647],\n",
      "        [ 0.7924],\n",
      "        [-0.7023],\n",
      "        [ 0.4910]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3729],\n",
      "        [ 1.4803],\n",
      "        [-1.8982],\n",
      "        [ 0.4398],\n",
      "        [-0.3052],\n",
      "        [-0.9381],\n",
      "        [ 1.0646],\n",
      "        [ 0.7924],\n",
      "        [-0.7026],\n",
      "        [ 0.4910]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3732],\n",
      "        [ 1.4807],\n",
      "        [-1.8984],\n",
      "        [ 0.4401],\n",
      "        [-0.3053],\n",
      "        [-0.9383],\n",
      "        [ 1.0644],\n",
      "        [ 0.7924],\n",
      "        [-0.7029],\n",
      "        [ 0.4910]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3736],\n",
      "        [ 1.4812],\n",
      "        [-1.8985],\n",
      "        [ 0.4403],\n",
      "        [-0.3055],\n",
      "        [-0.9386],\n",
      "        [ 1.0643],\n",
      "        [ 0.7924],\n",
      "        [-0.7031],\n",
      "        [ 0.4910]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3740],\n",
      "        [ 1.4816],\n",
      "        [-1.8987],\n",
      "        [ 0.4405],\n",
      "        [-0.3056],\n",
      "        [-0.9389],\n",
      "        [ 1.0642],\n",
      "        [ 0.7924],\n",
      "        [-0.7034],\n",
      "        [ 0.4910]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3743],\n",
      "        [ 1.4820],\n",
      "        [-1.8988],\n",
      "        [ 0.4408],\n",
      "        [-0.3057],\n",
      "        [-0.9392],\n",
      "        [ 1.0640],\n",
      "        [ 0.7924],\n",
      "        [-0.7037],\n",
      "        [ 0.4910]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3747],\n",
      "        [ 1.4825],\n",
      "        [-1.8990],\n",
      "        [ 0.4410],\n",
      "        [-0.3059],\n",
      "        [-0.9394],\n",
      "        [ 1.0639],\n",
      "        [ 0.7924],\n",
      "        [-0.7040],\n",
      "        [ 0.4910]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3750],\n",
      "        [ 1.4829],\n",
      "        [-1.8991],\n",
      "        [ 0.4412],\n",
      "        [-0.3060],\n",
      "        [-0.9397],\n",
      "        [ 1.0638],\n",
      "        [ 0.7924],\n",
      "        [-0.7043],\n",
      "        [ 0.4910]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3754],\n",
      "        [ 1.4833],\n",
      "        [-1.8993],\n",
      "        [ 0.4415],\n",
      "        [-0.3061],\n",
      "        [-0.9400],\n",
      "        [ 1.0636],\n",
      "        [ 0.7924],\n",
      "        [-0.7046],\n",
      "        [ 0.4910]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3757],\n",
      "        [ 1.4838],\n",
      "        [-1.8994],\n",
      "        [ 0.4417],\n",
      "        [-0.3063],\n",
      "        [-0.9403],\n",
      "        [ 1.0635],\n",
      "        [ 0.7924],\n",
      "        [-0.7049],\n",
      "        [ 0.4910]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3761],\n",
      "        [ 1.4842],\n",
      "        [-1.8996],\n",
      "        [ 0.4419],\n",
      "        [-0.3064],\n",
      "        [-0.9405],\n",
      "        [ 1.0634],\n",
      "        [ 0.7924],\n",
      "        [-0.7052],\n",
      "        [ 0.4910]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3765],\n",
      "        [ 1.4846],\n",
      "        [-1.8997],\n",
      "        [ 0.4422],\n",
      "        [-0.3065],\n",
      "        [-0.9408],\n",
      "        [ 1.0632],\n",
      "        [ 0.7924],\n",
      "        [-0.7055],\n",
      "        [ 0.4910]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3768],\n",
      "        [ 1.4851],\n",
      "        [-1.8999],\n",
      "        [ 0.4424],\n",
      "        [-0.3067],\n",
      "        [-0.9411],\n",
      "        [ 1.0631],\n",
      "        [ 0.7924],\n",
      "        [-0.7058],\n",
      "        [ 0.4910]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3772],\n",
      "        [ 1.4855],\n",
      "        [-1.9000],\n",
      "        [ 0.4426],\n",
      "        [-0.3068],\n",
      "        [-0.9413],\n",
      "        [ 1.0630],\n",
      "        [ 0.7924],\n",
      "        [-0.7061],\n",
      "        [ 0.4910]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3775],\n",
      "        [ 1.4859],\n",
      "        [-1.9001],\n",
      "        [ 0.4429],\n",
      "        [-0.3069],\n",
      "        [-0.9416],\n",
      "        [ 1.0628],\n",
      "        [ 0.7924],\n",
      "        [-0.7064],\n",
      "        [ 0.4910]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3779],\n",
      "        [ 1.4864],\n",
      "        [-1.9003],\n",
      "        [ 0.4431],\n",
      "        [-0.3071],\n",
      "        [-0.9419],\n",
      "        [ 1.0627],\n",
      "        [ 0.7924],\n",
      "        [-0.7067],\n",
      "        [ 0.4909]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3782],\n",
      "        [ 1.4868],\n",
      "        [-1.9004],\n",
      "        [ 0.4433],\n",
      "        [-0.3072],\n",
      "        [-0.9422],\n",
      "        [ 1.0626],\n",
      "        [ 0.7924],\n",
      "        [-0.7070],\n",
      "        [ 0.4909]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3786],\n",
      "        [ 1.4872],\n",
      "        [-1.9006],\n",
      "        [ 0.4435],\n",
      "        [-0.3073],\n",
      "        [-0.9424],\n",
      "        [ 1.0624],\n",
      "        [ 0.7924],\n",
      "        [-0.7073],\n",
      "        [ 0.4909]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3789],\n",
      "        [ 1.4877],\n",
      "        [-1.9007],\n",
      "        [ 0.4438],\n",
      "        [-0.3075],\n",
      "        [-0.9427],\n",
      "        [ 1.0623],\n",
      "        [ 0.7924],\n",
      "        [-0.7076],\n",
      "        [ 0.4909]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3793],\n",
      "        [ 1.4881],\n",
      "        [-1.9009],\n",
      "        [ 0.4440],\n",
      "        [-0.3076],\n",
      "        [-0.9430],\n",
      "        [ 1.0622],\n",
      "        [ 0.7924],\n",
      "        [-0.7079],\n",
      "        [ 0.4909]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3796],\n",
      "        [ 1.4885],\n",
      "        [-1.9010],\n",
      "        [ 0.4442],\n",
      "        [-0.3077],\n",
      "        [-0.9433],\n",
      "        [ 1.0620],\n",
      "        [ 0.7924],\n",
      "        [-0.7082],\n",
      "        [ 0.4909]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3800],\n",
      "        [ 1.4890],\n",
      "        [-1.9012],\n",
      "        [ 0.4445],\n",
      "        [-0.3079],\n",
      "        [-0.9435],\n",
      "        [ 1.0619],\n",
      "        [ 0.7924],\n",
      "        [-0.7084],\n",
      "        [ 0.4909]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3804],\n",
      "        [ 1.4894],\n",
      "        [-1.9013],\n",
      "        [ 0.4447],\n",
      "        [-0.3080],\n",
      "        [-0.9438],\n",
      "        [ 1.0618],\n",
      "        [ 0.7924],\n",
      "        [-0.7087],\n",
      "        [ 0.4909]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3807],\n",
      "        [ 1.4898],\n",
      "        [-1.9015],\n",
      "        [ 0.4449],\n",
      "        [-0.3081],\n",
      "        [-0.9441],\n",
      "        [ 1.0616],\n",
      "        [ 0.7924],\n",
      "        [-0.7090],\n",
      "        [ 0.4909]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3811],\n",
      "        [ 1.4903],\n",
      "        [-1.9016],\n",
      "        [ 0.4452],\n",
      "        [-0.3082],\n",
      "        [-0.9444],\n",
      "        [ 1.0615],\n",
      "        [ 0.7924],\n",
      "        [-0.7093],\n",
      "        [ 0.4909]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3814],\n",
      "        [ 1.4907],\n",
      "        [-1.9017],\n",
      "        [ 0.4454],\n",
      "        [-0.3084],\n",
      "        [-0.9446],\n",
      "        [ 1.0614],\n",
      "        [ 0.7924],\n",
      "        [-0.7096],\n",
      "        [ 0.4909]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3818],\n",
      "        [ 1.4911],\n",
      "        [-1.9019],\n",
      "        [ 0.4456],\n",
      "        [-0.3085],\n",
      "        [-0.9449],\n",
      "        [ 1.0612],\n",
      "        [ 0.7924],\n",
      "        [-0.7099],\n",
      "        [ 0.4909]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3821],\n",
      "        [ 1.4916],\n",
      "        [-1.9020],\n",
      "        [ 0.4458],\n",
      "        [-0.3086],\n",
      "        [-0.9452],\n",
      "        [ 1.0611],\n",
      "        [ 0.7924],\n",
      "        [-0.7102],\n",
      "        [ 0.4909]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3825],\n",
      "        [ 1.4920],\n",
      "        [-1.9022],\n",
      "        [ 0.4461],\n",
      "        [-0.3088],\n",
      "        [-0.9454],\n",
      "        [ 1.0610],\n",
      "        [ 0.7924],\n",
      "        [-0.7105],\n",
      "        [ 0.4909]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3828],\n",
      "        [ 1.4924],\n",
      "        [-1.9023],\n",
      "        [ 0.4463],\n",
      "        [-0.3089],\n",
      "        [-0.9457],\n",
      "        [ 1.0608],\n",
      "        [ 0.7924],\n",
      "        [-0.7108],\n",
      "        [ 0.4909]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3832],\n",
      "        [ 1.4928],\n",
      "        [-1.9025],\n",
      "        [ 0.4465],\n",
      "        [-0.3090],\n",
      "        [-0.9460],\n",
      "        [ 1.0607],\n",
      "        [ 0.7924],\n",
      "        [-0.7111],\n",
      "        [ 0.4909]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3835],\n",
      "        [ 1.4933],\n",
      "        [-1.9026],\n",
      "        [ 0.4468],\n",
      "        [-0.3092],\n",
      "        [-0.9463],\n",
      "        [ 1.0606],\n",
      "        [ 0.7924],\n",
      "        [-0.7114],\n",
      "        [ 0.4909]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3839],\n",
      "        [ 1.4937],\n",
      "        [-1.9028],\n",
      "        [ 0.4470],\n",
      "        [-0.3093],\n",
      "        [-0.9465],\n",
      "        [ 1.0605],\n",
      "        [ 0.7924],\n",
      "        [-0.7117],\n",
      "        [ 0.4909]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3842],\n",
      "        [ 1.4941],\n",
      "        [-1.9029],\n",
      "        [ 0.4472],\n",
      "        [-0.3094],\n",
      "        [-0.9468],\n",
      "        [ 1.0603],\n",
      "        [ 0.7924],\n",
      "        [-0.7120],\n",
      "        [ 0.4908]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3846],\n",
      "        [ 1.4946],\n",
      "        [-1.9030],\n",
      "        [ 0.4474],\n",
      "        [-0.3096],\n",
      "        [-0.9471],\n",
      "        [ 1.0602],\n",
      "        [ 0.7924],\n",
      "        [-0.7123],\n",
      "        [ 0.4908]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3849],\n",
      "        [ 1.4950],\n",
      "        [-1.9032],\n",
      "        [ 0.4477],\n",
      "        [-0.3097],\n",
      "        [-0.9473],\n",
      "        [ 1.0601],\n",
      "        [ 0.7924],\n",
      "        [-0.7125],\n",
      "        [ 0.4908]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3853],\n",
      "        [ 1.4954],\n",
      "        [-1.9033],\n",
      "        [ 0.4479],\n",
      "        [-0.3098],\n",
      "        [-0.9476],\n",
      "        [ 1.0599],\n",
      "        [ 0.7924],\n",
      "        [-0.7128],\n",
      "        [ 0.4908]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3856],\n",
      "        [ 1.4958],\n",
      "        [-1.9035],\n",
      "        [ 0.4481],\n",
      "        [-0.3100],\n",
      "        [-0.9479],\n",
      "        [ 1.0598],\n",
      "        [ 0.7924],\n",
      "        [-0.7131],\n",
      "        [ 0.4908]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3860],\n",
      "        [ 1.4963],\n",
      "        [-1.9036],\n",
      "        [ 0.4484],\n",
      "        [-0.3101],\n",
      "        [-0.9482],\n",
      "        [ 1.0597],\n",
      "        [ 0.7924],\n",
      "        [-0.7134],\n",
      "        [ 0.4908]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3863],\n",
      "        [ 1.4967],\n",
      "        [-1.9038],\n",
      "        [ 0.4486],\n",
      "        [-0.3102],\n",
      "        [-0.9484],\n",
      "        [ 1.0595],\n",
      "        [ 0.7924],\n",
      "        [-0.7137],\n",
      "        [ 0.4908]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3867],\n",
      "        [ 1.4971],\n",
      "        [-1.9039],\n",
      "        [ 0.4488],\n",
      "        [-0.3104],\n",
      "        [-0.9487],\n",
      "        [ 1.0594],\n",
      "        [ 0.7924],\n",
      "        [-0.7140],\n",
      "        [ 0.4908]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3870],\n",
      "        [ 1.4975],\n",
      "        [-1.9041],\n",
      "        [ 0.4490],\n",
      "        [-0.3105],\n",
      "        [-0.9490],\n",
      "        [ 1.0593],\n",
      "        [ 0.7924],\n",
      "        [-0.7143],\n",
      "        [ 0.4908]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3874],\n",
      "        [ 1.4980],\n",
      "        [-1.9042],\n",
      "        [ 0.4493],\n",
      "        [-0.3106],\n",
      "        [-0.9492],\n",
      "        [ 1.0591],\n",
      "        [ 0.7924],\n",
      "        [-0.7146],\n",
      "        [ 0.4908]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3877],\n",
      "        [ 1.4984],\n",
      "        [-1.9043],\n",
      "        [ 0.4495],\n",
      "        [-0.3107],\n",
      "        [-0.9495],\n",
      "        [ 1.0590],\n",
      "        [ 0.7924],\n",
      "        [-0.7149],\n",
      "        [ 0.4908]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3881],\n",
      "        [ 1.4988],\n",
      "        [-1.9045],\n",
      "        [ 0.4497],\n",
      "        [-0.3109],\n",
      "        [-0.9498],\n",
      "        [ 1.0589],\n",
      "        [ 0.7924],\n",
      "        [-0.7152],\n",
      "        [ 0.4908]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3884],\n",
      "        [ 1.4992],\n",
      "        [-1.9046],\n",
      "        [ 0.4499],\n",
      "        [-0.3110],\n",
      "        [-0.9501],\n",
      "        [ 1.0588],\n",
      "        [ 0.7924],\n",
      "        [-0.7155],\n",
      "        [ 0.4908]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3888],\n",
      "        [ 1.4997],\n",
      "        [-1.9048],\n",
      "        [ 0.4502],\n",
      "        [-0.3111],\n",
      "        [-0.9503],\n",
      "        [ 1.0586],\n",
      "        [ 0.7924],\n",
      "        [-0.7158],\n",
      "        [ 0.4908]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3891],\n",
      "        [ 1.5001],\n",
      "        [-1.9049],\n",
      "        [ 0.4504],\n",
      "        [-0.3113],\n",
      "        [-0.9506],\n",
      "        [ 1.0585],\n",
      "        [ 0.7924],\n",
      "        [-0.7161],\n",
      "        [ 0.4908]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3894],\n",
      "        [ 1.5005],\n",
      "        [-1.9051],\n",
      "        [ 0.4506],\n",
      "        [-0.3114],\n",
      "        [-0.9509],\n",
      "        [ 1.0584],\n",
      "        [ 0.7924],\n",
      "        [-0.7163],\n",
      "        [ 0.4908]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3898],\n",
      "        [ 1.5009],\n",
      "        [-1.9052],\n",
      "        [ 0.4508],\n",
      "        [-0.3115],\n",
      "        [-0.9511],\n",
      "        [ 1.0582],\n",
      "        [ 0.7924],\n",
      "        [-0.7166],\n",
      "        [ 0.4908]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3901],\n",
      "        [ 1.5013],\n",
      "        [-1.9053],\n",
      "        [ 0.4511],\n",
      "        [-0.3117],\n",
      "        [-0.9514],\n",
      "        [ 1.0581],\n",
      "        [ 0.7924],\n",
      "        [-0.7169],\n",
      "        [ 0.4907]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3905],\n",
      "        [ 1.5018],\n",
      "        [-1.9055],\n",
      "        [ 0.4513],\n",
      "        [-0.3118],\n",
      "        [-0.9517],\n",
      "        [ 1.0580],\n",
      "        [ 0.7924],\n",
      "        [-0.7172],\n",
      "        [ 0.4907]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3908],\n",
      "        [ 1.5022],\n",
      "        [-1.9056],\n",
      "        [ 0.4515],\n",
      "        [-0.3119],\n",
      "        [-0.9519],\n",
      "        [ 1.0578],\n",
      "        [ 0.7924],\n",
      "        [-0.7175],\n",
      "        [ 0.4907]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3912],\n",
      "        [ 1.5026],\n",
      "        [-1.9058],\n",
      "        [ 0.4517],\n",
      "        [-0.3120],\n",
      "        [-0.9522],\n",
      "        [ 1.0577],\n",
      "        [ 0.7924],\n",
      "        [-0.7178],\n",
      "        [ 0.4907]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3915],\n",
      "        [ 1.5030],\n",
      "        [-1.9059],\n",
      "        [ 0.4520],\n",
      "        [-0.3122],\n",
      "        [-0.9525],\n",
      "        [ 1.0576],\n",
      "        [ 0.7924],\n",
      "        [-0.7181],\n",
      "        [ 0.4907]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3919],\n",
      "        [ 1.5034],\n",
      "        [-1.9061],\n",
      "        [ 0.4522],\n",
      "        [-0.3123],\n",
      "        [-0.9527],\n",
      "        [ 1.0575],\n",
      "        [ 0.7924],\n",
      "        [-0.7184],\n",
      "        [ 0.4907]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3922],\n",
      "        [ 1.5039],\n",
      "        [-1.9062],\n",
      "        [ 0.4524],\n",
      "        [-0.3124],\n",
      "        [-0.9530],\n",
      "        [ 1.0573],\n",
      "        [ 0.7924],\n",
      "        [-0.7187],\n",
      "        [ 0.4907]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3926],\n",
      "        [ 1.5043],\n",
      "        [-1.9063],\n",
      "        [ 0.4526],\n",
      "        [-0.3126],\n",
      "        [-0.9533],\n",
      "        [ 1.0572],\n",
      "        [ 0.7924],\n",
      "        [-0.7190],\n",
      "        [ 0.4907]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3929],\n",
      "        [ 1.5047],\n",
      "        [-1.9065],\n",
      "        [ 0.4529],\n",
      "        [-0.3127],\n",
      "        [-0.9536],\n",
      "        [ 1.0571],\n",
      "        [ 0.7924],\n",
      "        [-0.7193],\n",
      "        [ 0.4907]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3932],\n",
      "        [ 1.5051],\n",
      "        [-1.9066],\n",
      "        [ 0.4531],\n",
      "        [-0.3128],\n",
      "        [-0.9538],\n",
      "        [ 1.0569],\n",
      "        [ 0.7924],\n",
      "        [-0.7196],\n",
      "        [ 0.4907]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3936],\n",
      "        [ 1.5055],\n",
      "        [-1.9068],\n",
      "        [ 0.4533],\n",
      "        [-0.3130],\n",
      "        [-0.9541],\n",
      "        [ 1.0568],\n",
      "        [ 0.7924],\n",
      "        [-0.7198],\n",
      "        [ 0.4907]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3939],\n",
      "        [ 1.5060],\n",
      "        [-1.9069],\n",
      "        [ 0.4535],\n",
      "        [-0.3131],\n",
      "        [-0.9544],\n",
      "        [ 1.0567],\n",
      "        [ 0.7924],\n",
      "        [-0.7201],\n",
      "        [ 0.4907]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3943],\n",
      "        [ 1.5064],\n",
      "        [-1.9071],\n",
      "        [ 0.4538],\n",
      "        [-0.3132],\n",
      "        [-0.9546],\n",
      "        [ 1.0565],\n",
      "        [ 0.7924],\n",
      "        [-0.7204],\n",
      "        [ 0.4907]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3946],\n",
      "        [ 1.5068],\n",
      "        [-1.9072],\n",
      "        [ 0.4540],\n",
      "        [-0.3133],\n",
      "        [-0.9549],\n",
      "        [ 1.0564],\n",
      "        [ 0.7924],\n",
      "        [-0.7207],\n",
      "        [ 0.4907]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3950],\n",
      "        [ 1.5072],\n",
      "        [-1.9073],\n",
      "        [ 0.4542],\n",
      "        [-0.3135],\n",
      "        [-0.9552],\n",
      "        [ 1.0563],\n",
      "        [ 0.7924],\n",
      "        [-0.7210],\n",
      "        [ 0.4907]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3953],\n",
      "        [ 1.5076],\n",
      "        [-1.9075],\n",
      "        [ 0.4544],\n",
      "        [-0.3136],\n",
      "        [-0.9554],\n",
      "        [ 1.0562],\n",
      "        [ 0.7924],\n",
      "        [-0.7213],\n",
      "        [ 0.4907]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3956],\n",
      "        [ 1.5081],\n",
      "        [-1.9076],\n",
      "        [ 0.4547],\n",
      "        [-0.3137],\n",
      "        [-0.9557],\n",
      "        [ 1.0560],\n",
      "        [ 0.7924],\n",
      "        [-0.7216],\n",
      "        [ 0.4907]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3960],\n",
      "        [ 1.5085],\n",
      "        [-1.9078],\n",
      "        [ 0.4549],\n",
      "        [-0.3139],\n",
      "        [-0.9560],\n",
      "        [ 1.0559],\n",
      "        [ 0.7924],\n",
      "        [-0.7219],\n",
      "        [ 0.4907]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3963],\n",
      "        [ 1.5089],\n",
      "        [-1.9079],\n",
      "        [ 0.4551],\n",
      "        [-0.3140],\n",
      "        [-0.9562],\n",
      "        [ 1.0558],\n",
      "        [ 0.7924],\n",
      "        [-0.7222],\n",
      "        [ 0.4906]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3967],\n",
      "        [ 1.5093],\n",
      "        [-1.9080],\n",
      "        [ 0.4553],\n",
      "        [-0.3141],\n",
      "        [-0.9565],\n",
      "        [ 1.0556],\n",
      "        [ 0.7924],\n",
      "        [-0.7225],\n",
      "        [ 0.4906]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3970],\n",
      "        [ 1.5097],\n",
      "        [-1.9082],\n",
      "        [ 0.4556],\n",
      "        [-0.3142],\n",
      "        [-0.9568],\n",
      "        [ 1.0555],\n",
      "        [ 0.7924],\n",
      "        [-0.7228],\n",
      "        [ 0.4906]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3974],\n",
      "        [ 1.5101],\n",
      "        [-1.9083],\n",
      "        [ 0.4558],\n",
      "        [-0.3144],\n",
      "        [-0.9570],\n",
      "        [ 1.0554],\n",
      "        [ 0.7924],\n",
      "        [-0.7230],\n",
      "        [ 0.4906]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3977],\n",
      "        [ 1.5106],\n",
      "        [-1.9085],\n",
      "        [ 0.4560],\n",
      "        [-0.3145],\n",
      "        [-0.9573],\n",
      "        [ 1.0553],\n",
      "        [ 0.7924],\n",
      "        [-0.7233],\n",
      "        [ 0.4906]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3980],\n",
      "        [ 1.5110],\n",
      "        [-1.9086],\n",
      "        [ 0.4562],\n",
      "        [-0.3146],\n",
      "        [-0.9576],\n",
      "        [ 1.0551],\n",
      "        [ 0.7924],\n",
      "        [-0.7236],\n",
      "        [ 0.4906]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3984],\n",
      "        [ 1.5114],\n",
      "        [-1.9088],\n",
      "        [ 0.4564],\n",
      "        [-0.3148],\n",
      "        [-0.9578],\n",
      "        [ 1.0550],\n",
      "        [ 0.7924],\n",
      "        [-0.7239],\n",
      "        [ 0.4906]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3987],\n",
      "        [ 1.5118],\n",
      "        [-1.9089],\n",
      "        [ 0.4567],\n",
      "        [-0.3149],\n",
      "        [-0.9581],\n",
      "        [ 1.0549],\n",
      "        [ 0.7924],\n",
      "        [-0.7242],\n",
      "        [ 0.4906]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3991],\n",
      "        [ 1.5122],\n",
      "        [-1.9090],\n",
      "        [ 0.4569],\n",
      "        [-0.3150],\n",
      "        [-0.9584],\n",
      "        [ 1.0548],\n",
      "        [ 0.7924],\n",
      "        [-0.7245],\n",
      "        [ 0.4906]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3994],\n",
      "        [ 1.5126],\n",
      "        [-1.9092],\n",
      "        [ 0.4571],\n",
      "        [-0.3151],\n",
      "        [-0.9586],\n",
      "        [ 1.0546],\n",
      "        [ 0.7924],\n",
      "        [-0.7248],\n",
      "        [ 0.4906]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.3997],\n",
      "        [ 1.5130],\n",
      "        [-1.9093],\n",
      "        [ 0.4573],\n",
      "        [-0.3153],\n",
      "        [-0.9589],\n",
      "        [ 1.0545],\n",
      "        [ 0.7924],\n",
      "        [-0.7251],\n",
      "        [ 0.4906]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4001],\n",
      "        [ 1.5135],\n",
      "        [-1.9095],\n",
      "        [ 0.4576],\n",
      "        [-0.3154],\n",
      "        [-0.9592],\n",
      "        [ 1.0544],\n",
      "        [ 0.7924],\n",
      "        [-0.7254],\n",
      "        [ 0.4906]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4004],\n",
      "        [ 1.5139],\n",
      "        [-1.9096],\n",
      "        [ 0.4578],\n",
      "        [-0.3155],\n",
      "        [-0.9594],\n",
      "        [ 1.0542],\n",
      "        [ 0.7924],\n",
      "        [-0.7256],\n",
      "        [ 0.4906]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4008],\n",
      "        [ 1.5143],\n",
      "        [-1.9097],\n",
      "        [ 0.4580],\n",
      "        [-0.3156],\n",
      "        [-0.9597],\n",
      "        [ 1.0541],\n",
      "        [ 0.7924],\n",
      "        [-0.7259],\n",
      "        [ 0.4906]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4011],\n",
      "        [ 1.5147],\n",
      "        [-1.9099],\n",
      "        [ 0.4582],\n",
      "        [-0.3158],\n",
      "        [-0.9600],\n",
      "        [ 1.0540],\n",
      "        [ 0.7924],\n",
      "        [-0.7262],\n",
      "        [ 0.4906]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4014],\n",
      "        [ 1.5151],\n",
      "        [-1.9100],\n",
      "        [ 0.4584],\n",
      "        [-0.3159],\n",
      "        [-0.9602],\n",
      "        [ 1.0539],\n",
      "        [ 0.7924],\n",
      "        [-0.7265],\n",
      "        [ 0.4906]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4018],\n",
      "        [ 1.5155],\n",
      "        [-1.9102],\n",
      "        [ 0.4587],\n",
      "        [-0.3160],\n",
      "        [-0.9605],\n",
      "        [ 1.0537],\n",
      "        [ 0.7924],\n",
      "        [-0.7268],\n",
      "        [ 0.4906]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4021],\n",
      "        [ 1.5159],\n",
      "        [-1.9103],\n",
      "        [ 0.4589],\n",
      "        [-0.3162],\n",
      "        [-0.9608],\n",
      "        [ 1.0536],\n",
      "        [ 0.7924],\n",
      "        [-0.7271],\n",
      "        [ 0.4906]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4025],\n",
      "        [ 1.5163],\n",
      "        [-1.9104],\n",
      "        [ 0.4591],\n",
      "        [-0.3163],\n",
      "        [-0.9610],\n",
      "        [ 1.0535],\n",
      "        [ 0.7924],\n",
      "        [-0.7274],\n",
      "        [ 0.4905]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4028],\n",
      "        [ 1.5167],\n",
      "        [-1.9106],\n",
      "        [ 0.4593],\n",
      "        [-0.3164],\n",
      "        [-0.9613],\n",
      "        [ 1.0533],\n",
      "        [ 0.7924],\n",
      "        [-0.7277],\n",
      "        [ 0.4905]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4031],\n",
      "        [ 1.5172],\n",
      "        [-1.9107],\n",
      "        [ 0.4595],\n",
      "        [-0.3165],\n",
      "        [-0.9616],\n",
      "        [ 1.0532],\n",
      "        [ 0.7924],\n",
      "        [-0.7280],\n",
      "        [ 0.4905]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4035],\n",
      "        [ 1.5176],\n",
      "        [-1.9109],\n",
      "        [ 0.4598],\n",
      "        [-0.3167],\n",
      "        [-0.9618],\n",
      "        [ 1.0531],\n",
      "        [ 0.7924],\n",
      "        [-0.7283],\n",
      "        [ 0.4905]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4038],\n",
      "        [ 1.5180],\n",
      "        [-1.9110],\n",
      "        [ 0.4600],\n",
      "        [-0.3168],\n",
      "        [-0.9621],\n",
      "        [ 1.0530],\n",
      "        [ 0.7924],\n",
      "        [-0.7285],\n",
      "        [ 0.4905]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4041],\n",
      "        [ 1.5184],\n",
      "        [-1.9111],\n",
      "        [ 0.4602],\n",
      "        [-0.3169],\n",
      "        [-0.9624],\n",
      "        [ 1.0528],\n",
      "        [ 0.7924],\n",
      "        [-0.7288],\n",
      "        [ 0.4905]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4045],\n",
      "        [ 1.5188],\n",
      "        [-1.9113],\n",
      "        [ 0.4604],\n",
      "        [-0.3170],\n",
      "        [-0.9626],\n",
      "        [ 1.0527],\n",
      "        [ 0.7924],\n",
      "        [-0.7291],\n",
      "        [ 0.4905]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4048],\n",
      "        [ 1.5192],\n",
      "        [-1.9114],\n",
      "        [ 0.4606],\n",
      "        [-0.3172],\n",
      "        [-0.9629],\n",
      "        [ 1.0526],\n",
      "        [ 0.7924],\n",
      "        [-0.7294],\n",
      "        [ 0.4905]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4052],\n",
      "        [ 1.5196],\n",
      "        [-1.9116],\n",
      "        [ 0.4609],\n",
      "        [-0.3173],\n",
      "        [-0.9631],\n",
      "        [ 1.0525],\n",
      "        [ 0.7924],\n",
      "        [-0.7297],\n",
      "        [ 0.4905]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4055],\n",
      "        [ 1.5200],\n",
      "        [-1.9117],\n",
      "        [ 0.4611],\n",
      "        [-0.3174],\n",
      "        [-0.9634],\n",
      "        [ 1.0523],\n",
      "        [ 0.7924],\n",
      "        [-0.7300],\n",
      "        [ 0.4905]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4058],\n",
      "        [ 1.5204],\n",
      "        [-1.9118],\n",
      "        [ 0.4613],\n",
      "        [-0.3175],\n",
      "        [-0.9637],\n",
      "        [ 1.0522],\n",
      "        [ 0.7924],\n",
      "        [-0.7303],\n",
      "        [ 0.4905]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4062],\n",
      "        [ 1.5208],\n",
      "        [-1.9120],\n",
      "        [ 0.4615],\n",
      "        [-0.3177],\n",
      "        [-0.9639],\n",
      "        [ 1.0521],\n",
      "        [ 0.7924],\n",
      "        [-0.7306],\n",
      "        [ 0.4905]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4065],\n",
      "        [ 1.5212],\n",
      "        [-1.9121],\n",
      "        [ 0.4617],\n",
      "        [-0.3178],\n",
      "        [-0.9642],\n",
      "        [ 1.0520],\n",
      "        [ 0.7924],\n",
      "        [-0.7308],\n",
      "        [ 0.4905]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4068],\n",
      "        [ 1.5217],\n",
      "        [-1.9123],\n",
      "        [ 0.4620],\n",
      "        [-0.3179],\n",
      "        [-0.9645],\n",
      "        [ 1.0518],\n",
      "        [ 0.7924],\n",
      "        [-0.7311],\n",
      "        [ 0.4905]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4072],\n",
      "        [ 1.5221],\n",
      "        [-1.9124],\n",
      "        [ 0.4622],\n",
      "        [-0.3181],\n",
      "        [-0.9647],\n",
      "        [ 1.0517],\n",
      "        [ 0.7924],\n",
      "        [-0.7314],\n",
      "        [ 0.4905]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4075],\n",
      "        [ 1.5225],\n",
      "        [-1.9125],\n",
      "        [ 0.4624],\n",
      "        [-0.3182],\n",
      "        [-0.9650],\n",
      "        [ 1.0516],\n",
      "        [ 0.7924],\n",
      "        [-0.7317],\n",
      "        [ 0.4905]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4078],\n",
      "        [ 1.5229],\n",
      "        [-1.9127],\n",
      "        [ 0.4626],\n",
      "        [-0.3183],\n",
      "        [-0.9653],\n",
      "        [ 1.0515],\n",
      "        [ 0.7924],\n",
      "        [-0.7320],\n",
      "        [ 0.4905]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4082],\n",
      "        [ 1.5233],\n",
      "        [-1.9128],\n",
      "        [ 0.4628],\n",
      "        [-0.3184],\n",
      "        [-0.9655],\n",
      "        [ 1.0513],\n",
      "        [ 0.7924],\n",
      "        [-0.7323],\n",
      "        [ 0.4905]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4085],\n",
      "        [ 1.5237],\n",
      "        [-1.9129],\n",
      "        [ 0.4630],\n",
      "        [-0.3186],\n",
      "        [-0.9658],\n",
      "        [ 1.0512],\n",
      "        [ 0.7924],\n",
      "        [-0.7326],\n",
      "        [ 0.4905]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4089],\n",
      "        [ 1.5241],\n",
      "        [-1.9131],\n",
      "        [ 0.4633],\n",
      "        [-0.3187],\n",
      "        [-0.9660],\n",
      "        [ 1.0511],\n",
      "        [ 0.7924],\n",
      "        [-0.7329],\n",
      "        [ 0.4904]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4092],\n",
      "        [ 1.5245],\n",
      "        [-1.9132],\n",
      "        [ 0.4635],\n",
      "        [-0.3188],\n",
      "        [-0.9663],\n",
      "        [ 1.0510],\n",
      "        [ 0.7924],\n",
      "        [-0.7332],\n",
      "        [ 0.4904]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4095],\n",
      "        [ 1.5249],\n",
      "        [-1.9134],\n",
      "        [ 0.4637],\n",
      "        [-0.3189],\n",
      "        [-0.9666],\n",
      "        [ 1.0508],\n",
      "        [ 0.7924],\n",
      "        [-0.7334],\n",
      "        [ 0.4904]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4099],\n",
      "        [ 1.5253],\n",
      "        [-1.9135],\n",
      "        [ 0.4639],\n",
      "        [-0.3191],\n",
      "        [-0.9668],\n",
      "        [ 1.0507],\n",
      "        [ 0.7924],\n",
      "        [-0.7337],\n",
      "        [ 0.4904]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4102],\n",
      "        [ 1.5257],\n",
      "        [-1.9136],\n",
      "        [ 0.4641],\n",
      "        [-0.3192],\n",
      "        [-0.9671],\n",
      "        [ 1.0506],\n",
      "        [ 0.7924],\n",
      "        [-0.7340],\n",
      "        [ 0.4904]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4105],\n",
      "        [ 1.5261],\n",
      "        [-1.9138],\n",
      "        [ 0.4644],\n",
      "        [-0.3193],\n",
      "        [-0.9674],\n",
      "        [ 1.0505],\n",
      "        [ 0.7924],\n",
      "        [-0.7343],\n",
      "        [ 0.4904]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4109],\n",
      "        [ 1.5265],\n",
      "        [-1.9139],\n",
      "        [ 0.4646],\n",
      "        [-0.3194],\n",
      "        [-0.9676],\n",
      "        [ 1.0503],\n",
      "        [ 0.7924],\n",
      "        [-0.7346],\n",
      "        [ 0.4904]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4112],\n",
      "        [ 1.5269],\n",
      "        [-1.9141],\n",
      "        [ 0.4648],\n",
      "        [-0.3196],\n",
      "        [-0.9679],\n",
      "        [ 1.0502],\n",
      "        [ 0.7924],\n",
      "        [-0.7349],\n",
      "        [ 0.4904]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4115],\n",
      "        [ 1.5273],\n",
      "        [-1.9142],\n",
      "        [ 0.4650],\n",
      "        [-0.3197],\n",
      "        [-0.9681],\n",
      "        [ 1.0501],\n",
      "        [ 0.7924],\n",
      "        [-0.7352],\n",
      "        [ 0.4904]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4119],\n",
      "        [ 1.5277],\n",
      "        [-1.9143],\n",
      "        [ 0.4652],\n",
      "        [-0.3198],\n",
      "        [-0.9684],\n",
      "        [ 1.0500],\n",
      "        [ 0.7924],\n",
      "        [-0.7354],\n",
      "        [ 0.4904]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4122],\n",
      "        [ 1.5281],\n",
      "        [-1.9145],\n",
      "        [ 0.4654],\n",
      "        [-0.3199],\n",
      "        [-0.9687],\n",
      "        [ 1.0498],\n",
      "        [ 0.7924],\n",
      "        [-0.7357],\n",
      "        [ 0.4904]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4125],\n",
      "        [ 1.5285],\n",
      "        [-1.9146],\n",
      "        [ 0.4657],\n",
      "        [-0.3201],\n",
      "        [-0.9689],\n",
      "        [ 1.0497],\n",
      "        [ 0.7924],\n",
      "        [-0.7360],\n",
      "        [ 0.4904]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4128],\n",
      "        [ 1.5289],\n",
      "        [-1.9147],\n",
      "        [ 0.4659],\n",
      "        [-0.3202],\n",
      "        [-0.9692],\n",
      "        [ 1.0496],\n",
      "        [ 0.7924],\n",
      "        [-0.7363],\n",
      "        [ 0.4904]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4132],\n",
      "        [ 1.5293],\n",
      "        [-1.9149],\n",
      "        [ 0.4661],\n",
      "        [-0.3203],\n",
      "        [-0.9695],\n",
      "        [ 1.0495],\n",
      "        [ 0.7924],\n",
      "        [-0.7366],\n",
      "        [ 0.4904]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4135],\n",
      "        [ 1.5297],\n",
      "        [-1.9150],\n",
      "        [ 0.4663],\n",
      "        [-0.3204],\n",
      "        [-0.9697],\n",
      "        [ 1.0493],\n",
      "        [ 0.7924],\n",
      "        [-0.7369],\n",
      "        [ 0.4904]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4138],\n",
      "        [ 1.5301],\n",
      "        [-1.9152],\n",
      "        [ 0.4665],\n",
      "        [-0.3206],\n",
      "        [-0.9700],\n",
      "        [ 1.0492],\n",
      "        [ 0.7924],\n",
      "        [-0.7372],\n",
      "        [ 0.4904]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4142],\n",
      "        [ 1.5305],\n",
      "        [-1.9153],\n",
      "        [ 0.4667],\n",
      "        [-0.3207],\n",
      "        [-0.9702],\n",
      "        [ 1.0491],\n",
      "        [ 0.7924],\n",
      "        [-0.7375],\n",
      "        [ 0.4904]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4145],\n",
      "        [ 1.5309],\n",
      "        [-1.9154],\n",
      "        [ 0.4670],\n",
      "        [-0.3208],\n",
      "        [-0.9705],\n",
      "        [ 1.0490],\n",
      "        [ 0.7924],\n",
      "        [-0.7377],\n",
      "        [ 0.4904]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4148],\n",
      "        [ 1.5313],\n",
      "        [-1.9156],\n",
      "        [ 0.4672],\n",
      "        [-0.3209],\n",
      "        [-0.9708],\n",
      "        [ 1.0488],\n",
      "        [ 0.7924],\n",
      "        [-0.7380],\n",
      "        [ 0.4903]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4152],\n",
      "        [ 1.5317],\n",
      "        [-1.9157],\n",
      "        [ 0.4674],\n",
      "        [-0.3211],\n",
      "        [-0.9710],\n",
      "        [ 1.0487],\n",
      "        [ 0.7924],\n",
      "        [-0.7383],\n",
      "        [ 0.4903]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4155],\n",
      "        [ 1.5321],\n",
      "        [-1.9158],\n",
      "        [ 0.4676],\n",
      "        [-0.3212],\n",
      "        [-0.9713],\n",
      "        [ 1.0486],\n",
      "        [ 0.7924],\n",
      "        [-0.7386],\n",
      "        [ 0.4903]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4158],\n",
      "        [ 1.5325],\n",
      "        [-1.9160],\n",
      "        [ 0.4678],\n",
      "        [-0.3213],\n",
      "        [-0.9715],\n",
      "        [ 1.0485],\n",
      "        [ 0.7924],\n",
      "        [-0.7389],\n",
      "        [ 0.4903]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4162],\n",
      "        [ 1.5329],\n",
      "        [-1.9161],\n",
      "        [ 0.4680],\n",
      "        [-0.3214],\n",
      "        [-0.9718],\n",
      "        [ 1.0483],\n",
      "        [ 0.7924],\n",
      "        [-0.7392],\n",
      "        [ 0.4903]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4165],\n",
      "        [ 1.5333],\n",
      "        [-1.9163],\n",
      "        [ 0.4682],\n",
      "        [-0.3215],\n",
      "        [-0.9721],\n",
      "        [ 1.0482],\n",
      "        [ 0.7924],\n",
      "        [-0.7395],\n",
      "        [ 0.4903]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4168],\n",
      "        [ 1.5337],\n",
      "        [-1.9164],\n",
      "        [ 0.4685],\n",
      "        [-0.3217],\n",
      "        [-0.9723],\n",
      "        [ 1.0481],\n",
      "        [ 0.7924],\n",
      "        [-0.7397],\n",
      "        [ 0.4903]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4171],\n",
      "        [ 1.5341],\n",
      "        [-1.9165],\n",
      "        [ 0.4687],\n",
      "        [-0.3218],\n",
      "        [-0.9726],\n",
      "        [ 1.0480],\n",
      "        [ 0.7924],\n",
      "        [-0.7400],\n",
      "        [ 0.4903]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4175],\n",
      "        [ 1.5345],\n",
      "        [-1.9167],\n",
      "        [ 0.4689],\n",
      "        [-0.3219],\n",
      "        [-0.9729],\n",
      "        [ 1.0478],\n",
      "        [ 0.7924],\n",
      "        [-0.7403],\n",
      "        [ 0.4903]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4178],\n",
      "        [ 1.5349],\n",
      "        [-1.9168],\n",
      "        [ 0.4691],\n",
      "        [-0.3220],\n",
      "        [-0.9731],\n",
      "        [ 1.0477],\n",
      "        [ 0.7924],\n",
      "        [-0.7406],\n",
      "        [ 0.4903]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4181],\n",
      "        [ 1.5353],\n",
      "        [-1.9169],\n",
      "        [ 0.4693],\n",
      "        [-0.3222],\n",
      "        [-0.9734],\n",
      "        [ 1.0476],\n",
      "        [ 0.7924],\n",
      "        [-0.7409],\n",
      "        [ 0.4903]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4185],\n",
      "        [ 1.5357],\n",
      "        [-1.9171],\n",
      "        [ 0.4695],\n",
      "        [-0.3223],\n",
      "        [-0.9736],\n",
      "        [ 1.0475],\n",
      "        [ 0.7924],\n",
      "        [-0.7412],\n",
      "        [ 0.4903]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4188],\n",
      "        [ 1.5361],\n",
      "        [-1.9172],\n",
      "        [ 0.4697],\n",
      "        [-0.3224],\n",
      "        [-0.9739],\n",
      "        [ 1.0473],\n",
      "        [ 0.7924],\n",
      "        [-0.7415],\n",
      "        [ 0.4903]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4191],\n",
      "        [ 1.5365],\n",
      "        [-1.9173],\n",
      "        [ 0.4700],\n",
      "        [-0.3225],\n",
      "        [-0.9742],\n",
      "        [ 1.0472],\n",
      "        [ 0.7924],\n",
      "        [-0.7417],\n",
      "        [ 0.4903]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4194],\n",
      "        [ 1.5369],\n",
      "        [-1.9175],\n",
      "        [ 0.4702],\n",
      "        [-0.3227],\n",
      "        [-0.9744],\n",
      "        [ 1.0471],\n",
      "        [ 0.7924],\n",
      "        [-0.7420],\n",
      "        [ 0.4903]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4198],\n",
      "        [ 1.5373],\n",
      "        [-1.9176],\n",
      "        [ 0.4704],\n",
      "        [-0.3228],\n",
      "        [-0.9747],\n",
      "        [ 1.0470],\n",
      "        [ 0.7924],\n",
      "        [-0.7423],\n",
      "        [ 0.4903]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4201],\n",
      "        [ 1.5377],\n",
      "        [-1.9177],\n",
      "        [ 0.4706],\n",
      "        [-0.3229],\n",
      "        [-0.9749],\n",
      "        [ 1.0469],\n",
      "        [ 0.7924],\n",
      "        [-0.7426],\n",
      "        [ 0.4903]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4204],\n",
      "        [ 1.5381],\n",
      "        [-1.9179],\n",
      "        [ 0.4708],\n",
      "        [-0.3230],\n",
      "        [-0.9752],\n",
      "        [ 1.0467],\n",
      "        [ 0.7924],\n",
      "        [-0.7429],\n",
      "        [ 0.4903]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4207],\n",
      "        [ 1.5385],\n",
      "        [-1.9180],\n",
      "        [ 0.4710],\n",
      "        [-0.3231],\n",
      "        [-0.9754],\n",
      "        [ 1.0466],\n",
      "        [ 0.7924],\n",
      "        [-0.7432],\n",
      "        [ 0.4903]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4211],\n",
      "        [ 1.5389],\n",
      "        [-1.9182],\n",
      "        [ 0.4712],\n",
      "        [-0.3233],\n",
      "        [-0.9757],\n",
      "        [ 1.0465],\n",
      "        [ 0.7924],\n",
      "        [-0.7435],\n",
      "        [ 0.4902]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4214],\n",
      "        [ 1.5393],\n",
      "        [-1.9183],\n",
      "        [ 0.4714],\n",
      "        [-0.3234],\n",
      "        [-0.9760],\n",
      "        [ 1.0464],\n",
      "        [ 0.7924],\n",
      "        [-0.7437],\n",
      "        [ 0.4902]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4217],\n",
      "        [ 1.5397],\n",
      "        [-1.9184],\n",
      "        [ 0.4717],\n",
      "        [-0.3235],\n",
      "        [-0.9762],\n",
      "        [ 1.0462],\n",
      "        [ 0.7924],\n",
      "        [-0.7440],\n",
      "        [ 0.4902]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4221],\n",
      "        [ 1.5401],\n",
      "        [-1.9186],\n",
      "        [ 0.4719],\n",
      "        [-0.3236],\n",
      "        [-0.9765],\n",
      "        [ 1.0461],\n",
      "        [ 0.7924],\n",
      "        [-0.7443],\n",
      "        [ 0.4902]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4224],\n",
      "        [ 1.5405],\n",
      "        [-1.9187],\n",
      "        [ 0.4721],\n",
      "        [-0.3238],\n",
      "        [-0.9767],\n",
      "        [ 1.0460],\n",
      "        [ 0.7924],\n",
      "        [-0.7446],\n",
      "        [ 0.4902]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4227],\n",
      "        [ 1.5409],\n",
      "        [-1.9188],\n",
      "        [ 0.4723],\n",
      "        [-0.3239],\n",
      "        [-0.9770],\n",
      "        [ 1.0459],\n",
      "        [ 0.7924],\n",
      "        [-0.7449],\n",
      "        [ 0.4902]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4230],\n",
      "        [ 1.5413],\n",
      "        [-1.9190],\n",
      "        [ 0.4725],\n",
      "        [-0.3240],\n",
      "        [-0.9773],\n",
      "        [ 1.0458],\n",
      "        [ 0.7924],\n",
      "        [-0.7452],\n",
      "        [ 0.4902]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4234],\n",
      "        [ 1.5417],\n",
      "        [-1.9191],\n",
      "        [ 0.4727],\n",
      "        [-0.3241],\n",
      "        [-0.9775],\n",
      "        [ 1.0456],\n",
      "        [ 0.7924],\n",
      "        [-0.7454],\n",
      "        [ 0.4902]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4237],\n",
      "        [ 1.5421],\n",
      "        [-1.9192],\n",
      "        [ 0.4729],\n",
      "        [-0.3243],\n",
      "        [-0.9778],\n",
      "        [ 1.0455],\n",
      "        [ 0.7924],\n",
      "        [-0.7457],\n",
      "        [ 0.4902]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4240],\n",
      "        [ 1.5424],\n",
      "        [-1.9194],\n",
      "        [ 0.4731],\n",
      "        [-0.3244],\n",
      "        [-0.9780],\n",
      "        [ 1.0454],\n",
      "        [ 0.7924],\n",
      "        [-0.7460],\n",
      "        [ 0.4902]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4243],\n",
      "        [ 1.5428],\n",
      "        [-1.9195],\n",
      "        [ 0.4734],\n",
      "        [-0.3245],\n",
      "        [-0.9783],\n",
      "        [ 1.0453],\n",
      "        [ 0.7924],\n",
      "        [-0.7463],\n",
      "        [ 0.4902]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4247],\n",
      "        [ 1.5432],\n",
      "        [-1.9196],\n",
      "        [ 0.4736],\n",
      "        [-0.3246],\n",
      "        [-0.9785],\n",
      "        [ 1.0451],\n",
      "        [ 0.7924],\n",
      "        [-0.7466],\n",
      "        [ 0.4902]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4250],\n",
      "        [ 1.5436],\n",
      "        [-1.9198],\n",
      "        [ 0.4738],\n",
      "        [-0.3247],\n",
      "        [-0.9788],\n",
      "        [ 1.0450],\n",
      "        [ 0.7924],\n",
      "        [-0.7469],\n",
      "        [ 0.4902]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4253],\n",
      "        [ 1.5440],\n",
      "        [-1.9199],\n",
      "        [ 0.4740],\n",
      "        [-0.3249],\n",
      "        [-0.9791],\n",
      "        [ 1.0449],\n",
      "        [ 0.7924],\n",
      "        [-0.7471],\n",
      "        [ 0.4902]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4256],\n",
      "        [ 1.5444],\n",
      "        [-1.9200],\n",
      "        [ 0.4742],\n",
      "        [-0.3250],\n",
      "        [-0.9793],\n",
      "        [ 1.0448],\n",
      "        [ 0.7924],\n",
      "        [-0.7474],\n",
      "        [ 0.4902]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4260],\n",
      "        [ 1.5448],\n",
      "        [-1.9202],\n",
      "        [ 0.4744],\n",
      "        [-0.3251],\n",
      "        [-0.9796],\n",
      "        [ 1.0447],\n",
      "        [ 0.7924],\n",
      "        [-0.7477],\n",
      "        [ 0.4902]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4263],\n",
      "        [ 1.5452],\n",
      "        [-1.9203],\n",
      "        [ 0.4746],\n",
      "        [-0.3252],\n",
      "        [-0.9798],\n",
      "        [ 1.0445],\n",
      "        [ 0.7924],\n",
      "        [-0.7480],\n",
      "        [ 0.4902]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4266],\n",
      "        [ 1.5456],\n",
      "        [-1.9205],\n",
      "        [ 0.4748],\n",
      "        [-0.3253],\n",
      "        [-0.9801],\n",
      "        [ 1.0444],\n",
      "        [ 0.7924],\n",
      "        [-0.7483],\n",
      "        [ 0.4902]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4269],\n",
      "        [ 1.5460],\n",
      "        [-1.9206],\n",
      "        [ 0.4750],\n",
      "        [-0.3255],\n",
      "        [-0.9804],\n",
      "        [ 1.0443],\n",
      "        [ 0.7924],\n",
      "        [-0.7486],\n",
      "        [ 0.4902]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4272],\n",
      "        [ 1.5464],\n",
      "        [-1.9207],\n",
      "        [ 0.4753],\n",
      "        [-0.3256],\n",
      "        [-0.9806],\n",
      "        [ 1.0442],\n",
      "        [ 0.7924],\n",
      "        [-0.7488],\n",
      "        [ 0.4902]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4276],\n",
      "        [ 1.5467],\n",
      "        [-1.9209],\n",
      "        [ 0.4755],\n",
      "        [-0.3257],\n",
      "        [-0.9809],\n",
      "        [ 1.0441],\n",
      "        [ 0.7924],\n",
      "        [-0.7491],\n",
      "        [ 0.4901]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4279],\n",
      "        [ 1.5471],\n",
      "        [-1.9210],\n",
      "        [ 0.4757],\n",
      "        [-0.3258],\n",
      "        [-0.9811],\n",
      "        [ 1.0439],\n",
      "        [ 0.7924],\n",
      "        [-0.7494],\n",
      "        [ 0.4901]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4282],\n",
      "        [ 1.5475],\n",
      "        [-1.9211],\n",
      "        [ 0.4759],\n",
      "        [-0.3260],\n",
      "        [-0.9814],\n",
      "        [ 1.0438],\n",
      "        [ 0.7924],\n",
      "        [-0.7497],\n",
      "        [ 0.4901]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4285],\n",
      "        [ 1.5479],\n",
      "        [-1.9213],\n",
      "        [ 0.4761],\n",
      "        [-0.3261],\n",
      "        [-0.9816],\n",
      "        [ 1.0437],\n",
      "        [ 0.7924],\n",
      "        [-0.7500],\n",
      "        [ 0.4901]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4289],\n",
      "        [ 1.5483],\n",
      "        [-1.9214],\n",
      "        [ 0.4763],\n",
      "        [-0.3262],\n",
      "        [-0.9819],\n",
      "        [ 1.0436],\n",
      "        [ 0.7924],\n",
      "        [-0.7503],\n",
      "        [ 0.4901]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4292],\n",
      "        [ 1.5487],\n",
      "        [-1.9215],\n",
      "        [ 0.4765],\n",
      "        [-0.3263],\n",
      "        [-0.9821],\n",
      "        [ 1.0434],\n",
      "        [ 0.7924],\n",
      "        [-0.7505],\n",
      "        [ 0.4901]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4295],\n",
      "        [ 1.5491],\n",
      "        [-1.9217],\n",
      "        [ 0.4767],\n",
      "        [-0.3264],\n",
      "        [-0.9824],\n",
      "        [ 1.0433],\n",
      "        [ 0.7924],\n",
      "        [-0.7508],\n",
      "        [ 0.4901]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4298],\n",
      "        [ 1.5495],\n",
      "        [-1.9218],\n",
      "        [ 0.4769],\n",
      "        [-0.3266],\n",
      "        [-0.9827],\n",
      "        [ 1.0432],\n",
      "        [ 0.7924],\n",
      "        [-0.7511],\n",
      "        [ 0.4901]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4301],\n",
      "        [ 1.5499],\n",
      "        [-1.9219],\n",
      "        [ 0.4771],\n",
      "        [-0.3267],\n",
      "        [-0.9829],\n",
      "        [ 1.0431],\n",
      "        [ 0.7924],\n",
      "        [-0.7514],\n",
      "        [ 0.4901]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4305],\n",
      "        [ 1.5502],\n",
      "        [-1.9221],\n",
      "        [ 0.4774],\n",
      "        [-0.3268],\n",
      "        [-0.9832],\n",
      "        [ 1.0430],\n",
      "        [ 0.7924],\n",
      "        [-0.7517],\n",
      "        [ 0.4901]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4308],\n",
      "        [ 1.5506],\n",
      "        [-1.9222],\n",
      "        [ 0.4776],\n",
      "        [-0.3269],\n",
      "        [-0.9834],\n",
      "        [ 1.0428],\n",
      "        [ 0.7924],\n",
      "        [-0.7519],\n",
      "        [ 0.4901]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4311],\n",
      "        [ 1.5510],\n",
      "        [-1.9223],\n",
      "        [ 0.4778],\n",
      "        [-0.3270],\n",
      "        [-0.9837],\n",
      "        [ 1.0427],\n",
      "        [ 0.7924],\n",
      "        [-0.7522],\n",
      "        [ 0.4901]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4314],\n",
      "        [ 1.5514],\n",
      "        [-1.9225],\n",
      "        [ 0.4780],\n",
      "        [-0.3272],\n",
      "        [-0.9839],\n",
      "        [ 1.0426],\n",
      "        [ 0.7924],\n",
      "        [-0.7525],\n",
      "        [ 0.4901]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4317],\n",
      "        [ 1.5518],\n",
      "        [-1.9226],\n",
      "        [ 0.4782],\n",
      "        [-0.3273],\n",
      "        [-0.9842],\n",
      "        [ 1.0425],\n",
      "        [ 0.7924],\n",
      "        [-0.7528],\n",
      "        [ 0.4901]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4321],\n",
      "        [ 1.5522],\n",
      "        [-1.9227],\n",
      "        [ 0.4784],\n",
      "        [-0.3274],\n",
      "        [-0.9844],\n",
      "        [ 1.0424],\n",
      "        [ 0.7924],\n",
      "        [-0.7531],\n",
      "        [ 0.4901]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4324],\n",
      "        [ 1.5526],\n",
      "        [-1.9229],\n",
      "        [ 0.4786],\n",
      "        [-0.3275],\n",
      "        [-0.9847],\n",
      "        [ 1.0422],\n",
      "        [ 0.7924],\n",
      "        [-0.7534],\n",
      "        [ 0.4901]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4327],\n",
      "        [ 1.5529],\n",
      "        [-1.9230],\n",
      "        [ 0.4788],\n",
      "        [-0.3276],\n",
      "        [-0.9850],\n",
      "        [ 1.0421],\n",
      "        [ 0.7924],\n",
      "        [-0.7536],\n",
      "        [ 0.4901]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4330],\n",
      "        [ 1.5533],\n",
      "        [-1.9231],\n",
      "        [ 0.4790],\n",
      "        [-0.3278],\n",
      "        [-0.9852],\n",
      "        [ 1.0420],\n",
      "        [ 0.7924],\n",
      "        [-0.7539],\n",
      "        [ 0.4901]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4333],\n",
      "        [ 1.5537],\n",
      "        [-1.9233],\n",
      "        [ 0.4792],\n",
      "        [-0.3279],\n",
      "        [-0.9855],\n",
      "        [ 1.0419],\n",
      "        [ 0.7924],\n",
      "        [-0.7542],\n",
      "        [ 0.4901]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4337],\n",
      "        [ 1.5541],\n",
      "        [-1.9234],\n",
      "        [ 0.4794],\n",
      "        [-0.3280],\n",
      "        [-0.9857],\n",
      "        [ 1.0418],\n",
      "        [ 0.7924],\n",
      "        [-0.7545],\n",
      "        [ 0.4901]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4340],\n",
      "        [ 1.5545],\n",
      "        [-1.9235],\n",
      "        [ 0.4796],\n",
      "        [-0.3281],\n",
      "        [-0.9860],\n",
      "        [ 1.0416],\n",
      "        [ 0.7924],\n",
      "        [-0.7548],\n",
      "        [ 0.4900]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4343],\n",
      "        [ 1.5549],\n",
      "        [-1.9237],\n",
      "        [ 0.4799],\n",
      "        [-0.3282],\n",
      "        [-0.9862],\n",
      "        [ 1.0415],\n",
      "        [ 0.7924],\n",
      "        [-0.7550],\n",
      "        [ 0.4900]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4346],\n",
      "        [ 1.5553],\n",
      "        [-1.9238],\n",
      "        [ 0.4801],\n",
      "        [-0.3284],\n",
      "        [-0.9865],\n",
      "        [ 1.0414],\n",
      "        [ 0.7924],\n",
      "        [-0.7553],\n",
      "        [ 0.4900]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4349],\n",
      "        [ 1.5556],\n",
      "        [-1.9239],\n",
      "        [ 0.4803],\n",
      "        [-0.3285],\n",
      "        [-0.9867],\n",
      "        [ 1.0413],\n",
      "        [ 0.7924],\n",
      "        [-0.7556],\n",
      "        [ 0.4900]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4352],\n",
      "        [ 1.5560],\n",
      "        [-1.9241],\n",
      "        [ 0.4805],\n",
      "        [-0.3286],\n",
      "        [-0.9870],\n",
      "        [ 1.0412],\n",
      "        [ 0.7924],\n",
      "        [-0.7559],\n",
      "        [ 0.4900]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4356],\n",
      "        [ 1.5564],\n",
      "        [-1.9242],\n",
      "        [ 0.4807],\n",
      "        [-0.3287],\n",
      "        [-0.9872],\n",
      "        [ 1.0410],\n",
      "        [ 0.7924],\n",
      "        [-0.7562],\n",
      "        [ 0.4900]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4359],\n",
      "        [ 1.5568],\n",
      "        [-1.9243],\n",
      "        [ 0.4809],\n",
      "        [-0.3288],\n",
      "        [-0.9875],\n",
      "        [ 1.0409],\n",
      "        [ 0.7924],\n",
      "        [-0.7564],\n",
      "        [ 0.4900]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4362],\n",
      "        [ 1.5572],\n",
      "        [-1.9244],\n",
      "        [ 0.4811],\n",
      "        [-0.3290],\n",
      "        [-0.9878],\n",
      "        [ 1.0408],\n",
      "        [ 0.7924],\n",
      "        [-0.7567],\n",
      "        [ 0.4900]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4365],\n",
      "        [ 1.5576],\n",
      "        [-1.9246],\n",
      "        [ 0.4813],\n",
      "        [-0.3291],\n",
      "        [-0.9880],\n",
      "        [ 1.0407],\n",
      "        [ 0.7924],\n",
      "        [-0.7570],\n",
      "        [ 0.4900]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4368],\n",
      "        [ 1.5579],\n",
      "        [-1.9247],\n",
      "        [ 0.4815],\n",
      "        [-0.3292],\n",
      "        [-0.9883],\n",
      "        [ 1.0406],\n",
      "        [ 0.7924],\n",
      "        [-0.7573],\n",
      "        [ 0.4900]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4372],\n",
      "        [ 1.5583],\n",
      "        [-1.9248],\n",
      "        [ 0.4817],\n",
      "        [-0.3293],\n",
      "        [-0.9885],\n",
      "        [ 1.0405],\n",
      "        [ 0.7924],\n",
      "        [-0.7576],\n",
      "        [ 0.4900]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4375],\n",
      "        [ 1.5587],\n",
      "        [-1.9250],\n",
      "        [ 0.4819],\n",
      "        [-0.3294],\n",
      "        [-0.9888],\n",
      "        [ 1.0403],\n",
      "        [ 0.7924],\n",
      "        [-0.7579],\n",
      "        [ 0.4900]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4378],\n",
      "        [ 1.5591],\n",
      "        [-1.9251],\n",
      "        [ 0.4821],\n",
      "        [-0.3295],\n",
      "        [-0.9890],\n",
      "        [ 1.0402],\n",
      "        [ 0.7924],\n",
      "        [-0.7581],\n",
      "        [ 0.4900]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4381],\n",
      "        [ 1.5595],\n",
      "        [-1.9252],\n",
      "        [ 0.4823],\n",
      "        [-0.3297],\n",
      "        [-0.9893],\n",
      "        [ 1.0401],\n",
      "        [ 0.7924],\n",
      "        [-0.7584],\n",
      "        [ 0.4900]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4384],\n",
      "        [ 1.5598],\n",
      "        [-1.9254],\n",
      "        [ 0.4825],\n",
      "        [-0.3298],\n",
      "        [-0.9895],\n",
      "        [ 1.0400],\n",
      "        [ 0.7924],\n",
      "        [-0.7587],\n",
      "        [ 0.4900]], dtype=torch.float64, grad_fn=<SubBackward0>), tensor([[ 2.4387],\n",
      "        [ 1.5602],\n",
      "        [-1.9255],\n",
      "        [ 0.4827],\n",
      "        [-0.3299],\n",
      "        [-0.9898],\n",
      "        [ 1.0399],\n",
      "        [ 0.7924],\n",
      "        [-0.7590],\n",
      "        [ 0.4900]], dtype=torch.float64, grad_fn=<SubBackward0>)]\n",
      "[tensor(0.4063, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.4032, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.4001, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3971, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3942, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3913, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3885, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3857, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3830, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3804, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3778, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3753, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3729, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3705, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3682, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3660, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3638, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3617, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3596, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3576, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3557, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3538, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3520, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3502, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3485, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3468, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3452, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3436, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3421, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3406, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3391, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3377, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3364, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3350, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3337, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3325, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3313, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3301, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3289, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3278, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3267, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3256, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3245, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3235, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3225, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3215, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3205, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3196, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3186, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3177, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3168, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3159, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3151, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3142, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3134, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3126, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3117, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3109, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3101, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3094, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3086, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3078, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3071, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3063, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3056, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3049, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3041, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3034, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3027, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3020, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3013, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.3006, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2999, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2993, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2986, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2979, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2972, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2966, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2959, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2952, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2946, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2939, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2933, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2927, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2920, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2914, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2907, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2901, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2895, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2888, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2882, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2876, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2870, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2864, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2857, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2851, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2845, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2839, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2833, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2827, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2821, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2815, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2809, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2803, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2797, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2791, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2785, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2779, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2773, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2767, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2761, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2755, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2749, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2744, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2738, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2732, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2726, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2720, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2715, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2709, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2703, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2697, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2692, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2686, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2680, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2675, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2669, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2664, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2658, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2652, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2647, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2641, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2636, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2630, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2625, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2619, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2614, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2608, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2603, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2598, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2592, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2587, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2581, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2576, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2571, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2566, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2560, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2555, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2550, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2545, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2539, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2534, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2529, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2524, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2519, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2514, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2509, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2503, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2498, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2493, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2488, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2483, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2478, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2473, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2469, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2464, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2459, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2454, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2449, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2444, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2439, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2435, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2430, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2425, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2420, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2416, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2411, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2406, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2402, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2397, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2392, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2388, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2383, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2379, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2374, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2370, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2365, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2361, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2356, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2352, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2347, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2343, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2338, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2334, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2330, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2325, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2321, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2317, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2313, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2308, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2304, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2300, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2296, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2292, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2287, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2283, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2279, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2275, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2271, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2267, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2263, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2259, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2255, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2251, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2247, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2243, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2239, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2235, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2231, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2228, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2224, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2220, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2216, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2212, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2208, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2205, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2201, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2197, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2194, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2190, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2186, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2182, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2179, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2175, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2172, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2168, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2164, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2161, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2157, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2154, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2150, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2147, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2143, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2140, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2136, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2133, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2129, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2126, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2123, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2119, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2116, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2113, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2109, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2106, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2103, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2099, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2096, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2093, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2090, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2086, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2083, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2080, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2077, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2074, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2070, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2067, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2064, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2061, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2058, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2055, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2052, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2049, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2046, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2043, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2040, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2037, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2034, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2031, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2028, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2025, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2022, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2019, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2016, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2013, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2010, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2007, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2004, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.2001, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1998, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1996, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1993, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1990, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1987, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1984, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1981, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1979, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1976, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1973, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1970, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1968, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1965, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1962, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1959, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1957, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1954, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1951, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1949, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1946, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1943, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1941, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1938, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1936, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1933, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1930, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1928, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1925, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1923, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1920, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1917, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1915, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1912, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1910, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1907, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1905, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1902, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1900, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1897, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1895, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1892, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1890, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1888, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1885, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1883, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1880, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1878, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1875, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1873, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1871, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1868, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1866, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1864, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1861, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1859, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1856, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1854, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1852, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1850, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1847, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1845, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1843, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1840, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1838, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1836, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1833, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1831, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1829, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1827, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1824, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1822, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1820, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1818, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1816, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1813, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1811, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1809, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1807, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1805, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1802, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1800, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1798, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1796, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1794, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1792, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1790, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1787, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1785, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1783, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1781, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1779, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1777, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1775, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1773, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1771, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1769, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1767, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1764, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1762, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1760, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1758, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1756, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1754, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1752, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1750, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1748, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1746, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1744, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1742, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1740, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1738, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1736, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1734, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1732, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1730, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1728, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1726, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1724, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1723, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1721, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1719, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1717, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1715, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1713, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1711, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1709, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1707, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1705, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1703, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1701, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1700, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1698, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1696, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1694, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1692, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1690, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1688, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1687, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1685, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1683, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1681, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1679, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1677, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1676, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1674, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1672, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1670, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1668, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1666, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1665, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1663, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1661, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1659, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1657, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1656, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1654, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1652, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1650, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1649, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1647, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1645, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1643, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1642, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1640, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1638, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1636, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1635, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1633, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1631, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1630, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1628, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1626, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1624, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1623, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1621, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1619, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1618, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1616, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1614, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1613, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1611, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1609, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1608, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1606, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1604, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1603, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1601, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1599, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1598, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1596, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1594, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1593, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1591, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1589, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1588, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1586, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1585, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1583, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1581, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1580, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1578, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1576, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1575, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1573, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1572, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1570, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1568, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1567, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1565, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1564, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1562, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1561, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1559, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1557, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1556, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1554, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1553, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1551, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1550, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1548, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1547, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1545, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1543, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1542, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1540, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1539, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1537, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1536, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1534, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1533, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1531, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1530, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1528, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1527, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1525, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1524, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1522, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1521, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1519, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1518, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1516, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1515, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1513, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1512, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1510, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1509, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1507, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1506, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1504, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1503, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1502, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1500, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1499, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1497, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1496, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1494, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1493, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1491, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1490, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1489, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1487, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1486, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1484, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1483, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1481, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1480, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1479, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1477, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1476, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1474, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1473, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1471, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1470, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1469, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1467, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1466, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1464, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1463, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1462, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1460, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1459, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1458, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1456, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1455, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1453, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1452, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1451, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1449, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1448, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1447, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1445, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1444, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1442, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1441, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1440, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1438, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1437, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1436, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1434, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1433, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1432, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1430, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1429, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1428, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1426, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1425, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1424, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1422, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1421, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1420, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1418, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1417, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1416, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1414, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1413, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1412, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1411, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1409, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1408, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1407, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1405, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1404, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1403, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1401, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1400, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1399, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1398, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1396, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1395, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1394, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1393, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1391, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1390, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1389, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1387, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1386, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1385, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1384, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1382, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1381, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1380, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1379, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1377, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1376, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1375, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1374, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1372, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1371, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1370, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1369, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1367, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1366, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1365, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1364, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1362, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1361, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1360, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1359, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1358, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1356, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1355, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1354, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1353, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1352, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1350, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1349, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1348, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1347, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1346, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1344, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1343, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1342, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1341, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1340, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1338, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1337, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1336, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1335, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1334, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1332, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1331, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1330, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1329, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1328, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1327, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1325, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1324, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1323, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1322, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1321, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1320, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1318, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1317, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1316, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1315, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1314, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1313, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1311, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1310, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1309, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1308, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1307, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1306, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1305, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1303, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1302, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1301, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1300, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1299, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1298, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1297, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1295, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1294, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1293, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1292, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1291, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1290, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1289, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1288, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1287, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1285, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1284, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1283, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1282, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1281, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1280, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1279, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1278, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1277, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1275, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1274, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1273, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1272, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1271, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1270, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1269, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1268, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1267, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1266, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1265, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1264, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1262, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1261, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1260, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1259, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1258, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1257, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1256, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1255, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1254, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1253, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1252, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1251, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1250, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1249, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1248, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1246, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1245, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1244, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1243, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1242, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1241, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1240, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1239, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1238, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1237, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1236, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1235, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1234, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1233, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1232, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1231, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1230, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1229, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1228, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1227, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1226, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1225, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1224, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1223, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1222, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1221, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1220, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1219, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1218, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1216, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1215, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1214, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1213, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1212, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1211, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1210, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1209, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1208, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1207, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1206, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1205, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1204, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1203, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1202, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1201, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1200, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1200, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1199, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1198, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1197, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1196, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1195, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1194, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1193, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1192, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1191, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1190, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1189, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1188, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1187, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1186, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1185, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1184, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1183, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1182, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1181, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1180, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1179, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1178, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1177, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1176, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1175, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1174, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1173, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1172, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1171, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1171, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1170, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1169, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1168, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1167, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1166, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1165, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1164, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1163, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1162, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1161, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1160, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1159, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1158, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1157, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1156, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1156, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1155, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1154, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1153, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1152, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1151, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1150, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1149, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1148, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1147, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1146, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1145, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1145, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1144, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1143, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1142, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1141, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1140, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1139, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1138, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1137, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1136, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1135, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1135, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1134, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1133, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1132, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1131, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1130, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1129, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1128, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1127, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1127, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1126, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1125, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1124, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1123, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1122, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1121, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1120, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1120, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1119, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1118, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1117, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1116, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1115, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1114, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1113, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1113, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1112, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1111, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1110, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1109, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1108, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1107, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1107, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1106, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1105, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1104, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1103, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1102, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1101, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1101, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1100, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1099, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1098, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1097, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1096, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1095, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1095, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1094, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1093, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1092, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1091, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1090, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1090, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1089, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1088, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1087, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1086, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1085, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1085, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1084, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1083, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1082, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1081, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1081, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1080, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1079, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1078, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1077, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1076, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1076, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1075, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1074, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1073, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1072, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1072, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1071, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1070, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1069, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1068, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1068, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1067, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1066, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1065, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1064, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1063, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1063, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1062, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1061, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1060, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1060, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1059, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1058, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1057, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1056, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1056, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1055, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1054, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1053, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1052, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1052, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1051, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1050, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1049, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1049, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1048, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1047, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1046, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1045, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1045, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1044, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1043, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1042, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1042, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1041, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1040, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1039, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1038, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1038, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1037, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1036, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1035, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1035, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1034, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1033, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1032, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1032, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1031, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1030, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1029, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1029, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1028, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1027, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1026, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1026, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1025, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1024, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1023, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1023, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1022, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1021, dtype=torch.float64, grad_fn=<NegBackward0>), tensor(0.1020, dtype=torch.float64, grad_fn=<NegBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement\n",
    "w1 = torch.randn((n_features, n_hidden_neuron), dtype=torch.double, requires_grad=True)\n",
    "w2 = torch.randn((n_hidden_neuron, 1), dtype=torch.double, requires_grad=True)\n",
    "\n",
    "w1_hist, w2_hist, l_hist = gdi_two_w(nn_shallow, bce, tensor_X, tensor_Y, w1, w2, 0.01, 1000)\n",
    "print(w1_hist)\n",
    "print(w2_hist)\n",
    "print(l_hist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ad319e2",
   "metadata": {},
   "source": [
    "7. Train 120 epochs of ``gdi_two_w`` for different learning rates (at least 3). Does the error always go down with more epochs? Which learning rates work well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4bcec703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate:  0.01\n",
      "is_always_smaller:  True \n",
      "\n",
      "Learning Rate:  0.5\n",
      "is_always_smaller:  True \n",
      "\n",
      "Learning Rate:  1\n",
      "is_always_smaller:  False \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement & Answer\n",
    "learning_rates = [0.01, 0.5, 1]\n",
    "\n",
    "for rate in learning_rates:\n",
    "    temp = gdi_two_w(nn_shallow, bce, tensor_X, tensor_Y, w1, w2, rate, 120)[-1]\n",
    "    is_always_smaller = True\n",
    "    print(\"Learning Rate: \", rate)\n",
    "    for index, elem in enumerate(temp):\n",
    "        #print(elem.item())\n",
    "        if(index != 0 and temp[index-1]<elem.item()):\n",
    "            is_always_smaller = False\n",
    "            break\n",
    "    print(\"is_always_smaller: \", is_always_smaller, \"\\n\")\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f0650640",
   "metadata": {},
   "source": [
    "## 3: Classifying the Fashion MNIST Dataset\n",
    "So far, we build everything by ourselves. PyTorch however also offers a wide variety of functions to define neural networks easier.\n",
    "In this example, we create a PyTorch Module to define a simple neural network that will classify the fashion mnist data.\n",
    "\n",
    "### 3.1: Load the Data into a tensor\n",
    "Just as in the PCA exercise, we first load the data from disk into a dataframe and quickly visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1eed4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Pixel000</th>\n",
       "      <th>Pixel001</th>\n",
       "      <th>Pixel002</th>\n",
       "      <th>Pixel003</th>\n",
       "      <th>Pixel004</th>\n",
       "      <th>Pixel005</th>\n",
       "      <th>Pixel006</th>\n",
       "      <th>Pixel007</th>\n",
       "      <th>Pixel008</th>\n",
       "      <th>...</th>\n",
       "      <th>Pixel774</th>\n",
       "      <th>Pixel775</th>\n",
       "      <th>Pixel776</th>\n",
       "      <th>Pixel777</th>\n",
       "      <th>Pixel778</th>\n",
       "      <th>Pixel779</th>\n",
       "      <th>Pixel780</th>\n",
       "      <th>Pixel781</th>\n",
       "      <th>Pixel782</th>\n",
       "      <th>Pixel783</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Category  Pixel000  Pixel001  Pixel002  Pixel003  Pixel004  Pixel005  \\\n",
       "Id                                                                         \n",
       "0          2         0         0         0         0         0         0   \n",
       "1          9         0         0         0         0         0         0   \n",
       "\n",
       "    Pixel006  Pixel007  Pixel008  ...  Pixel774  Pixel775  Pixel776  Pixel777  \\\n",
       "Id                                ...                                           \n",
       "0          0         0         0  ...         0         0         0         0   \n",
       "1          0         0         0  ...         0         0         0         0   \n",
       "\n",
       "    Pixel778  Pixel779  Pixel780  Pixel781  Pixel782  Pixel783  \n",
       "Id                                                              \n",
       "0          0         0         0         0         0         0  \n",
       "1          0         0         0         0         0         0  \n",
       "\n",
       "[2 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2400x400 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Dataset\n",
    "fm = pd.read_csv(\"data/fashion_mnist_train.csv.zip\", index_col=\"Id\")\n",
    "fm_labels = [\"T-Shirt\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Boot\"]\n",
    "display(fm.head(2))\n",
    "\n",
    "# Visualize Examples\n",
    "num_samples = 20\n",
    "ax = plt.subplots(nrows=1, ncols=num_samples, figsize=(24, 4))[1]\n",
    "for i in range(num_samples):\n",
    "    ax[i].set_axis_off()\n",
    "    ax[i].set_title(f\"{i}\\n{fm_labels[fm.Category[i]]}\")\n",
    "    ax[i].imshow(fm.loc[i].values[1:].reshape((28,28)), cmap=\"gray_r\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e34549d",
   "metadata": {},
   "source": [
    "Now, we transform it into PyTorch tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78f55490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 1, 28, 28]) torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "fm_X = torch.tensor(fm.drop(\"Category\", axis=1).values, dtype=torch.float32).reshape(-1, 1, 28, 28)\n",
    "fm_y = torch.tensor(fm.Category.values.astype('int') , dtype=torch.long)\n",
    "\n",
    "print(fm_X.shape, fm_y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c1fa529",
   "metadata": {},
   "source": [
    "### 3.2: Defining and Training a simple Classifier\n",
    "Defining a neural network in PyTorch using the Module API will look like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e60afd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(torch.nn.Module):\n",
    "    def __init__(self, num_outputs):\n",
    "        super().__init__()\n",
    "        # self.linear1 = nn.Linear(num_inputs, num_hidden_neurons)\n",
    "        # self.linear2 = torch.nn.Linear(num_hidden_neurons, num_outputs)\n",
    "        self.conv1 = torch.nn.Conv2d(1, 4, 3, 1)\n",
    "        self.conv2 = torch.nn.Conv2d(4, 8, 3, 1)\n",
    "        self.dropout1 = torch.nn.Dropout(0.25)\n",
    "        self.dropout2 = torch.nn.Dropout(0.5)\n",
    "        self.fc1 = torch.nn.Linear(1152, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, num_outputs)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = torch.nn.functional.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = torch.nn.functional.log_softmax(x, dim=1)\n",
    "        return output\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a7b6b29",
   "metadata": {},
   "source": [
    "Our training loop will look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55c40334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, X, y, loss_module, num_epochs=5):\n",
    "    model.train()\n",
    "    loss_history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        preds = model(X)\n",
    "        preds = preds.squeeze(dim=1)\n",
    "        loss = loss_module(preds, y)\n",
    "        loss_history.append(loss.detach().numpy().item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"loss after epoch {epoch}: {loss}\")\n",
    "    return loss_history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c9daba8c",
   "metadata": {},
   "source": [
    "For running our training loop, we simply need to populate all the method parameters. For optimizer and loss, we can simply choose from what's built-in. Training the neural network will take about 3 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "115b107b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleClassifier(\n",
      "  (conv1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=1152, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "loss after epoch 0: 10.412001609802246\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m model = SimpleClassifier(num_outputs=\u001b[32m10\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m loss_history = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# instead of GD\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfm_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfm_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_module\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# instead of BinaryCrossEntropy\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, optimizer, X, y, loss_module, num_epochs)\u001b[39m\n\u001b[32m      8\u001b[39m loss_history.append(loss.detach().numpy().item())\n\u001b[32m      9\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m optimizer.step()\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mloss after epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model = SimpleClassifier(num_outputs=10)\n",
    "print(model)\n",
    "\n",
    "loss_history = train_model(\n",
    "    model,\n",
    "    optimizer=torch.optim.SGD(model.parameters(), lr=0.1), # instead of GD\n",
    "    X=fm_X,\n",
    "    y=fm_y,\n",
    "    loss_module=torch.nn.CrossEntropyLoss(), # instead of BinaryCrossEntropy\n",
    "    num_epochs=10\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04c441f5",
   "metadata": {},
   "source": [
    "Everything the model learned is now contained in the ``model`` object, including weights.\n",
    "The history of losses was saved in our training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c19d212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'] tensor([-1.8579, -0.7588, -0.5228])\n",
      "[10.412001609802246, 7.3854899406433105, 2.3057525157928467, 2.3056130409240723, 2.3055520057678223, 2.3054959774017334, 2.3052563667297363, 2.305213451385498, 2.305086135864258, 2.3050899505615234]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_loss(errors):\n",
    "        \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(errors)\n",
    "    plt.title(\"Loss pro Epoche\")\n",
    "    plt.xlabel(\"Epoche\")\n",
    "    plt.ylabel(\"der bce Loss\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "print(list(model.state_dict().keys()), model.state_dict()[\"conv1.weight\"][0][0][0])\n",
    "print(loss_history)\n",
    "\n",
    "visualize_loss(loss_history)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ef389f5",
   "metadata": {},
   "source": [
    "### 4:  PyTorch model for Iris (Optional)\n",
    "1. Create a PyTorch classifier class, model and training function for classifying either Iris or Biris. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea6afd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleClassifier(\n",
      "  (conv1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=1152, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [150, 4]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m model2 = SimpleClassifier(num_outputs=\u001b[32m10\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m loss_history2 = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# instead of GD\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_X\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_Y\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_module\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# instead of BinaryCrossEntropy\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlist\u001b[39m(model2.state_dict().keys()), model2.state_dict()[\u001b[33m\"\u001b[39m\u001b[33mconv1.weight\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m])\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(loss_history2)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, optimizer, X, y, loss_module, num_epochs)\u001b[39m\n\u001b[32m      3\u001b[39m loss_history = []\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     preds = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     preds = preds.squeeze(dim=\u001b[32m1\u001b[39m)\n\u001b[32m      7\u001b[39m     loss = loss_module(preds, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mSimpleClassifier.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     x = torch.nn.functional.relu(x)\n\u001b[32m     17\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.conv2(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [150, 4]"
     ]
    }
   ],
   "source": [
    "# TODO: Implement (optional)\n",
    "\n",
    "model2 = SimpleClassifier(num_outputs=10)\n",
    "print(model)\n",
    "\n",
    "loss_history2 = train_model(\n",
    "    model2,\n",
    "    optimizer=torch.optim.SGD(model2.parameters(), lr=0.1), # instead of GD\n",
    "    X=tensor_X.float(),\n",
    "    y=tensor_Y.long(),\n",
    "    loss_module=torch.nn.CrossEntropyLoss(), # instead of BinaryCrossEntropy\n",
    "    num_epochs=10\n",
    ")\n",
    "\n",
    "print(list(model2.state_dict().keys()), model2.state_dict()[\"conv1.weight\"][0][0][0])\n",
    "print(loss_history2)\n",
    "\n",
    "visualize_loss(loss_history2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f97fd0d",
   "metadata": {},
   "source": [
    "2. Compare your accuracy to the previous approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80008898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement (optional)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
